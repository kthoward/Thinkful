{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import neighbors\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP for scientific articles\n",
    "This project is aimes at clustering scientific articles.\n",
    "\n",
    "## Why are we interested?\n",
    "There is so much scientific information online and countless resources to gain insights into scientific problems that I wanted to create a way to organize information based topic. This will help take disjointed information on the same topic and build resource databases\n",
    "\n",
    "## Why this dataset?\n",
    "Science is one of the fields where I believe data science can dramatically increase productivity and discovery by consolidating information and making it easier to access. I also wanted to create a model that succeeds in clustering articles within the same field.\n",
    "\n",
    "## What are we trying to achieve?\n",
    "\n",
    "The goal is to create a filter for articles and/or scientific documentation that can be used to unify scientific information. Once this model is successful it would make sense to create sub categories within the parent categories and continue to do so until we can easily access specific topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-75c8811a0193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0marticle_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "article_list = []\n",
    "true_labels = []\n",
    "categories = ['business', 'entertainment', 'politics', 'sport',  'tech']\n",
    "for i, category in enumerate(categories):\n",
    "    for root, dirs, files in os.walk(os.path.join(\"./bbc\",category)):\n",
    "        for file in sorted(files):\n",
    "            true_labels.append(i)\n",
    "            try:\n",
    "                with open(os.path.join(root,file),\"r\",encoding='utf-8') as f:\n",
    "                    article_list.append(f.read())\n",
    "            except:\n",
    "                with open(os.path.join(root,file),\"r\",encoding='iso-8859-1') as f:\n",
    "                    article_list.append(f.read())\n",
    "print(article_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizing \n",
    "nlp = spacy.load('en')\n",
    "stream = nlp.pipe(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 0 sentences\n"
     ]
    }
   ],
   "source": [
    "# Converting tokens to sentences and lemmas. Assuring punctuation is scrubbed\n",
    "sentences = []\n",
    "docs = []\n",
    "for doc in stream:\n",
    "    docs.append(doc)\n",
    "    for sentence in doc.sents:\n",
    "        sentence = [\n",
    "            token.lemma_\n",
    "            for token in sentence\n",
    "            if not token.is_stop\n",
    "            and not token.is_punct\n",
    "        ]\n",
    "        sentences.append(sentence)\n",
    "\n",
    "\n",
    "#print(sentences)\n",
    "print('We have {} sentences'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dfb2e9569e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m \u001b[0;34m,\u001b[0m  \u001b[0;31m# Penalize frequent words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Word vector length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m           \u001b[0;31m# Use hierarchical softmax.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             self.train(sentences, total_examples=self.corpus_count, epochs=self.iter,\n\u001b[0;32m--> 505\u001b[0;31m                        start_alpha=self.alpha, end_alpha=self.min_alpha)\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first finalize vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "#------------------------------------------CBOW word2vec-----------------------------------------------\n",
    "# Attempting to group words together based on proximity. Using CBOW due to smaller corpus\n",
    "cbow_model = word2vec.Word2Vec(\n",
    "    sentences,     \n",
    "    min_count=5,   # Minimum word count threshold.\n",
    "    window=5,     # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=100,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec analysis \n",
    "vocab = cbow_model.wv.vocab.keys()\n",
    "\n",
    "print(cbow_model.wv.most_similar(positive=['woman', 'man'], negative=['boy']))\n",
    "# Testing to see which words it will group with 'planet'\n",
    "#print('Similarity to planet')\n",
    "print('1:')\n",
    "print(cbow_model.wv.most_similar('politician'))\n",
    "print('2:')\n",
    "print(cbow_model.wv.most_similar('scientist'))\n",
    "print('3:')\n",
    "print(cbow_model.wv.most_similar('artist'))\n",
    "print('4:')\n",
    "print(cbow_model.wv.most_similar('musician'))\n",
    "\n",
    "# Testing for similarity \n",
    "#print('Cosine similatrity analysis:')\n",
    "#print('study / research')\n",
    "print('5:')\n",
    "print(cbow_model.wv.similarity('study', 'research'))\n",
    "#print('court / field')\n",
    "print('6:')\n",
    "print(cbow_model.wv.similarity('computer', 'tool'))\n",
    "print('7:')\n",
    "print(cbow_model.wv.similarity('musician', 'artist'))\n",
    "print('8:')\n",
    "print(cbow_model.wv.similarity('phone', 'device'))\n",
    "\n",
    "# Testing to see if it will leave out the right word (looking for 'dinosaur')\n",
    "#print('Which doesnt fit?')\n",
    "#print('bat / bird / dinosaur / bee')\n",
    "print(cbow_model.doesnt_match(\"man woman plane dog\".split()))\n",
    "print(cbow_model.doesnt_match(\"rock human computer dog\".split()))\n",
    "print(cbow_model.doesnt_match(\"rock human rocket dog\".split()))\n",
    "print(cbow_model.doesnt_match(\"car human rocket dog\".split()))\n",
    "print(cbow_model.doesnt_match(\"car human rocket boat\".split()))\n",
    "\n",
    "#function that adds up vectors, normalize vector?'''\n",
    "# compare\n",
    "# study / molecule\n",
    "# atom / research\n",
    "# unrelated\n",
    "# more doesn't match\n",
    "# dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = cbow_model.wv['human']\n",
    "print(len(x))\n",
    "vector_list = []\n",
    "for doc in docs:\n",
    "    article_vector = np.zeros_like(x)\n",
    "    for w in doc:\n",
    "        word = w.lemma_\n",
    "        if word in cbow_model.wv:\n",
    "            vector = cbow_model.wv[word]\n",
    "            article_vector += vector\n",
    "    norm = normalize(article_vector.reshape(1, -1))\n",
    "    norm = norm.flatten()\n",
    "    vector_list.append(norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3759f37d7ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_w2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vector_list' is not defined"
     ]
    }
   ],
   "source": [
    "clusters = [2, 3, 5, 8, 10, 15, 20]\n",
    "for num cluster in clusters:\n",
    "    X_w2v = vector_list\n",
    "    y_pred_w2v = KMeans(n_clusters=clusters).fit_predict(X_w2v)\n",
    "    model = KMeans(n_clusters=clusters).fit(X_w2v)\n",
    "    df = pd.DataFrame()\n",
    "    df['pred'] = y_pred_w2v\n",
    "    df['labels'] = true_labels\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Silhouette Score')\n",
    "print(metrics.silhouette_score(X_w2v, df['pred'], metric='euclidean'))\n",
    "#array = X.toarray()\n",
    "print('Calinski Harabaz Index')\n",
    "print(metrics.calinski_harabaz_score(X_w2v, df['pred']))\n",
    "print('Opposite of the value of X on the K-means objective.')\n",
    "print(model.score(X_w2v))\n",
    "print('Adjusted Rand Index')\n",
    "print(metrics.adjusted_rand_score(df['labels'], df['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-325fcfa22147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#y_w2v = df['pred']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "#y_w2v = df['pred']\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, true_labels , test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fa49d07fedbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknn_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_w2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_w2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Percentage accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_w2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "knn_w2v = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "knn_w2v.fit(X_train_w2v, y_train_w2v)\n",
    "y_pred = knn_w2v.predict(X_test_w2v)\n",
    "print('Percentage accuracy')\n",
    "print(knn_w2v.score(X_test_w2v, y_test_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(np.array(X_w2v))\n",
    "X_2 = pca.transform(X_w2v)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X_2[:,0],X_2[:,1],c=df['pred'])\n",
    "plt.title(\"Colors indicate clusters\")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X_2[:,0],X_2[:,1],c=true_labels)\n",
    "plt.title(\"Colors indicate True Labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X_w2v).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------tfidf-------------------------------------------------\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.25,          # drop words that occur in more than a quarter of the articles\n",
    "                             min_df=2,             # only use words that appear at least twice\n",
    "                             stop_words='english', # picking list of stop words\n",
    "                             lowercase=True,       # convert everything to lower case \n",
    "                             use_idf=True,         # use inverse document frequencies in our weighting\n",
    "                             norm=u'l2',           # Treat longer and shorter paragraphs equally\n",
    "                             smooth_idf=True       # Prevent divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "# Applying the vectorizer\n",
    "article_list_tfidf = vectorizer.fit_transform(article_list)\n",
    "print(\"Number of features: %d\" % article_list_tfidf.get_shape()[1])\n",
    "\n",
    "#X_train_tfidf, X_test_tfidf= train_test_split(article_list_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "# Reshape the vectorizer output to be legible \n",
    "article_list_tfidf_csr = article_list_tfidf.tocsr()\n",
    "\n",
    "# number of articles\n",
    "n = article_list_tfidf_csr.shape[0]\n",
    "\n",
    "# Making a list of dictionaries, one per article\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "# List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# for each article, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*article_list_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = article_list_tfidf_csr[i, j]\n",
    "\n",
    "\n",
    "print('Original article:', article_list[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_list_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cea461feb2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_list_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'article_list_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "dict(article_list_tfidf.tocsr()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_list_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-15af74e33895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run SVD on the training data and projecting the training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0marticle__list_lsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_list_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Checking variance explained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'article_list_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying SVD to reduce term document matrix into lower dimensional space (from 3417 to 260)\n",
    "svd= TruncatedSVD(260)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data and projecting the training data.\n",
    "article__list_lsa = lsa.fit_transform(article_list_tfidf)\n",
    "\n",
    "# Checking variance explained\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100) # Upon review seems like overfitting\n",
    "\n",
    "# Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "# It seems like some similarities exist but needs refining\n",
    "paras_by_component=pd.DataFrame(article__list_lsa,index=article_list)\n",
    "\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_list_tfidf_csr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7314c0fa0801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Viewing the vectorizer output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_list_tfidf_csr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'article_list_tfidf_csr' is not defined"
     ]
    }
   ],
   "source": [
    "# Viewing the vectorizer output\n",
    "print(article_list_tfidf_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_list_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b638c4a8e62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_list_tfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_norm_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_norm_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model_tfidf_labels = model_tfidf.labels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprediction_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_norm_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'article_list_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "X_tfidf = article_list_tfidf\n",
    "X_norm_tfidf = normalize(X_tfidf)\n",
    "model_tfidf = KMeans(n_clusters=5).fit(X_norm_tfidf)\n",
    "#model_tfidf_labels = model_tfidf.labels_\n",
    "prediction_tfidf = model_tfidf.predict(X_norm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_norm_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-654ef1282551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_norm_tfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_norm_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "X_norm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-68d015a4cc85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_tfidf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_tfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#labels_tfidf.flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels_tfidf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['pred_tfidf'] = prediction_tfidf\n",
    "#labels_tfidf.flatten()\n",
    "df['labels_tfidf'] = true_labels\n",
    "df.head(50)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(article_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score\n",
      "0.0114262569181\n",
      "Calinski Harabaz Index\n",
      "14.6964294444\n",
      "Opposite of the value of X on the K-means objective.\n",
      "-2126.4025846422614\n",
      "Adjusted Rand Index\n",
      "0.644223589628\n"
     ]
    }
   ],
   "source": [
    "print('Silhouette Score')\n",
    "print(metrics.silhouette_score(X_norm_tfidf, labels, metric='euclidean'))\n",
    "array = X_norm_tfidf.toarray()\n",
    "print('Calinski Harabaz Index')\n",
    "print(metrics.calinski_harabaz_score(array, labels))\n",
    "print('Opposite of the value of X on the K-means objective.')\n",
    "print(model_tfidf.score(X_norm_tfidf))\n",
    "print('Adjusted Rand Index')\n",
    "print(metrics.adjusted_rand_score(labels, prediction_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_tfidf = df['pred_tfidf']\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_norm_tfidf, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage accuracy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "kd_tree does not work with sparse matrices. Densify the data, or set algorithm='brute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9b121a964601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Percentage accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtual_envs/python3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtual_envs/python3/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtual_envs/python3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 raise ValueError(\n\u001b[1;32m    380\u001b[0m                     \u001b[0;34m\"%s does not work with sparse matrices. Densify the data, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \"or set algorithm='brute'\" % self._fit_method)\n\u001b[0m\u001b[1;32m    382\u001b[0m             result = Parallel(n_jobs, backend='threading')(\n\u001b[1;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n",
      "\u001b[0;31mValueError\u001b[0m: kd_tree does not work with sparse matrices. Densify the data, or set algorithm='brute'"
     ]
    }
   ],
   "source": [
    "knn_tfidf = neighbors.KNeighborsClassifier()\n",
    "knn_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred = knn_tfidf.predict(X_test_tfidf)\n",
    "print('Percentage accuracy')\n",
    "print(knn_w2v.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlonij/virtual_envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_tfidf</th>\n",
       "      <th>labels_tfidf</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_tfidf  labels_tfidf  predicted_label\n",
       "0            4             1                1\n",
       "1            4             1                1\n",
       "2            4             1                1\n",
       "3            4             1                1\n",
       "4            4             1                1\n",
       "5            4             1                1\n",
       "6            4             1                1\n",
       "7            4             1                1\n",
       "8            4             1                1\n",
       "9            4             1                1\n",
       "10           4             1                1\n",
       "11           4             1                1\n",
       "12           4             1                1\n",
       "13           4             1                1\n",
       "14           4             1                1\n",
       "15           4             1                1\n",
       "16           4             1                1\n",
       "17           4             1                1\n",
       "18           4             1                1\n",
       "19           1             2                2\n",
       "20           2             0                0\n",
       "21           4             1                1\n",
       "22           4             1                1\n",
       "23           4             1                1\n",
       "24           4             1                1\n",
       "25           4             1                1\n",
       "26           4             1                1\n",
       "27           4             1                1\n",
       "28           4             1                1\n",
       "29           4             1                1\n",
       "30           4             1                1\n",
       "31           4             1                1\n",
       "32           4             1                1\n",
       "33           4             1                1\n",
       "34           4             1                1\n",
       "35           4             1                1\n",
       "36           4             1                1\n",
       "37           4             1                1\n",
       "38           4             1                1\n",
       "39           4             1                1\n",
       "40           4             1                1\n",
       "41           4             1                1\n",
       "42           4             1                1\n",
       "43           4             1                1\n",
       "44           4             1                1\n",
       "45           4             1                1\n",
       "46           4             1                1\n",
       "47           4             1                1\n",
       "48           4             1                1\n",
       "49           4             1                1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_labels(df):\n",
    "    predicted_clusters = {}\n",
    "    for cluster_number in df.iloc[:, 0].unique():\n",
    "        df_sub = df[df.iloc[:, 0] == cluster_number]\n",
    "        counts = df_sub.groupby(df.columns[1]).count()\n",
    "        #print(counts)\n",
    "        predicted_label = counts.iloc[:, 0].argmax()\n",
    "        predicted_clusters[cluster_number] = predicted_label\n",
    "    return predicted_clusters\n",
    "label_map = generate_labels(df)\n",
    "df['predicted_label'] = df.iloc[:, 0].map(lambda x: label_map[x])\n",
    "df.head(50)\n",
    "\n",
    "        \n",
    "#Add fourth column with text categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage accuracy\n",
      "0.515695067265\n"
     ]
    }
   ],
   "source": [
    "knn_w2v = neighbors.KNeighborsClassifier()\n",
    "knn_w2v.fit(X_train_w2v, y_train_w2v)\n",
    "y_pred = knn_w2v.predict(X_test_w2v)\n",
    "print('Percentage accuracy')\n",
    "print(knn_w2v.score(X_test_w2v, y_test_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-973ef515e411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_label_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "pred_label = df['predicted_label']\n",
    "def generate_label_names(df):\n",
    "    labels = []\n",
    "    for _ in pred_label:\n",
    "        if df['predicted_label'] == 0:\n",
    "            labels.append('business')\n",
    "        if df['predicted_label'] == 1:\n",
    "            labels.append('entertainment')\n",
    "        if df['predicted_label'] == 2:\n",
    "            labels.append('politics')\n",
    "        if df['predicted_label'] == 3:\n",
    "            labels.append('sports')\n",
    "    if df['predicted_label'] == 4:\n",
    "        labels.append('tech')\n",
    "    return labels\n",
    "label_names = generate_label_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-eddf4e9763b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_label_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-08f6198e125b>\u001b[0m in \u001b[0;36mgenerate_label_names\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_label_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'business'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    954\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "label_names = generate_label_names(df)\n",
    "df['doc_label'] = label_names\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4\n",
      " 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 1 4 2 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 1 4 4 4 4 1 4 4 4 4 2 4 4 4 4 4 4 4 1 2 4 4 4 4 4 4 4 4 2 4 2 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'four'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = prediction_tfidf[:510]\n",
    "print(business)\n",
    "def business_label(business):\n",
    "    business_label = ''\n",
    "    mx = 0\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    for prediction in business:\n",
    "        if prediction == 0:\n",
    "            zero += 1\n",
    "        elif prediction == 1:\n",
    "            one += 1\n",
    "        elif prediction == 2:\n",
    "            two += 1\n",
    "        elif prediction == 3:\n",
    "            three += 1\n",
    "        elif prediction == 4:\n",
    "            four += 1\n",
    "        if zero > mx:\n",
    "            business_label = 'zero'\n",
    "            mx = zero\n",
    "        elif one > mx:\n",
    "            business_label = 'one'\n",
    "            mx = one\n",
    "        elif two > mx:\n",
    "            business_label = 'two'\n",
    "            mx = two\n",
    "        elif three > mx:\n",
    "            business_label = 'three'\n",
    "            mx = three\n",
    "        elif four > mx:\n",
    "            business_label = 'four'\n",
    "            mx = four\n",
    "        return business_label\n",
    "business_label(business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 4 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 4 3 4 3\n",
      " 3 4 4 4 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 2\n",
      " 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 4 3 3 4 3 4 3 3 3 3 4 4 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 4 3 3 3 3 3 4 3 3 2 3 4 4 3 3 3 4 4 4 3 4 3 3 4 3 4 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 3\n",
      " 3 3 3 3 3 3 2 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 2 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'four'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment = prediction_tfidf[510:896]\n",
    "print(entertainment)\n",
    "def entertainment_label(entertainment):\n",
    "    entertainment_label = ''\n",
    "    mx = 0\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    for prediction in entertainment:\n",
    "        if prediction == 0:\n",
    "            zero += 1\n",
    "        elif prediction == 1:\n",
    "            one += 1\n",
    "        elif prediction == 2:\n",
    "            two += 1\n",
    "        elif prediction == 3:\n",
    "            three += 1\n",
    "        elif prediction == 4:\n",
    "            four += 1\n",
    "        if zero > mx:\n",
    "            entertainment_label = 'zero'\n",
    "            mx = zero\n",
    "        elif one > mx:\n",
    "            entertainment_label = 'one'\n",
    "            mx = one\n",
    "        elif two > mx:\n",
    "            entertainment_label = 'two'\n",
    "            mx = two\n",
    "        elif three > mx:\n",
    "            entertainment_label = 'three'\n",
    "            mx = three\n",
    "        elif four > mx:\n",
    "            entertainment_label = 'four'\n",
    "            mx = four\n",
    "        return entertainment_label\n",
    "entertainment_label(entertainment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 0 0 4 0 0 0 4 0 4 0 0 4 4 4 4 4 4 0 0 4 0 4 4 0 0 4 4 4 4 4 0 4 0 0\n",
      " 4 4 4 0 4 0 4 4 0 4 4 0 4 4 4 4 0 4 4 4 4 0 4 4 0 4 4 4 4 4 4 4 0 4 0 4 4\n",
      " 0 4 0 4 4 4 0 4 0 4 4 4 0 0 4 4 4 4 0 4 0 0 4 4 0 4 4 0 4 4 4 0 0 4 2 0 0\n",
      " 0 4 4 4 4 0 4 4 0 4 0 2 4 4 4 4 0 4 4 4 4 4 4 0 4 4 4 4 4 0 4 0 4 4 4 0 4\n",
      " 0 4 4 4 0 4 4 4 0 4 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 0 4 0 4 0 4\n",
      " 0 4 4 0 1 4 4 0 4 4 0 4 4 2 0 0 4 4 4 4 0 0 4 4 4 4 0 0 4 4 4 0 0 1 0 4 4\n",
      " 0 4 0 0 0 0 4 4 4 4 4 4 0 0 4 0 4 4 4 4 4 4 4 4 0 4 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 4 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 4 4 4 0 4 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 4 4 2 4 4 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 4 0 4 4 4\n",
      " 0 0 4 0 0 0 4 0 0 4 4 0 4 4 4 4 0 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 4 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'four'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics = prediction_tfidf[896:1313]\n",
    "print(politics)\n",
    "def politics_label(politics):\n",
    "    politics_label = ''\n",
    "    mx = 0\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    for prediction in politics:\n",
    "        if prediction == 0:\n",
    "            zero += 1\n",
    "        elif prediction == 1:\n",
    "            one += 1\n",
    "        elif prediction == 2:\n",
    "            two += 1\n",
    "        elif prediction == 3:\n",
    "            three += 1\n",
    "        elif prediction == 4:\n",
    "            four += 1\n",
    "        if zero > mx:\n",
    "            politics_label = 'zero'\n",
    "            mx = zero\n",
    "        elif one > mx:\n",
    "            politics_label = 'one'\n",
    "            mx = one\n",
    "        elif two > mx:\n",
    "            politics_label = 'two'\n",
    "            mx = two\n",
    "        elif three > mx:\n",
    "            politics_label = 'three'\n",
    "            mx = three\n",
    "        elif four > mx:\n",
    "            politics_label = 'four'\n",
    "            mx = four\n",
    "        return politics_label\n",
    "politics_label(politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 4 1 1 1 1 1 1 1 1 1 1 4 3 3 1 1 1 1 1 3 1 1 4 3 1 1 1 1 1 3 1 4 4 1\n",
      " 1 4 1 3 1 1 4 4 1 3 3 4 3 3 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 3 3 3 3 1 1 1 1 1 4 3 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = prediction_tfidf[1313:1824]\n",
    "print(sports)\n",
    "def sports_label(sports):\n",
    "    sports_label = ''\n",
    "    mx = 0\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    for prediction in sports:\n",
    "        if prediction == 0:\n",
    "            zero += 1\n",
    "        elif prediction == 1:\n",
    "            one += 1\n",
    "        elif prediction == 2:\n",
    "            two += 1\n",
    "        elif prediction == 3:\n",
    "            three += 1\n",
    "        elif prediction == 4:\n",
    "            four += 1\n",
    "        if zero > mx:\n",
    "            sports_label = 'zero'\n",
    "            mx = zero\n",
    "        elif one > mx:\n",
    "            sports_label = 'one'\n",
    "            mx = one\n",
    "        elif two > mx:\n",
    "            sports_label = 'two'\n",
    "            mx = two\n",
    "        elif three > mx:\n",
    "            sports_label = 'three'\n",
    "            mx = three\n",
    "        elif four > mx:\n",
    "            sports_label = 'four'\n",
    "            mx = four\n",
    "        return sports_label\n",
    "sports_label(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 4 2 2 2 2 4 2 4 2 2\n",
      " 2 2 2 2 2 2 3 2 4 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2\n",
      " 4 2 2 2 2 4 2 2 2 2 2 1 3 2 2 2 2 2 4 4 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 4 2 2 2 4 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 4 2 2 2 2 2 2 4 2 2 2 2 4 2 2 2\n",
      " 2 2 2 2 1 2 2 2 2 2 2 4 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2\n",
      " 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech = prediction_tfidf[1824:]\n",
    "print(tech)\n",
    "def tech_label(tech):\n",
    "    tech_label = ''\n",
    "    mx = 0\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    four = 0\n",
    "    for prediction in tech:\n",
    "        if prediction == 0:\n",
    "            zero += 1\n",
    "        elif prediction == 1:\n",
    "            one += 1\n",
    "        elif prediction == 2:\n",
    "            two += 1\n",
    "        elif prediction == 3:\n",
    "            three += 1\n",
    "        elif prediction == 4:\n",
    "            four += 1\n",
    "        if zero > mx:\n",
    "            tech_label = 'zero'\n",
    "            mx = zero\n",
    "        elif one > mx:\n",
    "            tech_label = 'one'\n",
    "            mx = one\n",
    "        elif two > mx:\n",
    "            tech_label = 'two'\n",
    "            mx = two\n",
    "        elif three > mx:\n",
    "            tech_label = 'three'\n",
    "            mx = three\n",
    "        elif four > mx:\n",
    "            tech_label = 'four'\n",
    "            mx = four\n",
    "        return tech_label\n",
    "tech_label(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_norm_tfidf, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage accuracy\n",
      "0.913043478261\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf = neighbors.KNeighborsClassifier()\n",
    "knn_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred = knn_tfidf.predict(X_test_tfidf)\n",
    "print('Percentage accuracy')\n",
    "print(knn_tfidf.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score\n",
      "0.012023046525\n",
      "Calinski Harabaz Index\n",
      "14.6238562307\n",
      "Opposite of the value of X on the K-means objective.\n",
      "-2123.6796809241637\n",
      "Adjusted Rand Index\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels_true must be 1D: shape is (2223, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-fee6422e1abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_norm_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adjusted Rand Index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py\u001b[0m in \u001b[0;36madjusted_rand_score\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_clusterings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py\u001b[0m in \u001b[0;36mcheck_clusterings\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         raise ValueError(\n\u001b[0;32m---> 42\u001b[0;31m             \"labels_true must be 1D: shape is %r\" % (labels_true.shape,))\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: labels_true must be 1D: shape is (2223, 1)"
     ]
    }
   ],
   "source": [
    "labels = y\n",
    "print('Silhouette Score')\n",
    "print(metrics.silhouette_score(X_norm_tfidf, labels, metric='euclidean'))\n",
    "array = X_norm_tfidf.toarray()\n",
    "print('Calinski Harabaz Index')\n",
    "print(metrics.calinski_harabaz_score(array, labels))\n",
    "print('Opposite of the value of X on the K-means objective.')\n",
    "print(model_tfidf.score(X_norm_tfidf))\n",
    "print('Adjusted Rand Index')\n",
    "print(metrics.adjusted_rand_score(labels_tfidf, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
