{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of importing functions from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import my_practice_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "my_practice_module.hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        #data = unicode(data, errors='replace')\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "#read_data_list\n",
    "#fail_list\n",
    "list_of_file_names_org = list_of_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Listings_PriceCut_SeasAdj_AllHomes.csv'"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for file in useful_df:\n",
    "    file_2 = len(file)\n",
    "    len_list.append(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixteen_list = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 7000:\n",
    "        sixteen_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 19.,  11.,   4.,   5.,   0.,   0.,   3.,   1.,   0.,   5.,   2.,\n",
       "          0.,   8.,   4.,   0.,   0.,   3.,   2.,   2.,  14.]),\n",
       " array([  8.00000000e+00,   8.02550000e+02,   1.59710000e+03,\n",
       "          2.39165000e+03,   3.18620000e+03,   3.98075000e+03,\n",
       "          4.77530000e+03,   5.56985000e+03,   6.36440000e+03,\n",
       "          7.15895000e+03,   7.95350000e+03,   8.74805000e+03,\n",
       "          9.54260000e+03,   1.03371500e+04,   1.11317000e+04,\n",
       "          1.19262500e+04,   1.27208000e+04,   1.35153500e+04,\n",
       "          1.43099000e+04,   1.51044500e+04,   1.58990000e+04]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19580d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(len_list, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_business = []\n",
    "with open('./yelp_dataset/business.json') as data_file:    \n",
    "    for line in data_file:\n",
    "        data = json.loads(line)\n",
    "        yelp_business.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business = pd.DataFrame(yelp_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business = df_yelp_business.sort_values('state',ascending=False)\n",
    "#df_yelp_business = df_yelp_business.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EH1 3AA', 'EH30 9TA', 'EH2 3AA', ..., '1528', '1511', '1531'], dtype=object)"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_zip_list = df_yelp_business['postal_code'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reducing to only five digit zipcodes\n",
    "five_digit = []\n",
    "for z in yelp_zip_list:\n",
    "    if len(z) == 5:\n",
    "        five_digit.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a df with the yelp zipcodes so I can merge with the Zillow df\n",
    "five_digit.sort()\n",
    "five_digit_list = []\n",
    "bug_list = []\n",
    "for digit in five_digit:\n",
    "    try:\n",
    "        new_digit = int(digit)\n",
    "        five_digit_list.append(new_digit)\n",
    "    except:\n",
    "        bug_list.append(digit)\n",
    "yelp_zip = pd.DataFrame()\n",
    "yelp_zip['zips'] = five_digit_list\n",
    "len(yelp_zip)\n",
    "zero_list = []\n",
    "for x in range(len(yelp_zip)):\n",
    "    zero_list.append(0)\n",
    "yelp_zip['zeroes'] = zero_list\n",
    "yelp_zip = yelp_zip.set_index('zips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156754</th>\n",
       "      <td>Omni Centre, Greenside Place</td>\n",
       "      <td>{'RestaurantsGoodForGroups': True, 'Restaurant...</td>\n",
       "      <td>nWz3HA2RvJDZzDNeonsA_w</td>\n",
       "      <td>[Restaurants, Chicken Wings, Portuguese]</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>55.956392</td>\n",
       "      <td>-3.186225</td>\n",
       "      <td>Nando's</td>\n",
       "      <td>New Town</td>\n",
       "      <td>EH1 3AA</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ZET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142651</th>\n",
       "      <td>Airside Departures Lounge, Edinburgh Airport J...</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>8F4n9wX3mrD5MK4Nq2yeRg</td>\n",
       "      <td>[Food, British, Coffee &amp; Tea, Restaurants]</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>{'Monday': '4:30-20:30', 'Tuesday': '4:30-20:3...</td>\n",
       "      <td>1</td>\n",
       "      <td>55.948332</td>\n",
       "      <td>-3.364129</td>\n",
       "      <td>Costa Coffee</td>\n",
       "      <td></td>\n",
       "      <td>EH12 9DN</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>XGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155168</th>\n",
       "      <td>2 Crighton Place</td>\n",
       "      <td>{'RestaurantsPriceRange2': 1, 'WiFi': 'no', 'B...</td>\n",
       "      <td>5ho3ULJKSikoRJr-xpM4SQ</td>\n",
       "      <td>[Food, Convenience Stores, Coffee &amp; Tea]</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>55.962680</td>\n",
       "      <td>-3.178345</td>\n",
       "      <td>Bramble</td>\n",
       "      <td>Leith</td>\n",
       "      <td>EH7 4NZ</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>XGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93013</th>\n",
       "      <td>7 Newhalls Road</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'HasTV': False, 'Noise...</td>\n",
       "      <td>mmqSJyO2FNIlV18g4dMiWw</td>\n",
       "      <td>[Nightlife, Bars, Pubs]</td>\n",
       "      <td>South Queensferry</td>\n",
       "      <td>{'Monday': '12:00-23:00', 'Tuesday': '12:00-23...</td>\n",
       "      <td>1</td>\n",
       "      <td>55.989782</td>\n",
       "      <td>-3.385991</td>\n",
       "      <td>The Hawes Inn</td>\n",
       "      <td></td>\n",
       "      <td>EH30 9TA</td>\n",
       "      <td>18</td>\n",
       "      <td>3.5</td>\n",
       "      <td>XGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>109 Princes Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>PtOViDy0tqoocic2DAgd6A</td>\n",
       "      <td>[Shopping, Department Stores, Fashion]</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>{'Monday': '9:30-18:00', 'Tuesday': '9:30-19:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>55.951442</td>\n",
       "      <td>-3.202045</td>\n",
       "      <td>Debenhams</td>\n",
       "      <td>New Town</td>\n",
       "      <td>EH2 3AA</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>XGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  address  \\\n",
       "156754                       Omni Centre, Greenside Place   \n",
       "142651  Airside Departures Lounge, Edinburgh Airport J...   \n",
       "155168                                   2 Crighton Place   \n",
       "93013                                     7 Newhalls Road   \n",
       "28827                                  109 Princes Street   \n",
       "\n",
       "                                               attributes  \\\n",
       "156754  {'RestaurantsGoodForGroups': True, 'Restaurant...   \n",
       "142651  {'BusinessParking': {'garage': False, 'street'...   \n",
       "155168  {'RestaurantsPriceRange2': 1, 'WiFi': 'no', 'B...   \n",
       "93013   {'Alcohol': 'full_bar', 'HasTV': False, 'Noise...   \n",
       "28827   {'BusinessAcceptsCreditCards': True, 'Restaura...   \n",
       "\n",
       "                   business_id                                  categories  \\\n",
       "156754  nWz3HA2RvJDZzDNeonsA_w    [Restaurants, Chicken Wings, Portuguese]   \n",
       "142651  8F4n9wX3mrD5MK4Nq2yeRg  [Food, British, Coffee & Tea, Restaurants]   \n",
       "155168  5ho3ULJKSikoRJr-xpM4SQ    [Food, Convenience Stores, Coffee & Tea]   \n",
       "93013   mmqSJyO2FNIlV18g4dMiWw                     [Nightlife, Bars, Pubs]   \n",
       "28827   PtOViDy0tqoocic2DAgd6A      [Shopping, Department Stores, Fashion]   \n",
       "\n",
       "                     city                                              hours  \\\n",
       "156754          Edinburgh                                                 {}   \n",
       "142651          Edinburgh  {'Monday': '4:30-20:30', 'Tuesday': '4:30-20:3...   \n",
       "155168          Edinburgh                                                 {}   \n",
       "93013   South Queensferry  {'Monday': '12:00-23:00', 'Tuesday': '12:00-23...   \n",
       "28827           Edinburgh  {'Monday': '9:30-18:00', 'Tuesday': '9:30-19:0...   \n",
       "\n",
       "        is_open   latitude  longitude           name neighborhood postal_code  \\\n",
       "156754        1  55.956392  -3.186225        Nando's     New Town     EH1 3AA   \n",
       "142651        1  55.948332  -3.364129   Costa Coffee                 EH12 9DN   \n",
       "155168        1  55.962680  -3.178345        Bramble        Leith     EH7 4NZ   \n",
       "93013         1  55.989782  -3.385991  The Hawes Inn                 EH30 9TA   \n",
       "28827         1  55.951442  -3.202045      Debenhams     New Town     EH2 3AA   \n",
       "\n",
       "        review_count  stars state  \n",
       "156754             4    3.5   ZET  \n",
       "142651             6    4.5   XGL  \n",
       "155168             3    4.0   XGL  \n",
       "93013             18    3.5   XGL  \n",
       "28827             24    3.0   XGL  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset]\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(int)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_df = build_useful_df(read_data_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concat all dfs into one multi-index. I am not currently using this\n",
    "def df_build_dataframe(df_list, beginning, end):\n",
    "    length = len(df_list[beginning:end])\n",
    "    keys = []\n",
    "    values = []\n",
    "    final = []\n",
    "    for x in range(length):\n",
    "        y = str(x)\n",
    "        keys.append(y)\n",
    "    for df in df_list[beginning:end]:\n",
    "        values.append(df)\n",
    "    dictionary = dict(zip(keys, values))\n",
    "    df = pd.concat(dictionary)\n",
    "    return df\n",
    "single_df = df_build_dataframe(useful_df, 3, 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building a list of all dataframes that work seamlessly with function. Tested through trial and error to get these \n",
    "# values\n",
    "good_range = list(range(72))\n",
    "good_range.remove(0)\n",
    "good_range.remove(1)\n",
    "good_range.remove(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '1990-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "                    #big swing and gain, big swing and loss, big swing and big gain, big swing and big loss\n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_add(good_range, df_list, pure_feature_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for feature in pure_feature_list:\n",
    "        df = df_list[feature]\n",
    "        feature_df_list.append(df)\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '2011-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_bugs(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        df = df.loc[:, '2011-01':'2016-12']\n",
    "        features = pd.DataFrame()\n",
    "        for i, year in enumerate(year_list):\n",
    "            try:\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "                feature_df_list.append(features)\n",
    "            except:\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                #change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                \n",
    "                feature_df_list.append(features)\n",
    "        #    bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(useful_df)\n",
    "for num in range(len(useful_df)):\n",
    "    useful_df[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixteen_doc_features, bugs = build_feature_list(sixteen_list, useful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Zri_AllHomesPlusMultifamily_Summary.csv'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean</th>\n",
       "      <th>2011_std</th>\n",
       "      <th>2011_min</th>\n",
       "      <th>2011_max</th>\n",
       "      <th>2011_swing</th>\n",
       "      <th>2011_change</th>\n",
       "      <th>2012_mean</th>\n",
       "      <th>2012_std</th>\n",
       "      <th>2012_min</th>\n",
       "      <th>2012_max</th>\n",
       "      <th>...</th>\n",
       "      <th>2015_yoy</th>\n",
       "      <th>2015_gain</th>\n",
       "      <th>2016_mean</th>\n",
       "      <th>2016_std</th>\n",
       "      <th>2016_min</th>\n",
       "      <th>2016_max</th>\n",
       "      <th>2016_swing</th>\n",
       "      <th>2016_change</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99801</th>\n",
       "      <td>8.737707</td>\n",
       "      <td>2.668976</td>\n",
       "      <td>3.270054</td>\n",
       "      <td>12.457820</td>\n",
       "      <td>9.187766</td>\n",
       "      <td>-1.638298</td>\n",
       "      <td>8.375887</td>\n",
       "      <td>3.294851</td>\n",
       "      <td>4.551599</td>\n",
       "      <td>14.925776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142371</td>\n",
       "      <td>1</td>\n",
       "      <td>9.960122</td>\n",
       "      <td>3.179246</td>\n",
       "      <td>5.467737</td>\n",
       "      <td>16.714013</td>\n",
       "      <td>11.246276</td>\n",
       "      <td>1.219245</td>\n",
       "      <td>0.854903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>15.292930</td>\n",
       "      <td>4.304947</td>\n",
       "      <td>9.545075</td>\n",
       "      <td>25.197773</td>\n",
       "      <td>15.652698</td>\n",
       "      <td>4.628867</td>\n",
       "      <td>14.266617</td>\n",
       "      <td>2.313248</td>\n",
       "      <td>10.385404</td>\n",
       "      <td>17.292836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0</td>\n",
       "      <td>15.462566</td>\n",
       "      <td>2.426758</td>\n",
       "      <td>10.402901</td>\n",
       "      <td>19.308360</td>\n",
       "      <td>8.905459</td>\n",
       "      <td>-2.962278</td>\n",
       "      <td>1.046422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>14.771745</td>\n",
       "      <td>3.035814</td>\n",
       "      <td>9.219219</td>\n",
       "      <td>20.683859</td>\n",
       "      <td>11.464640</td>\n",
       "      <td>-0.895525</td>\n",
       "      <td>14.162195</td>\n",
       "      <td>2.279545</td>\n",
       "      <td>9.922699</td>\n",
       "      <td>18.353496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782346</td>\n",
       "      <td>0</td>\n",
       "      <td>13.083236</td>\n",
       "      <td>3.086111</td>\n",
       "      <td>8.977494</td>\n",
       "      <td>19.611700</td>\n",
       "      <td>10.634206</td>\n",
       "      <td>-7.710742</td>\n",
       "      <td>0.960138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99669</th>\n",
       "      <td>10.946112</td>\n",
       "      <td>1.839319</td>\n",
       "      <td>8.474595</td>\n",
       "      <td>14.084393</td>\n",
       "      <td>5.609798</td>\n",
       "      <td>-4.590275</td>\n",
       "      <td>9.620692</td>\n",
       "      <td>1.472063</td>\n",
       "      <td>7.015491</td>\n",
       "      <td>11.650463</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033731</td>\n",
       "      <td>1</td>\n",
       "      <td>13.225612</td>\n",
       "      <td>3.601565</td>\n",
       "      <td>8.603149</td>\n",
       "      <td>22.194993</td>\n",
       "      <td>13.591844</td>\n",
       "      <td>-1.786965</td>\n",
       "      <td>1.177421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99654</th>\n",
       "      <td>13.307311</td>\n",
       "      <td>2.180717</td>\n",
       "      <td>8.626867</td>\n",
       "      <td>16.407887</td>\n",
       "      <td>7.781020</td>\n",
       "      <td>-2.413729</td>\n",
       "      <td>14.321280</td>\n",
       "      <td>2.768978</td>\n",
       "      <td>10.590992</td>\n",
       "      <td>17.464021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033941</td>\n",
       "      <td>1</td>\n",
       "      <td>14.849717</td>\n",
       "      <td>2.158915</td>\n",
       "      <td>11.116177</td>\n",
       "      <td>17.820048</td>\n",
       "      <td>6.703871</td>\n",
       "      <td>-2.370956</td>\n",
       "      <td>0.872533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2011_mean  2011_std  2011_min   2011_max  2011_swing  2011_change  \\\n",
       "RegionName                                                                      \n",
       "99801        8.737707  2.668976  3.270054  12.457820    9.187766    -1.638298   \n",
       "99709       15.292930  4.304947  9.545075  25.197773   15.652698     4.628867   \n",
       "99705       14.771745  3.035814  9.219219  20.683859   11.464640    -0.895525   \n",
       "99669       10.946112  1.839319  8.474595  14.084393    5.609798    -4.590275   \n",
       "99654       13.307311  2.180717  8.626867  16.407887    7.781020    -2.413729   \n",
       "\n",
       "            2012_mean  2012_std   2012_min   2012_max    ...      2015_yoy  \\\n",
       "RegionName                                               ...                 \n",
       "99801        8.375887  3.294851   4.551599  14.925776    ...      1.142371   \n",
       "99709       14.266617  2.313248  10.385404  17.292836    ...      0.932655   \n",
       "99705       14.162195  2.279545   9.922699  18.353496    ...      0.782346   \n",
       "99669        9.620692  1.472063   7.015491  11.650463    ...      1.033731   \n",
       "99654       14.321280  2.768978  10.590992  17.464021    ...      1.033941   \n",
       "\n",
       "            2015_gain  2016_mean  2016_std   2016_min   2016_max  2016_swing  \\\n",
       "RegionName                                                                     \n",
       "99801               1   9.960122  3.179246   5.467737  16.714013   11.246276   \n",
       "99709               0  15.462566  2.426758  10.402901  19.308360    8.905459   \n",
       "99705               0  13.083236  3.086111   8.977494  19.611700   10.634206   \n",
       "99669               1  13.225612  3.601565   8.603149  22.194993   13.591844   \n",
       "99654               1  14.849717  2.158915  11.116177  17.820048    6.703871   \n",
       "\n",
       "            2016_change  2016_yoy  2016_gain  \n",
       "RegionName                                    \n",
       "99801          1.219245  0.854903          0  \n",
       "99709         -2.962278  1.046422          1  \n",
       "99705         -7.710742  0.960138          0  \n",
       "99669         -1.786965  1.177421          1  \n",
       "99654         -2.370956  0.872533          0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "sixteen_doc_features[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2011-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3484\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_searchsorted_monotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3485\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_searchsorted_monotonic\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3443\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index must be monotonic increasing or decreasing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: index must be monotonic increasing or decreasing",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-1b9faf1bbfae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbugs_list_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbugs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_feature_list_bugs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbugs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museful_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-192-ba764e269003>\u001b[0m in \u001b[0;36mbuild_feature_list_bugs\u001b[0;34m(good_range, df_list)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgood_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2011-01'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'2016-12'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n\u001b[0;32m-> 1356\u001b[0;31m                                        slice_obj.step, kind=self.name)\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \"\"\"\n\u001b[1;32m   3349\u001b[0m         start_slice, end_slice = self.slice_locs(start, end, step=step,\n\u001b[0;32m-> 3350\u001b[0;31m                                                  kind=kind)\n\u001b[0m\u001b[1;32m   3351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3538\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3540\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3485\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m                 \u001b[0;31m# raise the original KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3479\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3481\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_only_exact_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_loc_only_exact_matches\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3448\u001b[0m         \u001b[0mget_slice_bound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m         \"\"\"\n\u001b[0;32m-> 3450\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2011-01'"
     ]
    }
   ],
   "source": [
    "bugs_list_features, bugs = build_feature_list_bugs(bugs_list, useful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs_list_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>1996-07</th>\n",
       "      <th>1996-08</th>\n",
       "      <th>1996-09</th>\n",
       "      <th>1996-10</th>\n",
       "      <th>1996-11</th>\n",
       "      <th>1996-12</th>\n",
       "      <th>1997-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2013-04</th>\n",
       "      <th>2013-05</th>\n",
       "      <th>2013-06</th>\n",
       "      <th>2013-07</th>\n",
       "      <th>2013-08</th>\n",
       "      <th>2013-09</th>\n",
       "      <th>2013-10</th>\n",
       "      <th>2013-11</th>\n",
       "      <th>2013-12</th>\n",
       "      <th>2014-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99901</th>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>206.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99712</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1996-04  1996-05  1996-06  1996-07  1996-08  1996-09  1996-10  \\\n",
       "RegionName                                                                  \n",
       "99901         162.0    162.0    162.0    162.0    162.0    162.0    162.0   \n",
       "99801           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "99712           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "99709           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "99705           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "            1996-11  1996-12  1997-01   ...     2013-04  2013-05  2013-06  \\\n",
       "RegionName                              ...                                 \n",
       "99901         162.0    162.0    162.0   ...       161.0    162.0    162.0   \n",
       "99801           NaN      NaN      NaN   ...       206.0    207.0    208.0   \n",
       "99712           NaN      NaN      NaN   ...       123.0    122.0    122.0   \n",
       "99709           NaN      NaN      NaN   ...       119.0    119.0    119.0   \n",
       "99705           NaN      NaN      NaN   ...       124.0    124.0    124.0   \n",
       "\n",
       "            2013-07  2013-08  2013-09  2013-10  2013-11  2013-12  2014-01  \n",
       "RegionName                                                                 \n",
       "99901         162.0    162.0    162.0    162.0    161.0    161.0    161.0  \n",
       "99801         209.0    210.0    211.0    212.0    212.0    211.0    211.0  \n",
       "99712         122.0    120.0    120.0    120.0    120.0    120.0    120.0  \n",
       "99709         119.0    119.0    118.0    118.0    118.0    119.0    119.0  \n",
       "99705         123.0    123.0    123.0    122.0    123.0    123.0    124.0  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_df[52].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_swing(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '2011-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    mean_yoy = features[year + '_yoy'].mean()\n",
    "                    features[year + '_yoy_pos'] = np.where(features[year + '_yoy']>mean_yoy, 1, 0)\n",
    "                    big_yoy = features[year + '_yoy'].std() + mean_yoy\n",
    "                    features[year + '_yoy_big'] = np.where(features[year + '_yoy']>big_yoy, 1, 0)\n",
    "                    features[year + '_yoy_neg'] = np.where(features[year + '_yoy']<mean_yoy, 1, 0)\n",
    "                    big_loss = mean_yoy - features[year + '_yoy'].std() \n",
    "                    features[year + '_yoy_loss_big'] = np.where(features[year + '_yoy']<big_loss, 1, 0)\n",
    "                mean_swing = features[year + '_swing'].mean()\n",
    "                features[year + '_swing_pos'] = np.where(features[year + '_swing']>mean_swing, 1, 0)\n",
    "                big_swing = features[year + '_swing'].std() + mean_swing\n",
    "                features[year + '_swing_big'] = np.where(features[year + '_swing']>big_swing, 1, 0)\n",
    "                features[year + '_swing_neg'] = np.where(features[year + '_swing']<mean_swing, 1, 0)\n",
    "                swing_big_loss = mean_swing - features[year + '_swing'].std() \n",
    "                features[year + '_swing_loss_big'] = np.where(features[year + '_swing']<swing_big_loss, 1, 0)\n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df_list, bug_list = build_feature_list([23], useful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df_list_swing, bug_list_swing = build_feature_list_swing([23], useful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean</th>\n",
       "      <th>2011_std</th>\n",
       "      <th>2011_min</th>\n",
       "      <th>2011_max</th>\n",
       "      <th>2011_swing</th>\n",
       "      <th>2011_change</th>\n",
       "      <th>2011_swing_pos</th>\n",
       "      <th>2011_swing_big</th>\n",
       "      <th>2011_swing_neg</th>\n",
       "      <th>2011_swing_loss_big</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "      <th>2016_yoy_pos</th>\n",
       "      <th>2016_yoy_big</th>\n",
       "      <th>2016_yoy_neg</th>\n",
       "      <th>2016_yoy_loss_big</th>\n",
       "      <th>2016_swing_pos</th>\n",
       "      <th>2016_swing_big</th>\n",
       "      <th>2016_swing_neg</th>\n",
       "      <th>2016_swing_loss_big</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99901</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99801</th>\n",
       "      <td>188.225207</td>\n",
       "      <td>7.093943</td>\n",
       "      <td>172.811060</td>\n",
       "      <td>197.583313</td>\n",
       "      <td>24.772253</td>\n",
       "      <td>3.408637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>184.281590</td>\n",
       "      <td>14.153608</td>\n",
       "      <td>169.023628</td>\n",
       "      <td>208.530806</td>\n",
       "      <td>39.507178</td>\n",
       "      <td>-39.507178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067973</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>164.434369</td>\n",
       "      <td>3.401094</td>\n",
       "      <td>161.103048</td>\n",
       "      <td>172.209738</td>\n",
       "      <td>11.106690</td>\n",
       "      <td>-1.720695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.061596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99701</th>\n",
       "      <td>124.640998</td>\n",
       "      <td>5.854324</td>\n",
       "      <td>110.247445</td>\n",
       "      <td>131.628788</td>\n",
       "      <td>21.381343</td>\n",
       "      <td>-8.482437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             2011_mean   2011_std    2011_min    2011_max  2011_swing  \\\n",
       "RegionName                                                              \n",
       "99901              NaN        NaN         NaN         NaN         NaN   \n",
       "99801       188.225207   7.093943  172.811060  197.583313   24.772253   \n",
       "99709       184.281590  14.153608  169.023628  208.530806   39.507178   \n",
       "99705       164.434369   3.401094  161.103048  172.209738   11.106690   \n",
       "99701       124.640998   5.854324  110.247445  131.628788   21.381343   \n",
       "\n",
       "            2011_change  2011_swing_pos  2011_swing_big  2011_swing_neg  \\\n",
       "RegionName                                                                \n",
       "99901               NaN               0               0               0   \n",
       "99801          3.408637               1               0               0   \n",
       "99709        -39.507178               1               1               0   \n",
       "99705         -1.720695               0               0               1   \n",
       "99701         -8.482437               1               0               0   \n",
       "\n",
       "            2011_swing_loss_big         ...           2016_yoy  2016_gain  \\\n",
       "RegionName                              ...                                 \n",
       "99901                         0         ...           1.090750          1   \n",
       "99801                         0         ...           0.999862          0   \n",
       "99709                         0         ...           1.067973          1   \n",
       "99705                         0         ...           1.061596          1   \n",
       "99701                         0         ...           1.166714          1   \n",
       "\n",
       "            2016_yoy_pos  2016_yoy_big  2016_yoy_neg  2016_yoy_loss_big  \\\n",
       "RegionName                                                                \n",
       "99901                  1             0             0                  0   \n",
       "99801                  0             0             1                  0   \n",
       "99709                  1             0             0                  0   \n",
       "99705                  1             0             0                  0   \n",
       "99701                  1             1             0                  0   \n",
       "\n",
       "            2016_swing_pos  2016_swing_big  2016_swing_neg  \\\n",
       "RegionName                                                   \n",
       "99901                    0               0               1   \n",
       "99801                    0               0               1   \n",
       "99709                    1               0               0   \n",
       "99705                    0               0               1   \n",
       "99701                    1               0               0   \n",
       "\n",
       "            2016_swing_loss_big  \n",
       "RegionName                       \n",
       "99901                         0  \n",
       "99801                         0  \n",
       "99709                         0  \n",
       "99705                         0  \n",
       "99701                         0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df_list_swing[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sixteen_doc_features)\n",
    "for num in range(len(sixteen_doc_features)):\n",
    "    sixteen_doc_features[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(feature_df_list)\n",
    "for num in range(len(feature_df_list)):\n",
    "    feature_df_list[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(feature_df_list_swing)\n",
    "for num in range(len(feature_df_list_swing)):\n",
    "    feature_df_list_swing[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(feature_df_list_mult)\n",
    "for num in range(len(feature_df_list_mult)):\n",
    "    feature_df_list_mult[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(feature_df_list_swing_mult)\n",
    "for num in range(len(feature_df_list_swing_mult)):\n",
    "    feature_df_list_swing_mult[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6670"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 45, 48, 52, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging all dfs into one. Merging on indez which is zipcode. I was hoping for inner join but it looks like\n",
    "# There are many zipcodes that only exist in certain dfs. Im hoping that reducing them to metro areas will fix this\n",
    "def merge_dataframes(feature_df_list):\n",
    "    df_1 = feature_df_list[0]\n",
    "    for df in feature_df_list[1:]:\n",
    "        df_1 = pd.merge(df_1, df, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = merge_dataframes(sixteen_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2012_mean_x</th>\n",
       "      <th>2012_std_x</th>\n",
       "      <th>2012_min_x</th>\n",
       "      <th>2012_max_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2015_yoy</th>\n",
       "      <th>2015_gain</th>\n",
       "      <th>2016_mean</th>\n",
       "      <th>2016_std</th>\n",
       "      <th>2016_min</th>\n",
       "      <th>2016_max</th>\n",
       "      <th>2016_swing</th>\n",
       "      <th>2016_change</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99362</th>\n",
       "      <td>11.036472</td>\n",
       "      <td>1.492165</td>\n",
       "      <td>9.400227</td>\n",
       "      <td>14.401968</td>\n",
       "      <td>5.001741</td>\n",
       "      <td>-4.487889</td>\n",
       "      <td>10.576439</td>\n",
       "      <td>2.446100</td>\n",
       "      <td>8.135459</td>\n",
       "      <td>16.930241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025473</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99354</th>\n",
       "      <td>11.603599</td>\n",
       "      <td>2.824071</td>\n",
       "      <td>7.194803</td>\n",
       "      <td>16.110267</td>\n",
       "      <td>8.915463</td>\n",
       "      <td>-1.600303</td>\n",
       "      <td>10.357590</td>\n",
       "      <td>3.866544</td>\n",
       "      <td>5.474520</td>\n",
       "      <td>19.312839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954333</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1.076721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99352</th>\n",
       "      <td>12.441976</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>10.501647</td>\n",
       "      <td>14.742676</td>\n",
       "      <td>4.241029</td>\n",
       "      <td>2.483404</td>\n",
       "      <td>12.104165</td>\n",
       "      <td>1.145348</td>\n",
       "      <td>10.956463</td>\n",
       "      <td>14.625538</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040691</td>\n",
       "      <td>1</td>\n",
       "      <td>0.905167</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.072472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99337</th>\n",
       "      <td>12.516044</td>\n",
       "      <td>1.241358</td>\n",
       "      <td>10.124885</td>\n",
       "      <td>14.400625</td>\n",
       "      <td>4.275740</td>\n",
       "      <td>-2.111852</td>\n",
       "      <td>10.084839</td>\n",
       "      <td>1.982604</td>\n",
       "      <td>5.756287</td>\n",
       "      <td>12.123973</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885833</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.064490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99224</th>\n",
       "      <td>12.350641</td>\n",
       "      <td>2.021761</td>\n",
       "      <td>9.421085</td>\n",
       "      <td>16.200779</td>\n",
       "      <td>6.779694</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>11.630859</td>\n",
       "      <td>2.451484</td>\n",
       "      <td>7.557236</td>\n",
       "      <td>15.056059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055072</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.015172</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.041056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2011_mean_x  2011_std_x  2011_min_x  2011_max_x  2011_swing_x  \\\n",
       "RegionName                                                                  \n",
       "99362         11.036472    1.492165    9.400227   14.401968      5.001741   \n",
       "99354         11.603599    2.824071    7.194803   16.110267      8.915463   \n",
       "99352         12.441976    1.441693   10.501647   14.742676      4.241029   \n",
       "99337         12.516044    1.241358   10.124885   14.400625      4.275740   \n",
       "99224         12.350641    2.021761    9.421085   16.200779      6.779694   \n",
       "\n",
       "            2011_change_x  2012_mean_x  2012_std_x  2012_min_x  2012_max_x  \\\n",
       "RegionName                                                                   \n",
       "99362           -4.487889    10.576439    2.446100    8.135459   16.930241   \n",
       "99354           -1.600303    10.357590    3.866544    5.474520   19.312839   \n",
       "99352            2.483404    12.104165    1.145348   10.956463   14.625538   \n",
       "99337           -2.111852    10.084839    1.982604    5.756287   12.123973   \n",
       "99224            0.011361    11.630859    2.451484    7.557236   15.056059   \n",
       "\n",
       "              ...      2015_yoy  2015_gain  2016_mean  2016_std  2016_min  \\\n",
       "RegionName    ...                                                           \n",
       "99362         ...      1.025473          1   0.879167  0.012748     0.860   \n",
       "99354         ...      1.052236          1   0.954333  0.012265     0.930   \n",
       "99352         ...      1.040691          1   0.905167  0.009282     0.882   \n",
       "99337         ...      1.051158          1   0.885833  0.009003     0.868   \n",
       "99224         ...      1.055072          1   0.841000  0.015172     0.820   \n",
       "\n",
       "            2016_max  2016_swing  2016_change  2016_yoy  2016_gain  \n",
       "RegionName                                                          \n",
       "99362          0.898       0.038        0.010  0.992661          0  \n",
       "99354          0.966       0.036        0.020  1.076721          1  \n",
       "99352          0.912       0.030        0.022  1.072472          1  \n",
       "99337          0.898       0.030        0.012  1.064490          1  \n",
       "99224          0.864       0.044        0.044  1.041056          1  \n",
       "\n",
       "[5 rows x 690 columns]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_16.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_yelp_business.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business = df_yelp_business.sort_values('postal_code',ascending=False)\n",
    "df_yelp_business = df_yelp_business.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YO22 5LY</th>\n",
       "      <td>North York Moors National Park, The Green, Goa...</td>\n",
       "      <td>{'RestaurantsPriceRange2': 4}</td>\n",
       "      <td>hMAw6C_-67QgvkGVLaErEg</td>\n",
       "      <td>[Gift Shops, Event Planning &amp; Services, Flower...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.400141</td>\n",
       "      <td>-0.715568</td>\n",
       "      <td>Goathland Hotel</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 5AL</th>\n",
       "      <td>Goathland</td>\n",
       "      <td>{}</td>\n",
       "      <td>RqUt63tv4T3AvOBDMz34ng</td>\n",
       "      <td>[Train Stations, Hotels &amp; Travel]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.400509</td>\n",
       "      <td>-0.712087</td>\n",
       "      <td>Goathland Railway Station</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4RG</th>\n",
       "      <td>Robin Hoods Bay</td>\n",
       "      <td>{}</td>\n",
       "      <td>Y5VQLoDhjFmJQbSsLyjhAA</td>\n",
       "      <td>[Public Services &amp; Government, Landmarks &amp; His...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.435489</td>\n",
       "      <td>-0.533031</td>\n",
       "      <td>Robin Hood's Bay - Its History and Origins</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4NT</th>\n",
       "      <td>Stainsacre Hall, Stainsacre near Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>IaeRHjObw6ydKerDWQ0g4g</td>\n",
       "      <td>[Education, Hotels &amp; Travel]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.462985</td>\n",
       "      <td>-0.592173</td>\n",
       "      <td>Stainsacre Hall</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4JT</th>\n",
       "      <td>Abbey Lane</td>\n",
       "      <td>{'GoodForKids': True}</td>\n",
       "      <td>aWLt4-ADtKb8Nt9Bjgn6FQ</td>\n",
       "      <td>[Public Services &amp; Government, Active Life, Pa...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Sunday': '10:00-16:00', 'Saturday': '10:00-1...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.488134</td>\n",
       "      <td>-0.605429</td>\n",
       "      <td>Whitby Abbey</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4DL</th>\n",
       "      <td>Harbour</td>\n",
       "      <td>{}</td>\n",
       "      <td>ZqjJnu6h0e-y1wth43Vxbg</td>\n",
       "      <td>[Hotels &amp; Travel]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.489151</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>Whitby Harbour and Lighthouses</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4DE</th>\n",
       "      <td>105 Church Street</td>\n",
       "      <td>{'RestaurantsPriceRange2': 2, 'BusinessParking...</td>\n",
       "      <td>t1DWDiut4Q8hdSXdzlxyew</td>\n",
       "      <td>[Jewelry, Shopping]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.488492</td>\n",
       "      <td>-0.612049</td>\n",
       "      <td>One O Five Whitby Jet Shop</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4DE</th>\n",
       "      <td>Church Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'CoatChec...</td>\n",
       "      <td>2ueyRysdmvgvqXSfE5DCKw</td>\n",
       "      <td>[Nightlife, Bars, Pubs]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.488560</td>\n",
       "      <td>-0.612012</td>\n",
       "      <td>Duke Of York</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4DB</th>\n",
       "      <td>9 Sandgate</td>\n",
       "      <td>{}</td>\n",
       "      <td>GYAMJdFczYZj61BO34VNWA</td>\n",
       "      <td>[Home &amp; Garden, Shopping, Home Decor, Arts &amp; C...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487507</td>\n",
       "      <td>-0.612634</td>\n",
       "      <td>Whitby Glass</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4BH</th>\n",
       "      <td>95 Church Street</td>\n",
       "      <td>{'GoodForMeal': {'dessert': False, 'latenight'...</td>\n",
       "      <td>rn46ViXhb2z28jTqtft9Ng</td>\n",
       "      <td>[Restaurants, Vegetarian]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487908</td>\n",
       "      <td>-0.611981</td>\n",
       "      <td>Sanders Yard</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4BH</th>\n",
       "      <td>95 Church Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>eKhQtfiPiYu6gI2UIghHGQ</td>\n",
       "      <td>[Hotels &amp; Travel, Specialty Food, Health Marke...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '10:00-17:00', 'Tuesday': '10:00-17...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487908</td>\n",
       "      <td>-0.611981</td>\n",
       "      <td>Shepherds Purse</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4BH</th>\n",
       "      <td>92 Church Street</td>\n",
       "      <td>{'RestaurantsPriceRange2': 3, 'BusinessParking...</td>\n",
       "      <td>mMLH2s8vU9xu97HU6r0xsw</td>\n",
       "      <td>[Candy Stores, Specialty Food, Food, Chocolati...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487798</td>\n",
       "      <td>-0.611953</td>\n",
       "      <td>Justin Chocolatier</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4BG</th>\n",
       "      <td>11 Bridge Street</td>\n",
       "      <td>{'RestaurantsGoodForGroups': True, 'Restaurant...</td>\n",
       "      <td>Zut6vm6AZ-xmag12jywQyw</td>\n",
       "      <td>[Fish &amp; Chips, Restaurants]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487225</td>\n",
       "      <td>-0.611883</td>\n",
       "      <td>Hadley's Fish Restaurant</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4BG</th>\n",
       "      <td>Bridge Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True}</td>\n",
       "      <td>6_CLC99-LkZgD4pEm1VA0g</td>\n",
       "      <td>[Hotels &amp; Travel, Bars, Pubs, Nightlife, Hotel...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487141</td>\n",
       "      <td>-0.612091</td>\n",
       "      <td>The Dolphin Hotel</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4BA</th>\n",
       "      <td>9 Grape Lane</td>\n",
       "      <td>{'GoodForMeal': {'dessert': False, 'latenight'...</td>\n",
       "      <td>18ZoetuKrH67EaqaXobiew</td>\n",
       "      <td>[Restaurants, Italian]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486888</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>Moutreys Restaurant</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4AS</th>\n",
       "      <td>68-69 Church Street</td>\n",
       "      <td>{'RestaurantsTakeOut': True, 'RestaurantsPrice...</td>\n",
       "      <td>m05JNzmziiAed0UZvxzYGQ</td>\n",
       "      <td>[Restaurants, Fish &amp; Chips]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486334</td>\n",
       "      <td>-0.610744</td>\n",
       "      <td>Mister Chips</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4AS</th>\n",
       "      <td>Church Street</td>\n",
       "      <td>{}</td>\n",
       "      <td>eHyDrJiavmOd2PdzeWTszg</td>\n",
       "      <td>[Bars, Nightlife, Pubs]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486334</td>\n",
       "      <td>-0.610744</td>\n",
       "      <td>The Fleece</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4AS</th>\n",
       "      <td>163 Church Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': False, 'Restaur...</td>\n",
       "      <td>Z-xY1V3kYwtU4kDcyxwINg</td>\n",
       "      <td>[Coffee &amp; Tea, Event Planning &amp; Services, Food...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '12:00-20:00', 'Tuesday': '12:00-20...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487033</td>\n",
       "      <td>-0.611580</td>\n",
       "      <td>Humble Pie 'N' Mash Shop</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22</th>\n",
       "      <td>4 Sandgate</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>PCgUcbYxCH6afJsYut1lIA</td>\n",
       "      <td>[Flowers &amp; Gifts, Shopping, Gift Shops]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487507</td>\n",
       "      <td>-0.612634</td>\n",
       "      <td>Venus Trading</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22</th>\n",
       "      <td>87 Church Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'GoodForM...</td>\n",
       "      <td>FkRUQjJvvkEWUhzXBB8COg</td>\n",
       "      <td>[Hotels, Hotels &amp; Travel, Event Planning &amp; Ser...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487487</td>\n",
       "      <td>-0.611776</td>\n",
       "      <td>White Horse &amp; Griffin</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22</th>\n",
       "      <td>68 Church St</td>\n",
       "      <td>{'RestaurantsPriceRange2': 2}</td>\n",
       "      <td>GasfpvcT2jzFr4EPUQQsLQ</td>\n",
       "      <td>[Food]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486905</td>\n",
       "      <td>-0.611170</td>\n",
       "      <td>Carols Coffee Corner</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 9AA</th>\n",
       "      <td>All over town</td>\n",
       "      <td>{}</td>\n",
       "      <td>CTVzHfy6gtXrD-UzKKSB2A</td>\n",
       "      <td>[Shopping, Music &amp; DVDs, Festivals, Arts &amp; Ent...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487268</td>\n",
       "      <td>-0.621658</td>\n",
       "      <td>Whitby Folk Weekend</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3PZ</th>\n",
       "      <td>Khyber Pass</td>\n",
       "      <td>{}</td>\n",
       "      <td>nKPQKBDzhaJxJYO6nd71zg</td>\n",
       "      <td>[Restaurants, Gluten-Free, Seafood, Fish &amp; Chi...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '12:00-20:30', 'Tuesday': '12:00-20...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.489746</td>\n",
       "      <td>-0.615641</td>\n",
       "      <td>The Fishermans Wife</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3PW</th>\n",
       "      <td>St Annes Staith</td>\n",
       "      <td>{}</td>\n",
       "      <td>F5gF7Bn_mWSMV6X8Yu8kMA</td>\n",
       "      <td>[Bars, Nightlife, Pubs]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487424</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>Jolly Sailors Inn</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3PU</th>\n",
       "      <td>7 Pier Road</td>\n",
       "      <td>{'HasTV': True, 'RestaurantsGoodForGroups': Tr...</td>\n",
       "      <td>s5v0gnmwCasyYuLR7-qy0g</td>\n",
       "      <td>[Restaurants, Fish &amp; Chips]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.488500</td>\n",
       "      <td>-0.614902</td>\n",
       "      <td>Quayside</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3PU</th>\n",
       "      <td>14 Pier Road</td>\n",
       "      <td>{'GoodForMeal': {'dessert': False, 'latenight'...</td>\n",
       "      <td>_Wq-Ei5VKopb--qBHltLjA</td>\n",
       "      <td>[Coffee &amp; Tea, Fish &amp; Chips, Restaurants, Food...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '11:30-21:00', 'Tuesday': '11:30-21...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.489062</td>\n",
       "      <td>-0.614969</td>\n",
       "      <td>Magpie Cafe</td>\n",
       "      <td></td>\n",
       "      <td>37</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3PR</th>\n",
       "      <td>5 Marine Parade</td>\n",
       "      <td>{'RestaurantsPriceRange2': 4}</td>\n",
       "      <td>jMNdRZcHVfVMHNb0U7cnAg</td>\n",
       "      <td>[British, Restaurants]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487880</td>\n",
       "      <td>-0.614598</td>\n",
       "      <td>Moon and Sixpence</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3EN</th>\n",
       "      <td>West Cliff, The Spa</td>\n",
       "      <td>{'GoodForKids': True}</td>\n",
       "      <td>hjUTVItTU5pb3rs2Y9iqkQ</td>\n",
       "      <td>[Arts &amp; Entertainment, Arcades]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.490859</td>\n",
       "      <td>-0.620487</td>\n",
       "      <td>Whitby Pavilion Complex</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3EL</th>\n",
       "      <td>Cliff top</td>\n",
       "      <td>{}</td>\n",
       "      <td>dBAUTAHpsejsMybVyg9itw</td>\n",
       "      <td>[Public Services &amp; Government, Landmarks &amp; His...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.473910</td>\n",
       "      <td>-0.632580</td>\n",
       "      <td>Whale Bone Arch</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3EE</th>\n",
       "      <td>Various Venues</td>\n",
       "      <td>{}</td>\n",
       "      <td>zvJY4MXpx7DEDTuZFbLYYA</td>\n",
       "      <td>[Arts &amp; Entertainment]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.488251</td>\n",
       "      <td>-0.620374</td>\n",
       "      <td>whitby goth weekend</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3BS</th>\n",
       "      <td>Golden Lion Bank</td>\n",
       "      <td>{'RestaurantsPriceRange2': 4}</td>\n",
       "      <td>bEJoPcxx9QbXfXpGqEIVsw</td>\n",
       "      <td>[Restaurants, Fast Food]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486770</td>\n",
       "      <td>-0.614249</td>\n",
       "      <td>The Greedy Pig</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3AH</th>\n",
       "      <td>Skinner Street</td>\n",
       "      <td>{'RestaurantsPriceRange2': 2}</td>\n",
       "      <td>13hijoKn15lIAOMTuLETHA</td>\n",
       "      <td>[Hotels, Event Planning &amp; Services, Hotels &amp; T...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487158</td>\n",
       "      <td>-0.617332</td>\n",
       "      <td>Resolution Hotel</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3AH</th>\n",
       "      <td>5 B Skinner Street</td>\n",
       "      <td>{}</td>\n",
       "      <td>6sM44QYgFAnpvPHdtJ3smA</td>\n",
       "      <td>[Arts &amp; Entertainment, Arts &amp; Crafts, Shopping...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486800</td>\n",
       "      <td>-0.617227</td>\n",
       "      <td>Doodlepots</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3AH</th>\n",
       "      <td>35-39 Skinner Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>9hiZaQ8ZX1sno7wICZ64ZQ</td>\n",
       "      <td>[Food, Coffee &amp; Tea, Tea Rooms, Bakeries]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '8:30-17:30', 'Tuesday': '8:30-17:3...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487795</td>\n",
       "      <td>-0.617530</td>\n",
       "      <td>Elizabeth Botham &amp; Sons</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3AD</th>\n",
       "      <td>9 Skinner Street</td>\n",
       "      <td>{'GoodForMeal': {'dessert': False, 'latenight'...</td>\n",
       "      <td>3y5kPTXhLlyG8ZDZy37JpQ</td>\n",
       "      <td>[Food, Restaurants, Patisserie/Cake Shop, Cafes]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Sunday': '11:00-16:00', 'Friday': '10:00-16:...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486977</td>\n",
       "      <td>-0.617231</td>\n",
       "      <td>Beckett's Coffee Shop</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 3</th>\n",
       "      <td>10 Flowergate</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>9i4ftKXTyyzZqjXxd4E77w</td>\n",
       "      <td>[Food, Desserts, Coffee &amp; Tea]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.486328</td>\n",
       "      <td>-0.615492</td>\n",
       "      <td>Sherlock's Coffee House</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 2LY</th>\n",
       "      <td>2 West Lane</td>\n",
       "      <td>{'RestaurantsPriceRange2': 2, 'DogsAllowed': T...</td>\n",
       "      <td>PjzIBRm4pxV_mivCZtmZlw</td>\n",
       "      <td>[Hotels &amp; Travel, Event Planning &amp; Services, H...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.468654</td>\n",
       "      <td>-0.909247</td>\n",
       "      <td>Duke Of Wellington</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 1QL</th>\n",
       "      <td>Bagdale</td>\n",
       "      <td>{'RestaurantsPriceRange2': 3}</td>\n",
       "      <td>RUwIL0j-KkNXPh7On52eQw</td>\n",
       "      <td>[Hotels &amp; Travel, Hotels, Event Planning &amp; Ser...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.484304</td>\n",
       "      <td>-0.619396</td>\n",
       "      <td>Bagdale Hall Hotel &amp; Restaurant</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 1QE</th>\n",
       "      <td>11 Prospect Hill</td>\n",
       "      <td>{}</td>\n",
       "      <td>cr4xCQ0zTtQ8tmQUvQWWVg</td>\n",
       "      <td>[Guest Houses, Hotels &amp; Travel]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.481859</td>\n",
       "      <td>-0.620975</td>\n",
       "      <td>Bats &amp; Broomsticks</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 1EA</th>\n",
       "      <td>9 Marine Parade</td>\n",
       "      <td>{}</td>\n",
       "      <td>nobgXGP5KFEgEkXdI7BxEg</td>\n",
       "      <td>[Local Flavor, Arts &amp; Entertainment, Museums]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.487880</td>\n",
       "      <td>-0.614598</td>\n",
       "      <td>The Bram Stoker Dracula Experience</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 1DH</th>\n",
       "      <td>New Quay Road</td>\n",
       "      <td>{'RestaurantsTableService': True, 'GoodForMeal...</td>\n",
       "      <td>DcA9Zjvx5YdTlaqVuIyAGg</td>\n",
       "      <td>[Seafood, Fish &amp; Chips, British, Restaurants]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '11:30-20:30', 'Tuesday': '11:30-20...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.485670</td>\n",
       "      <td>-0.613968</td>\n",
       "      <td>Trenchers</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 1DH</th>\n",
       "      <td>1, New Quay Road</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>hsObd_dRmpxNGmXjwSYuHg</td>\n",
       "      <td>[Hotels, Hotels &amp; Travel, Event Planning &amp; Ser...</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.485670</td>\n",
       "      <td>-0.613968</td>\n",
       "      <td>Angel Hotel</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO21 1DH</th>\n",
       "      <td>New Quay Road</td>\n",
       "      <td>{}</td>\n",
       "      <td>rvEAhe--QWZ1qnUB16amAg</td>\n",
       "      <td>[Pubs, Nightlife, Bars]</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>{'Monday': '10:00-0:00', 'Tuesday': '10:00-0:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.485285</td>\n",
       "      <td>-0.615054</td>\n",
       "      <td>The Station Inn</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13 9HL</th>\n",
       "      <td>40 Main Street</td>\n",
       "      <td>{'Alcohol': 'beer_and_wine', 'HasTV': True, 'C...</td>\n",
       "      <td>OP8P2ipfWaVRQL-XPQNrBA</td>\n",
       "      <td>[Bars, Pubs, Nightlife]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.250348</td>\n",
       "      <td>-0.480931</td>\n",
       "      <td>The Denison Arms</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13 9DY</th>\n",
       "      <td>Main Street</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>J-9XxZMId2Wwban4h2GOCQ</td>\n",
       "      <td>[Food]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.230372</td>\n",
       "      <td>-0.622911</td>\n",
       "      <td>Anvil Inn Sawdon Near Scarborough</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13 0DA</th>\n",
       "      <td>Burniston Road</td>\n",
       "      <td>{'Alcohol': 'beer_and_wine', 'GoodForKids': Tr...</td>\n",
       "      <td>HonU2pj8I4lMJ60oRuy5OQ</td>\n",
       "      <td>[Restaurants, British]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.303672</td>\n",
       "      <td>-0.424763</td>\n",
       "      <td>Scalby Manor Brewers Fayre Restaurant</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13 0AU</th>\n",
       "      <td>, Hayburn Wyke Cloughton</td>\n",
       "      <td>{'BestNights': {'monday': False, 'tuesday': Fa...</td>\n",
       "      <td>65lsX6xUM8zDG6YKoNn5hA</td>\n",
       "      <td>[Nightlife, Pubs, Bars]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.358867</td>\n",
       "      <td>-0.448141</td>\n",
       "      <td>Hayburn Wyke</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13 0AR</th>\n",
       "      <td>Newlands Lane, Cloughton</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>2hIOkf1KqQpQBBr1FHoKuQ</td>\n",
       "      <td>[Nightlife, Bars, Pubs]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{'Monday': '18:00-20:30', 'Tuesday': '18:00-20...</td>\n",
       "      <td>1</td>\n",
       "      <td>54.348961</td>\n",
       "      <td>-0.447326</td>\n",
       "      <td>Bryherstones Country Inn</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13 0AD</th>\n",
       "      <td>Station Lane, Station House Cloughton</td>\n",
       "      <td>{}</td>\n",
       "      <td>l2M67j_7O0fOJiE28yaREA</td>\n",
       "      <td>[Restaurants, Coffee &amp; Tea, Cafes, Food]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.332609</td>\n",
       "      <td>-0.446601</td>\n",
       "      <td>Station Tea Rooms</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO13</th>\n",
       "      <td>The Old Chapel, Staintondale</td>\n",
       "      <td>{}</td>\n",
       "      <td>MC32egIPifgnPsgwjHu6Sw</td>\n",
       "      <td>[Health &amp; Medical]</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>54.323612</td>\n",
       "      <td>-0.548347</td>\n",
       "      <td>The Healing Touch</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       address  \\\n",
       "postal_code                                                      \n",
       "YO22 5LY     North York Moors National Park, The Green, Goa...   \n",
       "YO22 5AL                                             Goathland   \n",
       "YO22 4RG                                       Robin Hoods Bay   \n",
       "YO22 4NT               Stainsacre Hall, Stainsacre near Whitby   \n",
       "YO22 4JT                                            Abbey Lane   \n",
       "YO22 4DL                                               Harbour   \n",
       "YO22 4DE                                     105 Church Street   \n",
       "YO22 4DE                                         Church Street   \n",
       "YO22 4DB                                            9 Sandgate   \n",
       "YO22 4BH                                      95 Church Street   \n",
       "YO22 4BH                                      95 Church Street   \n",
       "YO22 4BH                                      92 Church Street   \n",
       "YO22 4BG                                      11 Bridge Street   \n",
       "YO22 4BG                                         Bridge Street   \n",
       "YO22 4BA                                          9 Grape Lane   \n",
       "YO22 4AS                                   68-69 Church Street   \n",
       "YO22 4AS                                         Church Street   \n",
       "YO22 4AS                                     163 Church Street   \n",
       "YO22                                                4 Sandgate   \n",
       "YO22                                          87 Church Street   \n",
       "YO22                                              68 Church St   \n",
       "YO21 9AA                                         All over town   \n",
       "YO21 3PZ                                           Khyber Pass   \n",
       "YO21 3PW                                       St Annes Staith   \n",
       "YO21 3PU                                           7 Pier Road   \n",
       "YO21 3PU                                          14 Pier Road   \n",
       "YO21 3PR                                       5 Marine Parade   \n",
       "YO21 3EN                                   West Cliff, The Spa   \n",
       "YO21 3EL                                             Cliff top   \n",
       "YO21 3EE                                        Various Venues   \n",
       "YO21 3BS                                      Golden Lion Bank   \n",
       "YO21 3AH                                        Skinner Street   \n",
       "YO21 3AH                                    5 B Skinner Street   \n",
       "YO21 3AH                                  35-39 Skinner Street   \n",
       "YO21 3AD                                      9 Skinner Street   \n",
       "YO21 3                                           10 Flowergate   \n",
       "YO21 2LY                                           2 West Lane   \n",
       "YO21 1QL                                               Bagdale   \n",
       "YO21 1QE                                      11 Prospect Hill   \n",
       "YO21 1EA                                       9 Marine Parade   \n",
       "YO21 1DH                                         New Quay Road   \n",
       "YO21 1DH                                      1, New Quay Road   \n",
       "YO21 1DH                                         New Quay Road   \n",
       "YO13 9HL                                        40 Main Street   \n",
       "YO13 9DY                                           Main Street   \n",
       "YO13 0DA                                        Burniston Road   \n",
       "YO13 0AU                              , Hayburn Wyke Cloughton   \n",
       "YO13 0AR                              Newlands Lane, Cloughton   \n",
       "YO13 0AD                 Station Lane, Station House Cloughton   \n",
       "YO13                              The Old Chapel, Staintondale   \n",
       "\n",
       "                                                    attributes  \\\n",
       "postal_code                                                      \n",
       "YO22 5LY                         {'RestaurantsPriceRange2': 4}   \n",
       "YO22 5AL                                                    {}   \n",
       "YO22 4RG                                                    {}   \n",
       "YO22 4NT                                                    {}   \n",
       "YO22 4JT                                 {'GoodForKids': True}   \n",
       "YO22 4DL                                                    {}   \n",
       "YO22 4DE     {'RestaurantsPriceRange2': 2, 'BusinessParking...   \n",
       "YO22 4DE     {'BusinessAcceptsCreditCards': True, 'CoatChec...   \n",
       "YO22 4DB                                                    {}   \n",
       "YO22 4BH     {'GoodForMeal': {'dessert': False, 'latenight'...   \n",
       "YO22 4BH     {'BusinessAcceptsCreditCards': True, 'Restaura...   \n",
       "YO22 4BH     {'RestaurantsPriceRange2': 3, 'BusinessParking...   \n",
       "YO22 4BG     {'RestaurantsGoodForGroups': True, 'Restaurant...   \n",
       "YO22 4BG                  {'BusinessAcceptsCreditCards': True}   \n",
       "YO22 4BA     {'GoodForMeal': {'dessert': False, 'latenight'...   \n",
       "YO22 4AS     {'RestaurantsTakeOut': True, 'RestaurantsPrice...   \n",
       "YO22 4AS                                                    {}   \n",
       "YO22 4AS     {'BusinessAcceptsCreditCards': False, 'Restaur...   \n",
       "YO22         {'BusinessAcceptsCreditCards': True, 'Restaura...   \n",
       "YO22         {'BusinessAcceptsCreditCards': True, 'GoodForM...   \n",
       "YO22                             {'RestaurantsPriceRange2': 2}   \n",
       "YO21 9AA                                                    {}   \n",
       "YO21 3PZ                                                    {}   \n",
       "YO21 3PW                                                    {}   \n",
       "YO21 3PU     {'HasTV': True, 'RestaurantsGoodForGroups': Tr...   \n",
       "YO21 3PU     {'GoodForMeal': {'dessert': False, 'latenight'...   \n",
       "YO21 3PR                         {'RestaurantsPriceRange2': 4}   \n",
       "YO21 3EN                                 {'GoodForKids': True}   \n",
       "YO21 3EL                                                    {}   \n",
       "YO21 3EE                                                    {}   \n",
       "YO21 3BS                         {'RestaurantsPriceRange2': 4}   \n",
       "YO21 3AH                         {'RestaurantsPriceRange2': 2}   \n",
       "YO21 3AH                                                    {}   \n",
       "YO21 3AH     {'BusinessAcceptsCreditCards': True, 'Restaura...   \n",
       "YO21 3AD     {'GoodForMeal': {'dessert': False, 'latenight'...   \n",
       "YO21 3       {'BusinessParking': {'garage': False, 'street'...   \n",
       "YO21 2LY     {'RestaurantsPriceRange2': 2, 'DogsAllowed': T...   \n",
       "YO21 1QL                         {'RestaurantsPriceRange2': 3}   \n",
       "YO21 1QE                                                    {}   \n",
       "YO21 1EA                                                    {}   \n",
       "YO21 1DH     {'RestaurantsTableService': True, 'GoodForMeal...   \n",
       "YO21 1DH     {'BusinessAcceptsCreditCards': True, 'Restaura...   \n",
       "YO21 1DH                                                    {}   \n",
       "YO13 9HL     {'Alcohol': 'beer_and_wine', 'HasTV': True, 'C...   \n",
       "YO13 9DY     {'BusinessAcceptsCreditCards': True, 'Restaura...   \n",
       "YO13 0DA     {'Alcohol': 'beer_and_wine', 'GoodForKids': Tr...   \n",
       "YO13 0AU     {'BestNights': {'monday': False, 'tuesday': Fa...   \n",
       "YO13 0AR     {'BusinessParking': {'garage': False, 'street'...   \n",
       "YO13 0AD                                                    {}   \n",
       "YO13                                                        {}   \n",
       "\n",
       "                        business_id  \\\n",
       "postal_code                           \n",
       "YO22 5LY     hMAw6C_-67QgvkGVLaErEg   \n",
       "YO22 5AL     RqUt63tv4T3AvOBDMz34ng   \n",
       "YO22 4RG     Y5VQLoDhjFmJQbSsLyjhAA   \n",
       "YO22 4NT     IaeRHjObw6ydKerDWQ0g4g   \n",
       "YO22 4JT     aWLt4-ADtKb8Nt9Bjgn6FQ   \n",
       "YO22 4DL     ZqjJnu6h0e-y1wth43Vxbg   \n",
       "YO22 4DE     t1DWDiut4Q8hdSXdzlxyew   \n",
       "YO22 4DE     2ueyRysdmvgvqXSfE5DCKw   \n",
       "YO22 4DB     GYAMJdFczYZj61BO34VNWA   \n",
       "YO22 4BH     rn46ViXhb2z28jTqtft9Ng   \n",
       "YO22 4BH     eKhQtfiPiYu6gI2UIghHGQ   \n",
       "YO22 4BH     mMLH2s8vU9xu97HU6r0xsw   \n",
       "YO22 4BG     Zut6vm6AZ-xmag12jywQyw   \n",
       "YO22 4BG     6_CLC99-LkZgD4pEm1VA0g   \n",
       "YO22 4BA     18ZoetuKrH67EaqaXobiew   \n",
       "YO22 4AS     m05JNzmziiAed0UZvxzYGQ   \n",
       "YO22 4AS     eHyDrJiavmOd2PdzeWTszg   \n",
       "YO22 4AS     Z-xY1V3kYwtU4kDcyxwINg   \n",
       "YO22         PCgUcbYxCH6afJsYut1lIA   \n",
       "YO22         FkRUQjJvvkEWUhzXBB8COg   \n",
       "YO22         GasfpvcT2jzFr4EPUQQsLQ   \n",
       "YO21 9AA     CTVzHfy6gtXrD-UzKKSB2A   \n",
       "YO21 3PZ     nKPQKBDzhaJxJYO6nd71zg   \n",
       "YO21 3PW     F5gF7Bn_mWSMV6X8Yu8kMA   \n",
       "YO21 3PU     s5v0gnmwCasyYuLR7-qy0g   \n",
       "YO21 3PU     _Wq-Ei5VKopb--qBHltLjA   \n",
       "YO21 3PR     jMNdRZcHVfVMHNb0U7cnAg   \n",
       "YO21 3EN     hjUTVItTU5pb3rs2Y9iqkQ   \n",
       "YO21 3EL     dBAUTAHpsejsMybVyg9itw   \n",
       "YO21 3EE     zvJY4MXpx7DEDTuZFbLYYA   \n",
       "YO21 3BS     bEJoPcxx9QbXfXpGqEIVsw   \n",
       "YO21 3AH     13hijoKn15lIAOMTuLETHA   \n",
       "YO21 3AH     6sM44QYgFAnpvPHdtJ3smA   \n",
       "YO21 3AH     9hiZaQ8ZX1sno7wICZ64ZQ   \n",
       "YO21 3AD     3y5kPTXhLlyG8ZDZy37JpQ   \n",
       "YO21 3       9i4ftKXTyyzZqjXxd4E77w   \n",
       "YO21 2LY     PjzIBRm4pxV_mivCZtmZlw   \n",
       "YO21 1QL     RUwIL0j-KkNXPh7On52eQw   \n",
       "YO21 1QE     cr4xCQ0zTtQ8tmQUvQWWVg   \n",
       "YO21 1EA     nobgXGP5KFEgEkXdI7BxEg   \n",
       "YO21 1DH     DcA9Zjvx5YdTlaqVuIyAGg   \n",
       "YO21 1DH     hsObd_dRmpxNGmXjwSYuHg   \n",
       "YO21 1DH     rvEAhe--QWZ1qnUB16amAg   \n",
       "YO13 9HL     OP8P2ipfWaVRQL-XPQNrBA   \n",
       "YO13 9DY     J-9XxZMId2Wwban4h2GOCQ   \n",
       "YO13 0DA     HonU2pj8I4lMJ60oRuy5OQ   \n",
       "YO13 0AU     65lsX6xUM8zDG6YKoNn5hA   \n",
       "YO13 0AR     2hIOkf1KqQpQBBr1FHoKuQ   \n",
       "YO13 0AD     l2M67j_7O0fOJiE28yaREA   \n",
       "YO13         MC32egIPifgnPsgwjHu6Sw   \n",
       "\n",
       "                                                    categories         city  \\\n",
       "postal_code                                                                   \n",
       "YO22 5LY     [Gift Shops, Event Planning & Services, Flower...       Whitby   \n",
       "YO22 5AL                     [Train Stations, Hotels & Travel]       Whitby   \n",
       "YO22 4RG     [Public Services & Government, Landmarks & His...       Whitby   \n",
       "YO22 4NT                          [Education, Hotels & Travel]       Whitby   \n",
       "YO22 4JT     [Public Services & Government, Active Life, Pa...       Whitby   \n",
       "YO22 4DL                                     [Hotels & Travel]       Whitby   \n",
       "YO22 4DE                                   [Jewelry, Shopping]       Whitby   \n",
       "YO22 4DE                               [Nightlife, Bars, Pubs]       Whitby   \n",
       "YO22 4DB     [Home & Garden, Shopping, Home Decor, Arts & C...       Whitby   \n",
       "YO22 4BH                             [Restaurants, Vegetarian]       Whitby   \n",
       "YO22 4BH     [Hotels & Travel, Specialty Food, Health Marke...       Whitby   \n",
       "YO22 4BH     [Candy Stores, Specialty Food, Food, Chocolati...       Whitby   \n",
       "YO22 4BG                           [Fish & Chips, Restaurants]       Whitby   \n",
       "YO22 4BG     [Hotels & Travel, Bars, Pubs, Nightlife, Hotel...       Whitby   \n",
       "YO22 4BA                                [Restaurants, Italian]       Whitby   \n",
       "YO22 4AS                           [Restaurants, Fish & Chips]       Whitby   \n",
       "YO22 4AS                               [Bars, Nightlife, Pubs]       Whitby   \n",
       "YO22 4AS     [Coffee & Tea, Event Planning & Services, Food...       Whitby   \n",
       "YO22                   [Flowers & Gifts, Shopping, Gift Shops]       Whitby   \n",
       "YO22         [Hotels, Hotels & Travel, Event Planning & Ser...       Whitby   \n",
       "YO22                                                    [Food]       Whitby   \n",
       "YO21 9AA     [Shopping, Music & DVDs, Festivals, Arts & Ent...       Whitby   \n",
       "YO21 3PZ     [Restaurants, Gluten-Free, Seafood, Fish & Chi...       Whitby   \n",
       "YO21 3PW                               [Bars, Nightlife, Pubs]       Whitby   \n",
       "YO21 3PU                           [Restaurants, Fish & Chips]       Whitby   \n",
       "YO21 3PU     [Coffee & Tea, Fish & Chips, Restaurants, Food...       Whitby   \n",
       "YO21 3PR                                [British, Restaurants]       Whitby   \n",
       "YO21 3EN                       [Arts & Entertainment, Arcades]       Whitby   \n",
       "YO21 3EL     [Public Services & Government, Landmarks & His...       Whitby   \n",
       "YO21 3EE                                [Arts & Entertainment]       Whitby   \n",
       "YO21 3BS                              [Restaurants, Fast Food]       Whitby   \n",
       "YO21 3AH     [Hotels, Event Planning & Services, Hotels & T...       Whitby   \n",
       "YO21 3AH     [Arts & Entertainment, Arts & Crafts, Shopping...       Whitby   \n",
       "YO21 3AH             [Food, Coffee & Tea, Tea Rooms, Bakeries]       Whitby   \n",
       "YO21 3AD      [Food, Restaurants, Patisserie/Cake Shop, Cafes]       Whitby   \n",
       "YO21 3                          [Food, Desserts, Coffee & Tea]       Whitby   \n",
       "YO21 2LY     [Hotels & Travel, Event Planning & Services, H...       Whitby   \n",
       "YO21 1QL     [Hotels & Travel, Hotels, Event Planning & Ser...       Whitby   \n",
       "YO21 1QE                       [Guest Houses, Hotels & Travel]       Whitby   \n",
       "YO21 1EA         [Local Flavor, Arts & Entertainment, Museums]       Whitby   \n",
       "YO21 1DH         [Seafood, Fish & Chips, British, Restaurants]       Whitby   \n",
       "YO21 1DH     [Hotels, Hotels & Travel, Event Planning & Ser...       Whitby   \n",
       "YO21 1DH                               [Pubs, Nightlife, Bars]       Whitby   \n",
       "YO13 9HL                               [Bars, Pubs, Nightlife]  Scarborough   \n",
       "YO13 9DY                                                [Food]  Scarborough   \n",
       "YO13 0DA                                [Restaurants, British]  Scarborough   \n",
       "YO13 0AU                               [Nightlife, Pubs, Bars]  Scarborough   \n",
       "YO13 0AR                               [Nightlife, Bars, Pubs]  Scarborough   \n",
       "YO13 0AD              [Restaurants, Coffee & Tea, Cafes, Food]  Scarborough   \n",
       "YO13                                        [Health & Medical]  Scarborough   \n",
       "\n",
       "                                                         hours  is_open  \\\n",
       "postal_code                                                               \n",
       "YO22 5LY                                                    {}        1   \n",
       "YO22 5AL                                                    {}        1   \n",
       "YO22 4RG                                                    {}        1   \n",
       "YO22 4NT                                                    {}        1   \n",
       "YO22 4JT     {'Sunday': '10:00-16:00', 'Saturday': '10:00-1...        1   \n",
       "YO22 4DL                                                    {}        1   \n",
       "YO22 4DE                                                    {}        1   \n",
       "YO22 4DE                                                    {}        1   \n",
       "YO22 4DB                                                    {}        1   \n",
       "YO22 4BH                                                    {}        1   \n",
       "YO22 4BH     {'Monday': '10:00-17:00', 'Tuesday': '10:00-17...        1   \n",
       "YO22 4BH                                                    {}        1   \n",
       "YO22 4BG                                                    {}        1   \n",
       "YO22 4BG                                                    {}        1   \n",
       "YO22 4BA                                                    {}        1   \n",
       "YO22 4AS                                                    {}        1   \n",
       "YO22 4AS                                                    {}        1   \n",
       "YO22 4AS     {'Monday': '12:00-20:00', 'Tuesday': '12:00-20...        1   \n",
       "YO22                                                        {}        1   \n",
       "YO22                                                        {}        1   \n",
       "YO22                                                        {}        1   \n",
       "YO21 9AA                                                    {}        1   \n",
       "YO21 3PZ     {'Monday': '12:00-20:30', 'Tuesday': '12:00-20...        1   \n",
       "YO21 3PW                                                    {}        1   \n",
       "YO21 3PU                                                    {}        1   \n",
       "YO21 3PU     {'Monday': '11:30-21:00', 'Tuesday': '11:30-21...        1   \n",
       "YO21 3PR                                                    {}        1   \n",
       "YO21 3EN                                                    {}        1   \n",
       "YO21 3EL                                                    {}        1   \n",
       "YO21 3EE                                                    {}        1   \n",
       "YO21 3BS                                                    {}        1   \n",
       "YO21 3AH                                                    {}        1   \n",
       "YO21 3AH                                                    {}        1   \n",
       "YO21 3AH     {'Monday': '8:30-17:30', 'Tuesday': '8:30-17:3...        1   \n",
       "YO21 3AD     {'Sunday': '11:00-16:00', 'Friday': '10:00-16:...        1   \n",
       "YO21 3                                                      {}        1   \n",
       "YO21 2LY                                                    {}        1   \n",
       "YO21 1QL                                                    {}        1   \n",
       "YO21 1QE                                                    {}        1   \n",
       "YO21 1EA                                                    {}        1   \n",
       "YO21 1DH     {'Monday': '11:30-20:30', 'Tuesday': '11:30-20...        1   \n",
       "YO21 1DH                                                    {}        1   \n",
       "YO21 1DH     {'Monday': '10:00-0:00', 'Tuesday': '10:00-0:0...        1   \n",
       "YO13 9HL                                                    {}        1   \n",
       "YO13 9DY                                                    {}        1   \n",
       "YO13 0DA                                                    {}        1   \n",
       "YO13 0AU                                                    {}        1   \n",
       "YO13 0AR     {'Monday': '18:00-20:30', 'Tuesday': '18:00-20...        1   \n",
       "YO13 0AD                                                    {}        1   \n",
       "YO13                                                        {}        1   \n",
       "\n",
       "              latitude  longitude                                        name  \\\n",
       "postal_code                                                                     \n",
       "YO22 5LY     54.400141  -0.715568                             Goathland Hotel   \n",
       "YO22 5AL     54.400509  -0.712087                   Goathland Railway Station   \n",
       "YO22 4RG     54.435489  -0.533031  Robin Hood's Bay - Its History and Origins   \n",
       "YO22 4NT     54.462985  -0.592173                             Stainsacre Hall   \n",
       "YO22 4JT     54.488134  -0.605429                                Whitby Abbey   \n",
       "YO22 4DL     54.489151  -0.611822              Whitby Harbour and Lighthouses   \n",
       "YO22 4DE     54.488492  -0.612049                  One O Five Whitby Jet Shop   \n",
       "YO22 4DE     54.488560  -0.612012                                Duke Of York   \n",
       "YO22 4DB     54.487507  -0.612634                                Whitby Glass   \n",
       "YO22 4BH     54.487908  -0.611981                                Sanders Yard   \n",
       "YO22 4BH     54.487908  -0.611981                             Shepherds Purse   \n",
       "YO22 4BH     54.487798  -0.611953                          Justin Chocolatier   \n",
       "YO22 4BG     54.487225  -0.611883                    Hadley's Fish Restaurant   \n",
       "YO22 4BG     54.487141  -0.612091                           The Dolphin Hotel   \n",
       "YO22 4BA     54.486888  -0.611945                         Moutreys Restaurant   \n",
       "YO22 4AS     54.486334  -0.610744                                Mister Chips   \n",
       "YO22 4AS     54.486334  -0.610744                                  The Fleece   \n",
       "YO22 4AS     54.487033  -0.611580                    Humble Pie 'N' Mash Shop   \n",
       "YO22         54.487507  -0.612634                               Venus Trading   \n",
       "YO22         54.487487  -0.611776                       White Horse & Griffin   \n",
       "YO22         54.486905  -0.611170                        Carols Coffee Corner   \n",
       "YO21 9AA     54.487268  -0.621658                         Whitby Folk Weekend   \n",
       "YO21 3PZ     54.489746  -0.615641                         The Fishermans Wife   \n",
       "YO21 3PW     54.487424  -0.614204                           Jolly Sailors Inn   \n",
       "YO21 3PU     54.488500  -0.614902                                    Quayside   \n",
       "YO21 3PU     54.489062  -0.614969                                 Magpie Cafe   \n",
       "YO21 3PR     54.487880  -0.614598                           Moon and Sixpence   \n",
       "YO21 3EN     54.490859  -0.620487                     Whitby Pavilion Complex   \n",
       "YO21 3EL     54.473910  -0.632580                             Whale Bone Arch   \n",
       "YO21 3EE     54.488251  -0.620374                         whitby goth weekend   \n",
       "YO21 3BS     54.486770  -0.614249                              The Greedy Pig   \n",
       "YO21 3AH     54.487158  -0.617332                            Resolution Hotel   \n",
       "YO21 3AH     54.486800  -0.617227                                  Doodlepots   \n",
       "YO21 3AH     54.487795  -0.617530                     Elizabeth Botham & Sons   \n",
       "YO21 3AD     54.486977  -0.617231                       Beckett's Coffee Shop   \n",
       "YO21 3       54.486328  -0.615492                     Sherlock's Coffee House   \n",
       "YO21 2LY     54.468654  -0.909247                          Duke Of Wellington   \n",
       "YO21 1QL     54.484304  -0.619396             Bagdale Hall Hotel & Restaurant   \n",
       "YO21 1QE     54.481859  -0.620975                          Bats & Broomsticks   \n",
       "YO21 1EA     54.487880  -0.614598          The Bram Stoker Dracula Experience   \n",
       "YO21 1DH     54.485670  -0.613968                                   Trenchers   \n",
       "YO21 1DH     54.485670  -0.613968                                 Angel Hotel   \n",
       "YO21 1DH     54.485285  -0.615054                             The Station Inn   \n",
       "YO13 9HL     54.250348  -0.480931                            The Denison Arms   \n",
       "YO13 9DY     54.230372  -0.622911           Anvil Inn Sawdon Near Scarborough   \n",
       "YO13 0DA     54.303672  -0.424763       Scalby Manor Brewers Fayre Restaurant   \n",
       "YO13 0AU     54.358867  -0.448141                                Hayburn Wyke   \n",
       "YO13 0AR     54.348961  -0.447326                    Bryherstones Country Inn   \n",
       "YO13 0AD     54.332609  -0.446601                           Station Tea Rooms   \n",
       "YO13         54.323612  -0.548347                           The Healing Touch   \n",
       "\n",
       "            neighborhood  review_count  stars state  \n",
       "postal_code                                          \n",
       "YO22 5LY                             4    3.5   NYK  \n",
       "YO22 5AL                             4    4.5   NYK  \n",
       "YO22 4RG                             3    4.5   NYK  \n",
       "YO22 4NT                             3    3.5   NYK  \n",
       "YO22 4JT                            15    4.5   NYK  \n",
       "YO22 4DL                             3    4.5   NYK  \n",
       "YO22 4DE                             4    4.5   NYK  \n",
       "YO22 4DE                             7    4.0   NYK  \n",
       "YO22 4DB                             4    5.0   NYK  \n",
       "YO22 4BH                             5    4.5   NYK  \n",
       "YO22 4BH                             3    4.5   NYK  \n",
       "YO22 4BH                             5    5.0   NYK  \n",
       "YO22 4BG                             3    3.5   NYK  \n",
       "YO22 4BG                             3    2.5   NYK  \n",
       "YO22 4BA                             5    3.5   NYK  \n",
       "YO22 4AS                             8    3.5   NYK  \n",
       "YO22 4AS                             3    4.0   NYK  \n",
       "YO22 4AS                             8    5.0   RCC  \n",
       "YO22                                 5    4.0   NYK  \n",
       "YO22                                 6    3.0   NYK  \n",
       "YO22                                 3    1.5   NYK  \n",
       "YO21 9AA                             3    4.5   NYK  \n",
       "YO21 3PZ                             4    4.0   NYK  \n",
       "YO21 3PW                             3    3.0   NYK  \n",
       "YO21 3PU                             6    3.5   NYK  \n",
       "YO21 3PU                            37    4.5   NYK  \n",
       "YO21 3PR                             6    5.0   NYK  \n",
       "YO21 3EN                             3    4.0   NYK  \n",
       "YO21 3EL                             3    3.5   NYK  \n",
       "YO21 3EE                             4    5.0   NYK  \n",
       "YO21 3BS                             5    4.0   NYK  \n",
       "YO21 3AH                             3    3.5   NYK  \n",
       "YO21 3AH                             3    3.5   NYK  \n",
       "YO21 3AH                             3    4.5   NYK  \n",
       "YO21 3AD                             5    5.0   NYK  \n",
       "YO21 3                               4    4.5   NYK  \n",
       "YO21 2LY                             3    5.0   NYK  \n",
       "YO21 1QL                             4    4.0   NYK  \n",
       "YO21 1QE                             5    4.5   NYK  \n",
       "YO21 1EA                             7    3.0   NYK  \n",
       "YO21 1DH                            17    4.0   NYK  \n",
       "YO21 1DH                             3    3.5   NYK  \n",
       "YO21 1DH                             5    4.5   NYK  \n",
       "YO13 9HL                             8    4.0   NYK  \n",
       "YO13 9DY                             3    3.0   NYK  \n",
       "YO13 0DA                             7    4.0   NYK  \n",
       "YO13 0AU                             4    4.0   NYK  \n",
       "YO13 0AR                             3    4.0   NYK  \n",
       "YO13 0AD                             3    4.5   NYK  \n",
       "YO13                                 3    5.0   NYK  "
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_business.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([99362, 99354, 99352, 99337, 99224, 99223, 99218, 99217, 99216,\n",
       "            99212,\n",
       "            ...\n",
       "             1077,  1075,  1069,  1056,  1040,  1028,  1020,  1013,  1002,\n",
       "             1001],\n",
       "           dtype='int64', name='RegionName', length=4149)"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the Zillow data and the yelp zipcodes \n",
    "df_2 = pd.merge(X_16, yelp_zip, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_one_sm = pd.merge(feature_df_list_swing_mult[0], feature_df_list_swing_mult[1], left_index=True, right_index=True, how='inner')\n",
    "df_two_sm = pd.merge(df_one_sm, feature_df_list_swing_mult[2], left_index=True, right_index=True, how='inner')\n",
    "df_three_sm = pd.merge(df_two_sm, feature_df_list_swing_mult[3], left_index=True, right_index=True, how='inner')\n",
    "df_four_sm = pd.merge(df_three_sm, feature_df_list_swing_mult[4], left_index=True, right_index=True, how='inner')\n",
    "df_five_sm = pd.merge(df_four_sm, feature_df_list_swing_mult[5], left_index=True, right_index=True, how='inner')\n",
    "#df_six = pd.merge(df_five, feature_df_list[6], left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_one_m = pd.merge(feature_df_list_mult[0], feature_df_list_mult[1], left_index=True, right_index=True, how='inner')\n",
    "df_two_m = pd.merge(df_one_m, feature_df_list_mult[2], left_index=True, right_index=True, how='inner')\n",
    "df_three_m = pd.merge(df_two_m, feature_df_list_mult[3], left_index=True, right_index=True, how='inner')\n",
    "df_four_m = pd.merge(df_three_m, feature_df_list_mult[4], left_index=True, right_index=True, how='inner')\n",
    "df_five_m = pd.merge(df_four_m, feature_df_list_mult[5], left_index=True, right_index=True, how='inner')\n",
    "#df_six = pd.merge(df_five, feature_df_list[6], left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2733"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_four_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./zip_2/Zip_MedianListingPricePerSqft_CondoCoop.csv',\n",
       " './zip_2/Zip_MedianListingPricePerSqft_DuplexTriplex.csv',\n",
       " './zip_2/Zip_MedianListingPricePerSqft_Sfr.csv',\n",
       " './zip_2/Zip_MedianPctOfPriceReduction_AllHomes.csv',\n",
       " './zip_2/Zip_MedianPctOfPriceReduction_Condominum.csv',\n",
       " './zip_2/Zip_MedianPctOfPriceReduction_SingleFamilyResidence.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_1Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_2Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_3Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_4Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_5BedroomOrMore.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_AllHomes.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_CondoCoop.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_DuplexTriplex.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_Mfr5Plus.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_Sfr.csv',\n",
       " './zip_2/Zip_MedianRentalPrice_Studio.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_1Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_2Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_3Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_4Bedroom.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_5BedroomOrMore.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_AllHomes.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_CondoCoop.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_DuplexTriplex.csv',\n",
       " './zip_2/Zip_MedianRentalPricePerSqft_Mfr5Plus.csv']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[24:50]\n",
    "# 3, 6, 14, 23, 27, 35, 46, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_ratio(df, col_1, col_2):\n",
    "    y = pd.DataFrame()\n",
    "    y['RegionName'] = df['RegionName']\n",
    "    y['y'] = df[col_2] / df[col_1]\n",
    "    y = y.sort_values('RegionName',ascending=False)\n",
    "    y = y.set_index('RegionName')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = create_y_ratio(read_data_list_2[23], '2016-12', '2017-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.059853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.635848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.013011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.056295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.104116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.438448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y\n",
       "count  10454.000000\n",
       "mean       1.059853\n",
       "std        0.081299\n",
       "min        0.635848\n",
       "25%        1.013011\n",
       "50%        1.056295\n",
       "75%        1.104116\n",
       "max        1.438448"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_cless(y):\n",
    "    y = y\n",
    "    y['y_classes'] = np.where(((y['y'] >= 1) & (y['y'] < 1.1), 4), \n",
    "         (np.where((y['y'] >= 1.1) & (y['y'] < 1.2), 5)), \n",
    "         (np.where((y['y'] >= 1.2) & (y['y'] < 1.3), 6)),\n",
    "         (np.where(y['y'] >= 1.3, 7)),\n",
    "         (np.where((y['y'] < 1) & (y['y'] >= .9), 3)),\n",
    "         (np.where((y['y'] < .9) & (y['y'] >= .8), 2, 1)))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_y_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-6ae5b9e91a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_y_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_y_class' is not defined"
     ]
    }
   ],
   "source": [
    "y_test = create_y_class(y)\n",
    "y_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feature_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s = feature_df_list_swing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_m = df_four_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sm = df_four_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = pd.merge(X_16, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2_df = pd.merge(df_2, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df = pd.merge(X, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xm_df = pd.merge(X_m, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs_df = pd.merge(X_s, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsm_df = pd.merge(X_sm, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2733"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(second_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2012_mean_x</th>\n",
       "      <th>2012_std_x</th>\n",
       "      <th>2012_min_x</th>\n",
       "      <th>2012_max_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2015_gain</th>\n",
       "      <th>2016_mean</th>\n",
       "      <th>2016_std</th>\n",
       "      <th>2016_min</th>\n",
       "      <th>2016_max</th>\n",
       "      <th>2016_swing</th>\n",
       "      <th>2016_change</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.221260</td>\n",
       "      <td>2.939228</td>\n",
       "      <td>9.784779</td>\n",
       "      <td>19.273019</td>\n",
       "      <td>9.488240</td>\n",
       "      <td>-2.825004</td>\n",
       "      <td>11.827926</td>\n",
       "      <td>2.655637</td>\n",
       "      <td>7.767436</td>\n",
       "      <td>16.566353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972509</td>\n",
       "      <td>0.870070</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.851402</td>\n",
       "      <td>0.884729</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>1.032905</td>\n",
       "      <td>0.934708</td>\n",
       "      <td>1.077076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.009130</td>\n",
       "      <td>1.252772</td>\n",
       "      <td>2.616664</td>\n",
       "      <td>2.915912</td>\n",
       "      <td>3.850881</td>\n",
       "      <td>4.847252</td>\n",
       "      <td>3.401679</td>\n",
       "      <td>0.933927</td>\n",
       "      <td>3.306389</td>\n",
       "      <td>4.028423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163792</td>\n",
       "      <td>0.285701</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.280179</td>\n",
       "      <td>0.290911</td>\n",
       "      <td>0.022824</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>0.027667</td>\n",
       "      <td>0.247466</td>\n",
       "      <td>0.068373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.633182</td>\n",
       "      <td>0.813359</td>\n",
       "      <td>0.436835</td>\n",
       "      <td>11.926510</td>\n",
       "      <td>2.688029</td>\n",
       "      <td>-23.062877</td>\n",
       "      <td>4.134850</td>\n",
       "      <td>1.176347</td>\n",
       "      <td>-0.014776</td>\n",
       "      <td>6.645988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527667</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>-0.088000</td>\n",
       "      <td>0.941028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.814587</td>\n",
       "      <td>2.065125</td>\n",
       "      <td>8.193079</td>\n",
       "      <td>17.368975</td>\n",
       "      <td>6.855841</td>\n",
       "      <td>-5.274488</td>\n",
       "      <td>9.678199</td>\n",
       "      <td>1.957905</td>\n",
       "      <td>5.588202</td>\n",
       "      <td>13.952067</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748083</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.018599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.032679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.362419</td>\n",
       "      <td>2.641240</td>\n",
       "      <td>10.021496</td>\n",
       "      <td>18.975319</td>\n",
       "      <td>8.543629</td>\n",
       "      <td>-2.205505</td>\n",
       "      <td>12.403405</td>\n",
       "      <td>2.518386</td>\n",
       "      <td>8.287641</td>\n",
       "      <td>16.839613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.030833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.065823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.495098</td>\n",
       "      <td>3.545311</td>\n",
       "      <td>11.555948</td>\n",
       "      <td>20.799199</td>\n",
       "      <td>11.528685</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>14.357412</td>\n",
       "      <td>3.136168</td>\n",
       "      <td>10.225409</td>\n",
       "      <td>19.448615</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.041845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.106040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.383593</td>\n",
       "      <td>9.054726</td>\n",
       "      <td>15.893417</td>\n",
       "      <td>31.246429</td>\n",
       "      <td>26.778011</td>\n",
       "      <td>8.031676</td>\n",
       "      <td>19.493785</td>\n",
       "      <td>7.867667</td>\n",
       "      <td>15.649228</td>\n",
       "      <td>30.525216</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.570167</td>\n",
       "      <td>0.044676</td>\n",
       "      <td>4.494000</td>\n",
       "      <td>4.618000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>1.161409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.425089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 691 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2011_mean_x  2011_std_x  2011_min_x  2011_max_x  2011_swing_x  \\\n",
       "count   291.000000  291.000000  291.000000  291.000000    291.000000   \n",
       "mean     14.221260    2.939228    9.784779   19.273019      9.488240   \n",
       "std       2.009130    1.252772    2.616664    2.915912      3.850881   \n",
       "min       7.633182    0.813359    0.436835   11.926510      2.688029   \n",
       "25%      12.814587    2.065125    8.193079   17.368975      6.855841   \n",
       "50%      14.362419    2.641240   10.021496   18.975319      8.543629   \n",
       "75%      15.495098    3.545311   11.555948   20.799199     11.528685   \n",
       "max      20.383593    9.054726   15.893417   31.246429     26.778011   \n",
       "\n",
       "       2011_change_x  2012_mean_x  2012_std_x  2012_min_x  2012_max_x  \\\n",
       "count     291.000000   291.000000  291.000000  291.000000  291.000000   \n",
       "mean       -2.825004    11.827926    2.655637    7.767436   16.566353   \n",
       "std         4.847252     3.401679    0.933927    3.306389    4.028423   \n",
       "min       -23.062877     4.134850    1.176347   -0.014776    6.645988   \n",
       "25%        -5.274488     9.678199    1.957905    5.588202   13.952067   \n",
       "50%        -2.205505    12.403405    2.518386    8.287641   16.839613   \n",
       "75%         0.285976    14.357412    3.136168   10.225409   19.448615   \n",
       "max         8.031676    19.493785    7.867667   15.649228   30.525216   \n",
       "\n",
       "          ...       2015_gain   2016_mean    2016_std    2016_min    2016_max  \\\n",
       "count     ...      291.000000  291.000000  291.000000  291.000000  291.000000   \n",
       "mean      ...        0.972509    0.870070    0.011161    0.851402    0.884729   \n",
       "std       ...        0.163792    0.285701    0.008130    0.280179    0.290911   \n",
       "min       ...        0.000000    0.527667    0.001435    0.512000    0.540000   \n",
       "25%       ...        1.000000    0.748083    0.005747    0.733000    0.760000   \n",
       "50%       ...        1.000000    0.816667    0.008758    0.800000    0.824000   \n",
       "75%       ...        1.000000    0.925333    0.013806    0.905000    0.937000   \n",
       "max       ...        1.000000    4.570167    0.044676    4.494000    4.618000   \n",
       "\n",
       "       2016_swing  2016_change    2016_yoy   2016_gain           y  \n",
       "count  291.000000   291.000000  291.000000  291.000000  291.000000  \n",
       "mean     0.033326     0.019993    1.032905    0.934708    1.077076  \n",
       "std      0.022824     0.027356    0.027667    0.247466    0.068373  \n",
       "min      0.006000    -0.088000    0.941028    0.000000    0.941771  \n",
       "25%      0.018000     0.005000    1.018599    1.000000    1.032679  \n",
       "50%      0.028000     0.020000    1.030833    1.000000    1.065823  \n",
       "75%      0.042000     0.034000    1.041845    1.000000    1.106040  \n",
       "max      0.146000     0.118000    1.161409    1.000000    1.425089  \n",
       "\n",
       "[8 rows x 691 columns]"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.dropna(inplace=True)\n",
    "X_2.isnull().sum().sum()\n",
    "X_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347079037800687"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_df['2016_gain'].sum() / len(X_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000_mean_x</th>\n",
       "      <th>2000_std_x</th>\n",
       "      <th>2000_min_x</th>\n",
       "      <th>2000_max_x</th>\n",
       "      <th>2000_swing_x</th>\n",
       "      <th>2000_change_x</th>\n",
       "      <th>2001_mean_x</th>\n",
       "      <th>2001_std_x</th>\n",
       "      <th>2001_min_x</th>\n",
       "      <th>2001_max_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2015_gain</th>\n",
       "      <th>2016_mean</th>\n",
       "      <th>2016_std</th>\n",
       "      <th>2016_min</th>\n",
       "      <th>2016_max</th>\n",
       "      <th>2016_swing</th>\n",
       "      <th>2016_change</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.739977</td>\n",
       "      <td>6.039539</td>\n",
       "      <td>9.340652</td>\n",
       "      <td>28.410314</td>\n",
       "      <td>19.069662</td>\n",
       "      <td>-1.397967</td>\n",
       "      <td>17.495490</td>\n",
       "      <td>6.392419</td>\n",
       "      <td>8.842147</td>\n",
       "      <td>28.839196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339720</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.026257</td>\n",
       "      <td>0.076434</td>\n",
       "      <td>0.050177</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>-1.748281</td>\n",
       "      <td>0.510748</td>\n",
       "      <td>1.067610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.596746</td>\n",
       "      <td>4.863403</td>\n",
       "      <td>8.035894</td>\n",
       "      <td>19.226890</td>\n",
       "      <td>14.779159</td>\n",
       "      <td>16.151423</td>\n",
       "      <td>12.871771</td>\n",
       "      <td>5.612938</td>\n",
       "      <td>8.136627</td>\n",
       "      <td>20.261481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473669</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.010885</td>\n",
       "      <td>0.037293</td>\n",
       "      <td>0.043751</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.047964</td>\n",
       "      <td>164.822264</td>\n",
       "      <td>0.499943</td>\n",
       "      <td>0.073020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.059167</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-88.580000</td>\n",
       "      <td>0.044167</td>\n",
       "      <td>0.033699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.069977</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>-0.121595</td>\n",
       "      <td>-0.024656</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>-0.228894</td>\n",
       "      <td>-10650.532154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.828542</td>\n",
       "      <td>2.490601</td>\n",
       "      <td>3.197500</td>\n",
       "      <td>13.357500</td>\n",
       "      <td>7.937500</td>\n",
       "      <td>-8.280000</td>\n",
       "      <td>6.950833</td>\n",
       "      <td>2.484759</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>12.420000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.045801</td>\n",
       "      <td>0.028555</td>\n",
       "      <td>-0.020620</td>\n",
       "      <td>0.591019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.022508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.622083</td>\n",
       "      <td>4.849436</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>25.155000</td>\n",
       "      <td>15.355000</td>\n",
       "      <td>-1.175000</td>\n",
       "      <td>14.966667</td>\n",
       "      <td>4.961817</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>25.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045193</td>\n",
       "      <td>0.014237</td>\n",
       "      <td>0.023607</td>\n",
       "      <td>0.069847</td>\n",
       "      <td>0.042676</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>1.021689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.062211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.100000</td>\n",
       "      <td>8.378150</td>\n",
       "      <td>13.317500</td>\n",
       "      <td>39.932500</td>\n",
       "      <td>26.380000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>25.228958</td>\n",
       "      <td>8.479304</td>\n",
       "      <td>13.210000</td>\n",
       "      <td>41.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072141</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>0.049174</td>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.062750</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>1.604732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.106966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.092500</td>\n",
       "      <td>37.417051</td>\n",
       "      <td>51.440000</td>\n",
       "      <td>99.370000</td>\n",
       "      <td>97.680000</td>\n",
       "      <td>77.070000</td>\n",
       "      <td>85.063333</td>\n",
       "      <td>43.794022</td>\n",
       "      <td>55.610000</td>\n",
       "      <td>99.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210652</td>\n",
       "      <td>0.093161</td>\n",
       "      <td>0.173223</td>\n",
       "      <td>0.311653</td>\n",
       "      <td>0.246608</td>\n",
       "      <td>0.246608</td>\n",
       "      <td>834.736426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.435638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2000_mean_x   2000_std_x   2000_min_x   2000_max_x  2000_swing_x  \\\n",
       "count  4280.000000  4280.000000  4280.000000  4280.000000   4280.000000   \n",
       "mean     17.739977     6.039539     9.340652    28.410314     19.069662   \n",
       "std      12.596746     4.863403     8.035894    19.226890     14.779159   \n",
       "min       0.059167     0.043589     0.000000     0.290000      0.120000   \n",
       "25%       7.828542     2.490601     3.197500    13.357500      7.937500   \n",
       "50%      15.622083     4.849436     7.560000    25.155000     15.355000   \n",
       "75%      25.100000     8.378150    13.317500    39.932500     26.380000   \n",
       "max      71.092500    37.417051    51.440000    99.370000     97.680000   \n",
       "\n",
       "       2000_change_x  2001_mean_x   2001_std_x   2001_min_x   2001_max_x  \\\n",
       "count    4280.000000  4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean       -1.397967    17.495490     6.392419     8.842147    28.839196   \n",
       "std        16.151423    12.871771     5.612938     8.136627    20.261481   \n",
       "min       -88.580000     0.044167     0.033699     0.000000     0.140000   \n",
       "25%        -8.280000     6.950833     2.484759     2.400000    12.420000   \n",
       "50%        -1.175000    14.966667     4.961817     6.550000    25.080000   \n",
       "75%         5.190000    25.228958     8.479304    13.210000    41.480000   \n",
       "max        77.070000    85.063333    43.794022    55.610000    99.670000   \n",
       "\n",
       "          ...         2015_gain    2016_mean     2016_std     2016_min  \\\n",
       "count     ...       4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean      ...          0.339720     0.049256     0.017040     0.026257   \n",
       "std       ...          0.473669     0.038246     0.010885     0.037293   \n",
       "min       ...          0.000000    -0.069977     0.001964    -0.121595   \n",
       "25%       ...          0.000000     0.022373     0.009304     0.001385   \n",
       "50%       ...          0.000000     0.045193     0.014237     0.023607   \n",
       "75%       ...          1.000000     0.072141     0.021674     0.049174   \n",
       "max       ...          1.000000     0.210652     0.093161     0.173223   \n",
       "\n",
       "          2016_max   2016_swing  2016_change      2016_yoy    2016_gain  \\\n",
       "count  4280.000000  4280.000000  4280.000000   4280.000000  4280.000000   \n",
       "mean      0.076434     0.050177     0.008114     -1.748281     0.510748   \n",
       "std       0.043751     0.030705     0.047964    164.822264     0.499943   \n",
       "min      -0.024656     0.006188    -0.228894 -10650.532154     0.000000   \n",
       "25%       0.045801     0.028555    -0.020620      0.591019     0.000000   \n",
       "50%       0.069847     0.042676     0.009022      1.021689     1.000000   \n",
       "75%       0.100877     0.062750     0.036916      1.604732     1.000000   \n",
       "max       0.311653     0.246608     0.246608    834.736426     1.000000   \n",
       "\n",
       "                 y  \n",
       "count  4280.000000  \n",
       "mean      1.067610  \n",
       "std       0.073020  \n",
       "min       0.790926  \n",
       "25%       1.022508  \n",
       "50%       1.062211  \n",
       "75%       1.106966  \n",
       "max       1.435638  \n",
       "\n",
       "[8 rows x 671 columns]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.dropna(inplace=True)\n",
    "X_16.isnull().sum().sum()\n",
    "X_16.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2_df.iloc[:, :-1].values\n",
    "y_2 = X_2_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16_df = X_16.iloc[:, :-1].values\n",
    "y_16 = X_16.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_df.iloc[:, :-1].values\n",
    "y = X_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s = Xs_df.iloc[:, :-1].values\n",
    "y_s = Xs_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_m = Xm_df.iloc[:, :-1].values\n",
    "y_m = Xm_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sm = Xsm_df.iloc[:, :-1].values\n",
    "y_sm = Xsm_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    291.000000\n",
       "mean       1.077076\n",
       "std        0.068373\n",
       "min        0.941771\n",
       "25%        1.032679\n",
       "50%        1.065823\n",
       "75%        1.106040\n",
       "max        1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_df['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4280.000000\n",
       "mean        1.067610\n",
       "std         0.073020\n",
       "min         0.790926\n",
       "25%         1.022508\n",
       "50%         1.062211\n",
       "75%         1.106966\n",
       "max         1.435638\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.98408333e+01,   5.28288568e+00,   1.26100000e+01, ...,\n",
       "          4.44783710e-02,   1.11710935e+00,   1.00000000e+00],\n",
       "       [  8.59416667e+00,   2.68156148e+00,   4.90000000e+00, ...,\n",
       "          3.36152944e-02,   1.16117045e+00,   1.00000000e+00],\n",
       "       [  9.57916667e+00,   4.12912815e+00,   4.05000000e+00, ...,\n",
       "          2.08722085e-02,   1.76863352e+00,   1.00000000e+00],\n",
       "       ..., \n",
       "       [  3.84833333e+00,   7.56057457e+00,   3.00000000e-02, ...,\n",
       "         -1.84320184e-02,   2.15476923e+01,   1.00000000e+00],\n",
       "       [  7.37000000e+00,   8.97160267e+00,   1.15000000e+00, ...,\n",
       "          1.24468539e-02,   9.77659456e-01,   0.00000000e+00],\n",
       "       [  2.06333333e+00,   1.31138604e+00,   6.10000000e-01, ...,\n",
       "         -1.59529241e-02,   8.84642600e-01,   0.00000000e+00]])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000.0"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94695.609918770569"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = X_2 / 400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16_df = X_16_df / 94650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X / 3299000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s = X_s / 3299000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_m = X_m / 3299000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sm = X_sm / 3299000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6670,)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_s, y_s, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(X_16_df, y_16, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y_m, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(46,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.002)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5336 samples, validate on 1334 samples\n",
      "Epoch 1/2000\n",
      "5336/5336 [==============================] - 5s 926us/step - loss: 1.1111 - val_loss: 1.0666\n",
      "Epoch 2/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 1.0558 - val_loss: 1.0107\n",
      "Epoch 3/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 1.0013 - val_loss: 0.9576\n",
      "Epoch 4/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.9495 - val_loss: 0.9072\n",
      "Epoch 5/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.9002 - val_loss: 0.8591\n",
      "Epoch 6/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.8532 - val_loss: 0.8134\n",
      "Epoch 7/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.8086 - val_loss: 0.7701\n",
      "Epoch 8/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.7661 - val_loss: 0.7289\n",
      "Epoch 9/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.7258 - val_loss: 0.6897\n",
      "Epoch 10/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.6874 - val_loss: 0.6524\n",
      "Epoch 11/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.6509 - val_loss: 0.6170\n",
      "Epoch 12/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.6163 - val_loss: 0.5833\n",
      "Epoch 13/2000\n",
      "5336/5336 [==============================] - 3s 525us/step - loss: 0.5832 - val_loss: 0.5514\n",
      "Epoch 14/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.5517 - val_loss: 0.5209\n",
      "Epoch 15/2000\n",
      "5336/5336 [==============================] - 3s 508us/step - loss: 0.5219 - val_loss: 0.4920\n",
      "Epoch 16/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.4932 - val_loss: 0.4645\n",
      "Epoch 17/2000\n",
      "5336/5336 [==============================] - 3s 534us/step - loss: 0.4664 - val_loss: 0.4384\n",
      "Epoch 18/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.4408 - val_loss: 0.4136\n",
      "Epoch 19/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.4162 - val_loss: 0.3900\n",
      "Epoch 20/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.3931 - val_loss: 0.3676\n",
      "Epoch 21/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.3712 - val_loss: 0.3465\n",
      "Epoch 22/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.3504 - val_loss: 0.3264\n",
      "Epoch 23/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.3310 - val_loss: 0.3075\n",
      "Epoch 24/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.3117 - val_loss: 0.2894\n",
      "Epoch 25/2000\n",
      "5336/5336 [==============================] - 3s 535us/step - loss: 0.2944 - val_loss: 0.2723\n",
      "Epoch 26/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.2769 - val_loss: 0.2561\n",
      "Epoch 27/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.2609 - val_loss: 0.2408\n",
      "Epoch 28/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.2460 - val_loss: 0.2263\n",
      "Epoch 29/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.2316 - val_loss: 0.2126\n",
      "Epoch 30/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.2183 - val_loss: 0.1997\n",
      "Epoch 31/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.2055 - val_loss: 0.1875\n",
      "Epoch 32/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.1932 - val_loss: 0.1761\n",
      "Epoch 33/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.1816 - val_loss: 0.1652\n",
      "Epoch 34/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.1710 - val_loss: 0.1550\n",
      "Epoch 35/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.1608 - val_loss: 0.1453\n",
      "Epoch 36/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.1512 - val_loss: 0.1362\n",
      "Epoch 37/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.1419 - val_loss: 0.1277\n",
      "Epoch 38/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.1335 - val_loss: 0.1196\n",
      "Epoch 39/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.1257 - val_loss: 0.1120\n",
      "Epoch 40/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.1178 - val_loss: 0.1049\n",
      "Epoch 41/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.1107 - val_loss: 0.0981\n",
      "Epoch 42/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.1037 - val_loss: 0.0918\n",
      "Epoch 43/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0978 - val_loss: 0.0859\n",
      "Epoch 44/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0917 - val_loss: 0.0804\n",
      "Epoch 45/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0860 - val_loss: 0.0752\n",
      "Epoch 46/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0807 - val_loss: 0.0703\n",
      "Epoch 47/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0759 - val_loss: 0.0657\n",
      "Epoch 48/2000\n",
      "5336/5336 [==============================] - 3s 531us/step - loss: 0.0712 - val_loss: 0.0615\n",
      "Epoch 49/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0669 - val_loss: 0.0574\n",
      "Epoch 50/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0628 - val_loss: 0.0537\n",
      "Epoch 51/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0590 - val_loss: 0.0502\n",
      "Epoch 52/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0553 - val_loss: 0.0469\n",
      "Epoch 53/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0519 - val_loss: 0.0438\n",
      "Epoch 54/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0487 - val_loss: 0.0410\n",
      "Epoch 55/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0459 - val_loss: 0.0383\n",
      "Epoch 56/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0432 - val_loss: 0.0359\n",
      "Epoch 57/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0405 - val_loss: 0.0336\n",
      "Epoch 58/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0382 - val_loss: 0.0314\n",
      "Epoch 59/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0359 - val_loss: 0.0294\n",
      "Epoch 60/2000\n",
      "5336/5336 [==============================] - 3s 534us/step - loss: 0.0338 - val_loss: 0.0275\n",
      "Epoch 61/2000\n",
      "5336/5336 [==============================] - 3s 556us/step - loss: 0.0319 - val_loss: 0.0258\n",
      "Epoch 62/2000\n",
      "5336/5336 [==============================] - 3s 566us/step - loss: 0.0301 - val_loss: 0.0242\n",
      "Epoch 63/2000\n",
      "5336/5336 [==============================] - 3s 542us/step - loss: 0.0282 - val_loss: 0.0227\n",
      "Epoch 64/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0266 - val_loss: 0.0213\n",
      "Epoch 65/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0252 - val_loss: 0.0200\n",
      "Epoch 66/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0238 - val_loss: 0.0188\n",
      "Epoch 67/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0226 - val_loss: 0.0177\n",
      "Epoch 68/2000\n",
      "5336/5336 [==============================] - 3s 534us/step - loss: 0.0213 - val_loss: 0.0166\n",
      "Epoch 69/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0201 - val_loss: 0.0157\n",
      "Epoch 70/2000\n",
      "5336/5336 [==============================] - 3s 528us/step - loss: 0.0192 - val_loss: 0.0148\n",
      "Epoch 71/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0182 - val_loss: 0.0140\n",
      "Epoch 72/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0173 - val_loss: 0.0132\n",
      "Epoch 73/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 74/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 75/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 76/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 77/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 78/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 79/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 80/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 81/2000\n",
      "5336/5336 [==============================] - 3s 541us/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 82/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 83/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 84/2000\n",
      "5336/5336 [==============================] - 3s 542us/step - loss: 0.0103 - val_loss: 0.0076\n",
      "Epoch 85/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0101 - val_loss: 0.0074\n",
      "Epoch 86/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 87/2000\n",
      "5336/5336 [==============================] - 3s 540us/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 88/2000\n",
      "5336/5336 [==============================] - 3s 558us/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 89/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 90/2000\n",
      "5336/5336 [==============================] - 3s 532us/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 91/2000\n",
      "5336/5336 [==============================] - 3s 574us/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 92/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 93/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 94/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 95/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 96/2000\n",
      "5336/5336 [==============================] - 3s 530us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 97/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 98/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 99/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 100/2000\n",
      "5336/5336 [==============================] - 3s 523us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 101/2000\n",
      "5336/5336 [==============================] - 3s 512us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 102/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 103/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 105/2000\n",
      "5336/5336 [==============================] - 3s 522us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 106/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 107/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 108/2000\n",
      "5336/5336 [==============================] - 3s 508us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 109/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 110/2000\n",
      "5336/5336 [==============================] - 3s 542us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 111/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 112/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 113/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 114/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 115/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 116/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 117/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 118/2000\n",
      "5336/5336 [==============================] - 3s 523us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 119/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 120/2000\n",
      "5336/5336 [==============================] - 3s 541us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 121/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 122/2000\n",
      "5336/5336 [==============================] - 3s 549us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 123/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 124/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 125/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 126/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 127/2000\n",
      "5336/5336 [==============================] - 3s 523us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 128/2000\n",
      "5336/5336 [==============================] - 3s 577us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 129/2000\n",
      "5336/5336 [==============================] - 3s 550us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 130/2000\n",
      "5336/5336 [==============================] - 3s 524us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 131/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 132/2000\n",
      "5336/5336 [==============================] - 3s 622us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 133/2000\n",
      "5336/5336 [==============================] - 3s 569us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 134/2000\n",
      "5336/5336 [==============================] - 3s 569us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 135/2000\n",
      "5336/5336 [==============================] - 3s 581us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 136/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 137/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 138/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 139/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 140/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 141/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 142/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 143/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 144/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 145/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 146/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 147/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 148/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 149/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 150/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 151/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 152/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 154/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 155/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 156/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 157/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 158/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 159/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 160/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 161/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 162/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 163/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 164/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 165/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 166/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 167/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 168/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 169/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 170/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 171/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 172/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 173/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 174/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 175/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 176/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 177/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 178/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 179/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 180/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 181/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 182/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 184/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 185/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 186/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 187/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 188/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 189/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 190/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 191/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 192/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 193/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 194/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 195/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 196/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 197/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 198/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 199/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 200/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 201/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 202/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 203/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 204/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 205/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 206/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 207/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 208/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 209/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 210/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 211/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 212/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 213/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 214/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 215/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 216/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 217/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 218/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 219/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 220/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 221/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 222/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 223/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 224/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 225/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 226/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 227/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 228/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 230/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 231/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 232/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 233/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 234/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 235/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 236/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 237/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 238/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 239/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 240/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 241/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 242/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 243/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 244/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 245/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 246/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 247/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 249/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 250/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 251/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 252/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 253/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 254/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 255/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 256/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 257/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 258/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 259/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 260/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 261/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 262/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 263/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 264/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 265/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 266/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 267/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 268/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 269/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 270/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 271/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 272/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 273/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 274/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 275/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 276/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 277/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 278/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 279/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 280/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 281/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 282/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 283/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 284/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 285/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 286/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 287/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 288/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 289/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 290/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 291/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 292/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 293/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 294/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 295/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 296/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 297/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 298/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 299/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 300/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 301/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 302/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 303/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 304/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 306/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 307/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 308/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 309/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 310/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 311/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 312/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 313/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 314/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 315/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 316/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 317/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 318/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 319/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 320/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 321/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 322/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 323/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 324/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 325/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 326/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 327/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 328/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 329/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 330/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 331/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 332/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 333/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 334/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 335/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 336/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 337/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 338/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 339/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 340/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 341/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 342/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 343/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 344/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 345/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 346/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 347/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 348/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 349/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 350/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 351/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 352/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 353/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 354/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 355/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 356/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 357/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 358/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 359/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 360/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 361/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 362/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 363/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 364/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 365/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 366/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 367/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 368/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 369/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 370/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 371/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 372/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 373/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 374/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 375/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 376/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 377/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 378/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 379/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 380/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 382/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 383/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 384/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 385/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 386/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 387/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 388/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 389/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 390/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 391/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 392/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 393/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 394/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 395/2000\n",
      "5336/5336 [==============================] - 3s 479us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 396/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 397/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 398/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 399/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 400/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 401/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 402/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 403/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 404/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 405/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 406/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 407/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 408/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 409/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 410/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 411/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 412/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 413/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 414/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 415/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 416/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 417/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 418/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 419/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 420/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 421/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 422/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 423/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 424/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 425/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 426/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 427/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 428/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 429/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 430/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 431/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 432/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 433/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 434/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 435/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 436/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 437/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 438/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 439/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 440/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 441/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 442/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 443/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 444/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 445/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 446/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 447/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 448/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 449/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 450/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 451/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 452/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 453/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 454/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 455/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 456/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 458/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 459/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 460/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 461/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 462/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 463/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 464/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 465/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 466/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 467/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 468/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 469/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 470/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 471/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 472/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 473/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 474/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 475/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 477/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 478/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 479/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 480/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 481/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 482/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 483/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 484/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 485/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 486/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 487/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 488/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 489/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 490/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 491/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 492/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 494/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 495/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 496/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 497/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 498/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 499/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 500/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 501/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 502/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 503/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 504/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 505/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 506/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 507/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 508/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 509/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 510/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 511/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 512/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 513/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 514/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 515/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 516/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 517/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 518/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 519/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 520/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 521/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 522/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 523/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 524/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 525/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 526/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 527/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 528/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 529/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 530/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 531/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 532/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 534/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 535/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 536/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 537/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 538/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 539/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 540/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 541/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 542/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 543/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 544/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 545/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 546/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 547/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 548/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 549/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 550/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 551/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 552/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 553/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 554/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 555/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 556/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 557/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 558/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 559/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 560/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 561/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 562/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 563/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 564/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 565/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 566/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 567/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 568/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 569/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 570/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 571/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 572/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 573/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 574/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 575/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 576/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 577/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 578/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 579/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 580/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 581/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 582/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 583/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 584/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 585/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 586/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 587/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 588/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 589/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 590/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 591/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 592/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 593/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 594/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 595/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 596/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 597/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 598/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 599/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 600/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 601/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 602/2000\n",
      "5336/5336 [==============================] - 3s 512us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 603/2000\n",
      "5336/5336 [==============================] - 3s 549us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 604/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 605/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 606/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 607/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 608/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 610/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 611/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 612/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 613/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 614/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 615/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 616/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 617/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 618/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 619/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 620/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 621/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 622/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 623/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 624/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 625/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 626/2000\n",
      "5336/5336 [==============================] - 3s 512us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 627/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 628/2000\n",
      "5336/5336 [==============================] - 2s 301us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 629/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 630/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 631/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 632/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 633/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 634/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 635/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 636/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 637/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 638/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 639/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 640/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 641/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 642/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 643/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 644/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 645/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 646/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 647/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 648/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 649/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 650/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 651/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 652/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 653/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 654/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 655/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 656/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 657/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 658/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 659/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 660/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 661/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 662/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 663/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 664/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 665/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 666/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 667/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 668/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 669/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 670/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 671/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 672/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 673/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 674/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 675/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 676/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 677/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 678/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 679/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 680/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 681/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 682/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 683/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 684/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 686/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 687/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 688/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 689/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 690/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 691/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 692/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 693/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 694/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 695/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 696/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 697/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 698/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 699/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 700/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 701/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 702/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 703/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 704/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 705/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 706/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 707/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 708/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 709/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 710/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 711/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 712/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 713/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 714/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 715/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 716/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 717/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 718/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 719/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 720/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 721/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 722/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 723/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 724/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 725/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 726/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 727/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 728/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 729/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 730/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 731/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 732/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 733/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 734/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 735/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 736/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 737/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 738/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 739/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 740/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 741/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 742/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 743/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 744/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 745/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 746/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 747/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 748/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 749/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 750/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 751/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 752/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 753/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 754/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 755/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 756/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 757/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 758/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 759/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 760/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 762/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 763/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 764/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 765/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 766/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 767/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 768/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 769/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 770/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 771/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 772/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 773/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 774/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 775/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 776/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 777/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 778/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 779/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 780/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 781/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 782/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 783/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 784/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 785/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 786/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 787/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 788/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 789/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 790/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 791/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 792/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 793/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 794/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 795/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 796/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 797/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 798/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 799/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 800/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 801/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 802/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 804/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 805/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 806/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 807/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 808/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 809/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 810/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 811/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 812/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 813/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 814/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 815/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 816/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 817/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 818/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 819/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 820/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 821/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 822/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 823/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 824/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 825/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 826/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 827/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 828/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 829/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 830/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 831/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 832/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 833/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 834/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 835/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 836/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 838/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 839/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 840/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 841/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 842/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 843/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 844/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 845/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 846/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 847/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 848/2000\n",
      "5336/5336 [==============================] - 97s 18ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 849/2000\n",
      "5336/5336 [==============================] - 3s 580us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 850/2000\n",
      "5336/5336 [==============================] - 3s 608us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 851/2000\n",
      "5336/5336 [==============================] - 4s 656us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 852/2000\n",
      "5336/5336 [==============================] - 3s 632us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 853/2000\n",
      "5336/5336 [==============================] - 3s 617us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 854/2000\n",
      "5336/5336 [==============================] - 3s 567us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 855/2000\n",
      "5336/5336 [==============================] - 3s 617us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 856/2000\n",
      "5336/5336 [==============================] - 3s 622us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 857/2000\n",
      "5336/5336 [==============================] - 3s 636us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 858/2000\n",
      "5336/5336 [==============================] - 3s 568us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 859/2000\n",
      "5336/5336 [==============================] - 3s 542us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 860/2000\n",
      "5336/5336 [==============================] - 3s 653us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 861/2000\n",
      "5336/5336 [==============================] - 3s 532us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 862/2000\n",
      "5336/5336 [==============================] - 3s 557us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 863/2000\n",
      "5336/5336 [==============================] - 3s 538us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 864/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 865/2000\n",
      "5336/5336 [==============================] - 3s 531us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 866/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 867/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 868/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 869/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 870/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 871/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 872/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 873/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 874/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 875/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 876/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 877/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 878/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 879/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 880/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 881/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 882/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 883/2000\n",
      "5336/5336 [==============================] - 3s 556us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 884/2000\n",
      "5336/5336 [==============================] - 3s 596us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 885/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 886/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 887/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 888/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 889/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 890/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 891/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 892/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 893/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 894/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 895/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 896/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 897/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 898/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 899/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 900/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 901/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 902/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 903/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 904/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 905/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 906/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 907/2000\n",
      "5336/5336 [==============================] - 3s 478us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 908/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 909/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 910/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 911/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 912/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 914/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 915/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 916/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 917/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 918/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 919/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 920/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 921/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 922/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 923/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 925/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 926/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 927/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 928/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 929/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 930/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 931/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 932/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 933/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 934/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 935/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 936/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 937/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 938/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 939/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 940/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 941/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 942/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 943/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 944/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 945/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 946/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 947/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 948/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 949/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 950/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 951/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 952/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 953/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 954/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 955/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 956/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 957/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 958/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 959/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 960/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 961/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 962/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 963/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 964/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 965/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 966/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 967/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 968/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 969/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 970/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 971/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 972/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 973/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 974/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 975/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 976/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 977/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 978/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 979/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 980/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 981/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 982/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 983/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 984/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 985/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 986/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 987/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 988/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 990/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 991/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 992/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 993/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 994/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 995/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 996/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 997/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 998/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 999/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1000/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1001/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1002/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1003/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1004/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1005/2000\n",
      "5336/5336 [==============================] - 3s 479us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1006/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1007/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1008/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1009/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1010/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1011/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1012/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1013/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1014/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1015/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1016/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1017/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1018/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1019/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1020/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1021/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1022/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1023/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1024/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1025/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1026/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1027/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1028/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1029/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1030/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1031/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1032/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1033/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1034/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1035/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1036/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1037/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1038/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1039/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1040/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1041/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1042/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1043/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1044/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1045/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1046/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1047/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1048/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1049/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1050/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1051/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1052/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1053/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1054/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1055/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1056/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1057/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1058/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1059/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1060/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1061/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1062/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1063/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1064/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1065/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1066/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1067/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1068/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1069/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1070/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1071/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1072/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1073/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1074/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1075/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1076/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1077/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1078/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1079/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1080/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1081/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1082/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1083/2000\n",
      "5336/5336 [==============================] - 3s 597us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1084/2000\n",
      "5336/5336 [==============================] - 3s 597us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1085/2000\n",
      "5336/5336 [==============================] - 3s 595us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1086/2000\n",
      "5336/5336 [==============================] - 3s 600us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1087/2000\n",
      "5336/5336 [==============================] - 3s 606us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1088/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1089/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1090/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1091/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1092/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1093/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1094/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1095/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1096/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1097/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1098/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1099/2000\n",
      "5336/5336 [==============================] - 3s 567us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1100/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1101/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1102/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1103/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1104/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1105/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1106/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1107/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1108/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1109/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1110/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1111/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1112/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1113/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1114/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1115/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1116/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1117/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1118/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1119/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1120/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1121/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1122/2000\n",
      "5336/5336 [==============================] - 3s 508us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1124/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1125/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1126/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1127/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1128/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1129/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1130/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1131/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1132/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1133/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1134/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1135/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1136/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1137/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1138/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1139/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1140/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1141/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1142/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1143/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1144/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1145/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1146/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1147/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1148/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1149/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1150/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1151/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1152/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1153/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1154/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1155/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1156/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1157/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1158/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1159/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1160/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1161/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1162/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1163/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1164/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1165/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1166/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1167/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1168/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1169/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1170/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1171/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1172/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1173/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1174/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1175/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1176/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1177/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1178/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1179/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1180/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1181/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1182/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1183/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1184/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1185/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1186/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1187/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1188/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1189/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1190/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1191/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1192/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1193/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1194/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1195/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1196/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1197/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1198/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1199/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1200/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1201/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1202/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1203/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1204/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1205/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1206/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1207/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1208/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1209/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1210/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1211/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1213/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1214/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1215/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1216/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1217/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1218/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1219/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1220/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1221/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1222/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1223/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1224/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1225/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1226/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1227/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1228/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1229/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1230/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1231/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1232/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1233/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1234/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1235/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1236/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1237/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1238/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1239/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1240/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1241/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1242/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1243/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1244/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1245/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1246/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1247/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1248/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1249/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1250/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1251/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1252/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1253/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1254/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1255/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1256/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1258/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1259/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1260/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1261/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1262/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1263/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1264/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1265/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1266/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1267/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1268/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1269/2000\n",
      "5336/5336 [==============================] - 3s 479us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1270/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1271/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1272/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1273/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1274/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1275/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1276/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1277/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1278/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1279/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1280/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1281/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1282/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1283/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1284/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1285/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1286/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1287/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1288/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1290/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1291/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1292/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1293/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1294/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1295/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1296/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1297/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1298/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1299/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1300/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1301/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1302/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1303/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1304/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1305/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1306/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1307/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1308/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1309/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1310/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1311/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1312/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1313/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1314/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1315/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1316/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1317/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1318/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1319/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1320/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1321/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1322/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1323/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1324/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1325/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1326/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1327/2000\n",
      "5336/5336 [==============================] - 3s 479us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1328/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1329/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1330/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1331/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1332/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1333/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1334/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1335/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1336/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1337/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1338/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1339/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1340/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1341/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1342/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1343/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1344/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1345/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1346/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1347/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1348/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1349/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1350/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1351/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1352/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1353/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1354/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1355/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1356/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1357/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1358/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1359/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1360/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1361/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1362/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1363/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1364/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1365/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1366/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1367/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1368/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1369/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1370/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1371/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1372/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1373/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1374/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1375/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1376/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1377/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1378/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1379/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1380/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1382/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1383/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1384/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1385/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1386/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1387/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1388/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1389/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1390/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1391/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1392/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1393/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1394/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1395/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1396/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1397/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1398/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1399/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1400/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1401/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1402/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1403/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1404/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1405/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1406/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1407/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1408/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1409/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1410/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1411/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1412/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1413/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1414/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1415/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1416/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1417/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1418/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1419/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1420/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1421/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1422/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1423/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1424/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1425/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1427/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1428/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1429/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1430/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1431/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1432/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1433/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1434/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1435/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1436/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1437/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1438/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1439/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1440/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1441/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1442/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1443/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1444/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1445/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1446/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1448/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1449/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1450/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1451/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1452/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1453/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1454/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1455/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1456/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1457/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1458/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1459/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1460/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1461/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1462/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1463/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1464/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1465/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1466/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1467/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1468/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1469/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1470/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1471/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1473/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1474/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1475/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1476/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1477/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1478/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1479/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1480/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1481/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1482/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1483/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1485/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1486/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1487/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1488/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1489/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1490/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1491/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1492/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1493/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1494/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1495/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1496/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1497/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1498/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1499/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1500/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1501/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1502/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1503/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1504/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1505/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1506/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1507/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1508/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1509/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1510/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1511/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1512/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1513/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1514/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1515/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1516/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1517/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1518/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1519/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1520/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1521/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1522/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1523/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1524/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1525/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1526/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1527/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1528/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1529/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1530/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1531/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1532/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1533/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1534/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1535/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1536/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1537/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1538/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1539/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1540/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1541/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1542/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1543/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1544/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1545/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1546/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1547/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1548/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1549/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1550/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1551/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1552/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1553/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1554/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1555/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1556/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1557/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1558/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1559/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1560/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1561/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1562/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1563/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1564/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1565/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1566/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1567/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1568/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1569/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1570/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1571/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1572/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1573/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1574/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1576/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1577/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1578/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1579/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1580/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1581/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1582/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1583/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1584/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1585/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1586/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1587/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1588/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1590/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1591/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1592/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1593/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1594/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1595/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1596/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1597/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1598/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1599/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1600/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1601/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1602/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1603/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1604/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1605/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1606/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1607/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1608/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1609/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1610/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1611/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1612/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1613/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1614/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1615/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1616/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1617/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1618/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1619/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1620/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1621/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1622/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1623/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1624/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1625/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1626/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1627/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1628/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1629/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1630/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1631/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1632/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1633/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1634/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1635/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1636/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1637/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1638/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1639/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1640/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1641/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1642/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1643/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1644/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1645/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1646/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1647/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1648/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1649/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1650/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1651/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1652/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1653/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1654/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1655/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1656/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1657/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1658/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1659/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1660/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1661/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1662/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1663/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1664/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1665/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1666/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1667/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1668/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1669/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1670/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1671/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1672/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1673/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1674/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1675/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1676/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1677/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1678/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1679/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1680/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1681/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1682/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1683/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1684/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1685/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1686/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1687/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1688/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1689/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1690/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1691/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1692/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1693/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1694/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1695/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1696/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1697/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1698/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1699/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1700/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1701/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1702/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1703/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1704/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1705/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1706/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1707/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1708/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1709/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1710/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1711/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1712/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1713/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1714/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1715/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1716/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1717/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1718/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1719/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1720/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1721/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1722/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1723/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1724/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1725/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1726/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1727/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1728/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1729/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1730/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1731/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1732/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1733/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1734/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1735/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1736/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1737/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1738/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1740/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1741/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1742/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1743/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1744/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1745/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1746/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1747/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1748/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1749/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1750/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1751/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1752/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1753/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1754/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1755/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1756/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1757/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1758/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1759/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1760/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1761/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1762/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1763/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1764/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1765/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1766/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1767/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1768/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1769/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1770/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1771/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1772/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1773/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1774/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1775/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1776/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1777/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1778/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1779/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1780/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1781/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1782/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1783/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1784/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1785/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1787/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1788/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1789/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1790/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1791/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1792/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1793/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1794/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1795/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1796/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1797/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1798/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1799/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1800/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1801/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1802/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1803/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1804/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1805/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1806/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1807/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1808/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1809/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1810/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1811/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1812/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1813/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1814/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1815/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1816/2000\n",
      "5336/5336 [==============================] - 3597s 674ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1817/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1818/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1819/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1820/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1821/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1822/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1823/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1824/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1825/2000\n",
      "5336/5336 [==============================] - 3s 479us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1826/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1827/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1828/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1829/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1830/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1831/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1832/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1833/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1834/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1835/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1836/2000\n",
      "5336/5336 [==============================] - 1241s 233ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1837/2000\n",
      "5336/5336 [==============================] - 4s 689us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1838/2000\n",
      "5336/5336 [==============================] - 3s 622us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1839/2000\n",
      "5336/5336 [==============================] - 4s 687us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1840/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1841/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1842/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1843/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1844/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1845/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1846/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1847/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1848/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1849/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1850/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1851/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1852/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1853/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1854/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1855/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1856/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1857/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1858/2000\n",
      "5336/5336 [==============================] - 3s 524us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1859/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1860/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1861/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1862/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1863/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1864/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1865/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1866/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1867/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1868/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1869/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1870/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1871/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1872/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1873/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1874/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1875/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1876/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1877/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1878/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1879/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1880/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1881/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1882/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1883/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1884/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1885/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1886/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1887/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1888/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1889/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1890/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1891/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1892/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1893/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1894/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1895/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1896/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1897/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1898/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1899/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1900/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1901/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1902/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1903/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1904/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1905/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1906/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1907/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1908/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1909/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1910/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1911/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1912/2000\n",
      "5336/5336 [==============================] - 3s 479us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1913/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1914/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1915/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1916/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1917/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1918/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1919/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1920/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1921/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1922/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1923/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1924/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1925/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1926/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1927/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1928/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1929/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1930/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1931/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1932/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1933/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1934/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1935/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1936/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1937/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1938/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1939/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1940/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1941/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1942/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1943/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1944/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1945/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1946/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1947/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1948/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1949/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1950/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1951/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1952/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1953/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1954/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1955/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1956/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1957/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1958/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1959/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1960/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1961/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1962/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1963/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1964/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1965/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1966/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1967/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1968/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1969/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1970/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1971/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1972/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1973/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1974/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1975/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1976/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1977/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1978/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1979/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1980/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1981/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1982/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1983/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1984/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1985/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1986/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1987/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 1988/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1989/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 1990/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1991/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1992/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1993/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1994/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1995/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1996/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1997/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1998/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 1999/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 2000/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d66ce48>"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(90,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5336 samples, validate on 1334 samples\n",
      "Epoch 1/2000\n",
      "5336/5336 [==============================] - 5s 906us/step - loss: 1.0742 - val_loss: 0.8664\n",
      "Epoch 2/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.8218 - val_loss: 0.6511\n",
      "Epoch 3/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.6200 - val_loss: 0.4853\n",
      "Epoch 4/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.4641 - val_loss: 0.3586\n",
      "Epoch 5/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.3450 - val_loss: 0.2620\n",
      "Epoch 6/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.2540 - val_loss: 0.1897\n",
      "Epoch 7/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.1856 - val_loss: 0.1357\n",
      "Epoch 8/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.1340 - val_loss: 0.0961\n",
      "Epoch 9/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0967 - val_loss: 0.0677\n",
      "Epoch 10/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0694 - val_loss: 0.0474\n",
      "Epoch 11/2000\n",
      "5336/5336 [==============================] - 3s 603us/step - loss: 0.0498 - val_loss: 0.0334\n",
      "Epoch 12/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0362 - val_loss: 0.0237\n",
      "Epoch 13/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0265 - val_loss: 0.0170\n",
      "Epoch 14/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0198 - val_loss: 0.0126\n",
      "Epoch 15/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 16/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 17/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 18/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 19/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 20/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 21/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 22/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 23/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 24/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 25/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 26/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 27/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 28/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 29/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 30/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 31/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 32/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 33/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 34/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 35/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 36/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 37/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 38/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 39/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 40/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 41/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 42/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 43/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 44/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 45/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 46/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 47/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 48/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 49/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 50/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 51/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 52/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 53/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 54/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 55/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 56/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 57/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 58/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 59/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 60/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 61/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 62/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 63/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 64/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 65/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 66/2000\n",
      "5336/5336 [==============================] - 3s 512us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 67/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 68/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 69/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 70/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 71/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 72/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 73/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 74/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 75/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 76/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 77/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 78/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 79/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 80/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 81/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 82/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 83/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 84/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 85/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 86/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 87/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 88/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 89/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 90/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 91/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 92/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 93/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 94/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 95/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 96/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 97/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 98/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 99/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 100/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 101/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 102/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 103/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 105/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 106/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 107/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 108/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 109/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 110/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 111/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 112/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 113/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 114/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 115/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 116/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 117/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 118/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 119/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 120/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 121/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 122/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 124/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 125/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 126/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 127/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 128/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 129/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 130/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 131/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 132/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 133/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 134/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 135/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 136/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 137/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 138/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 139/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 140/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 141/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 142/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 143/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 144/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 145/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 146/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 147/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 148/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 149/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 150/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 151/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 152/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 154/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 155/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 156/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 157/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 158/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 159/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 160/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 161/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 162/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 163/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 164/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 165/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 166/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 167/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 168/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 169/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 170/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 171/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 172/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 173/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 174/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 175/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 176/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 177/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 178/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 179/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 180/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 181/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 182/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 184/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 185/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 186/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 187/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 188/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 189/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 190/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 191/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 192/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 193/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 194/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 195/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 196/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 197/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 198/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 199/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 200/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 201/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 202/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 203/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 204/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 205/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 206/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 207/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 208/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 209/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 210/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 211/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 213/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 214/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 215/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 216/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 217/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 218/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 219/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 220/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 221/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 222/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 223/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 224/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 225/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 226/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 227/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 228/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 230/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 231/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 232/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 233/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 234/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 235/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 236/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 237/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 238/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 239/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 240/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 241/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 242/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 243/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 244/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 245/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 246/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 247/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 249/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 250/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 251/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 252/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 253/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 254/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 255/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 256/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 258/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 259/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 260/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 261/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 262/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 263/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 264/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 265/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 266/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 267/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 268/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 269/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 270/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 271/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 272/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 273/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 274/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 275/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 276/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 277/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 278/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 279/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 280/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 281/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 282/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 283/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 284/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 285/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 286/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 287/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 288/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 289/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 290/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 291/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 292/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 293/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 294/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 295/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 296/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 297/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 298/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 299/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 300/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 301/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 302/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 303/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 304/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 306/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 307/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 308/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 309/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 310/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 311/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 312/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 313/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 314/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 315/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 316/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 317/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 318/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 319/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 320/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 321/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 322/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 323/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 324/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 325/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 326/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 327/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 328/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 329/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 330/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 331/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 332/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 333/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 334/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 335/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 336/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 337/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 338/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 339/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 340/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 341/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 342/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 343/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 344/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 345/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 346/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 347/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 348/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 349/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 350/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 351/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 352/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 353/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 354/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 355/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 356/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 357/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 358/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 359/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 360/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 361/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 362/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 363/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 364/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 365/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 366/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 367/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 368/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 369/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 370/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 371/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 372/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 373/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 374/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 375/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 376/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 377/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 378/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 379/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 380/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 382/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 383/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 384/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 385/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 386/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 387/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 388/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 389/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 390/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 391/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 392/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 393/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 394/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 395/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 396/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 397/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 398/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 399/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 400/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 401/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 402/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 403/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 404/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 405/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 406/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 407/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 408/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 409/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 410/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 411/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 412/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 413/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 414/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 415/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 416/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 417/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 418/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 419/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 420/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 421/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 422/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 423/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 424/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 425/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 427/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 428/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 429/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 430/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 431/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 432/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 433/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 434/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 435/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 436/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 437/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 438/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 439/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 440/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 441/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 442/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 443/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 444/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 445/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 446/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 448/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 449/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 450/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 451/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 452/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 453/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 454/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 455/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 456/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 458/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 459/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 460/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 461/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 462/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 463/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 464/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 465/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 466/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 467/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 468/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 469/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 470/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 471/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 473/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 474/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 475/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 477/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 478/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 479/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 480/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 481/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 482/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 483/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 485/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 486/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 487/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 488/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 489/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 490/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 491/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 492/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 494/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 495/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 496/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 497/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 498/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 499/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 500/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 501/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 502/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 503/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 504/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 505/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 506/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 507/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 508/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 509/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 510/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 511/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 512/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 513/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 514/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 515/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 516/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 517/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 518/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 519/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 520/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 521/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 522/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 523/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 524/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 525/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 526/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 527/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 528/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 529/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 530/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 531/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 532/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 534/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 535/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 536/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 537/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 538/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 539/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 540/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 541/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 542/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 543/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 544/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 545/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 546/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 547/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 548/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 549/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 550/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 551/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 552/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 553/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 554/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 555/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 556/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 557/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 558/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 559/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 560/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 561/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 562/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 563/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 564/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 565/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 566/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 567/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 568/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 569/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 570/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 571/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 572/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 573/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 574/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 576/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 577/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 578/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 579/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 580/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 581/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 582/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 583/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 584/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 585/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 586/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 587/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 588/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 589/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 590/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 591/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 592/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 593/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 594/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 595/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 596/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 597/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 598/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 599/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 600/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 601/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 602/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 603/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 604/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 605/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 606/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 607/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 608/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/2000\n",
      "5336/5336 [==============================] - 3s 517us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 610/2000\n",
      "5336/5336 [==============================] - 3s 592us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 611/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 612/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 613/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 614/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 615/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 616/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 617/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 618/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 619/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 620/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 621/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 622/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 623/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 624/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 625/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 626/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 627/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 628/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 629/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 630/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 631/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 632/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 633/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 634/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 635/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 636/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 637/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 638/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 639/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 640/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 641/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 642/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 643/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 644/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 645/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 646/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 647/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 648/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 649/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 650/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 651/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 652/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 653/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 654/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 655/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 656/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 657/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 658/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 659/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 660/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 661/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 662/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 663/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 664/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 665/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 666/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 667/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 668/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 669/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 670/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 671/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 672/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 673/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 674/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 675/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 676/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 677/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 678/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 679/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 680/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 681/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 682/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 683/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 684/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 686/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 687/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 688/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 689/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 690/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 691/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 692/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 693/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 694/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 695/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 696/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 697/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 698/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 699/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 700/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 701/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 702/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 703/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 704/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 705/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 706/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 707/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 708/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 709/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 710/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 711/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 712/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 713/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 714/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 715/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 716/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 717/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 718/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 719/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 720/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 721/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 722/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 723/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 724/2000\n",
      "5336/5336 [==============================] - 3034s 569ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 725/2000\n",
      "5336/5336 [==============================] - 3s 653us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 726/2000\n",
      "5336/5336 [==============================] - 4s 680us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 727/2000\n",
      "5336/5336 [==============================] - 4s 767us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 728/2000\n",
      "5336/5336 [==============================] - 5s 891us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 729/2000\n",
      "5336/5336 [==============================] - 5s 930us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 730/2000\n",
      "5336/5336 [==============================] - 4s 750us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 731/2000\n",
      "5336/5336 [==============================] - 5s 853us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 732/2000\n",
      "5336/5336 [==============================] - 5s 959us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 733/2000\n",
      "5336/5336 [==============================] - 5s 951us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 734/2000\n",
      "5336/5336 [==============================] - 4s 704us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 735/2000\n",
      "5336/5336 [==============================] - 5s 859us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 736/2000\n",
      "5336/5336 [==============================] - 4s 835us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 737/2000\n",
      "5336/5336 [==============================] - 5s 989us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 738/2000\n",
      "5336/5336 [==============================] - 5s 950us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 739/2000\n",
      "5336/5336 [==============================] - 3s 561us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 740/2000\n",
      "5336/5336 [==============================] - 3s 540us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 741/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 742/2000\n",
      "5336/5336 [==============================] - 3s 569us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 743/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 744/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 745/2000\n",
      "5336/5336 [==============================] - 3s 628us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 746/2000\n",
      "5336/5336 [==============================] - 3s 577us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 747/2000\n",
      "5336/5336 [==============================] - 3s 566us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 748/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 749/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 750/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 751/2000\n",
      "5336/5336 [==============================] - 3s 635us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 752/2000\n",
      "5336/5336 [==============================] - 3s 546us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 753/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 754/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 755/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 756/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 757/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 758/2000\n",
      "5336/5336 [==============================] - 3s 537us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 759/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 760/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 762/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 763/2000\n",
      "5336/5336 [==============================] - 3s 553us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 764/2000\n",
      "5336/5336 [==============================] - 3s 557us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 765/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 766/2000\n",
      "5336/5336 [==============================] - 3s 523us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 767/2000\n",
      "5336/5336 [==============================] - 3s 528us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 768/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 769/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 770/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 771/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 772/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 773/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 774/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 775/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 776/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 777/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 778/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 779/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 780/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 781/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 782/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 783/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 784/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 785/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 787/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 788/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 789/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 790/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 791/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 792/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 793/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 794/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 795/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 796/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 797/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 798/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 799/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 800/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 801/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 802/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 804/2000\n",
      "5336/5336 [==============================] - 3s 529us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 805/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 806/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 807/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 808/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 809/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 810/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 811/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 812/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 813/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 814/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 815/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 816/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 817/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 818/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 819/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 820/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 821/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 822/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 823/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 824/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 825/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 826/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 827/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 828/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 829/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 830/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 831/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 832/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 833/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 834/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 835/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 836/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 838/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 839/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 840/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 841/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 842/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 843/2000\n",
      "5336/5336 [==============================] - 3s 520us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 844/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 845/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 846/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 847/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 848/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 849/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 850/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 851/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 852/2000\n",
      "5336/5336 [==============================] - 3s 524us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 853/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 854/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 855/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 856/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 857/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 858/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 859/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 860/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 861/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 862/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 863/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 864/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 865/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 866/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 867/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 868/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 869/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 870/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 871/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 872/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 873/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 874/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 875/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 876/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 877/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 878/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 879/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 880/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 881/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 882/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 883/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 884/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 885/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 886/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 887/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 888/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 889/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 890/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 891/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 892/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 893/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 894/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 895/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 896/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 897/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 898/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 899/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 900/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 901/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 902/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 903/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 904/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 905/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 906/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 907/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 908/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 909/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 910/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 911/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 912/2000\n",
      "5336/5336 [==============================] - 3s 517us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 914/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 915/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 916/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 917/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 918/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 919/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 920/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 921/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 922/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 923/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 925/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 926/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 927/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 928/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 929/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 930/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 931/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 932/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 933/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 934/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 935/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 936/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 937/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 938/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 939/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 940/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 941/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 942/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 943/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 944/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 945/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 946/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 947/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 948/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 949/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 950/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 951/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 952/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 953/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 954/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 955/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 956/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 957/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 958/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 959/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 960/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 961/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 962/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 963/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 964/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 965/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 966/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 967/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 968/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 969/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 970/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 971/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 972/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 973/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 974/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 975/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 976/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 977/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 978/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 979/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 980/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 981/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 982/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 983/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 984/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 985/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 986/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 987/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 988/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 990/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 991/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 992/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 993/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 994/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 995/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 996/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 997/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 998/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 999/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1000/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1001/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1002/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1003/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1004/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1005/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1006/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1007/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1008/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1009/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1010/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1011/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1012/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1013/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1014/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1015/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1016/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1017/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1018/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1019/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1020/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1021/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1022/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1023/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1024/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1025/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1026/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 1027/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1028/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1029/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1030/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1031/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1032/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1033/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1034/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1035/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1036/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1037/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1038/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1039/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1040/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1041/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1042/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1043/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1044/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1045/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1046/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1047/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1048/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1049/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1050/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1051/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1052/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1053/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1054/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1055/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1056/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1057/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1058/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1059/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1060/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1061/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1062/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1063/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1064/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1065/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1066/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1067/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1068/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1069/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1070/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1071/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1072/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1073/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1074/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1075/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1076/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1077/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1078/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1079/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1080/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1081/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1082/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1083/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1084/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1085/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1086/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1087/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1088/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1089/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1090/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1091/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1092/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1093/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1094/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1095/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1096/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1097/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1098/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1099/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1100/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1101/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1102/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1103/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1105/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1106/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1107/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1108/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1109/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1110/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1111/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1112/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1113/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1114/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1115/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1116/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1117/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1118/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1119/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1120/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1121/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1122/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1124/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1125/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1126/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1127/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1128/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1129/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1130/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1131/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1132/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1133/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1134/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1135/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1136/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1137/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1138/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1139/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1140/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1141/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1142/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1143/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1144/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1145/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1146/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1147/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1148/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1149/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1150/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1151/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1152/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1153/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1154/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1155/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1156/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1157/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1158/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1159/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1160/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1161/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1162/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1163/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1164/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1165/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1166/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1167/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1168/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1169/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1170/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1171/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1172/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1173/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1174/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1175/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1176/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1177/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1178/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1179/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1180/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1181/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1182/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1184/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1185/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1186/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1187/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1188/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1189/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1190/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1191/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1192/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1193/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1194/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1195/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1196/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1197/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1198/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1199/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1200/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1201/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1202/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1203/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1204/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1205/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1206/2000\n",
      "5336/5336 [==============================] - 3s 568us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1207/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1208/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1209/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1210/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1211/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1213/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1214/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1215/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1216/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1217/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1218/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1219/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1220/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1221/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1222/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1223/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1224/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1225/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1226/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1227/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1228/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1229/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1230/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1231/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1232/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1233/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1234/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1235/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1236/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1237/2000\n",
      "5336/5336 [==============================] - 3s 522us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1238/2000\n",
      "5336/5336 [==============================] - 3s 575us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1239/2000\n",
      "5336/5336 [==============================] - 3s 618us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1240/2000\n",
      "5336/5336 [==============================] - 3s 621us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1241/2000\n",
      "5336/5336 [==============================] - 3s 616us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1242/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1243/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1244/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1245/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1246/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1247/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1249/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1250/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1251/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1252/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1253/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1254/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1255/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1256/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1258/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1259/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1260/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1261/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1262/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1263/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1264/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1265/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1266/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1267/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1268/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1269/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1270/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1271/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1272/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1273/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1274/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1275/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1276/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1277/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1278/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1279/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1280/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1281/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1282/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1283/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1284/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1285/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1286/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1287/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1288/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1290/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1291/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1292/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1293/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1294/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1295/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1296/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1297/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1298/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1299/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1300/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1301/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1302/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1303/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1304/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1305/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1306/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1307/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1308/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1309/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1310/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1311/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1312/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1313/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1314/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1315/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1316/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1317/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1318/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1319/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1320/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1321/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1322/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1323/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1324/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1325/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1326/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1327/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1328/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1329/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1330/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1331/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1332/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1333/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1334/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1335/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1336/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1337/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1338/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1339/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1340/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1341/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1342/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1343/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1344/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1345/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1346/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1347/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1348/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1349/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1350/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1351/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1352/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1353/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1354/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1355/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1356/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1357/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1358/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1359/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1360/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1361/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1362/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1363/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1364/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1365/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1366/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1367/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1368/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1369/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1370/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1371/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1372/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1373/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1374/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1375/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1376/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1377/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1378/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1379/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1380/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1382/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1383/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1384/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1385/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1386/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1387/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1388/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1389/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1390/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1391/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1392/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1393/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1394/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1395/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1396/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1397/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1398/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1399/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1400/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1401/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1402/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1403/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1404/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1405/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1406/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1407/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1408/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1409/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1410/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1411/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1412/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1413/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1414/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1415/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1416/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1417/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1418/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1419/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1420/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1421/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1422/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1423/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1424/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1425/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1427/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1428/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1429/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1430/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1431/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1432/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1433/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1434/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1435/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1436/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1437/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1438/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1439/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1440/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1441/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1442/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1443/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1444/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1445/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1446/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1448/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1449/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1450/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1451/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1452/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1453/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1454/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1455/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1456/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1457/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1458/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1459/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1460/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1461/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1462/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1463/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1464/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1465/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1466/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1467/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1468/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1469/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1470/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1471/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1473/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1474/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1475/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1477/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1478/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1479/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1480/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1481/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1482/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1483/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1485/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1486/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1487/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1488/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1489/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1490/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1491/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1492/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1494/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1495/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1496/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1497/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1498/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1499/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1500/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1501/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1502/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1503/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1504/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1505/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1506/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1507/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1508/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1509/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1510/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1511/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1512/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1513/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1514/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1515/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1516/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1517/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1518/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1519/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1520/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1521/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1522/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1523/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1524/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1525/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1526/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1527/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1528/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1529/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1530/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1531/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1532/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1533/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1534/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1535/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1536/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1537/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1538/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1539/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1540/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1541/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1542/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1543/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1544/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1545/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1546/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1547/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1548/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1549/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1550/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1551/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1552/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1553/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1554/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1555/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1556/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1557/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1558/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1559/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1560/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1561/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1562/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1563/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1564/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1565/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1566/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1567/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1568/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1569/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1570/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1571/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1572/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1573/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1574/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1576/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1577/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1578/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1579/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1580/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1581/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1582/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1583/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1584/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1585/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1586/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1587/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1588/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1590/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1591/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1592/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1593/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1594/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1595/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1596/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1597/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1598/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1599/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1600/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1601/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1602/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1603/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1604/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1605/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1606/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1607/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1608/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1609/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1610/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1611/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1612/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1613/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1614/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1615/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1616/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1617/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1618/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1619/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1620/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1621/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1622/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1623/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1624/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1625/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1626/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1627/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1628/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1629/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1630/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1631/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1632/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1633/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1634/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1635/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1636/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1637/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1638/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1639/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1640/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1641/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1642/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1643/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1644/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1645/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1646/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1647/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1648/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1649/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1650/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1651/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1652/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1653/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1654/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1655/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1656/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1657/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1658/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1659/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1660/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1661/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1662/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1663/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1664/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1665/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1666/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1667/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1668/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1669/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1670/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1671/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1672/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1673/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1674/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1675/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1676/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1677/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1678/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1679/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1680/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1681/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1682/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1683/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1684/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1685/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1686/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1687/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1688/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1689/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1690/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1691/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1692/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1693/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1694/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1695/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1696/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1697/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1698/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1699/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1700/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1701/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1702/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1703/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1704/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1705/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1706/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1707/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1708/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1709/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1710/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1711/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1712/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1713/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1714/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1715/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1716/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1717/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1718/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1719/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1720/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1721/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1722/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1723/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1724/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1725/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1726/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1727/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1728/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1729/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1730/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1731/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1732/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1733/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1734/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1735/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1736/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1737/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1738/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1740/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1741/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1742/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1743/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1744/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1745/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1746/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1747/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1748/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1749/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1750/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1751/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1752/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1753/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1754/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1755/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1756/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1757/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1758/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1759/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1760/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1761/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1762/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1763/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1764/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1765/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1766/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1767/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1768/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1769/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1770/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1771/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1772/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1773/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1774/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1775/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1776/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1777/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1778/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1779/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1780/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1781/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1782/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1783/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1784/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1785/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1787/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1788/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1789/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1790/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1791/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1792/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1793/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1794/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1795/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1796/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1797/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1798/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1799/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1800/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1801/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1802/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1804/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1805/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1806/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1807/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1808/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1809/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1810/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1811/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1812/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1813/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1814/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1815/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1816/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1817/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1818/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1819/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1820/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1821/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1822/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1823/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1824/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1825/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1826/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1827/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1828/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1829/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1830/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1831/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1832/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1833/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1834/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1835/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1836/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1837/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1838/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1839/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1840/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1841/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1842/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1843/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1844/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1845/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1846/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1847/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1848/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1849/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1850/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1851/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1852/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1853/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1854/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1855/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1856/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1857/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1858/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1859/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1860/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1861/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1862/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1863/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1864/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1865/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1866/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1867/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1868/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1869/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1870/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1871/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1872/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1873/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1874/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1875/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1876/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1877/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1878/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1879/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1880/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1881/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1882/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1883/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1884/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1885/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1886/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1887/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1888/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1889/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1890/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1891/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1892/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1893/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1894/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1895/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1896/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1897/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1898/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1899/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1900/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1901/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1902/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1903/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1904/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1905/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1906/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1907/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1908/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1909/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1910/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1911/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1912/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1913/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1914/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1915/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1916/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1917/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1918/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1919/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1920/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1921/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1922/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1923/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1925/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1926/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1927/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1928/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1929/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1930/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1931/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1932/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1933/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1934/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1935/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1936/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1937/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1938/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1939/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1940/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1941/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1942/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1943/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1944/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1945/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1946/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1947/2000\n",
      "5336/5336 [==============================] - 3597s 674ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1948/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1949/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1950/2000\n",
      "5336/5336 [==============================] - 3s 536us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1951/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1952/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1953/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1954/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1955/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1956/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1957/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1958/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1959/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1960/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1961/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1962/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1963/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1964/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1965/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1966/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1967/2000\n",
      "5336/5336 [==============================] - 3598s 674ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1968/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1969/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1970/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1971/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1972/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1973/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1974/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1975/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1976/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1977/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1978/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1979/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 1980/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1981/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1982/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1983/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1984/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1985/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 1986/2000\n",
      "5336/5336 [==============================] - 2135s 400ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1987/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1988/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1989/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1990/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1991/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1992/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1993/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1994/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1995/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1996/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1997/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1998/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1999/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 2000/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15455b550>"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_s, y=y_train_s, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_s, y_test_s),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(X_16, y_16, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size= .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.05329405,  1.12662344,  1.08065202, ...,  0.99302723,\n",
       "        1.0074516 ,  1.07181999])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.20542047e-04,   2.94347206e-06,   1.17223911e-04, ...,\n",
       "          1.01317123e-07,   1.00573546e-05,   0.00000000e+00],\n",
       "       [  1.08620399e-04,   2.74134129e-06,   1.05876393e-04, ...,\n",
       "          2.02634245e-07,   1.09090230e-05,   1.01317123e-05],\n",
       "       [  1.15501520e-04,   3.06397696e-06,   1.13069909e-04, ...,\n",
       "          2.22897670e-07,   1.08659813e-05,   1.01317123e-05],\n",
       "       ..., \n",
       "       [  1.01148261e-04,   2.54756143e-06,   9.73657548e-05, ...,\n",
       "          4.45795339e-07,   1.02013002e-05,   1.01317123e-05],\n",
       "       [  1.45533604e-04,   5.09203118e-06,   1.37689970e-04, ...,\n",
       "          9.72644377e-07,   1.07722709e-05,   1.01317123e-05],\n",
       "       [  1.06779804e-04,   4.98123265e-06,   1.02026342e-04, ...,\n",
       "          2.43161094e-07,   1.02495897e-05,   1.01317123e-05]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07416198487095663"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0055 ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(690,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .02\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(1350,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "# Added\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .005\n",
    "sgd = keras.optimizers.SGD(lr=0.005)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(690,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "# Added\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .005\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203 samples, validate on 88 samples\n",
      "Epoch 1/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 2/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 3/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 6/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 7/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 8/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 9/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 10/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 11/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 13/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 15/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 16/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 17/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 18/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 19/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 21/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 22/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 23/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 24/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 25/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-732-3cf934d04b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_2, y=y_train_2, \n",
    "          batch_size=2500, \n",
    "          epochs=30, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_2, y_test_2),\n",
    "          callbacks=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Without new features\n",
    "root = .0040 ** .5\n",
    "# .071\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2400.000000\n",
       "mean        1.066686\n",
       "std         0.065818\n",
       "min         0.831398\n",
       "25%         1.024956\n",
       "50%         1.061385\n",
       "75%         1.101586\n",
       "max         1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2186 samples, validate on 547 samples\n",
      "Epoch 1/2000\n",
      "2186/2186 [==============================] - 3s 2ms/step - loss: 1.1054 - val_loss: 1.0352\n",
      "Epoch 2/2000\n",
      "2186/2186 [==============================] - 1s 502us/step - loss: 1.0320 - val_loss: 0.9584\n",
      "Epoch 3/2000\n",
      "2186/2186 [==============================] - 1s 519us/step - loss: 0.9561 - val_loss: 0.8839\n",
      "Epoch 4/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.8826 - val_loss: 0.8130\n",
      "Epoch 5/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.8131 - val_loss: 0.7462\n",
      "Epoch 6/2000\n",
      "2186/2186 [==============================] - 1s 506us/step - loss: 0.7475 - val_loss: 0.6837\n",
      "Epoch 7/2000\n",
      "2186/2186 [==============================] - 1s 508us/step - loss: 0.6858 - val_loss: 0.6255\n",
      "Epoch 8/2000\n",
      "2186/2186 [==============================] - 1s 505us/step - loss: 0.6284 - val_loss: 0.5714\n",
      "Epoch 9/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.5750 - val_loss: 0.5213\n",
      "Epoch 10/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.5258 - val_loss: 0.4750\n",
      "Epoch 11/2000\n",
      "2186/2186 [==============================] - 1s 540us/step - loss: 0.4802 - val_loss: 0.4323\n",
      "Epoch 12/2000\n",
      "2186/2186 [==============================] - 1s 537us/step - loss: 0.4374 - val_loss: 0.3929\n",
      "Epoch 13/2000\n",
      "2186/2186 [==============================] - 1s 507us/step - loss: 0.3984 - val_loss: 0.3566\n",
      "Epoch 14/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.3623 - val_loss: 0.3233\n",
      "Epoch 15/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.3296 - val_loss: 0.2927\n",
      "Epoch 16/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.2987 - val_loss: 0.2646\n",
      "Epoch 17/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.2709 - val_loss: 0.2389\n",
      "Epoch 18/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.2446 - val_loss: 0.2155\n",
      "Epoch 19/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.2219 - val_loss: 0.1941\n",
      "Epoch 20/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.2004 - val_loss: 0.1746\n",
      "Epoch 21/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.1811 - val_loss: 0.1568\n",
      "Epoch 22/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.1634 - val_loss: 0.1407\n",
      "Epoch 23/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.1468 - val_loss: 0.1261\n",
      "Epoch 24/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.1323 - val_loss: 0.1129\n",
      "Epoch 25/2000\n",
      "2186/2186 [==============================] - 1s 501us/step - loss: 0.1189 - val_loss: 0.1010\n",
      "Epoch 26/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.1068 - val_loss: 0.0902\n",
      "Epoch 27/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0957 - val_loss: 0.0805\n",
      "Epoch 28/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0864 - val_loss: 0.0718\n",
      "Epoch 29/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0774 - val_loss: 0.0640\n",
      "Epoch 30/2000\n",
      "2186/2186 [==============================] - 1s 510us/step - loss: 0.0694 - val_loss: 0.0570\n",
      "Epoch 31/2000\n",
      "2186/2186 [==============================] - 1s 514us/step - loss: 0.0621 - val_loss: 0.0507\n",
      "Epoch 32/2000\n",
      "2186/2186 [==============================] - 1s 678us/step - loss: 0.0556 - val_loss: 0.0451\n",
      "Epoch 33/2000\n",
      "2186/2186 [==============================] - 1s 599us/step - loss: 0.0500 - val_loss: 0.0401\n",
      "Epoch 34/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.0452 - val_loss: 0.0356\n",
      "Epoch 35/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.0402 - val_loss: 0.0317\n",
      "Epoch 36/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0363 - val_loss: 0.0282\n",
      "Epoch 37/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0326 - val_loss: 0.0251\n",
      "Epoch 38/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.0293 - val_loss: 0.0223\n",
      "Epoch 39/2000\n",
      "2186/2186 [==============================] - 1s 524us/step - loss: 0.0262 - val_loss: 0.0199\n",
      "Epoch 40/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0238 - val_loss: 0.0178\n",
      "Epoch 41/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0214 - val_loss: 0.0159\n",
      "Epoch 42/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.0192 - val_loss: 0.0142\n",
      "Epoch 43/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 44/2000\n",
      "2186/2186 [==============================] - 1s 499us/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 45/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 46/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 47/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 48/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 49/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 50/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 51/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 52/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 53/2000\n",
      "2186/2186 [==============================] - 1s 501us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 54/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 55/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 56/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 57/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 58/2000\n",
      "2186/2186 [==============================] - 1s 524us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 59/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 60/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 61/2000\n",
      "2186/2186 [==============================] - 1s 511us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 62/2000\n",
      "2186/2186 [==============================] - 1s 505us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 63/2000\n",
      "2186/2186 [==============================] - 1s 506us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 64/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 65/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 66/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 67/2000\n",
      "2186/2186 [==============================] - 1s 521us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 68/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 69/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 70/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 71/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 72/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 73/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 74/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 75/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 76/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 77/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0043 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 79/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 80/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 81/2000\n",
      "2186/2186 [==============================] - 1s 489us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 82/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 83/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 84/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 85/2000\n",
      "2186/2186 [==============================] - 1s 508us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 86/2000\n",
      "2186/2186 [==============================] - 1s 499us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 87/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 88/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 89/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 90/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 91/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 92/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 93/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 94/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 95/2000\n",
      "2186/2186 [==============================] - 1s 522us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 96/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 97/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 98/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 99/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 100/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 101/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 102/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 103/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 104/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 105/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 106/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 107/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 108/2000\n",
      "2186/2186 [==============================] - 1s 488us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 109/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 110/2000\n",
      "2186/2186 [==============================] - 1s 488us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 111/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 112/2000\n",
      "2186/2186 [==============================] - 1s 489us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 113/2000\n",
      "2186/2186 [==============================] - 1s 513us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 114/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 115/2000\n",
      "2186/2186 [==============================] - 1s 502us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 116/2000\n",
      "2186/2186 [==============================] - 1s 586us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 117/2000\n",
      "2186/2186 [==============================] - 2s 726us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 118/2000\n",
      "2186/2186 [==============================] - 1s 628us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 119/2000\n",
      "2186/2186 [==============================] - 1s 655us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 120/2000\n",
      "2186/2186 [==============================] - 1s 634us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 121/2000\n",
      "2186/2186 [==============================] - 2s 723us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 122/2000\n",
      "2186/2186 [==============================] - 1s 594us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 123/2000\n",
      "2186/2186 [==============================] - 1s 592us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 124/2000\n",
      "2186/2186 [==============================] - 1s 555us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 125/2000\n",
      "2186/2186 [==============================] - 1s 595us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 126/2000\n",
      "2186/2186 [==============================] - 1s 659us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 127/2000\n",
      "2186/2186 [==============================] - 1s 623us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 128/2000\n",
      "2186/2186 [==============================] - 1s 534us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 129/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-562-052235ad6671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing) and new layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2186 samples, validate on 547 samples\n",
      "Epoch 1/2000\n",
      "2186/2186 [==============================] - 9s 4ms/step - loss: 1.1104 - val_loss: 1.0365\n",
      "Epoch 2/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 1.0305 - val_loss: 0.9589\n",
      "Epoch 3/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.9543 - val_loss: 0.8822\n",
      "Epoch 4/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.8791 - val_loss: 0.8091\n",
      "Epoch 5/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.8070 - val_loss: 0.7405\n",
      "Epoch 6/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.7393 - val_loss: 0.6766\n",
      "Epoch 7/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.6760 - val_loss: 0.6172\n",
      "Epoch 8/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.6172 - val_loss: 0.5622\n",
      "Epoch 9/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.5626 - val_loss: 0.5114\n",
      "Epoch 10/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.5124 - val_loss: 0.4645\n",
      "Epoch 11/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.4658 - val_loss: 0.4213\n",
      "Epoch 12/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.4228 - val_loss: 0.3816\n",
      "Epoch 13/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3833 - val_loss: 0.3451\n",
      "Epoch 14/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3474 - val_loss: 0.3117\n",
      "Epoch 15/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3142 - val_loss: 0.2811\n",
      "Epoch 16/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2837 - val_loss: 0.2532\n",
      "Epoch 17/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2559 - val_loss: 0.2277\n",
      "Epoch 18/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2306 - val_loss: 0.2045\n",
      "Epoch 19/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2076 - val_loss: 0.1834\n",
      "Epoch 20/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1868 - val_loss: 0.1643\n",
      "Epoch 21/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1672 - val_loss: 0.1470\n",
      "Epoch 22/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1500 - val_loss: 0.1313\n",
      "Epoch 23/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1343 - val_loss: 0.1171\n",
      "Epoch 24/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1203 - val_loss: 0.1044\n",
      "Epoch 25/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1076 - val_loss: 0.0929\n",
      "Epoch 26/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0959 - val_loss: 0.0826\n",
      "Epoch 27/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0856 - val_loss: 0.0734\n",
      "Epoch 28/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0765 - val_loss: 0.0652\n",
      "Epoch 29/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0681 - val_loss: 0.0578\n",
      "Epoch 30/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0607 - val_loss: 0.0513\n",
      "Epoch 31/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0542 - val_loss: 0.0454\n",
      "Epoch 32/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0481 - val_loss: 0.0403\n",
      "Epoch 33/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0428 - val_loss: 0.0357\n",
      "Epoch 34/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0382 - val_loss: 0.0316\n",
      "Epoch 35/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0341 - val_loss: 0.0280\n",
      "Epoch 36/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0249\n",
      "Epoch 37/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0270 - val_loss: 0.0221\n",
      "Epoch 38/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0243 - val_loss: 0.0197\n",
      "Epoch 39/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0217 - val_loss: 0.0175\n",
      "Epoch 40/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 41/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0175 - val_loss: 0.0140\n",
      "Epoch 42/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 43/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 44/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 45/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 46/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 47/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 48/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 49/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 50/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 51/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 52/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 53/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 54/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 55/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 56/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 57/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 58/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 59/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 60/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 61/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 62/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 63/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 64/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 65/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 66/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 67/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 68/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 69/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 70/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 71/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 72/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 73/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 74/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 75/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 76/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 77/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 78/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 80/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 81/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 82/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 83/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 84/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 85/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 86/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 87/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 88/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 89/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 90/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 91/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 92/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 93/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 94/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 95/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 96/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 97/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 98/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 99/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 100/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 101/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 102/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 103/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 104/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 105/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 106/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 107/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 108/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 109/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 110/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 111/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 112/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 113/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 114/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 115/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 116/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 117/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 118/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 119/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 120/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 121/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 122/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 123/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 124/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 125/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 126/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 127/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 128/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 129/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 130/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 131/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 132/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 133/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 134/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 135/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 136/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 137/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 138/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 139/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 140/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 141/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 142/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 143/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 144/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 145/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 146/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 147/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 148/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 149/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 150/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 151/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 152/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 153/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 154/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 155/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 156/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 158/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 159/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 160/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 161/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 162/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 163/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 164/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 165/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 166/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 167/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 168/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 169/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 170/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 171/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 172/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 173/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 174/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 175/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 176/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 177/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 178/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 179/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 180/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 181/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 182/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 183/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 184/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 185/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 186/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 187/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 188/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 189/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 190/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 191/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 192/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 193/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 194/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 195/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 196/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 197/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 198/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 199/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 200/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 201/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 202/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 203/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 204/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 205/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 206/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 207/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 208/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 209/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 210/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 211/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 212/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 213/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 214/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 215/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 216/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 217/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 218/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 219/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 220/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 221/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 222/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 223/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 224/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 225/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 226/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 227/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 228/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 229/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 230/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 231/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 232/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 233/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 234/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 236/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 237/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 238/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 239/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 240/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 241/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 242/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 243/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 244/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 245/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 246/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 247/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 248/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 249/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 250/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 251/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 252/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 253/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 254/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 255/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 256/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 257/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 258/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 259/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 260/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 261/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 262/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 263/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 264/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 265/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 266/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 267/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 268/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 269/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 270/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 271/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 272/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 273/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 274/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 275/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 276/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 277/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 278/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 279/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 280/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 281/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 282/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 283/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 284/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 285/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 286/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 287/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 288/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 289/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 290/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 291/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 292/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 293/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 294/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 295/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 296/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 297/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 298/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 299/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 300/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 301/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 302/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 303/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 304/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 305/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 306/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 307/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 308/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 309/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 310/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 311/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 312/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 314/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 315/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 316/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 317/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 318/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 319/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 320/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 321/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 322/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 323/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 324/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 325/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 326/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 327/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 328/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 329/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 330/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 331/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 332/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 333/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 334/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 335/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 336/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 337/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 338/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 339/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 340/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 341/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 342/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 343/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 344/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 345/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 346/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 347/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 348/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 349/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 350/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 351/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 352/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 353/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 354/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 355/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 356/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 357/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 358/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 359/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 360/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 361/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 362/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 363/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 364/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 365/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 366/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 367/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 368/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 369/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 370/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 371/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 372/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 373/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 374/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 375/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 376/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 377/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 378/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 379/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 380/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 381/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 382/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 383/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 384/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 385/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 386/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 387/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 388/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 389/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 390/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 392/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 393/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 394/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 395/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 396/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 397/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 398/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 399/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 400/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 401/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 402/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 403/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 404/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 405/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 406/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 407/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 408/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 409/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 410/2000\n",
      "2186/2186 [==============================] - 245s 112ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 411/2000\n",
      "2186/2186 [==============================] - 8s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 412/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 413/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 414/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 415/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 416/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 417/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 418/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 419/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 420/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 421/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 422/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 423/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 424/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 425/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 426/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 427/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 428/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 429/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 430/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 431/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 432/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 433/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 434/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 435/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 436/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 437/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 438/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 439/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 440/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 441/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 442/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 443/2000\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing) and new layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.0001)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
