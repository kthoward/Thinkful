{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import keras\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean notebook to be only new \n",
    "- Be able to merge train features and train targets\n",
    "- same with test\n",
    "- be able to then split and run program\n",
    "- test for overfit\n",
    "- create additional features (business/extra features from swing/ extra features from bugs)\n",
    "- run reviews for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        #data = unicode(data, errors='replace')\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "#read_data_list\n",
    "#fail_list\n",
    "list_of_file_names_org = list_of_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Listings_PriceCut_SeasAdj_AllHomes.csv'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset]\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(str)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_df = build_useful_df(read_data_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_list = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 10000:\n",
    "        sixteen_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(useful_df)\n",
    "for num in range(len(useful_df)):\n",
    "    useful_df[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_good = [3, 14, 26, 53, 54, 55, 58, 66, 69, 73, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data = useful_df[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data_list = []\n",
    "for i, data in enumerate(useful_df):\n",
    "    if i in sixteen_good:\n",
    "        final_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MoM</th>\n",
       "      <th>QoQ</th>\n",
       "      <th>YoY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>-0.007928</td>\n",
       "      <td>-0.007928</td>\n",
       "      <td>0.019197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99669</th>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>0.012134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99654</th>\n",
       "      <td>-0.015574</td>\n",
       "      <td>-0.036213</td>\n",
       "      <td>-0.074436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99645</th>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-0.040398</td>\n",
       "      <td>-0.093365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99623</th>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.007314</td>\n",
       "      <td>-0.042949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MoM       QoQ       YoY\n",
       "RegionName                              \n",
       "99705      -0.007928 -0.007928  0.019197\n",
       "99669       0.002829  0.021614  0.012134\n",
       "99654      -0.015574 -0.036213 -0.074436\n",
       "99645      -0.010256 -0.040398 -0.093365\n",
       "99623      -0.002005 -0.007314 -0.042949"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "useful_df[77].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df, past_time_string, now_string):\n",
    "    #df.dropna(inplace=True)\n",
    "    features = pd.DataFrame()\n",
    "    mean = df.loc[:, past_time_string : now_string].mean(axis=1)\n",
    "    features['mean'] = mean\n",
    "    std = df.loc[:, past_time_string : now_string].std(axis=1)\n",
    "    features['std'] = std\n",
    "    mn = df.loc[:, past_time_string : now_string].min(axis=1)\n",
    "    features['min'] = mn\n",
    "    mx = df.loc[:, past_time_string : now_string].max(axis=1)\n",
    "    features['max'] = mx\n",
    "    features['swing'] = mx - mn\n",
    "    change = df[now_string] - df[past_time_string]\n",
    "    features['change'] = change\n",
    "    mean_swing = features['swing'].mean()\n",
    "    features['swing_pos'] = np.where(features['swing']>mean_swing, 1, 0)\n",
    "    big_swing = features['swing'].std() + mean_swing\n",
    "    features['swing_big'] = np.where(features['swing']>big_swing, 1, 0)\n",
    "    features['swing_neg'] = np.where(features['swing']<mean_swing, 1, 0)\n",
    "    swing_big_loss = mean_swing - features['swing'].std() \n",
    "    features['swing_loss_big'] = np.where(features['swing']<swing_big_loss, 1, 0)\n",
    "    #features.dropna(inplace=True)\n",
    "    #features = features.set_index(df.index)\n",
    "    #print(features.iloc[1, :])\n",
    "    return features\n",
    "    \n",
    "# List of data frames only on one now_time\n",
    "def make_modeling_data(df_list, df_for_target, now_string):\n",
    "    df_one = pd.DataFrame()\n",
    "    target = pd.DataFrame()\n",
    "    now_time = pd.to_datetime(now_string)\n",
    "    now_value = df_for_target[now_string]\n",
    "    future_time = now_time + timedelta(days=6*31)\n",
    "    future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    future_value = df_for_target[future_time_string]\n",
    "    target['target'] = future_value/now_value\n",
    "    \n",
    "    \n",
    "    past_time = now_time - timedelta(days=6*31)\n",
    "    past_time_string= past_time.strftime(\"%Y-%m\")\n",
    "    df_to_use_for_features_org= df_list[0].loc[:, :now_string]\n",
    "    features_org = make_features(df_to_use_for_features_org, past_time_string, now_string)\n",
    "    df_one = pd.merge(df_one, features_org, left_index=True, right_index=True, how = 'right')\n",
    "    for i, df in enumerate(df_list[1:]):\n",
    "        ind = str(i)\n",
    "        columns = df.columns\n",
    "        if '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "            df_to_use_for_features= df.loc[:, :now_string]\n",
    "            features = make_features(df_to_use_for_features, past_time_string, now_string)\n",
    "            df_one = df_one.append(features)\n",
    "            \n",
    "    #now_time = pd.to_datetime(now_string)\n",
    "    #now_value = df_for_target[now_string]\n",
    "    #future_time = now_time + timedelta(days=6*31)\n",
    "    #future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    #future_value = df_for_target[future_time_string]\n",
    "            #target = future_value/now_value\n",
    "\n",
    "    \n",
    "    return df_one, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_features, test_targets = make_modeling_data(final_data_list, target_data, \"2017-06\")\n",
    "train_features, train_targets = make_modeling_data(final_data_list, target_data, \"2016-12\")\n",
    "extra_train_features_1, extra_train_targets_1 = make_modeling_data(final_data_list, target_data, '2016-06')\n",
    "train_features = train_features.append(extra_train_features_1)\n",
    "train_targets = train_targets.append(extra_train_targets_1)\n",
    "#df = useful_df[num]\n",
    "#columns = df.columns\n",
    "date_counter = 0\n",
    "for year in [\"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]:\n",
    "    for month in [\"06\",\"12\"]:\n",
    "            new_time = year+\"-\"+month\n",
    "            date_counter += 1\n",
    "            #if '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "                 #   extra_train_features, extra_train_targets = make_modeling_data(df, new_time)\n",
    "                  #  train_features = train_features.append(extra_train_features)\n",
    "                   # train_targets = train_targets.append(extra_train_targets)\n",
    "            extra_train_features, extra_train_targets = make_modeling_data(final_data_list, target_data, new_time)\n",
    "            extra_train_features.dropna(inplace=True)\n",
    "            train_features = train_features.append(extra_train_features)\n",
    "            train_targets = train_targets.append(extra_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.dropna(inplace=True)\n",
    "train_targets.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The way to extrapolate smaller df. Now must finish. Smaller must hae index like merge column\n",
    "train_merge = pd.merge(train_features, train_targets, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = pd.merge(test_features, test_targets, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7471872, 7)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business = df_yelp_business.sort_values('postal_code',ascending=False)\n",
    "df_yelp_business = df_yelp_business.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business_merge = pd.DataFrame()\n",
    "df_yelp_business_merge['review_count'] = df_yelp_business['review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YO22 5LY</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 5AL</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4RG</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4NT</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4JT</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_count\n",
       "postal_code              \n",
       "YO22 5LY                4\n",
       "YO22 5AL                4\n",
       "YO22 4RG                3\n",
       "YO22 4NT                3\n",
       "YO22 4JT               15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_business_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>zeroes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_count, zeroes]\n",
       "Index: []"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_business_merge.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    features[\"my_first_feature\"] = df.iloc[:,-1]/df.iloc[:,-2]\n",
    "    features = features.set_index(df.index)\n",
    "    return features\n",
    "    \n",
    "# List of data frames only on one now_time\n",
    "def make_modeling_data(df_list, df_for_target, now_string):\n",
    "    df_one = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        columns = df.columns\n",
    "        if '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "            df_to_use_for_features= df.loc[:, :now_string]\n",
    "            features = make_features(df_to_use_for_features)\n",
    "            df_one = pd.merge(df_one, features, left_index=True, right_index=True, how = 'right')\n",
    "    \n",
    "    now_time = pd.to_datetime(now_string)\n",
    "    now_value = df_for_target[now_string]\n",
    "    future_time = now_time + timedelta(days=6*31)\n",
    "    future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    future_value = df_for_target[future_time_string]\n",
    "    target = future_value/now_value\n",
    "\n",
    "    \n",
    "    return df_one, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_features, test_targets = make_modeling_data(useful_df, useful_df[23], \"2017-01\")\n",
    "train_features, train_targets = make_modeling_data(useful_df, useful_df[23], \"2016-07\")\n",
    "df = useful_df[num]\n",
    "columns = df.columns\n",
    "for year in [\"2015\",\"2016\"]:\n",
    "    for month in [\"01\",\"07\"]:\n",
    "            new_time = year+\"-\"+month\n",
    "                #if '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "                 #   extra_train_features, extra_train_targets = make_modeling_data(df, new_time)\n",
    "                  #  train_features = train_features.append(extra_train_features)\n",
    "                   # train_targets = train_targets.append(extra_train_targets)\n",
    "            extra_train_features, extra_targets = make_modeling_data(useful_df, useful_df[23], new_time)\n",
    "            train_features = train_features.append(extra_train_features)\n",
    "            train_targets = train_targets.append(extra_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_merge.iloc[:, :-1].values\n",
    "y_train = train_merge.iloc[:, -1].values\n",
    "X_test = test_merge.iloc[:, :-1].values\n",
    "y_test = test_merge.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_per_column(X):\n",
    "    new_array = []\n",
    "    shape = X.shape\n",
    "    columns = shape[1]\n",
    "    for num in range(columns):\n",
    "        mx = X[:, num].max()\n",
    "        if mx == 0:\n",
    "            new_array.append(X[:, num])\n",
    "        else:\n",
    "            X[:, num] = X[:, num] / mx\n",
    "            new_array.append(X[:, num])\n",
    "    new_array = np.array(new_array)\n",
    "    new_array = np.transpose(new_array)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = norm_per_column(X_train)\n",
    "X_test = norm_per_column(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51888, 10)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold overfit model for now\n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(10,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(10,), activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7471872 samples, validate on 51888 samples\n",
      "Epoch 1/10\n",
      "4760000/7471872 [==================>...........] - ETA: 1:22:17 - loss: 0.0070"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, \n",
    "          batch_size=5000, \n",
    "          epochs=10, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss = .00001441 (overfit) = .0038\n",
    "\n",
    "#std = .072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
