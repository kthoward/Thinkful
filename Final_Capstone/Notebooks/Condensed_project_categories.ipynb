{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of importing functions from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import my_practice_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "my_practice_module.hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        #data = unicode(data, errors='replace')\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "#read_data_list\n",
    "#fail_list\n",
    "list_of_file_names_org = list_of_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Listings_PriceCut_SeasAdj_AllHomes.csv'"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset]\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(int)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_df = build_useful_df(read_data_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for file in useful_df:\n",
    "    file_2 = len(file)\n",
    "    len_list.append(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7296,\n",
       " 10949,\n",
       " 10949,\n",
       " 10172,\n",
       " 844,\n",
       " 9597,\n",
       " 7801,\n",
       " 455,\n",
       " 7301,\n",
       " 156,\n",
       " 1316,\n",
       " 5045,\n",
       " 2612,\n",
       " 554,\n",
       " 10131,\n",
       " 1043,\n",
       " 180,\n",
       " 9830,\n",
       " 145,\n",
       " 1470,\n",
       " 5366,\n",
       " 2749,\n",
       " 563,\n",
       " 10521,\n",
       " 1102,\n",
       " 150,\n",
       " 10066,\n",
       " 7801,\n",
       " 455,\n",
       " 7301,\n",
       " 823,\n",
       " 1359,\n",
       " 1083,\n",
       " 174,\n",
       " 15,\n",
       " 2644,\n",
       " 489,\n",
       " 368,\n",
       " 2354,\n",
       " 1954,\n",
       " 647,\n",
       " 616,\n",
       " 1134,\n",
       " 946,\n",
       " 145,\n",
       " 8,\n",
       " 2629,\n",
       " 454,\n",
       " 156,\n",
       " 1906,\n",
       " 1947,\n",
       " 565,\n",
       " 14829,\n",
       " 12960,\n",
       " 12960,\n",
       " 10172,\n",
       " 844,\n",
       " 9597,\n",
       " 15437,\n",
       " 2485,\n",
       " 10196,\n",
       " 13275,\n",
       " 10841,\n",
       " 5558,\n",
       " 15437,\n",
       " 13927,\n",
       " 13927,\n",
       " 5645,\n",
       " 15430,\n",
       " 15430,\n",
       " 15338,\n",
       " 15437,\n",
       " 15558,\n",
       " 15558,\n",
       " 15881,\n",
       " 15881,\n",
       " 15899,\n",
       " 15899,\n",
       " 8637,\n",
       " 8635,\n",
       " 15840,\n",
       " 15840,\n",
       " 14853]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_list = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 10000:\n",
    "        sixteen_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 19.,  11.,   4.,   5.,   0.,   0.,   3.,   1.,   0.,   5.,   2.,\n",
       "          0.,   8.,   4.,   0.,   0.,   3.,   2.,   2.,  14.]),\n",
       " array([  8.00000000e+00,   8.02550000e+02,   1.59710000e+03,\n",
       "          2.39165000e+03,   3.18620000e+03,   3.98075000e+03,\n",
       "          4.77530000e+03,   5.56985000e+03,   6.36440000e+03,\n",
       "          7.15895000e+03,   7.95350000e+03,   8.74805000e+03,\n",
       "          9.54260000e+03,   1.03371500e+04,   1.11317000e+04,\n",
       "          1.19262500e+04,   1.27208000e+04,   1.35153500e+04,\n",
       "          1.43099000e+04,   1.51044500e+04,   1.58990000e+04]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12800e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(len_list, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '1990-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "                    #big swing and gain, big swing and loss, big swing and big gain, big swing and big loss\n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_add(good_range, df_list, pure_feature_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for feature in pure_feature_list:\n",
    "        df = df_list[feature]\n",
    "        feature_df_list.append(df)\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '2011-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    mean_yoy = features[year + '_yoy'].mean()\n",
    "                    features[year + '_yoy_pos'] = np.where(features[year + '_yoy']>mean_yoy, 1, 0)\n",
    "                    big_yoy = features[year + '_yoy'].std() + mean_yoy\n",
    "                    features[year + '_yoy_big'] = np.where(features[year + '_yoy']>big_yoy, 1, 0)\n",
    "                    features[year + '_yoy_neg'] = np.where(features[year + '_yoy']<mean_yoy, 1, 0)\n",
    "                    big_loss = mean_yoy - features[year + '_yoy'].std() \n",
    "                    features[year + '_yoy_loss_big'] = np.where(features[year + '_yoy']<big_loss, 1, 0)\n",
    "                mean_swing = features[year + '_swing'].mean()\n",
    "                features[year + '_swing_pos'] = np.where(features[year + '_swing']>mean_swing, 1, 0)\n",
    "                big_swing = features[year + '_swing'].std() + mean_swing\n",
    "                features[year + '_swing_big'] = np.where(features[year + '_swing']>big_swing, 1, 0)\n",
    "                features[year + '_swing_neg'] = np.where(features[year + '_swing']<mean_swing, 1, 0)\n",
    "                swing_big_loss = mean_swing - features[year + '_swing'].std() \n",
    "                features[year + '_swing_loss_big'] = np.where(features[year + '_swing']<swing_big_loss, 1, 0)\n",
    "                    \n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_bugs(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        df = df.loc[:, '2011-01':'2016-12']\n",
    "        features = pd.DataFrame()\n",
    "        for i, year in enumerate(year_list):\n",
    "            try:\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "                feature_df_list.append(features)\n",
    "            except:\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                #change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                \n",
    "                feature_df_list.append(features)\n",
    "        #    bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_swing(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '2011-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    mean_yoy = features[year + '_yoy'].mean()\n",
    "                    features[year + '_yoy_pos'] = np.where(features[year + '_yoy']>mean_yoy, 1, 0)\n",
    "                    big_yoy = features[year + '_yoy'].std() + mean_yoy\n",
    "                    features[year + '_yoy_big'] = np.where(features[year + '_yoy']>big_yoy, 1, 0)\n",
    "                    features[year + '_yoy_neg'] = np.where(features[year + '_yoy']<mean_yoy, 1, 0)\n",
    "                    big_loss = mean_yoy - features[year + '_yoy'].std() \n",
    "                    features[year + '_yoy_loss_big'] = np.where(features[year + '_yoy']<big_loss, 1, 0)\n",
    "                mean_swing = features[year + '_swing'].mean()\n",
    "                features[year + '_swing_pos'] = np.where(features[year + '_swing']>mean_swing, 1, 0)\n",
    "                big_swing = features[year + '_swing'].std() + mean_swing\n",
    "                features[year + '_swing_big'] = np.where(features[year + '_swing']>big_swing, 1, 0)\n",
    "                features[year + '_swing_neg'] = np.where(features[year + '_swing']<mean_swing, 1, 0)\n",
    "                swing_big_loss = mean_swing - features[year + '_swing'].std() \n",
    "                features[year + '_swing_loss_big'] = np.where(features[year + '_swing']<swing_big_loss, 1, 0)\n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(useful_df)\n",
    "for num in range(len(useful_df)):\n",
    "    useful_df[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_doc_features, bugs = build_feature_list_swing(sixteen_list, useful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Zri_AllHomesPlusMultifamily_Summary.csv'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean</th>\n",
       "      <th>2011_std</th>\n",
       "      <th>2011_min</th>\n",
       "      <th>2011_max</th>\n",
       "      <th>2011_swing</th>\n",
       "      <th>2011_change</th>\n",
       "      <th>2011_swing_pos</th>\n",
       "      <th>2011_swing_big</th>\n",
       "      <th>2011_swing_neg</th>\n",
       "      <th>2011_swing_loss_big</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "      <th>2016_yoy_pos</th>\n",
       "      <th>2016_yoy_big</th>\n",
       "      <th>2016_yoy_neg</th>\n",
       "      <th>2016_yoy_loss_big</th>\n",
       "      <th>2016_swing_pos</th>\n",
       "      <th>2016_swing_big</th>\n",
       "      <th>2016_swing_neg</th>\n",
       "      <th>2016_swing_loss_big</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99801</th>\n",
       "      <td>8.737707</td>\n",
       "      <td>2.668976</td>\n",
       "      <td>3.270054</td>\n",
       "      <td>12.457820</td>\n",
       "      <td>9.187766</td>\n",
       "      <td>-1.638298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>15.292930</td>\n",
       "      <td>4.304947</td>\n",
       "      <td>9.545075</td>\n",
       "      <td>25.197773</td>\n",
       "      <td>15.652698</td>\n",
       "      <td>4.628867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046422</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>14.771745</td>\n",
       "      <td>3.035814</td>\n",
       "      <td>9.219219</td>\n",
       "      <td>20.683859</td>\n",
       "      <td>11.464640</td>\n",
       "      <td>-0.895525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99669</th>\n",
       "      <td>10.946112</td>\n",
       "      <td>1.839319</td>\n",
       "      <td>8.474595</td>\n",
       "      <td>14.084393</td>\n",
       "      <td>5.609798</td>\n",
       "      <td>-4.590275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177421</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99654</th>\n",
       "      <td>13.307311</td>\n",
       "      <td>2.180717</td>\n",
       "      <td>8.626867</td>\n",
       "      <td>16.407887</td>\n",
       "      <td>7.781020</td>\n",
       "      <td>-2.413729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2011_mean  2011_std  2011_min   2011_max  2011_swing  2011_change  \\\n",
       "RegionName                                                                      \n",
       "99801        8.737707  2.668976  3.270054  12.457820    9.187766    -1.638298   \n",
       "99709       15.292930  4.304947  9.545075  25.197773   15.652698     4.628867   \n",
       "99705       14.771745  3.035814  9.219219  20.683859   11.464640    -0.895525   \n",
       "99669       10.946112  1.839319  8.474595  14.084393    5.609798    -4.590275   \n",
       "99654       13.307311  2.180717  8.626867  16.407887    7.781020    -2.413729   \n",
       "\n",
       "            2011_swing_pos  2011_swing_big  2011_swing_neg  \\\n",
       "RegionName                                                   \n",
       "99801                    0               0               1   \n",
       "99709                    1               1               0   \n",
       "99705                    1               0               0   \n",
       "99669                    0               0               1   \n",
       "99654                    0               0               1   \n",
       "\n",
       "            2011_swing_loss_big         ...           2016_yoy  2016_gain  \\\n",
       "RegionName                              ...                                 \n",
       "99801                         0         ...           0.854903          0   \n",
       "99709                         0         ...           1.046422          1   \n",
       "99705                         0         ...           0.960138          0   \n",
       "99669                         1         ...           1.177421          1   \n",
       "99654                         0         ...           0.872533          0   \n",
       "\n",
       "            2016_yoy_pos  2016_yoy_big  2016_yoy_neg  2016_yoy_loss_big  \\\n",
       "RegionName                                                                \n",
       "99801                  0             0             1                  0   \n",
       "99709                  1             0             0                  0   \n",
       "99705                  0             0             1                  0   \n",
       "99669                  1             1             0                  0   \n",
       "99654                  0             0             1                  0   \n",
       "\n",
       "            2016_swing_pos  2016_swing_big  2016_swing_neg  \\\n",
       "RegionName                                                   \n",
       "99801                    1               0               0   \n",
       "99709                    0               0               1   \n",
       "99705                    1               0               0   \n",
       "99669                    1               0               0   \n",
       "99654                    0               0               1   \n",
       "\n",
       "            2016_swing_loss_big  \n",
       "RegionName                       \n",
       "99801                         0  \n",
       "99709                         0  \n",
       "99705                         0  \n",
       "99669                         0  \n",
       "99654                         0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "sixteen_doc_features[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(sixteen_doc_features)\n",
    "for num in range(len(sixteen_doc_features)):\n",
    "    sixteen_doc_features[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bug_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-49fa965fc1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbug_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bug_list' is not defined"
     ]
    }
   ],
   "source": [
    "bug_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging all dfs into one. Merging on indez which is zipcode. I was hoping for inner join but it looks like\n",
    "# There are many zipcodes that only exist in certain dfs. Im hoping that reducing them to metro areas will fix this\n",
    "def merge_dataframes(feature_df_list):\n",
    "    df_1 = feature_df_list[0]\n",
    "    for df in feature_df_list[1:]:\n",
    "        df_1 = pd.merge(df_1, df, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = merge_dataframes(sixteen_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2011_swing_pos_x</th>\n",
       "      <th>2011_swing_big_x</th>\n",
       "      <th>2011_swing_neg_x</th>\n",
       "      <th>2011_swing_loss_big_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_yoy_y</th>\n",
       "      <th>2016_gain_y</th>\n",
       "      <th>2016_yoy_pos_y</th>\n",
       "      <th>2016_yoy_big_y</th>\n",
       "      <th>2016_yoy_neg_y</th>\n",
       "      <th>2016_yoy_loss_big_y</th>\n",
       "      <th>2016_swing_pos_y</th>\n",
       "      <th>2016_swing_big_y</th>\n",
       "      <th>2016_swing_neg_y</th>\n",
       "      <th>2016_swing_loss_big_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99362</th>\n",
       "      <td>11.036472</td>\n",
       "      <td>1.492165</td>\n",
       "      <td>9.400227</td>\n",
       "      <td>14.401968</td>\n",
       "      <td>5.001741</td>\n",
       "      <td>-4.487889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99354</th>\n",
       "      <td>11.603599</td>\n",
       "      <td>2.824071</td>\n",
       "      <td>7.194803</td>\n",
       "      <td>16.110267</td>\n",
       "      <td>8.915463</td>\n",
       "      <td>-1.600303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076721</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99352</th>\n",
       "      <td>12.441976</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>10.501647</td>\n",
       "      <td>14.742676</td>\n",
       "      <td>4.241029</td>\n",
       "      <td>2.483404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072472</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99337</th>\n",
       "      <td>12.516044</td>\n",
       "      <td>1.241358</td>\n",
       "      <td>10.124885</td>\n",
       "      <td>14.400625</td>\n",
       "      <td>4.275740</td>\n",
       "      <td>-2.111852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99336</th>\n",
       "      <td>11.792236</td>\n",
       "      <td>1.516523</td>\n",
       "      <td>8.975535</td>\n",
       "      <td>14.907430</td>\n",
       "      <td>5.931895</td>\n",
       "      <td>2.162776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070530</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2011_mean_x  2011_std_x  2011_min_x  2011_max_x  2011_swing_x  \\\n",
       "RegionName                                                                  \n",
       "99362         11.036472    1.492165    9.400227   14.401968      5.001741   \n",
       "99354         11.603599    2.824071    7.194803   16.110267      8.915463   \n",
       "99352         12.441976    1.441693   10.501647   14.742676      4.241029   \n",
       "99337         12.516044    1.241358   10.124885   14.400625      4.275740   \n",
       "99336         11.792236    1.516523    8.975535   14.907430      5.931895   \n",
       "\n",
       "            2011_change_x  2011_swing_pos_x  2011_swing_big_x  \\\n",
       "RegionName                                                      \n",
       "99362           -4.487889                 0                 0   \n",
       "99354           -1.600303                 0                 0   \n",
       "99352            2.483404                 0                 0   \n",
       "99337           -2.111852                 0                 0   \n",
       "99336            2.162776                 0                 0   \n",
       "\n",
       "            2011_swing_neg_x  2011_swing_loss_big_x          ...            \\\n",
       "RegionName                                                   ...             \n",
       "99362                      1                      1          ...             \n",
       "99354                      1                      0          ...             \n",
       "99352                      1                      1          ...             \n",
       "99337                      1                      1          ...             \n",
       "99336                      1                      1          ...             \n",
       "\n",
       "            2016_yoy_y  2016_gain_y  2016_yoy_pos_y  2016_yoy_big_y  \\\n",
       "RegionName                                                            \n",
       "99362         0.992661            0               0               0   \n",
       "99354         1.076721            1               1               1   \n",
       "99352         1.072472            1               1               1   \n",
       "99337         1.064490            1               1               1   \n",
       "99336         1.070530            1               1               1   \n",
       "\n",
       "            2016_yoy_neg_y  2016_yoy_loss_big_y  2016_swing_pos_y  \\\n",
       "RegionName                                                          \n",
       "99362                    1                    0                 0   \n",
       "99354                    0                    0                 0   \n",
       "99352                    0                    0                 0   \n",
       "99337                    0                    0                 0   \n",
       "99336                    0                    0                 0   \n",
       "\n",
       "            2016_swing_big_y  2016_swing_neg_y  2016_swing_loss_big_y  \n",
       "RegionName                                                             \n",
       "99362                      0                 1                      0  \n",
       "99354                      0                 1                      0  \n",
       "99352                      0                 1                      0  \n",
       "99337                      0                 1                      0  \n",
       "99336                      0                 1                      0  \n",
       "\n",
       "[5 rows x 540 columns]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4301"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_ratio(df, col_1, col_2):\n",
    "    y = pd.DataFrame()\n",
    "    y['RegionName'] = df['RegionName']\n",
    "    y['y'] = df[col_2] / df[col_1]\n",
    "    y = y.sort_values('RegionName',ascending=False)\n",
    "    y = y.set_index('RegionName')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = create_y_ratio(read_data_list_2[23], '2016-12', '2017-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.059853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.635848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.013011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.056295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.104116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.438448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y\n",
       "count  10454.000000\n",
       "mean       1.059853\n",
       "std        0.081299\n",
       "min        0.635848\n",
       "25%        1.013011\n",
       "50%        1.056295\n",
       "75%        1.104116\n",
       "max        1.438448"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    0.635848\n",
       "dtype: float64"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max must be larger than min in range parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-977170970e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3079\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m                       stacked=stacked, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3082\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6193\u001b[0m             \u001b[0;31m# this will automatically overwrite bins,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6194\u001b[0m             \u001b[0;31m# so that each histogram uses the same bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6195\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6196\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# causes problems later if it's an int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         raise ValueError(\n\u001b[0;32m--> 666\u001b[0;31m             'max must be larger than min in range parameter.')\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: max must be larger than min in range parameter."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26f9077f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_class(y_list):\n",
    "    y_df = pd.DataFrame()\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    y_3 = []\n",
    "    y_4 = []\n",
    "    y_5 = []\n",
    "    y_6 = []\n",
    "    y_7 = []\n",
    "    for y in y_list:\n",
    "        if y <= .75:\n",
    "            y_1.append(1)\n",
    "        else:\n",
    "            y_1.append(0)\n",
    "        if y > .75 and y <= .85:\n",
    "            y_2.append(1)\n",
    "        else:\n",
    "            y_2.append(0)\n",
    "        if y > .85 and y <= .95:\n",
    "            y_3.append(1)\n",
    "        else:\n",
    "            y_3.append(0)\n",
    "        if y > .95 and y <= 1.05:\n",
    "            y_4.append(1)\n",
    "        else:\n",
    "            y_4.append(0)\n",
    "        if y > 1.05 and y <= 1.15:\n",
    "            y_5.append(1)\n",
    "        else:\n",
    "            y_5.append(0)\n",
    "        if y > 1.15 and y <= 1.25:\n",
    "            y_6.append(1)\n",
    "        else:\n",
    "            y_6.append(0)\n",
    "        if y > 1.25:\n",
    "            y_7.append(1)\n",
    "        else:\n",
    "            y_7.append(0)\n",
    "    y_df['1'] = y_1\n",
    "    y_df['2'] = y_2\n",
    "    y_df['3'] = y_3\n",
    "    y_df['4'] = y_4\n",
    "    y_df['5'] = y_5\n",
    "    y_df['6'] = y_6\n",
    "    y_df['7'] = y_7\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16_df = pd.merge(X_16, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = X_16_df.iloc[:, :-1].values\n",
    "y_16 = X_16_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       1  2  3  4  5  6  7\n",
       "0     0  0  0  0  1  0  0\n",
       "1     0  0  0  0  1  0  0\n",
       "2     0  0  0  0  1  0  0\n",
       "3     0  0  0  0  1  0  0\n",
       "4     0  0  0  1  0  0  0\n",
       "5     0  0  0  0  1  0  0\n",
       "6     0  0  0  1  0  0  0\n",
       "7     0  0  0  0  1  0  0\n",
       "8     0  0  0  0  0  1  0\n",
       "9     0  0  0  0  1  0  0\n",
       "10    0  0  0  1  0  0  0\n",
       "11    0  0  0  0  0  1  0\n",
       "12    0  0  0  0  0  1  0\n",
       "13    0  0  0  1  0  0  0\n",
       "14    0  0  0  0  1  0  0\n",
       "15    0  0  0  0  1  0  0\n",
       "16    0  0  0  1  0  0  0\n",
       "17    0  0  0  0  0  1  0\n",
       "18    0  0  0  1  0  0  0\n",
       "19    0  0  0  0  1  0  0\n",
       "20    0  0  0  0  0  1  0\n",
       "21    0  0  0  1  0  0  0\n",
       "22    0  0  0  0  0  0  0\n",
       "23    0  0  0  0  1  0  0\n",
       "24    0  0  0  1  0  0  0\n",
       "25    0  0  0  1  0  0  0\n",
       "26    0  0  0  0  1  0  0\n",
       "27    0  0  0  0  0  1  0\n",
       "28    0  0  0  0  1  0  0\n",
       "29    0  0  0  0  0  1  0\n",
       "...  .. .. .. .. .. .. ..\n",
       "5108  0  0  0  0  0  1  0\n",
       "5109  0  0  0  0  1  0  0\n",
       "5110  0  0  0  0  1  0  0\n",
       "5111  0  0  0  0  0  0  1\n",
       "5112  0  0  0  0  0  1  0\n",
       "5113  0  0  0  1  0  0  0\n",
       "5114  0  0  0  1  0  0  0\n",
       "5115  0  0  0  0  1  0  0\n",
       "5116  0  0  0  1  0  0  0\n",
       "5117  0  0  0  1  0  0  0\n",
       "5118  0  0  0  1  0  0  0\n",
       "5119  0  0  0  0  1  0  0\n",
       "5120  0  0  0  0  1  0  0\n",
       "5121  0  0  0  0  1  0  0\n",
       "5122  0  0  0  1  0  0  0\n",
       "5123  0  0  0  0  1  0  0\n",
       "5124  0  0  0  0  1  0  0\n",
       "5125  0  0  0  1  0  0  0\n",
       "5126  0  0  0  0  1  0  0\n",
       "5127  0  0  0  0  0  1  0\n",
       "5128  0  0  0  0  0  1  0\n",
       "5129  0  0  0  1  0  0  0\n",
       "5130  0  0  0  1  0  0  0\n",
       "5131  0  0  0  0  1  0  0\n",
       "5132  0  0  0  0  1  0  0\n",
       "5133  0  0  0  1  0  0  0\n",
       "5134  0  0  0  1  0  0  0\n",
       "5135  0  0  0  1  0  0  0\n",
       "5136  0  0  0  1  0  0  0\n",
       "5137  0  0  0  0  1  0  0\n",
       "\n",
       "[5138 rows x 7 columns]>"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weight 6 & 7 more? Also 1 & 2?\n",
    "y_cat = create_y_class(y_16)\n",
    "y_cat.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5129.000000\n",
       "mean        1.067475\n",
       "std         0.072273\n",
       "min         0.791820\n",
       "25%         1.023399\n",
       "50%         1.061971\n",
       "75%         1.106317\n",
       "max         1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13331.838146306203"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.62726008,  1.62726008,  1.62726008, ...,  8.37273992,\n",
       "        8.37273992,  8.37273992])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16[:, 3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16272601,  0.16272601,  0.16272601, ...,  0.83727399,\n",
       "        0.83727399,  0.83727399])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_16[:, 3].max()\n",
    "X_16[:, 3] / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_16.shape\n",
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_per_column(X):\n",
    "    new_array = []\n",
    "    shape = X.shape\n",
    "    columns = shape[1]\n",
    "    for num in range(columns):\n",
    "        mx = X[:, num].max()\n",
    "        if mx == 0:\n",
    "            new_array.append(X[:, num])\n",
    "        else:\n",
    "            X[:, num] = X[:, num] / mx\n",
    "            new_array.append(X[:, num])\n",
    "    new_array = np.array(new_array)\n",
    "    new_array = np.transpose(new_array)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = norm_per_column(X_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = np.array(X_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = np.transpose(X_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5138, 540)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(X_16, y_cat, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best by far! Same as linear but converted to be categorical\n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(540,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4110 samples, validate on 1028 samples\n",
      "Epoch 1/100\n",
      "4110/4110 [==============================] - 12s 3ms/step - loss: 1.8075 - acc: 0.4701 - val_loss: 2.1506 - val_acc: 0.3794\n",
      "Epoch 2/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.7725 - acc: 0.3798 - val_loss: 1.2996 - val_acc: 0.4591\n",
      "Epoch 3/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.2729 - acc: 0.4701 - val_loss: 1.2521 - val_acc: 0.4591\n",
      "Epoch 4/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.2132 - acc: 0.4701 - val_loss: 1.1988 - val_acc: 0.4591\n",
      "Epoch 5/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.1711 - acc: 0.4771 - val_loss: 1.1815 - val_acc: 0.5010\n",
      "Epoch 6/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.1447 - acc: 0.4964 - val_loss: 1.1678 - val_acc: 0.4591\n",
      "Epoch 7/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.1343 - acc: 0.4703 - val_loss: 1.1651 - val_acc: 0.4591\n",
      "Epoch 8/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.1213 - acc: 0.4779 - val_loss: 1.1549 - val_acc: 0.5078\n",
      "Epoch 9/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.1134 - acc: 0.5165 - val_loss: 1.1370 - val_acc: 0.5097\n",
      "Epoch 10/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0947 - acc: 0.5202 - val_loss: 1.1322 - val_acc: 0.4767\n",
      "Epoch 11/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0856 - acc: 0.5090 - val_loss: 1.1143 - val_acc: 0.5146\n",
      "Epoch 12/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0707 - acc: 0.5290 - val_loss: 1.1126 - val_acc: 0.5126\n",
      "Epoch 13/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0603 - acc: 0.5343 - val_loss: 1.1164 - val_acc: 0.5204\n",
      "Epoch 14/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0570 - acc: 0.5440 - val_loss: 1.1039 - val_acc: 0.5165\n",
      "Epoch 15/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0502 - acc: 0.5348 - val_loss: 1.0964 - val_acc: 0.5272\n",
      "Epoch 16/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0402 - acc: 0.5460 - val_loss: 1.0960 - val_acc: 0.5195\n",
      "Epoch 17/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0334 - acc: 0.5489 - val_loss: 1.0898 - val_acc: 0.5379\n",
      "Epoch 18/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0261 - acc: 0.5535 - val_loss: 1.0925 - val_acc: 0.5233\n",
      "Epoch 19/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 1.0222 - acc: 0.5533 - val_loss: 1.0938 - val_acc: 0.5282\n",
      "Epoch 20/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0172 - acc: 0.5550 - val_loss: 1.0903 - val_acc: 0.5302\n",
      "Epoch 21/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0098 - acc: 0.5618 - val_loss: 1.0892 - val_acc: 0.5302\n",
      "Epoch 22/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.0043 - acc: 0.5642 - val_loss: 1.0909 - val_acc: 0.5370\n",
      "Epoch 23/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9982 - acc: 0.5659 - val_loss: 1.0939 - val_acc: 0.5243\n",
      "Epoch 24/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9974 - acc: 0.5650 - val_loss: 1.0890 - val_acc: 0.5350\n",
      "Epoch 25/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9894 - acc: 0.5640 - val_loss: 1.0960 - val_acc: 0.5233\n",
      "Epoch 26/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9832 - acc: 0.5657 - val_loss: 1.0855 - val_acc: 0.5418\n",
      "Epoch 27/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9826 - acc: 0.5674 - val_loss: 1.0911 - val_acc: 0.5321\n",
      "Epoch 28/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9758 - acc: 0.5684 - val_loss: 1.0904 - val_acc: 0.5340\n",
      "Epoch 29/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9661 - acc: 0.5701 - val_loss: 1.0880 - val_acc: 0.5311\n",
      "Epoch 30/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9619 - acc: 0.5793 - val_loss: 1.1025 - val_acc: 0.5243\n",
      "Epoch 31/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9540 - acc: 0.5827 - val_loss: 1.0918 - val_acc: 0.5272\n",
      "Epoch 32/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9478 - acc: 0.5895 - val_loss: 1.1023 - val_acc: 0.5360\n",
      "Epoch 33/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9361 - acc: 0.5871 - val_loss: 1.1079 - val_acc: 0.5399\n",
      "Epoch 34/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9240 - acc: 0.5956 - val_loss: 1.1049 - val_acc: 0.5379\n",
      "Epoch 35/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9208 - acc: 0.6002 - val_loss: 1.1172 - val_acc: 0.5389\n",
      "Epoch 36/100\n",
      "4110/4110 [==============================] - 7s 2ms/step - loss: 0.9085 - acc: 0.6051 - val_loss: 1.1131 - val_acc: 0.5263\n",
      "Epoch 37/100\n",
      "4110/4110 [==============================] - 7s 2ms/step - loss: 0.8940 - acc: 0.6085 - val_loss: 1.1324 - val_acc: 0.5253\n",
      "Epoch 38/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.8910 - acc: 0.6109 - val_loss: 1.1334 - val_acc: 0.5272\n",
      "Epoch 39/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.8714 - acc: 0.6285 - val_loss: 1.1323 - val_acc: 0.5272\n",
      "Epoch 40/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.8497 - acc: 0.6426 - val_loss: 1.1430 - val_acc: 0.5243\n",
      "Epoch 41/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.8351 - acc: 0.6472 - val_loss: 1.1702 - val_acc: 0.5010\n",
      "Epoch 42/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.8534 - acc: 0.6304 - val_loss: 1.2524 - val_acc: 0.4874\n",
      "Epoch 43/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.8592 - acc: 0.6214 - val_loss: 1.1595 - val_acc: 0.5117\n",
      "Epoch 44/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.8136 - acc: 0.6669 - val_loss: 1.1881 - val_acc: 0.5146\n",
      "Epoch 45/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.7901 - acc: 0.6652 - val_loss: 1.2080 - val_acc: 0.4825\n",
      "Epoch 46/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.7868 - acc: 0.6640 - val_loss: 1.2057 - val_acc: 0.5126\n",
      "Epoch 47/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.7338 - acc: 0.7044 - val_loss: 1.2020 - val_acc: 0.5146\n",
      "Epoch 48/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.7076 - acc: 0.7241 - val_loss: 1.2453 - val_acc: 0.5156\n",
      "Epoch 49/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6797 - acc: 0.7258 - val_loss: 1.2408 - val_acc: 0.5146\n",
      "Epoch 50/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6676 - acc: 0.7389 - val_loss: 1.4687 - val_acc: 0.4543\n",
      "Epoch 51/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.9612 - acc: 0.5599 - val_loss: 1.3688 - val_acc: 0.5029\n",
      "Epoch 52/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.7310 - acc: 0.6793 - val_loss: 1.2389 - val_acc: 0.4942\n",
      "Epoch 53/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.7394 - acc: 0.7297 - val_loss: 1.3393 - val_acc: 0.5039\n",
      "Epoch 54/100\n",
      "4110/4110 [==============================] - 7s 2ms/step - loss: 0.7505 - acc: 0.7000 - val_loss: 1.2067 - val_acc: 0.5146\n",
      "Epoch 55/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6773 - acc: 0.7625 - val_loss: 1.2092 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.6287 - acc: 0.7759 - val_loss: 1.4134 - val_acc: 0.5117\n",
      "Epoch 57/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.6250 - acc: 0.7645 - val_loss: 1.3008 - val_acc: 0.4825\n",
      "Epoch 58/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6049 - acc: 0.7832 - val_loss: 1.4221 - val_acc: 0.5049\n",
      "Epoch 59/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.5684 - acc: 0.7805 - val_loss: 1.3322 - val_acc: 0.4990\n",
      "Epoch 60/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.5126 - acc: 0.8304 - val_loss: 1.3688 - val_acc: 0.4981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.4793 - acc: 0.8251 - val_loss: 1.4504 - val_acc: 0.4912\n",
      "Epoch 62/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.4969 - acc: 0.7993 - val_loss: 1.5623 - val_acc: 0.4718\n",
      "Epoch 63/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6027 - acc: 0.7380 - val_loss: 1.4871 - val_acc: 0.4942\n",
      "Epoch 64/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.4154 - acc: 0.8467 - val_loss: 1.5715 - val_acc: 0.4903\n",
      "Epoch 65/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.4311 - acc: 0.8345 - val_loss: 1.5686 - val_acc: 0.4903\n",
      "Epoch 66/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.4179 - acc: 0.8304 - val_loss: 1.4935 - val_acc: 0.4893\n",
      "Epoch 67/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.3388 - acc: 0.8949 - val_loss: 1.6918 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.3345 - acc: 0.8732 - val_loss: 1.5973 - val_acc: 0.4718\n",
      "Epoch 69/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.2632 - acc: 0.9297 - val_loss: 1.7391 - val_acc: 0.4981\n",
      "Epoch 70/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.2445 - acc: 0.9282 - val_loss: 1.7202 - val_acc: 0.4669\n",
      "Epoch 71/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.2122 - acc: 0.9482 - val_loss: 1.9330 - val_acc: 0.4844\n",
      "Epoch 72/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.1828 - acc: 0.9547 - val_loss: 1.9943 - val_acc: 0.4854\n",
      "Epoch 73/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.1544 - acc: 0.9620 - val_loss: 2.1138 - val_acc: 0.4679\n",
      "Epoch 74/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.3070 - acc: 0.8764 - val_loss: 4.9980 - val_acc: 0.4591\n",
      "Epoch 75/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 2.0561 - acc: 0.7078 - val_loss: 2.9870 - val_acc: 0.3949\n",
      "Epoch 76/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.3144 - acc: 0.5937 - val_loss: 1.5082 - val_acc: 0.4883\n",
      "Epoch 77/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6120 - acc: 0.7535 - val_loss: 1.5734 - val_acc: 0.4679\n",
      "Epoch 78/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.7742 - acc: 0.6022 - val_loss: 1.2354 - val_acc: 0.5039\n",
      "Epoch 79/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6614 - acc: 0.7596 - val_loss: 1.2216 - val_acc: 0.4835\n",
      "Epoch 80/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.7207 - acc: 0.6859 - val_loss: 1.2275 - val_acc: 0.4718\n",
      "Epoch 81/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6968 - acc: 0.7243 - val_loss: 1.2518 - val_acc: 0.5097\n",
      "Epoch 82/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.6134 - acc: 0.7910 - val_loss: 1.3678 - val_acc: 0.4971\n",
      "Epoch 83/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.5513 - acc: 0.7859 - val_loss: 1.4611 - val_acc: 0.5068\n",
      "Epoch 84/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.4716 - acc: 0.8105 - val_loss: 1.6902 - val_acc: 0.5068\n",
      "Epoch 85/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.4431 - acc: 0.8241 - val_loss: 1.8114 - val_acc: 0.5146\n",
      "Epoch 86/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.3715 - acc: 0.8564 - val_loss: 1.7314 - val_acc: 0.4582\n",
      "Epoch 87/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.3305 - acc: 0.8873 - val_loss: 1.9535 - val_acc: 0.5039\n",
      "Epoch 88/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.2719 - acc: 0.9056 - val_loss: 1.8977 - val_acc: 0.4553\n",
      "Epoch 89/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.2151 - acc: 0.9363 - val_loss: 2.1594 - val_acc: 0.4912\n",
      "Epoch 90/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.1872 - acc: 0.9380 - val_loss: 2.1685 - val_acc: 0.4650\n",
      "Epoch 91/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.1571 - acc: 0.9586 - val_loss: 2.4846 - val_acc: 0.4854\n",
      "Epoch 92/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.1312 - acc: 0.9625 - val_loss: 2.4516 - val_acc: 0.4679\n",
      "Epoch 93/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.1048 - acc: 0.9754 - val_loss: 2.6755 - val_acc: 0.4582\n",
      "Epoch 94/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.0833 - acc: 0.9764 - val_loss: 2.7371 - val_acc: 0.4484\n",
      "Epoch 95/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.0743 - acc: 0.9810 - val_loss: 2.9745 - val_acc: 0.4747\n",
      "Epoch 96/100\n",
      "4110/4110 [==============================] - 6s 2ms/step - loss: 0.0670 - acc: 0.9798 - val_loss: 2.9785 - val_acc: 0.4514\n",
      "Epoch 97/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.0650 - acc: 0.9805 - val_loss: 3.5301 - val_acc: 0.4747\n",
      "Epoch 98/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 0.3264 - acc: 0.8703 - val_loss: 5.4915 - val_acc: 0.3891\n",
      "Epoch 99/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 2.1829 - acc: 0.4939 - val_loss: 4.7964 - val_acc: 0.4815\n",
      "Epoch 100/100\n",
      "4110/4110 [==============================] - 6s 1ms/step - loss: 1.7388 - acc: 0.6384 - val_loss: 3.4305 - val_acc: 0.4679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c593dc50>"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_16, y=y_train_16, \n",
    "          batch_size=2500, \n",
    "          epochs=100, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_16, y_test_16),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .9810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(811,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "learning_rate = .001\n",
    "epochs = 20\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.5\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3292 samples, validate on 824 samples\n",
      "Epoch 1/20\n",
      "3292/3292 [==============================] - 8s 2ms/step - loss: nan - acc: 0.0826 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "3292/3292 [==============================] - 5s 2ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "3292/3292 [==============================] - 5s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "3292/3292 [==============================] - 5s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "3292/3292 [==============================] - 5s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "3292/3292 [==============================] - 4s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "3292/3292 [==============================] - 5s 1ms/step - loss: nan - acc: 0.0024 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-79e3aa87ca24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           callbacks=None)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_weight = {1: 10,\n",
    "    2: 5,\n",
    "    3: 1,\n",
    "    4: 1,\n",
    "    5: 1,\n",
    "    6: 5,\n",
    "                7:10}\n",
    "model.fit(x=X_train_16, y=y_train_16, \n",
    "          batch_size=3000, \n",
    "          epochs=epochs, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_16, y_test_16),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(90,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5336 samples, validate on 1334 samples\n",
      "Epoch 1/2000\n",
      "5336/5336 [==============================] - 5s 906us/step - loss: 1.0742 - val_loss: 0.8664\n",
      "Epoch 2/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.8218 - val_loss: 0.6511\n",
      "Epoch 3/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.6200 - val_loss: 0.4853\n",
      "Epoch 4/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.4641 - val_loss: 0.3586\n",
      "Epoch 5/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.3450 - val_loss: 0.2620\n",
      "Epoch 6/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.2540 - val_loss: 0.1897\n",
      "Epoch 7/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.1856 - val_loss: 0.1357\n",
      "Epoch 8/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.1340 - val_loss: 0.0961\n",
      "Epoch 9/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0967 - val_loss: 0.0677\n",
      "Epoch 10/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0694 - val_loss: 0.0474\n",
      "Epoch 11/2000\n",
      "5336/5336 [==============================] - 3s 603us/step - loss: 0.0498 - val_loss: 0.0334\n",
      "Epoch 12/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0362 - val_loss: 0.0237\n",
      "Epoch 13/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0265 - val_loss: 0.0170\n",
      "Epoch 14/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0198 - val_loss: 0.0126\n",
      "Epoch 15/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 16/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 17/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 18/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 19/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 20/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 21/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 22/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 23/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 24/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 25/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 26/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 27/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 28/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 29/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 30/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 31/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 32/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 33/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 34/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 35/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 36/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 37/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 38/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 39/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 40/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 41/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 42/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 43/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 44/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 45/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 46/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 47/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 48/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 49/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 50/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 51/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 52/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 53/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 54/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 55/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 56/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 57/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 58/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 59/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 60/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 61/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 62/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 63/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 64/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 65/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 66/2000\n",
      "5336/5336 [==============================] - 3s 512us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 67/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 68/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 69/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 70/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 71/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 72/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 73/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 74/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 75/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 76/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 77/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 78/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 79/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 80/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 81/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 82/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 83/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 84/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 85/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 86/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 87/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 88/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 89/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 90/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 91/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 92/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 93/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 94/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 95/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 96/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 97/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 98/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 99/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 100/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 101/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 102/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 103/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 105/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 106/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 107/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 108/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 109/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 110/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 111/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 112/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 113/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 114/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 115/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 116/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 117/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 118/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 119/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 120/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 121/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 122/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 124/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 125/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 126/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 127/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 128/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 129/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 130/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 131/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 132/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 133/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 134/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 135/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 136/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 137/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 138/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 139/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 140/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 141/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 142/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 143/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 144/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 145/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 146/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 147/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 148/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 149/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 150/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 151/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 152/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 154/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 155/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 156/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 157/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 158/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 159/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 160/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 161/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 162/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 163/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 164/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 165/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 166/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 167/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 168/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 169/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 170/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 171/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 172/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 173/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 174/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 175/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 176/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 177/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 178/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 179/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 180/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 181/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 182/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 184/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 185/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 186/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 187/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 188/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 189/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 190/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 191/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 192/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 193/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 194/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 195/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 196/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 197/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 198/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 199/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 200/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 201/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 202/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 203/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 204/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 205/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 206/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 207/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 208/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 209/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 210/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 211/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 213/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 214/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 215/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 216/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 217/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 218/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 219/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 220/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 221/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 222/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 223/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 224/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 225/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 226/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 227/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 228/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 230/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 231/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 232/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 233/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 234/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 235/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 236/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 237/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 238/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 239/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 240/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 241/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 242/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 243/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 244/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 245/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 246/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 247/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 249/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 250/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 251/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 252/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 253/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 254/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 255/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 256/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 258/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 259/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 260/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 261/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 262/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 263/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 264/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 265/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 266/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 267/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 268/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 269/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 270/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 271/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 272/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 273/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 274/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 275/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 276/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 277/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 278/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 279/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 280/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 281/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 282/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 283/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 284/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 285/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 286/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 287/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 288/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 289/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 290/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 291/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 292/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 293/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 294/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 295/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 296/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 297/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 298/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 299/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 300/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 301/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 302/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 303/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 304/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 306/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 307/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 308/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 309/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 310/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 311/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 312/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 313/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 314/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 315/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 316/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 317/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 318/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 319/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 320/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 321/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 322/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 323/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 324/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 325/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 326/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 327/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 328/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 329/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 330/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 331/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 332/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 333/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 334/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 335/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 336/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 337/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 338/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 339/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 340/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 341/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 342/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 343/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 344/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 345/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 346/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 347/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 348/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 349/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 350/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 351/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 352/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 353/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 354/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 355/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 356/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 357/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 358/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 359/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 360/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 361/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 362/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 363/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 364/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 365/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 366/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 367/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 368/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 369/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 370/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 371/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 372/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 373/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 374/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 375/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 376/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 377/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 378/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 379/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 380/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 382/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 383/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 384/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 385/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 386/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 387/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 388/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 389/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 390/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 391/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 392/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 393/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 394/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 395/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 396/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 397/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 398/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 399/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 400/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 401/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 402/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 403/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 404/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 405/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 406/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 407/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 408/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 409/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 410/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 411/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 412/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 413/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 414/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 415/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 416/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 417/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 418/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 419/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 420/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 421/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 422/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 423/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 424/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 425/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 427/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 428/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 429/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 430/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 431/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 432/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 433/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 434/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 435/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 436/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 437/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 438/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 439/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 440/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 441/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 442/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 443/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 444/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 445/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 446/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 448/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 449/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 450/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 451/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 452/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 453/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 454/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 455/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 456/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 458/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 459/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 460/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 461/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 462/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 463/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 464/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 465/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 466/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 467/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 468/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 469/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 470/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 471/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 473/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 474/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 475/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 477/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 478/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 479/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 480/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 481/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 482/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 483/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 485/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 486/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 487/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 488/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 489/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 490/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 491/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 492/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 494/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 495/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 496/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 497/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 498/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 499/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 500/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 501/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 502/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 503/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 504/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 505/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 506/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 507/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 508/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 509/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 510/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 511/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 512/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 513/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 514/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 515/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 516/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 517/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 518/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 519/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 520/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 521/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 522/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 523/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 524/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 525/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 526/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 527/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 528/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 529/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 530/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 531/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 532/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 534/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 535/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 536/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 537/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 538/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 539/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 540/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 541/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 542/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 543/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 544/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 545/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 546/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 547/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 548/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 549/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 550/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 551/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 552/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 553/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 554/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 555/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 556/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 557/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 558/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 559/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 560/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 561/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 562/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 563/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 564/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 565/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 566/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 567/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 568/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 569/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 570/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 571/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 572/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 573/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 574/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 576/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 577/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 578/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 579/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 580/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 581/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 582/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 583/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 584/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 585/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 586/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 587/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 588/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 589/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 590/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 591/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 592/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 593/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 594/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 595/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 596/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 597/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 598/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 599/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 600/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 601/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 602/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 603/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 604/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 605/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 606/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 607/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 608/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/2000\n",
      "5336/5336 [==============================] - 3s 517us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 610/2000\n",
      "5336/5336 [==============================] - 3s 592us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 611/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 612/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 613/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 614/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 615/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 616/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 617/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 618/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 619/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 620/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 621/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 622/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 623/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 624/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 625/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 626/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 627/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 628/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 629/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 630/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 631/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 632/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 633/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 634/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 635/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 636/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 637/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 638/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 639/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 640/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 641/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 642/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 643/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 644/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 645/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 646/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 647/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 648/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 649/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 650/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 651/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 652/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 653/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 654/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 655/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 656/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 657/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 658/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 659/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 660/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 661/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 662/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 663/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 664/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 665/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 666/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 667/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 668/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 669/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 670/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 671/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 672/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 673/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 674/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 675/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 676/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 677/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 678/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 679/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 680/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 681/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 682/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 683/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 684/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 686/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 687/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 688/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 689/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 690/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 691/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 692/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 693/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 694/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 695/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 696/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 697/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 698/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 699/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 700/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 701/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 702/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 703/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 704/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 705/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 706/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 707/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 708/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 709/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 710/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 711/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 712/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 713/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 714/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 715/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 716/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 717/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 718/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 719/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 720/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 721/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 722/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 723/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 724/2000\n",
      "5336/5336 [==============================] - 3034s 569ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 725/2000\n",
      "5336/5336 [==============================] - 3s 653us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 726/2000\n",
      "5336/5336 [==============================] - 4s 680us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 727/2000\n",
      "5336/5336 [==============================] - 4s 767us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 728/2000\n",
      "5336/5336 [==============================] - 5s 891us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 729/2000\n",
      "5336/5336 [==============================] - 5s 930us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 730/2000\n",
      "5336/5336 [==============================] - 4s 750us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 731/2000\n",
      "5336/5336 [==============================] - 5s 853us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 732/2000\n",
      "5336/5336 [==============================] - 5s 959us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 733/2000\n",
      "5336/5336 [==============================] - 5s 951us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 734/2000\n",
      "5336/5336 [==============================] - 4s 704us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 735/2000\n",
      "5336/5336 [==============================] - 5s 859us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 736/2000\n",
      "5336/5336 [==============================] - 4s 835us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 737/2000\n",
      "5336/5336 [==============================] - 5s 989us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 738/2000\n",
      "5336/5336 [==============================] - 5s 950us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 739/2000\n",
      "5336/5336 [==============================] - 3s 561us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 740/2000\n",
      "5336/5336 [==============================] - 3s 540us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 741/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 742/2000\n",
      "5336/5336 [==============================] - 3s 569us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 743/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 744/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 745/2000\n",
      "5336/5336 [==============================] - 3s 628us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 746/2000\n",
      "5336/5336 [==============================] - 3s 577us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 747/2000\n",
      "5336/5336 [==============================] - 3s 566us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 748/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 749/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 750/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 751/2000\n",
      "5336/5336 [==============================] - 3s 635us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 752/2000\n",
      "5336/5336 [==============================] - 3s 546us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 753/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 754/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 755/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 756/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 757/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 758/2000\n",
      "5336/5336 [==============================] - 3s 537us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 759/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 760/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 762/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 763/2000\n",
      "5336/5336 [==============================] - 3s 553us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 764/2000\n",
      "5336/5336 [==============================] - 3s 557us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 765/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 766/2000\n",
      "5336/5336 [==============================] - 3s 523us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 767/2000\n",
      "5336/5336 [==============================] - 3s 528us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 768/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 769/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 770/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 771/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 772/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 773/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 774/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 775/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 776/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 777/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 778/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 779/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 780/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 781/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 782/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 783/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 784/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 785/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 787/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 788/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 789/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 790/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 791/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 792/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 793/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 794/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 795/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 796/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 797/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 798/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 799/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 800/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 801/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 802/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 804/2000\n",
      "5336/5336 [==============================] - 3s 529us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 805/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 806/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 807/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 808/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 809/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 810/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 811/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 812/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 813/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 814/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 815/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 816/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 817/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 818/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 819/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 820/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 821/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 822/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 823/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 824/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 825/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 826/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 827/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 828/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 829/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 830/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 831/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 832/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 833/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 834/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 835/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 836/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 838/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 839/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 840/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 841/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 842/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 843/2000\n",
      "5336/5336 [==============================] - 3s 520us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 844/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 845/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 846/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 847/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 848/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 849/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 850/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 851/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 852/2000\n",
      "5336/5336 [==============================] - 3s 524us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 853/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 854/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 855/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 856/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 857/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 858/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 859/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 860/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 861/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 862/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 863/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 864/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 865/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 866/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 867/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 868/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 869/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 870/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 871/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 872/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 873/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 874/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 875/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 876/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 877/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 878/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 879/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 880/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 881/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 882/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 883/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 884/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 885/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 886/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 887/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 888/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 889/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 890/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 891/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 892/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 893/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 894/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 895/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 896/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 897/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 898/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 899/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 900/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 901/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 902/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 903/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 904/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 905/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 906/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 907/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 908/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 909/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 910/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 911/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 912/2000\n",
      "5336/5336 [==============================] - 3s 517us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 914/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 915/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 916/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 917/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 918/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 919/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 920/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 921/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 922/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 923/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 925/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 926/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 927/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 928/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 929/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 930/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 931/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 932/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 933/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 934/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 935/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 936/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 937/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 938/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 939/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 940/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 941/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 942/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 943/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 944/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 945/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 946/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 947/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 948/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 949/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 950/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 951/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 952/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 953/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 954/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 955/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 956/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 957/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 958/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 959/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 960/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 961/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 962/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 963/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 964/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 965/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 966/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 967/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 968/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 969/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 970/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 971/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 972/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 973/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 974/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 975/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 976/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 977/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 978/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 979/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 980/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 981/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 982/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 983/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 984/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 985/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 986/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 987/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 988/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 990/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 991/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 992/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 993/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 994/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 995/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 996/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 997/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 998/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 999/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1000/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1001/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1002/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1003/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1004/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1005/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1006/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1007/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1008/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1009/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1010/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1011/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1012/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1013/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1014/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1015/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1016/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1017/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1018/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1019/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1020/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1021/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1022/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1023/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1024/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1025/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1026/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 1027/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1028/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1029/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1030/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1031/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1032/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1033/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1034/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1035/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1036/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1037/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1038/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1039/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1040/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1041/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1042/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1043/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1044/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1045/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1046/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1047/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1048/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1049/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1050/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1051/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1052/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1053/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1054/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1055/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1056/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1057/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1058/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1059/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1060/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1061/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1062/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1063/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1064/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1065/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1066/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1067/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1068/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1069/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1070/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1071/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1072/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1073/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1074/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1075/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1076/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1077/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1078/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1079/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1080/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1081/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1082/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1083/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1084/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1085/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1086/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1087/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1088/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1089/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1090/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1091/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1092/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1093/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1094/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1095/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1096/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1097/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1098/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1099/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1100/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1101/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1102/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1103/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1105/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1106/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1107/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1108/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1109/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1110/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1111/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1112/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1113/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1114/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1115/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1116/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1117/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1118/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1119/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1120/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1121/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1122/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1124/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1125/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1126/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1127/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1128/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1129/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1130/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1131/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1132/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1133/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1134/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1135/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1136/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1137/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1138/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1139/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1140/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1141/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1142/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1143/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1144/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1145/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1146/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1147/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1148/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1149/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1150/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1151/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1152/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1153/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1154/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1155/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1156/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1157/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1158/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1159/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1160/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1161/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1162/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1163/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1164/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1165/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1166/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1167/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1168/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1169/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1170/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1171/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1172/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1173/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1174/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1175/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1176/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1177/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1178/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1179/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1180/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1181/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1182/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1184/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1185/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1186/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1187/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1188/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1189/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1190/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1191/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1192/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1193/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1194/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1195/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1196/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1197/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1198/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1199/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1200/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1201/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1202/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1203/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1204/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1205/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1206/2000\n",
      "5336/5336 [==============================] - 3s 568us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1207/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1208/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1209/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1210/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1211/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1213/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1214/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1215/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1216/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1217/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1218/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1219/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1220/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1221/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1222/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1223/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1224/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1225/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1226/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1227/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1228/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1229/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1230/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1231/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1232/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1233/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1234/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1235/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1236/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1237/2000\n",
      "5336/5336 [==============================] - 3s 522us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1238/2000\n",
      "5336/5336 [==============================] - 3s 575us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1239/2000\n",
      "5336/5336 [==============================] - 3s 618us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1240/2000\n",
      "5336/5336 [==============================] - 3s 621us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1241/2000\n",
      "5336/5336 [==============================] - 3s 616us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1242/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1243/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1244/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1245/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1246/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1247/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1249/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1250/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1251/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1252/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1253/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1254/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1255/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1256/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1258/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1259/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1260/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1261/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1262/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1263/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1264/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1265/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1266/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1267/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1268/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1269/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1270/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1271/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1272/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1273/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1274/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1275/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1276/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1277/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1278/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1279/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1280/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1281/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1282/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1283/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1284/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1285/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1286/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1287/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1288/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1290/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1291/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1292/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1293/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1294/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1295/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1296/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1297/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1298/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1299/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1300/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1301/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1302/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1303/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1304/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1305/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1306/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1307/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1308/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1309/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1310/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1311/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1312/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1313/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1314/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1315/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1316/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1317/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1318/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1319/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1320/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1321/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1322/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1323/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1324/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1325/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1326/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1327/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1328/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1329/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1330/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1331/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1332/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1333/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1334/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1335/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1336/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1337/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1338/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1339/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1340/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1341/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1342/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1343/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1344/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1345/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1346/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1347/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1348/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1349/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1350/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1351/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1352/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1353/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1354/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1355/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1356/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1357/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1358/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1359/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1360/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1361/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1362/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1363/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1364/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1365/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1366/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1367/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1368/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1369/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1370/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1371/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1372/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1373/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1374/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1375/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1376/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1377/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1378/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1379/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1380/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1382/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1383/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1384/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1385/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1386/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1387/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1388/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1389/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1390/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1391/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1392/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1393/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1394/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1395/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1396/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1397/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1398/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1399/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1400/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1401/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1402/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1403/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1404/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1405/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1406/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1407/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1408/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1409/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1410/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1411/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1412/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1413/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1414/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1415/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1416/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1417/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1418/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1419/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1420/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1421/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1422/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1423/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1424/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1425/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1427/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1428/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1429/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1430/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1431/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1432/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1433/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1434/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1435/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1436/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1437/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1438/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1439/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1440/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1441/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1442/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1443/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1444/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1445/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1446/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1448/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1449/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1450/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1451/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1452/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1453/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1454/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1455/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1456/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1457/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1458/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1459/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1460/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1461/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1462/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1463/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1464/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1465/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1466/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1467/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1468/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1469/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1470/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1471/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1473/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1474/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1475/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1477/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1478/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1479/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1480/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1481/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1482/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1483/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1485/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1486/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1487/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1488/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1489/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1490/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1491/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1492/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1494/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1495/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1496/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1497/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1498/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1499/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1500/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1501/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1502/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1503/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1504/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1505/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1506/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1507/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1508/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1509/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1510/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1511/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1512/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1513/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1514/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1515/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1516/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1517/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1518/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1519/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1520/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1521/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1522/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1523/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1524/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1525/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1526/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1527/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1528/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1529/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1530/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1531/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1532/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1533/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1534/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1535/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1536/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1537/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1538/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1539/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1540/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1541/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1542/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1543/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1544/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1545/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1546/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1547/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1548/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1549/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1550/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1551/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1552/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1553/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1554/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1555/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1556/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1557/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1558/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1559/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1560/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1561/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1562/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1563/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1564/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1565/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1566/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1567/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1568/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1569/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1570/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1571/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1572/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1573/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1574/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1576/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1577/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1578/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1579/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1580/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1581/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1582/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1583/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1584/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1585/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1586/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1587/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1588/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1590/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1591/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1592/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1593/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1594/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1595/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1596/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1597/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1598/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1599/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1600/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1601/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1602/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1603/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1604/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1605/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1606/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1607/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1608/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1609/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1610/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1611/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1612/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1613/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1614/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1615/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1616/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1617/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1618/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1619/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1620/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1621/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1622/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1623/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1624/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1625/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1626/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1627/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1628/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1629/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1630/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1631/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1632/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1633/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1634/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1635/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1636/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1637/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1638/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1639/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1640/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1641/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1642/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1643/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1644/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1645/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1646/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1647/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1648/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1649/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1650/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1651/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1652/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1653/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1654/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1655/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1656/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1657/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1658/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1659/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1660/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1661/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1662/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1663/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1664/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1665/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1666/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1667/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1668/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1669/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1670/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1671/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1672/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1673/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1674/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1675/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1676/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1677/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1678/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1679/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1680/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1681/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1682/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1683/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1684/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1685/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1686/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1687/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1688/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1689/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1690/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1691/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1692/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1693/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1694/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1695/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1696/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1697/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1698/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1699/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1700/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1701/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1702/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1703/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1704/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1705/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1706/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1707/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1708/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1709/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1710/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1711/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1712/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1713/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1714/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1715/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1716/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1717/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1718/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1719/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1720/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1721/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1722/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1723/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1724/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1725/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1726/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1727/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1728/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1729/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1730/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1731/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1732/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1733/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1734/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1735/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1736/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1737/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1738/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1740/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1741/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1742/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1743/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1744/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1745/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1746/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1747/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1748/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1749/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1750/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1751/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1752/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1753/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1754/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1755/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1756/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1757/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1758/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1759/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1760/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1761/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1762/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1763/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1764/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1765/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1766/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1767/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1768/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1769/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1770/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1771/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1772/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1773/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1774/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1775/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1776/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1777/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1778/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1779/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1780/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1781/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1782/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1783/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1784/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1785/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1787/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1788/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1789/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1790/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1791/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1792/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1793/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1794/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1795/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1796/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1797/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1798/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1799/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1800/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1801/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1802/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1804/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1805/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1806/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1807/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1808/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1809/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1810/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1811/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1812/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1813/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1814/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1815/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1816/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1817/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1818/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1819/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1820/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1821/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1822/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1823/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1824/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1825/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1826/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1827/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1828/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1829/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1830/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1831/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1832/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1833/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1834/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1835/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1836/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1837/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1838/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1839/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1840/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1841/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1842/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1843/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1844/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1845/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1846/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1847/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1848/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1849/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1850/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1851/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1852/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1853/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1854/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1855/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1856/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1857/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1858/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1859/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1860/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1861/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1862/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1863/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1864/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1865/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1866/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1867/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1868/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1869/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1870/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1871/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1872/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1873/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1874/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1875/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1876/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1877/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1878/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1879/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1880/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1881/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1882/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1883/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1884/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1885/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1886/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1887/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1888/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1889/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1890/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1891/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1892/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1893/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1894/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1895/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1896/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1897/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1898/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1899/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1900/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1901/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1902/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1903/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1904/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1905/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1906/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1907/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1908/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1909/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1910/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1911/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1912/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1913/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1914/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1915/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1916/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1917/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1918/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1919/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1920/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1921/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1922/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1923/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1925/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1926/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1927/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1928/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1929/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1930/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1931/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1932/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1933/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1934/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1935/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1936/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1937/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1938/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1939/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1940/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1941/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1942/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1943/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1944/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1945/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1946/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1947/2000\n",
      "5336/5336 [==============================] - 3597s 674ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1948/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1949/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1950/2000\n",
      "5336/5336 [==============================] - 3s 536us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1951/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1952/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1953/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1954/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1955/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1956/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1957/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1958/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1959/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1960/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1961/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1962/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1963/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1964/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1965/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1966/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1967/2000\n",
      "5336/5336 [==============================] - 3598s 674ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1968/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1969/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1970/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1971/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1972/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1973/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1974/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1975/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1976/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1977/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1978/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1979/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 1980/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1981/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1982/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1983/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1984/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1985/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 1986/2000\n",
      "5336/5336 [==============================] - 2135s 400ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1987/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1988/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1989/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1990/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1991/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1992/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1993/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1994/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1995/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1996/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1997/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1998/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1999/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 2000/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15455b550>"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_s, y=y_train_s, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_s, y_test_s),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(X_16, y_16, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size= .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.05329405,  1.12662344,  1.08065202, ...,  0.99302723,\n",
       "        1.0074516 ,  1.07181999])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.20542047e-04,   2.94347206e-06,   1.17223911e-04, ...,\n",
       "          1.01317123e-07,   1.00573546e-05,   0.00000000e+00],\n",
       "       [  1.08620399e-04,   2.74134129e-06,   1.05876393e-04, ...,\n",
       "          2.02634245e-07,   1.09090230e-05,   1.01317123e-05],\n",
       "       [  1.15501520e-04,   3.06397696e-06,   1.13069909e-04, ...,\n",
       "          2.22897670e-07,   1.08659813e-05,   1.01317123e-05],\n",
       "       ..., \n",
       "       [  1.01148261e-04,   2.54756143e-06,   9.73657548e-05, ...,\n",
       "          4.45795339e-07,   1.02013002e-05,   1.01317123e-05],\n",
       "       [  1.45533604e-04,   5.09203118e-06,   1.37689970e-04, ...,\n",
       "          9.72644377e-07,   1.07722709e-05,   1.01317123e-05],\n",
       "       [  1.06779804e-04,   4.98123265e-06,   1.02026342e-04, ...,\n",
       "          2.43161094e-07,   1.02495897e-05,   1.01317123e-05]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07416198487095663"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0055 ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(690,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .02\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(1350,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "# Added\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .005\n",
    "sgd = keras.optimizers.SGD(lr=0.005)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(690,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "# Added\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .005\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203 samples, validate on 88 samples\n",
      "Epoch 1/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 2/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 3/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 4/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 5/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 6/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 7/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 8/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 9/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 10/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 11/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 12/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 13/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 14/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 15/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 16/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 17/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 18/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 19/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 21/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 22/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 23/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 24/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 25/30\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-732-3cf934d04b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_2, y=y_train_2, \n",
    "          batch_size=2500, \n",
    "          epochs=30, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_2, y_test_2),\n",
    "          callbacks=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Without new features\n",
    "root = .0040 ** .5\n",
    "# .071\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2400.000000\n",
       "mean        1.066686\n",
       "std         0.065818\n",
       "min         0.831398\n",
       "25%         1.024956\n",
       "50%         1.061385\n",
       "75%         1.101586\n",
       "max         1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2186 samples, validate on 547 samples\n",
      "Epoch 1/2000\n",
      "2186/2186 [==============================] - 3s 2ms/step - loss: 1.1054 - val_loss: 1.0352\n",
      "Epoch 2/2000\n",
      "2186/2186 [==============================] - 1s 502us/step - loss: 1.0320 - val_loss: 0.9584\n",
      "Epoch 3/2000\n",
      "2186/2186 [==============================] - 1s 519us/step - loss: 0.9561 - val_loss: 0.8839\n",
      "Epoch 4/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.8826 - val_loss: 0.8130\n",
      "Epoch 5/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.8131 - val_loss: 0.7462\n",
      "Epoch 6/2000\n",
      "2186/2186 [==============================] - 1s 506us/step - loss: 0.7475 - val_loss: 0.6837\n",
      "Epoch 7/2000\n",
      "2186/2186 [==============================] - 1s 508us/step - loss: 0.6858 - val_loss: 0.6255\n",
      "Epoch 8/2000\n",
      "2186/2186 [==============================] - 1s 505us/step - loss: 0.6284 - val_loss: 0.5714\n",
      "Epoch 9/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.5750 - val_loss: 0.5213\n",
      "Epoch 10/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.5258 - val_loss: 0.4750\n",
      "Epoch 11/2000\n",
      "2186/2186 [==============================] - 1s 540us/step - loss: 0.4802 - val_loss: 0.4323\n",
      "Epoch 12/2000\n",
      "2186/2186 [==============================] - 1s 537us/step - loss: 0.4374 - val_loss: 0.3929\n",
      "Epoch 13/2000\n",
      "2186/2186 [==============================] - 1s 507us/step - loss: 0.3984 - val_loss: 0.3566\n",
      "Epoch 14/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.3623 - val_loss: 0.3233\n",
      "Epoch 15/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.3296 - val_loss: 0.2927\n",
      "Epoch 16/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.2987 - val_loss: 0.2646\n",
      "Epoch 17/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.2709 - val_loss: 0.2389\n",
      "Epoch 18/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.2446 - val_loss: 0.2155\n",
      "Epoch 19/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.2219 - val_loss: 0.1941\n",
      "Epoch 20/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.2004 - val_loss: 0.1746\n",
      "Epoch 21/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.1811 - val_loss: 0.1568\n",
      "Epoch 22/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.1634 - val_loss: 0.1407\n",
      "Epoch 23/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.1468 - val_loss: 0.1261\n",
      "Epoch 24/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.1323 - val_loss: 0.1129\n",
      "Epoch 25/2000\n",
      "2186/2186 [==============================] - 1s 501us/step - loss: 0.1189 - val_loss: 0.1010\n",
      "Epoch 26/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.1068 - val_loss: 0.0902\n",
      "Epoch 27/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0957 - val_loss: 0.0805\n",
      "Epoch 28/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0864 - val_loss: 0.0718\n",
      "Epoch 29/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0774 - val_loss: 0.0640\n",
      "Epoch 30/2000\n",
      "2186/2186 [==============================] - 1s 510us/step - loss: 0.0694 - val_loss: 0.0570\n",
      "Epoch 31/2000\n",
      "2186/2186 [==============================] - 1s 514us/step - loss: 0.0621 - val_loss: 0.0507\n",
      "Epoch 32/2000\n",
      "2186/2186 [==============================] - 1s 678us/step - loss: 0.0556 - val_loss: 0.0451\n",
      "Epoch 33/2000\n",
      "2186/2186 [==============================] - 1s 599us/step - loss: 0.0500 - val_loss: 0.0401\n",
      "Epoch 34/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.0452 - val_loss: 0.0356\n",
      "Epoch 35/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.0402 - val_loss: 0.0317\n",
      "Epoch 36/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0363 - val_loss: 0.0282\n",
      "Epoch 37/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0326 - val_loss: 0.0251\n",
      "Epoch 38/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.0293 - val_loss: 0.0223\n",
      "Epoch 39/2000\n",
      "2186/2186 [==============================] - 1s 524us/step - loss: 0.0262 - val_loss: 0.0199\n",
      "Epoch 40/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0238 - val_loss: 0.0178\n",
      "Epoch 41/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0214 - val_loss: 0.0159\n",
      "Epoch 42/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.0192 - val_loss: 0.0142\n",
      "Epoch 43/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 44/2000\n",
      "2186/2186 [==============================] - 1s 499us/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 45/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 46/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 47/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 48/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 49/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 50/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 51/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 52/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 53/2000\n",
      "2186/2186 [==============================] - 1s 501us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 54/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 55/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 56/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 57/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 58/2000\n",
      "2186/2186 [==============================] - 1s 524us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 59/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 60/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 61/2000\n",
      "2186/2186 [==============================] - 1s 511us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 62/2000\n",
      "2186/2186 [==============================] - 1s 505us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 63/2000\n",
      "2186/2186 [==============================] - 1s 506us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 64/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 65/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 66/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 67/2000\n",
      "2186/2186 [==============================] - 1s 521us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 68/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 69/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 70/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 71/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 72/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 73/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 74/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 75/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 76/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 77/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0043 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 79/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 80/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 81/2000\n",
      "2186/2186 [==============================] - 1s 489us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 82/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 83/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 84/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 85/2000\n",
      "2186/2186 [==============================] - 1s 508us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 86/2000\n",
      "2186/2186 [==============================] - 1s 499us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 87/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 88/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 89/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 90/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 91/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 92/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 93/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 94/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 95/2000\n",
      "2186/2186 [==============================] - 1s 522us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 96/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 97/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 98/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 99/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 100/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 101/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 102/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 103/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 104/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 105/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 106/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 107/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 108/2000\n",
      "2186/2186 [==============================] - 1s 488us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 109/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 110/2000\n",
      "2186/2186 [==============================] - 1s 488us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 111/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 112/2000\n",
      "2186/2186 [==============================] - 1s 489us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 113/2000\n",
      "2186/2186 [==============================] - 1s 513us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 114/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 115/2000\n",
      "2186/2186 [==============================] - 1s 502us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 116/2000\n",
      "2186/2186 [==============================] - 1s 586us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 117/2000\n",
      "2186/2186 [==============================] - 2s 726us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 118/2000\n",
      "2186/2186 [==============================] - 1s 628us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 119/2000\n",
      "2186/2186 [==============================] - 1s 655us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 120/2000\n",
      "2186/2186 [==============================] - 1s 634us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 121/2000\n",
      "2186/2186 [==============================] - 2s 723us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 122/2000\n",
      "2186/2186 [==============================] - 1s 594us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 123/2000\n",
      "2186/2186 [==============================] - 1s 592us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 124/2000\n",
      "2186/2186 [==============================] - 1s 555us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 125/2000\n",
      "2186/2186 [==============================] - 1s 595us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 126/2000\n",
      "2186/2186 [==============================] - 1s 659us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 127/2000\n",
      "2186/2186 [==============================] - 1s 623us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 128/2000\n",
      "2186/2186 [==============================] - 1s 534us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 129/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-562-052235ad6671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing) and new layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2186 samples, validate on 547 samples\n",
      "Epoch 1/2000\n",
      "2186/2186 [==============================] - 9s 4ms/step - loss: 1.1104 - val_loss: 1.0365\n",
      "Epoch 2/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 1.0305 - val_loss: 0.9589\n",
      "Epoch 3/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.9543 - val_loss: 0.8822\n",
      "Epoch 4/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.8791 - val_loss: 0.8091\n",
      "Epoch 5/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.8070 - val_loss: 0.7405\n",
      "Epoch 6/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.7393 - val_loss: 0.6766\n",
      "Epoch 7/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.6760 - val_loss: 0.6172\n",
      "Epoch 8/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.6172 - val_loss: 0.5622\n",
      "Epoch 9/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.5626 - val_loss: 0.5114\n",
      "Epoch 10/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.5124 - val_loss: 0.4645\n",
      "Epoch 11/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.4658 - val_loss: 0.4213\n",
      "Epoch 12/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.4228 - val_loss: 0.3816\n",
      "Epoch 13/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3833 - val_loss: 0.3451\n",
      "Epoch 14/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3474 - val_loss: 0.3117\n",
      "Epoch 15/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3142 - val_loss: 0.2811\n",
      "Epoch 16/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2837 - val_loss: 0.2532\n",
      "Epoch 17/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2559 - val_loss: 0.2277\n",
      "Epoch 18/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2306 - val_loss: 0.2045\n",
      "Epoch 19/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2076 - val_loss: 0.1834\n",
      "Epoch 20/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1868 - val_loss: 0.1643\n",
      "Epoch 21/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1672 - val_loss: 0.1470\n",
      "Epoch 22/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1500 - val_loss: 0.1313\n",
      "Epoch 23/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1343 - val_loss: 0.1171\n",
      "Epoch 24/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1203 - val_loss: 0.1044\n",
      "Epoch 25/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1076 - val_loss: 0.0929\n",
      "Epoch 26/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0959 - val_loss: 0.0826\n",
      "Epoch 27/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0856 - val_loss: 0.0734\n",
      "Epoch 28/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0765 - val_loss: 0.0652\n",
      "Epoch 29/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0681 - val_loss: 0.0578\n",
      "Epoch 30/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0607 - val_loss: 0.0513\n",
      "Epoch 31/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0542 - val_loss: 0.0454\n",
      "Epoch 32/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0481 - val_loss: 0.0403\n",
      "Epoch 33/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0428 - val_loss: 0.0357\n",
      "Epoch 34/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0382 - val_loss: 0.0316\n",
      "Epoch 35/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0341 - val_loss: 0.0280\n",
      "Epoch 36/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0249\n",
      "Epoch 37/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0270 - val_loss: 0.0221\n",
      "Epoch 38/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0243 - val_loss: 0.0197\n",
      "Epoch 39/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0217 - val_loss: 0.0175\n",
      "Epoch 40/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 41/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0175 - val_loss: 0.0140\n",
      "Epoch 42/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 43/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 44/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 45/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 46/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 47/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 48/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 49/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 50/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 51/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 52/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 53/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 54/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 55/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 56/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 57/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 58/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 59/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 60/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 61/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 62/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 63/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 64/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 65/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 66/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 67/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 68/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 69/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 70/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 71/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 72/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 73/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 74/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 75/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 76/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 77/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 78/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 80/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 81/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 82/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 83/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 84/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 85/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 86/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 87/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 88/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 89/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 90/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 91/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 92/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 93/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 94/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 95/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 96/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 97/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 98/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 99/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 100/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 101/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 102/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 103/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 104/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 105/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 106/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 107/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 108/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 109/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 110/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 111/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 112/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 113/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 114/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 115/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 116/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 117/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 118/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 119/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 120/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 121/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 122/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 123/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 124/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 125/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 126/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 127/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 128/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 129/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 130/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 131/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 132/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 133/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 134/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 135/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 136/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 137/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 138/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 139/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 140/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 141/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 142/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 143/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 144/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 145/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 146/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 147/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 148/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 149/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 150/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 151/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 152/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 153/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 154/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 155/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 156/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 158/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 159/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 160/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 161/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 162/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 163/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 164/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 165/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 166/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 167/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 168/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 169/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 170/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 171/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 172/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 173/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 174/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 175/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 176/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 177/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 178/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 179/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 180/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 181/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 182/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 183/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 184/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 185/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 186/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 187/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 188/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 189/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 190/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 191/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 192/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 193/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 194/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 195/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 196/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 197/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 198/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 199/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 200/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 201/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 202/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 203/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 204/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 205/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 206/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 207/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 208/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 209/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 210/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 211/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 212/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 213/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 214/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 215/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 216/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 217/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 218/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 219/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 220/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 221/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 222/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 223/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 224/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 225/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 226/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 227/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 228/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 229/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 230/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 231/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 232/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 233/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 234/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 236/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 237/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 238/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 239/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 240/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 241/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 242/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 243/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 244/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 245/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 246/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 247/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 248/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 249/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 250/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 251/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 252/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 253/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 254/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 255/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 256/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 257/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 258/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 259/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 260/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 261/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 262/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 263/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 264/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 265/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 266/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 267/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 268/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 269/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 270/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 271/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 272/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 273/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 274/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 275/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 276/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 277/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 278/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 279/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 280/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 281/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 282/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 283/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 284/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 285/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 286/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 287/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 288/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 289/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 290/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 291/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 292/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 293/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 294/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 295/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 296/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 297/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 298/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 299/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 300/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 301/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 302/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 303/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 304/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 305/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 306/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 307/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 308/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 309/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 310/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 311/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 312/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 314/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 315/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 316/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 317/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 318/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 319/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 320/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 321/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 322/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 323/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 324/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 325/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 326/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 327/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 328/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 329/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 330/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 331/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 332/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 333/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 334/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 335/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 336/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 337/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 338/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 339/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 340/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 341/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 342/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 343/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 344/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 345/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 346/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 347/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 348/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 349/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 350/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 351/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 352/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 353/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 354/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 355/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 356/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 357/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 358/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 359/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 360/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 361/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 362/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 363/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 364/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 365/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 366/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 367/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 368/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 369/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 370/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 371/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 372/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 373/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 374/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 375/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 376/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 377/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 378/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 379/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 380/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 381/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 382/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 383/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 384/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 385/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 386/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 387/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 388/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 389/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 390/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 392/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 393/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 394/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 395/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 396/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 397/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 398/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 399/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 400/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 401/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 402/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 403/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 404/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 405/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 406/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 407/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 408/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 409/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 410/2000\n",
      "2186/2186 [==============================] - 245s 112ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 411/2000\n",
      "2186/2186 [==============================] - 8s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 412/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 413/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 414/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 415/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 416/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 417/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 418/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 419/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 420/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 421/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 422/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 423/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 424/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 425/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 426/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 427/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 428/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 429/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 430/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 431/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 432/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 433/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 434/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 435/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 436/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 437/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 438/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 439/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 440/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 441/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 442/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 443/2000\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing) and new layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.0001)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
