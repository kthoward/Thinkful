{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import keras\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean notebook to be only new \n",
    "- Be able to merge train features and train targets\n",
    "- same with test\n",
    "- be able to then split and run program\n",
    "- test for overfit\n",
    "- create additional features (business/extra features from swing/ extra features from bugs)\n",
    "- run reviews for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        #data = unicode(data, errors='replace')\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "#read_data_list\n",
    "#fail_list\n",
    "list_of_file_names_org = list_of_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_MedianListingPricePerSqft_AllHomes.csv'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset].copy()\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(str)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_df = build_useful_df(read_data_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_list = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 10000:\n",
    "        sixteen_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_columns = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    columns = file.columns\n",
    "    if '2017-01' in columns:\n",
    "        good_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_good = []\n",
    "for num in sixteen_list:\n",
    "    if num in good_columns:\n",
    "        sixteen_good.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data = useful_df[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data_list = []\n",
    "for i, data in enumerate(useful_df):\n",
    "    if i in sixteen_good:\n",
    "        final_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10066"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PctPriceCut</th>\n",
       "      <th>DaysOnMarket</th>\n",
       "      <th>BuyerSellerIndex</th>\n",
       "      <th>BuyerSellerIndexMetro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99654</th>\n",
       "      <td>11.142857</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99645</th>\n",
       "      <td>7.589286</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99577</th>\n",
       "      <td>8.108108</td>\n",
       "      <td>79.5</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99567</th>\n",
       "      <td>9.836066</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99518</th>\n",
       "      <td>14.925373</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PctPriceCut  DaysOnMarket  BuyerSellerIndex  BuyerSellerIndexMetro\n",
       "RegionName                                                                    \n",
       "99654         11.142857          82.0          9.230769               7.260083\n",
       "99645          7.589286          74.0          0.769231               7.260083\n",
       "99577          8.108108          79.5          4.615385               7.260083\n",
       "99567          9.836066          76.0          2.307692               7.260083\n",
       "99518         14.925373          85.0         10.000000               7.260083"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "useful_df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(df, past_time_string, now_string):\n",
    "    #df.dropna(inplace=True)\n",
    "    features = pd.DataFrame()\n",
    "    #features['RegionName'] = df['RegionName']\n",
    "    mean = df.loc[:, past_time_string : now_string].mean(axis=1)\n",
    "    features['mean'] = mean\n",
    "    std = df.loc[:, past_time_string : now_string].std(axis=1)\n",
    "    features['std'] = std\n",
    "    mn = df.loc[:, past_time_string : now_string].min(axis=1)\n",
    "    features['min'] = mn\n",
    "    mx = df.loc[:, past_time_string : now_string].max(axis=1)\n",
    "    features['max'] = mx\n",
    "    features['swing'] = mx - mn\n",
    "    change = df[now_string] - df[past_time_string]\n",
    "    features['change'] = change\n",
    "    mean_swing = features['swing'].mean()\n",
    "    features['swing_pos'] = np.where(features['swing']>mean_swing, 1, 0)\n",
    "    big_swing = features['swing'].std() + mean_swing\n",
    "    features['swing_big'] = np.where(features['swing']>big_swing, 1, 0)\n",
    "    features['swing_neg'] = np.where(features['swing']<mean_swing, 1, 0)\n",
    "    swing_big_loss = mean_swing - features['swing'].std() \n",
    "    features['swing_loss_big'] = np.where(features['swing']<swing_big_loss, 1, 0)\n",
    "    #features.dropna(inplace=True)\n",
    "    \n",
    "    #features = features.set_index(df.index)\n",
    "    #print(features.iloc[1, :])\n",
    "    return features\n",
    "    \n",
    "# List of data frames only on one now_time\n",
    "def make_modeling_data(df_list, df_for_target, now_string):\n",
    "    df_one = pd.DataFrame()\n",
    "    target = pd.DataFrame()\n",
    "    now_time = pd.to_datetime(now_string)\n",
    "    now_value = df_for_target[now_string]\n",
    "    future_time = now_time + timedelta(days=6*31)\n",
    "    future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    future_value = df_for_target[future_time_string]\n",
    "    target['target'] = future_value/now_value\n",
    "    \n",
    "    \n",
    "    past_time = now_time - timedelta(days=6*31)\n",
    "    past_time_string= past_time.strftime(\"%Y-%m\")\n",
    "    df_to_use_for_features_org= df_list[0].loc[:, :now_string]\n",
    "    features_org = make_features(df_to_use_for_features_org, past_time_string, now_string)\n",
    "    df_one = pd.merge(df_one, features_org, left_index=True, right_index=True, how = 'right')\n",
    "    for i, df in enumerate(df_list[1:]):\n",
    "        ind = str(i)\n",
    "        columns = df.columns\n",
    "        if '2011-01' in columns and '2012-01' in columns and '2013-01' in columns and '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "            df_to_use_for_features= df.loc[:, :now_string]\n",
    "            features = make_features(df_to_use_for_features, past_time_string, now_string)\n",
    "            df_one = pd.merge(df_one, features, right_index=True, left_index=True, how='inner')\n",
    "    target = target.loc[df_one.index]    \n",
    "    #now_time = pd.to_datetime(now_string)\n",
    "    #now_value = df_for_target[now_string]\n",
    "    #future_time = now_time + timedelta(days=6*31)\n",
    "    #future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    #future_value = df_for_target[future_time_string]\n",
    "            #target = future_value/now_value\n",
    "\n",
    "    \n",
    "    return df_one, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_features, test_targets = make_modeling_data(final_data_list, target_data, \"2017-06\")\n",
    "train_features, train_targets = make_modeling_data(final_data_list, target_data, \"2017-01\")\n",
    "#extra_train_features_1, extra_train_targets_1 = make_modeling_data(final_data_list, target_data, '2016-06')\n",
    "train_features = train_features.append(train_features)\n",
    "train_targets = train_targets.append(train_targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df = useful_df[num]\n",
    "#columns = df.columns\n",
    "#\"2012\", \"2012\", \"2013\",\n",
    "date_counter = 0\n",
    "for year in [\"2012\", \"2013\", \"2014\", \"2015\", \"2016\"]:\n",
    "    for month in [\"06\",\"12\"]:\n",
    "            new_time = year+\"-\"+month\n",
    "            date_counter += 1\n",
    "            #if '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "                    #extra_train_features, extra_train_targets = make_modeling_data(df, new_time)\n",
    "                    #train_features = train_features.append(extra_train_features)\n",
    "                    #train_targets = train_targets.append(extra_train_targets)\n",
    "            extra_train_features, extra_train_targets = make_modeling_data(final_data_list, target_data, new_time)\n",
    "            #extra_train_features.dropna(inplace=True)\n",
    "            train_features = train_features.append(extra_train_features)\n",
    "            train_targets = train_targets.append(extra_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66132, 1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66132, 120)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99362</th>\n",
       "      <td>1.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99353</th>\n",
       "      <td>1.122185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99352</th>\n",
       "      <td>1.061993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99338</th>\n",
       "      <td>1.073945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99337</th>\n",
       "      <td>1.084956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target\n",
       "RegionName          \n",
       "99362       1.047544\n",
       "99353       1.122185\n",
       "99352       1.061993\n",
       "99338       1.073945\n",
       "99337       1.084956"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have not worked on w2v today; focused on business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features = pd.read_csv('real_business_w2v_features_3_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features['postal_code'] = w2v_features['postal_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 512)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features.index = w2v_features['postal_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features = w2v_features.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>average_review_count</th>\n",
       "      <th>business_count</th>\n",
       "      <th>zip_review_count</th>\n",
       "      <th>average_review_max</th>\n",
       "      <th>average_review_min</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.499208</td>\n",
       "      <td>-81.536689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>-0.050745</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>-0.067859</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.073559</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>-0.062522</td>\n",
       "      <td>0.054272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.964078</td>\n",
       "      <td>-73.285549</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>0.043280</td>\n",
       "      <td>-0.032233</td>\n",
       "      <td>-0.017144</td>\n",
       "      <td>0.060047</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>0.063483</td>\n",
       "      <td>-0.041164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.780821</td>\n",
       "      <td>-74.150722</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032312</td>\n",
       "      <td>-0.024693</td>\n",
       "      <td>-0.019165</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>-0.044335</td>\n",
       "      <td>-0.020998</td>\n",
       "      <td>0.041530</td>\n",
       "      <td>-0.048317</td>\n",
       "      <td>0.086379</td>\n",
       "      <td>-0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.083200</td>\n",
       "      <td>11.858200</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014649</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.033006</td>\n",
       "      <td>-0.015937</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.094979</td>\n",
       "      <td>0.085854</td>\n",
       "      <td>-0.037768</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>0.033392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.213256</td>\n",
       "      <td>11.763245</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013431</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.083113</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>0.023717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_open   latitude  longitude  review_count     stars  \\\n",
       "postal_code                                                          \n",
       "2224             1.0  41.499208 -81.536689      7.000000  2.500000   \n",
       "5440             1.0  44.964078 -73.285549      4.000000  4.250000   \n",
       "5452             1.0  40.780821 -74.150722     49.000000  4.000000   \n",
       "6618             1.0  51.083200  11.858200      8.000000  3.500000   \n",
       "6632             1.0  51.213256  11.763245      5.888889  4.222222   \n",
       "\n",
       "             average_review_count  business_count  zip_review_count  \\\n",
       "postal_code                                                           \n",
       "2224                     7.000000             1.0               7.0   \n",
       "5440                     4.000000             2.0               8.0   \n",
       "5452                    49.000000             1.0              49.0   \n",
       "6618                     8.000000             1.0               8.0   \n",
       "6632                     5.888889             9.0              53.0   \n",
       "\n",
       "             average_review_max  average_review_min    ...          490  \\\n",
       "postal_code                                            ...                \n",
       "2224                        7.0                 7.0    ...    -0.007905   \n",
       "5440                        5.0                 3.0    ...     0.024744   \n",
       "5452                       49.0                49.0    ...    -0.032312   \n",
       "6618                        8.0                 8.0    ...    -0.014649   \n",
       "6632                        8.0                 3.0    ...    -0.013431   \n",
       "\n",
       "                  491       492       493       494       495       496  \\\n",
       "postal_code                                                               \n",
       "2224        -0.050745  0.019509  0.089886 -0.067859 -0.057686 -0.073559   \n",
       "5440         0.024881  0.039596  0.043280 -0.032233 -0.017144  0.060047   \n",
       "5452        -0.024693 -0.019165  0.015924 -0.044335 -0.020998  0.041530   \n",
       "6618         0.000344  0.033006 -0.015937  0.011044  0.094979  0.085854   \n",
       "6632         0.007048  0.017738 -0.013003  0.016217  0.083113  0.092610   \n",
       "\n",
       "                  497       498       499  \n",
       "postal_code                                \n",
       "2224         0.004500 -0.062522  0.054272  \n",
       "5440        -0.002217  0.063483 -0.041164  \n",
       "5452        -0.048317  0.086379 -0.008370  \n",
       "6618        -0.037768 -0.038649  0.033392  \n",
       "6632        -0.032904 -0.048000  0.023717  \n",
       "\n",
       "[5 rows x 511 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is where business is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Up to date business features where all rows are a singular zipcode\n",
    "business_features = pd.read_csv('real_business_features_3_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(business_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 959 entries, 0 to 958\n",
      "Data columns (total 11 columns):\n",
      "postal_code             959 non-null int64\n",
      "is_open                 959 non-null float64\n",
      "latitude                959 non-null float64\n",
      "longitude               959 non-null float64\n",
      "review_count            959 non-null float64\n",
      "stars                   959 non-null float64\n",
      "average_review_count    959 non-null float64\n",
      "business_count          959 non-null float64\n",
      "zip_review_count        959 non-null float64\n",
      "average_review_max      959 non-null float64\n",
      "average_review_min      959 non-null float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 82.5 KB\n"
     ]
    }
   ],
   "source": [
    "business_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 11)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features['postal_code'] = business_features['postal_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features['postal_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features = business_features.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>average_review_count</th>\n",
       "      <th>business_count</th>\n",
       "      <th>zip_review_count</th>\n",
       "      <th>average_review_max</th>\n",
       "      <th>average_review_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.499208</td>\n",
       "      <td>-81.536689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.964078</td>\n",
       "      <td>-73.285549</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.780821</td>\n",
       "      <td>-74.150722</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.083200</td>\n",
       "      <td>11.858200</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.213256</td>\n",
       "      <td>11.763245</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_open   latitude  longitude  review_count     stars  \\\n",
       "postal_code                                                          \n",
       "2224             1.0  41.499208 -81.536689      7.000000  2.500000   \n",
       "5440             1.0  44.964078 -73.285549      4.000000  4.250000   \n",
       "5452             1.0  40.780821 -74.150722     49.000000  4.000000   \n",
       "6618             1.0  51.083200  11.858200      8.000000  3.500000   \n",
       "6632             1.0  51.213256  11.763245      5.888889  4.222222   \n",
       "\n",
       "             average_review_count  business_count  zip_review_count  \\\n",
       "postal_code                                                           \n",
       "2224                     7.000000             1.0               7.0   \n",
       "5440                     4.000000             2.0               8.0   \n",
       "5452                    49.000000             1.0              49.0   \n",
       "6618                     8.000000             1.0               8.0   \n",
       "6632                     5.888889             9.0              53.0   \n",
       "\n",
       "             average_review_max  average_review_min  \n",
       "postal_code                                          \n",
       "2224                        7.0                 7.0  \n",
       "5440                        5.0                 3.0  \n",
       "5452                       49.0                49.0  \n",
       "6618                        8.0                 8.0  \n",
       "6632                        8.0                 3.0  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66132, 120)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test_features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5511"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_targets = train_targets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_targets = test_targets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features_index = business_features.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_name_list = train_features['RegionName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_list = []\n",
    "for zipc in business_features_index:\n",
    "    if zipc in region_name_list:\n",
    "        shared_list.append(zipc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66132"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging on index for train features and targets so it doesn't multiply \n",
    "train_merge = pd.merge(train_features, train_targets, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = pd.merge(test_features, test_targets, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66132"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName_x</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>std_x</th>\n",
       "      <th>min_x</th>\n",
       "      <th>max_x</th>\n",
       "      <th>swing_x</th>\n",
       "      <th>change_x</th>\n",
       "      <th>swing_pos_x</th>\n",
       "      <th>swing_big_x</th>\n",
       "      <th>swing_neg_x</th>\n",
       "      <th>...</th>\n",
       "      <th>min_y</th>\n",
       "      <th>max_y</th>\n",
       "      <th>swing_y</th>\n",
       "      <th>change_y</th>\n",
       "      <th>swing_pos_y</th>\n",
       "      <th>swing_big_y</th>\n",
       "      <th>swing_neg_y</th>\n",
       "      <th>swing_loss_big_y</th>\n",
       "      <th>RegionName_y</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99362</td>\n",
       "      <td>9.899305</td>\n",
       "      <td>2.694838</td>\n",
       "      <td>7.225547</td>\n",
       "      <td>15.562721</td>\n",
       "      <td>8.337174</td>\n",
       "      <td>-8.337174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99362</td>\n",
       "      <td>1.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99353</td>\n",
       "      <td>12.713502</td>\n",
       "      <td>4.201132</td>\n",
       "      <td>8.701869</td>\n",
       "      <td>20.788350</td>\n",
       "      <td>12.086481</td>\n",
       "      <td>6.728607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99353</td>\n",
       "      <td>1.137133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99352</td>\n",
       "      <td>13.114296</td>\n",
       "      <td>2.222078</td>\n",
       "      <td>10.907130</td>\n",
       "      <td>17.667674</td>\n",
       "      <td>6.760545</td>\n",
       "      <td>2.172499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99352</td>\n",
       "      <td>1.011334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99338</td>\n",
       "      <td>10.337470</td>\n",
       "      <td>2.859324</td>\n",
       "      <td>6.462035</td>\n",
       "      <td>15.113417</td>\n",
       "      <td>8.651382</td>\n",
       "      <td>-1.678754</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99338</td>\n",
       "      <td>1.014762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99337</td>\n",
       "      <td>12.309892</td>\n",
       "      <td>3.922309</td>\n",
       "      <td>7.724349</td>\n",
       "      <td>18.444138</td>\n",
       "      <td>10.719789</td>\n",
       "      <td>-6.511823</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99337</td>\n",
       "      <td>1.062254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RegionName_x     mean_x     std_x      min_x      max_x    swing_x  \\\n",
       "0        99362   9.899305  2.694838   7.225547  15.562721   8.337174   \n",
       "1        99353  12.713502  4.201132   8.701869  20.788350  12.086481   \n",
       "2        99352  13.114296  2.222078  10.907130  17.667674   6.760545   \n",
       "3        99338  10.337470  2.859324   6.462035  15.113417   8.651382   \n",
       "4        99337  12.309892  3.922309   7.724349  18.444138  10.719789   \n",
       "\n",
       "   change_x  swing_pos_x  swing_big_x  swing_neg_x    ...     min_y  max_y  \\\n",
       "0 -8.337174            0            0            1    ...     0.874  0.894   \n",
       "1  6.728607            1            1            0    ...     0.874  0.886   \n",
       "2  2.172499            0            0            1    ...     0.900  0.908   \n",
       "3 -1.678754            1            0            0    ...     0.884  0.896   \n",
       "4 -6.511823            1            0            0    ...     0.878  0.890   \n",
       "\n",
       "   swing_y  change_y  swing_pos_y  swing_big_y  swing_neg_y  swing_loss_big_y  \\\n",
       "0    0.020     0.018            0            0            1                 0   \n",
       "1    0.012    -0.010            0            0            1                 0   \n",
       "2    0.008    -0.004            0            0            1                 0   \n",
       "3    0.012     0.008            0            0            1                 0   \n",
       "4    0.012     0.012            0            0            1                 0   \n",
       "\n",
       "   RegionName_y    target  \n",
       "0         99362  1.000168  \n",
       "1         99353  1.137133  \n",
       "2         99352  1.011334  \n",
       "3         99338  1.014762  \n",
       "4         99337  1.062254  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merge = train_merge.set_index('RegionName_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = test_merge.set_index('RegionName_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66132, 122)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 66132 entries, 99362 to 1001\n",
      "Columns: 122 entries, mean_x to target\n",
      "dtypes: float64(73), int64(48), object(1)\n",
      "memory usage: 62.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_merge.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 10)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5511"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge['RegionName_y'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_train_merge = pd.merge(train_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_test_merge = pd.merge(test_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_merge = pd.merge(train_merge, w2v_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_test_merge = pd.merge(test_merge, w2v_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_zillow_test_merge = pd.merge(test_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nztmc = new_zillow_test_merge.columns\n",
    "test_merge = new_zillow_test_merge.iloc[:, :-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_zillow_train_merge = pd.merge(train_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge = new_zillow_train_merge.iloc[:, :-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_merge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_merge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3996, 132)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should have all instances of the train and test. \n",
    "business_train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3996, 633)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_x</th>\n",
       "      <th>std_x</th>\n",
       "      <th>min_x</th>\n",
       "      <th>max_x</th>\n",
       "      <th>swing_x</th>\n",
       "      <th>change_x</th>\n",
       "      <th>swing_pos_x</th>\n",
       "      <th>swing_big_x</th>\n",
       "      <th>swing_neg_x</th>\n",
       "      <th>swing_loss_big_x</th>\n",
       "      <th>...</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>average_review_count</th>\n",
       "      <th>business_count</th>\n",
       "      <th>zip_review_count</th>\n",
       "      <th>average_review_max</th>\n",
       "      <th>average_review_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>14.464006</td>\n",
       "      <td>2.323347</td>\n",
       "      <td>11.537536</td>\n",
       "      <td>18.258360</td>\n",
       "      <td>6.720823</td>\n",
       "      <td>5.131603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>14.464006</td>\n",
       "      <td>2.323347</td>\n",
       "      <td>11.537536</td>\n",
       "      <td>18.258360</td>\n",
       "      <td>6.720823</td>\n",
       "      <td>5.131603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.066543</td>\n",
       "      <td>2.749281</td>\n",
       "      <td>9.918464</td>\n",
       "      <td>18.321159</td>\n",
       "      <td>8.402695</td>\n",
       "      <td>-1.485973</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>14.267149</td>\n",
       "      <td>3.381999</td>\n",
       "      <td>9.615653</td>\n",
       "      <td>19.912455</td>\n",
       "      <td>10.296802</td>\n",
       "      <td>-3.850137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>15.460086</td>\n",
       "      <td>3.876415</td>\n",
       "      <td>9.615653</td>\n",
       "      <td>20.093610</td>\n",
       "      <td>10.477957</td>\n",
       "      <td>8.783796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>16.248923</td>\n",
       "      <td>2.768642</td>\n",
       "      <td>11.968512</td>\n",
       "      <td>21.010779</td>\n",
       "      <td>9.042267</td>\n",
       "      <td>2.144157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>16.116125</td>\n",
       "      <td>4.855846</td>\n",
       "      <td>8.884885</td>\n",
       "      <td>24.155285</td>\n",
       "      <td>15.270400</td>\n",
       "      <td>2.256744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>16.885622</td>\n",
       "      <td>3.206663</td>\n",
       "      <td>13.813915</td>\n",
       "      <td>24.155285</td>\n",
       "      <td>10.341370</td>\n",
       "      <td>-8.362070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.163923</td>\n",
       "      <td>2.375110</td>\n",
       "      <td>9.706724</td>\n",
       "      <td>16.074128</td>\n",
       "      <td>6.367404</td>\n",
       "      <td>-2.375702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>14.980037</td>\n",
       "      <td>2.924676</td>\n",
       "      <td>9.706724</td>\n",
       "      <td>19.470481</td>\n",
       "      <td>9.763757</td>\n",
       "      <td>8.018858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>15.011149</td>\n",
       "      <td>3.868854</td>\n",
       "      <td>8.586176</td>\n",
       "      <td>21.331859</td>\n",
       "      <td>12.745683</td>\n",
       "      <td>-3.823192</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.59825</td>\n",
       "      <td>-80.223206</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>10.861111</td>\n",
       "      <td>36.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean_x     std_x      min_x      max_x    swing_x  change_x  \\\n",
       "15003  14.464006  2.323347  11.537536  18.258360   6.720823  5.131603   \n",
       "15003  14.464006  2.323347  11.537536  18.258360   6.720823  5.131603   \n",
       "15003  13.066543  2.749281   9.918464  18.321159   8.402695 -1.485973   \n",
       "15003  14.267149  3.381999   9.615653  19.912455  10.296802 -3.850137   \n",
       "15003  15.460086  3.876415   9.615653  20.093610  10.477957  8.783796   \n",
       "15003  16.248923  2.768642  11.968512  21.010779   9.042267  2.144157   \n",
       "15003  16.116125  4.855846   8.884885  24.155285  15.270400  2.256744   \n",
       "15003  16.885622  3.206663  13.813915  24.155285  10.341370 -8.362070   \n",
       "15003  13.163923  2.375110   9.706724  16.074128   6.367404 -2.375702   \n",
       "15003  14.980037  2.924676   9.706724  19.470481   9.763757  8.018858   \n",
       "15003  15.011149  3.868854   8.586176  21.331859  12.745683 -3.823192   \n",
       "\n",
       "       swing_pos_x  swing_big_x  swing_neg_x  swing_loss_big_x  \\\n",
       "15003            0            0            1                 0   \n",
       "15003            0            0            1                 0   \n",
       "15003            1            0            0                 0   \n",
       "15003            1            0            0                 0   \n",
       "15003            1            0            0                 0   \n",
       "15003            1            0            0                 0   \n",
       "15003            1            1            0                 0   \n",
       "15003            1            0            0                 0   \n",
       "15003            0            0            1                 0   \n",
       "15003            1            0            0                 0   \n",
       "15003            1            1            0                 0   \n",
       "\n",
       "              ...           is_open  latitude  longitude  review_count  \\\n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "15003         ...          0.916667  40.59825 -80.223206     10.861111   \n",
       "\n",
       "          stars  average_review_count  business_count  zip_review_count  \\\n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "15003  3.958333             10.861111            36.0             391.0   \n",
       "\n",
       "       average_review_max  average_review_min  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "15003                50.0                 3.0  \n",
       "\n",
       "[11 rows x 132 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is it ok that I have multiple of the aggregated information from Yelp?\n",
    "business_train_merge.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merge = train_merge.drop('RegionName_y', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = test_merge.drop('RegionName_y', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most up to date Business attempt\n",
    "- Why is y glitching with NaN?\n",
    "- Update I have not removed any NaN's yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_x', 'std_x', 'min_x', 'max_x', 'swing_x', 'change_x',\n",
       "       'swing_pos_x', 'swing_big_x', 'swing_neg_x', 'swing_loss_big_x',\n",
       "       ...\n",
       "       'std_y', 'min_y', 'max_y', 'swing_y', 'change_y', 'swing_pos_y',\n",
       "       'swing_big_y', 'swing_neg_y', 'swing_loss_big_y', 'target'],\n",
       "      dtype='object', length=121)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_test_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 331 entries, 95966 to 15003\n",
      "Columns: 132 entries, mean_x to average_review_min\n",
      "dtypes: float64(83), int64(48), object(1)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 169 zipcodes in common after dropna. Had about double that before\n",
    "business_test_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = w2v_test_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RegionName_y', 'target', 'is_open', 'latitude', 'longitude',\n",
       "       'review_count', 'stars', 'average_review_count', 'business_count',\n",
       "       'zip_review_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col[120:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_merge.iloc[:, :-1].values\n",
    "y_train = train_merge.iloc[:, -1].values\n",
    "X_test = test_merge.iloc[:, :-1].values\n",
    "y_test = test_merge.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_merge = w2v_train_merge.drop('RegionName_y', 1)\n",
    "w2v_test_merge = w2v_test_merge.drop('RegionName_y', 1)\n",
    "y_train_w2v = w2v_train_merge.loc[:, 'target'].values\n",
    "y_test_w2v = w2v_test_merge.loc[:, 'target'].values\n",
    "w2v_train = pd.DataFrame()\n",
    "w2v_train_features = w2v_train_merge.drop('target', 1).values\n",
    "X_train_w2v = pd.DataFrame()\n",
    "X_train_w2v = w2v_train_features\n",
    "X_test_w2v_features = pd.DataFrame()\n",
    "X_test_w2v_features = w2v_test_merge.drop('target', 1).values\n",
    "X_test_w2v = pd.DataFrame()\n",
    "X_test_w2v = X_test_w2v_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up train and test\n",
    "business_train_merge = business_train_merge.drop('RegionName_y', 1)\n",
    "business_test_merge = business_test_merge.drop('RegionName_y', 1)\n",
    "y_train_business = business_train_merge.loc[:, 'target'].values\n",
    "y_test_business = business_test_merge.loc[:, 'target'].values\n",
    "business_train = pd.DataFrame()\n",
    "business_train_features = business_train_merge.drop('target', 1).values\n",
    "X_train_business = pd.DataFrame()\n",
    "X_train_business = business_train_features\n",
    "X_test_business_features = pd.DataFrame()\n",
    "X_test_business_features = business_test_merge.drop('target', 1).values\n",
    "X_test_business = pd.DataFrame()\n",
    "X_test_business = X_test_business_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 130)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2839, 631)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 631)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_per_column(X):\n",
    "    new_array = []\n",
    "    shape = X.shape\n",
    "    columns = shape[1]\n",
    "    for num in range(columns):\n",
    "        mx = X[:, num].max()\n",
    "        if mx == 0:\n",
    "            new_array.append(X[:, num])\n",
    "        else:\n",
    "            X[:, num] = X[:, num] / mx\n",
    "            new_array.append(X[:, num])\n",
    "    new_array = np.array(new_array)\n",
    "    new_array = np.transpose(new_array)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = norm_per_column(X_train)\n",
    "X_test = norm_per_column(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_business = norm_per_column(X_train_business)\n",
    "X_test_business = norm_per_column(X_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_w2v = norm_per_column(X_train_w2v)\n",
    "X_test_w2v = norm_per_column(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028560998107322942"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03568676443\n",
      "0.809566962437\n",
      "1.32300764356\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean())\n",
    "print(y_train.min())\n",
    "print(y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01812630226\n",
      "0.833675690212\n",
      "1.18704258259\n"
     ]
    }
   ],
   "source": [
    "print(y_test.mean())\n",
    "print(y_test.min())\n",
    "print(y_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_class_2(y_list):\n",
    "    y_df = pd.DataFrame()\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    y_3 = []\n",
    "    y_4 = []\n",
    "    y_5 = []\n",
    "    \n",
    "    for y in y_list:\n",
    "        if y <= .9:\n",
    "            y_1.append(1)\n",
    "        else:\n",
    "            y_1.append(0)\n",
    "        if y > .9 and y <= .97:\n",
    "            y_2.append(1)\n",
    "        else:\n",
    "            y_2.append(0)\n",
    "        if y > .97 and y < 1.03:\n",
    "            y_3.append(1)\n",
    "        else:\n",
    "            y_3.append(0)\n",
    "        if y >= 1.03 and y < 1.1:\n",
    "            y_4.append(1)\n",
    "        else:\n",
    "            y_4.append(0)\n",
    "        if y >= 1.1:\n",
    "            y_5.append(1)\n",
    "        else:\n",
    "            y_5.append(0)\n",
    "    y_df['1'] = y_1\n",
    "    y_df['2'] = y_2\n",
    "    y_df['3'] = y_3\n",
    "    y_df['4'] = y_4\n",
    "    y_df['5'] = y_5\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_class(y_list):\n",
    "    y_df = pd.DataFrame()\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    y_3 = []\n",
    "    y_4 = []\n",
    "    y_5 = []\n",
    "    y_6 = []\n",
    "    y_7 = []\n",
    "    for y in y_list:\n",
    "        if y <= .89:\n",
    "            y_1.append(1)\n",
    "        else:\n",
    "            y_1.append(0)\n",
    "        if y > .89 and y <= .95:\n",
    "            y_2.append(1)\n",
    "        else:\n",
    "            y_2.append(0)\n",
    "        if y > .95 and y <= 1.01:\n",
    "            y_3.append(1)\n",
    "        else:\n",
    "            y_3.append(0)\n",
    "        if y > 1.01 and y <= 1.07:\n",
    "            y_4.append(1)\n",
    "        else:\n",
    "            y_4.append(0)\n",
    "        if y > 1.07 and y <= 1.13:\n",
    "            y_5.append(1)\n",
    "        else:\n",
    "            y_5.append(0)\n",
    "        if y > 1.13 and y <= 1.19:\n",
    "            y_6.append(1)\n",
    "        else:\n",
    "            y_6.append(0)\n",
    "        if y > 1.19:\n",
    "            y_7.append(1)\n",
    "        else:\n",
    "            y_7.append(0)\n",
    "    y_df['1'] = y_1\n",
    "    y_df['2'] = y_2\n",
    "    y_df['3'] = y_3\n",
    "    y_df['4'] = y_4\n",
    "    y_df['5'] = y_5\n",
    "    y_df['6'] = y_6\n",
    "    y_df['7'] = y_7\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = create_y_class_2(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test = create_y_class_2(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_train_w2v = create_y_class_2(y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_test_w2v = create_y_class_2(y_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_train_business = create_y_class_2(y_train_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_test_business = create_y_class_2(y_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test['5'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028560998107322942"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_business.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold overfit model for now\n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(110,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.005)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 1s 236us/step - loss: 5.0520 - val_loss: 0.8179\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7713 - val_loss: 0.3394\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.3612 - val_loss: 0.2371\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.2764 - val_loss: 0.1511\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2429 - val_loss: 0.2028\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2299 - val_loss: 0.2910\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.2521 - val_loss: 0.2652\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.2281 - val_loss: 0.2487\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.2222 - val_loss: 0.2714\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2144 - val_loss: 0.1786\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1842 - val_loss: 0.2195\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1916 - val_loss: 0.1885\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1832 - val_loss: 0.2151\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1816 - val_loss: 0.1826\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1745 - val_loss: 0.2086\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1787 - val_loss: 0.1617\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1594 - val_loss: 0.1338\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1550 - val_loss: 0.2199\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1771 - val_loss: 0.0895\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1299 - val_loss: 0.1363\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1379 - val_loss: 0.1503\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1506 - val_loss: 0.1746\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1463 - val_loss: 0.1642\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1469 - val_loss: 0.1819\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1473 - val_loss: 0.1741\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1459 - val_loss: 0.1045\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1194 - val_loss: 0.1406\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1274 - val_loss: 0.1488\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1401 - val_loss: 0.2289\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1646 - val_loss: 0.0925\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1192 - val_loss: 0.1926\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1455 - val_loss: 0.1263\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1286 - val_loss: 0.1707\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1246 - val_loss: 0.1325\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1191 - val_loss: 0.1444\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1252 - val_loss: 0.1304\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1141 - val_loss: 0.1527\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1287 - val_loss: 0.1246\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1096 - val_loss: 0.1241\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1153 - val_loss: 0.1390\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1042 - val_loss: 0.1025\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0994 - val_loss: 0.1072\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0937 - val_loss: 0.1136\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0999 - val_loss: 0.1187\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0955 - val_loss: 0.1036\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0905 - val_loss: 0.1051\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0981 - val_loss: 0.1360\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1053 - val_loss: 0.0596\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0663 - val_loss: 0.0843\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0873 - val_loss: 0.1162\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0937 - val_loss: 0.0669\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0693 - val_loss: 0.0726\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0788 - val_loss: 0.1341\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0954 - val_loss: 0.0610\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0626 - val_loss: 0.0632\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0674 - val_loss: 0.1003\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0855 - val_loss: 0.0638\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0689 - val_loss: 0.0794\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0687 - val_loss: 0.0567\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0618 - val_loss: 0.0543\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0574 - val_loss: 0.0688\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0632 - val_loss: 0.0472\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0532 - val_loss: 0.0417\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0493 - val_loss: 0.0448\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0508 - val_loss: 0.0559\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0575 - val_loss: 0.0423\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0486 - val_loss: 0.0483\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0493 - val_loss: 0.0308\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0394 - val_loss: 0.0309\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0398 - val_loss: 0.0246\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0375 - val_loss: 0.0292\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0394 - val_loss: 0.0235\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0366 - val_loss: 0.0210\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0341 - val_loss: 0.0183\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0328 - val_loss: 0.0115\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0292 - val_loss: 0.0160\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0309 - val_loss: 0.0143\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0288 - val_loss: 0.0085\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0262 - val_loss: 0.0080\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0244 - val_loss: 0.0064\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0244 - val_loss: 0.0034\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0232 - val_loss: 0.0029\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0228 - val_loss: 0.0033\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.022 - 0s 30us/step - loss: 0.0216 - val_loss: 0.0048\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0216 - val_loss: 0.0069\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0240 - val_loss: 0.0053\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0222 - val_loss: 0.0046\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0210 - val_loss: 0.0049\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0200 - val_loss: 0.0047\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0203 - val_loss: 0.0042\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0195 - val_loss: 0.0048\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0196 - val_loss: 0.0058\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0199 - val_loss: 0.0036\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0181 - val_loss: 0.0029\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0182 - val_loss: 0.0030\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0174 - val_loss: 0.0032\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0163 - val_loss: 0.0035\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0169 - val_loss: 0.0044\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0172 - val_loss: 0.0040\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0167 - val_loss: 0.0031\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0154 - val_loss: 0.0030\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0152 - val_loss: 0.0028\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0149 - val_loss: 0.0031\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0152 - val_loss: 0.0061\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0163 - val_loss: 0.0032\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0140 - val_loss: 0.0029\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0141 - val_loss: 0.0028\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0130 - val_loss: 0.0028\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0130 - val_loss: 0.0030\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0130 - val_loss: 0.0030\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0129 - val_loss: 0.0040\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0140 - val_loss: 0.0034\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0040\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0134 - val_loss: 0.0046\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0138 - val_loss: 0.0030\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0121 - val_loss: 0.0027\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0115 - val_loss: 0.0026\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0108 - val_loss: 0.0027\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0111 - val_loss: 0.0028\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0108 - val_loss: 0.0037\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0114 - val_loss: 0.0030\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0102 - val_loss: 0.0028\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0099 - val_loss: 0.0026\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0101 - val_loss: 0.0027\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0090 - val_loss: 0.0027\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0097 - val_loss: 0.0045\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0031\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0088 - val_loss: 0.0028\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0084 - val_loss: 0.0035\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0090 - val_loss: 0.0030\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0078 - val_loss: 0.0031\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0082 - val_loss: 0.0037\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0071 - val_loss: 0.0028\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.004 - 0s 29us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0086\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 0.0077\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0077\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0069\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0075\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0073\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0074\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0069\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0096\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0085\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0071\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0082\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0089\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0076\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0082\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0103\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0076\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0095\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0091\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0082\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0095\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0072\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0091\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0088\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0080\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0081\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0075\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0088\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0075\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0103\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0087\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0123\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0079\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0079\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0080\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0071\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0071\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0074\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0088\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0092\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0074\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.0015 - val_loss: 0.0074\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0022 - val_loss: 0.0068\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0096\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0027 - val_loss: 0.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161274f28>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss = .00001441 (overfit) = .0038\n",
    "\n",
    "#std = .072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.01)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 1s 216us/step - loss: 102.0821 - val_loss: 1.4821\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.1341 - val_loss: 0.2196\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1817 - val_loss: 0.0314\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0701 - val_loss: 0.0266\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0657 - val_loss: 0.0245\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0631 - val_loss: 0.0236\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0640 - val_loss: 0.0221\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0590 - val_loss: 0.0209\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0551 - val_loss: 0.0190\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0541 - val_loss: 0.0164\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0515 - val_loss: 0.0135\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0494 - val_loss: 0.0096\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0457 - val_loss: 0.0108\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0532 - val_loss: 0.0504\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0761 - val_loss: 0.0172\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0451 - val_loss: 0.0146\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0427 - val_loss: 0.0120\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0405 - val_loss: 0.0256\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0609 - val_loss: 0.0473\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0705 - val_loss: 0.0146\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0426 - val_loss: 0.0106\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0393 - val_loss: 0.0114\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0443 - val_loss: 0.0632\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0817 - val_loss: 0.0216\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0475 - val_loss: 0.0103\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0367 - val_loss: 0.0179\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0521 - val_loss: 0.0719\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0843 - val_loss: 0.0160\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0399 - val_loss: 0.0138\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0378 - val_loss: 0.0426\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0839 - val_loss: 0.1059\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1239 - val_loss: 0.0703\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1016 - val_loss: 0.1552\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1600 - val_loss: 0.1321\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.1246 - val_loss: 0.0649\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0737 - val_loss: 0.0484\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0601 - val_loss: 0.0372\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0511 - val_loss: 0.0586\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0673 - val_loss: 0.0794\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1001 - val_loss: 0.1924\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.203 - 0s 28us/step - loss: 0.1859 - val_loss: 0.2647\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.2162 - val_loss: 0.0884\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0979 - val_loss: 0.1312\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1226 - val_loss: 0.1166\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.1093 - val_loss: 0.0926\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0893 - val_loss: 0.0733\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0740 - val_loss: 0.0807\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0879 - val_loss: 0.1426\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1254 - val_loss: 0.1211\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1132 - val_loss: 0.1357\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.1130 - val_loss: 0.0504\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0576 - val_loss: 0.0806\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0899 - val_loss: 0.0742\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1412 - val_loss: 0.3710\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2881 - val_loss: 0.2190\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.2753 - val_loss: 0.0069\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0296 - val_loss: 0.0280\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0666 - val_loss: 0.2307\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.244 - 0s 29us/step - loss: 0.1834 - val_loss: 0.0165\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0389 - val_loss: 0.0228\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0452 - val_loss: 0.0414\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0621 - val_loss: 0.0366\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0622 - val_loss: 0.0656\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1030 - val_loss: 0.0503\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0679 - val_loss: 0.0280\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0486 - val_loss: 0.0399\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0668 - val_loss: 0.0745\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0906 - val_loss: 0.0909\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.1303 - val_loss: 0.0051\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0203 - val_loss: 0.0058\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0172 - val_loss: 0.0093\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0214 - val_loss: 0.0354\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0436 - val_loss: 0.0724\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0701 - val_loss: 0.0756\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0695 - val_loss: 0.0479\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.058 - 0s 29us/step - loss: 0.0539 - val_loss: 0.0621\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0566 - val_loss: 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0369 - val_loss: 0.0637\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0661 - val_loss: 0.0851\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0725 - val_loss: 0.0168\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0257 - val_loss: 0.0227\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0328 - val_loss: 0.0473\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0509 - val_loss: 0.0493\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0494 - val_loss: 0.0221\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0298 - val_loss: 0.0179\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0266 - val_loss: 0.0308\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0465 - val_loss: 0.0866\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0738 - val_loss: 0.0139\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0290 - val_loss: 0.0419\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0417 - val_loss: 0.0106\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0199 - val_loss: 0.0105\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0201 - val_loss: 0.0171\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0242 - val_loss: 0.0273\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0325 - val_loss: 0.0325\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0351 - val_loss: 0.0238\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0288 - val_loss: 0.0144\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0212 - val_loss: 0.0192\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0247 - val_loss: 0.0201\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0247 - val_loss: 0.0194\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0236 - val_loss: 0.0138\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0224 - val_loss: 0.0361\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0381 - val_loss: 0.0314\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0304 - val_loss: 0.0062\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0119 - val_loss: 0.0055\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0116 - val_loss: 0.0060\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0132 - val_loss: 0.0139\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.019 - 0s 30us/step - loss: 0.0203 - val_loss: 0.0228\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0280 - val_loss: 0.0266\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0260 - val_loss: 0.0051\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0113 - val_loss: 0.0048\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0096 - val_loss: 0.0046\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0104 - val_loss: 0.0186\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0292 - val_loss: 0.0488\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0623 - val_loss: 0.0517\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0428 - val_loss: 0.0031\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0387 - val_loss: 0.0598\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0521 - val_loss: 0.0073\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0108 - val_loss: 0.0028\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0068 - val_loss: 0.0024\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0066 - val_loss: 0.0027\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0117 - val_loss: 0.0235\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0473 - val_loss: 0.3525\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2696 - val_loss: 0.0145\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0173 - val_loss: 0.0022\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0076 - val_loss: 0.0022\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0075 - val_loss: 0.0022\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0021\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0072 - val_loss: 0.0022\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0067 - val_loss: 0.0021\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0080 - val_loss: 0.0050\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0151 - val_loss: 0.0068\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0070 - val_loss: 0.0090\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0125 - val_loss: 0.0388\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0432 - val_loss: 0.0837\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0687 - val_loss: 0.0029\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0108 - val_loss: 0.0038\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0096 - val_loss: 0.0038\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0067 - val_loss: 0.0254\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0191 - val_loss: 0.0035\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 43us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0084 - val_loss: 0.0025\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0101 - val_loss: 0.0032\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0030 - val_loss: 0.0069\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0026 - val_loss: 0.0073\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0038 - val_loss: 0.0078\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0085\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0103\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a17ec88>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_business, y=y_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_test_business),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.002)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 100us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 70us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 94us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 70us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 70us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 70us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 94us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0012 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 93us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0012 - val_loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c3f5f28>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_w2v, y=y_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_test_w2v),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {0 : 2,\n",
    "    1: 1.25,\n",
    "    2: .75,\n",
    "    3: .25,\n",
    "    4: .75,\n",
    "    5: 1.25,\n",
    "    6: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {0 : 2,\n",
    "    1: 1,\n",
    "    2: .5,\n",
    "    3: 1,\n",
    "    4: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.00001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 3s 894us/step - loss: 1.2431 - acc: 0.0588 - val_loss: 1.2546 - val_acc: 0.0846\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.2358 - acc: 0.0634 - val_loss: 1.2500 - val_acc: 0.0846\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.2332 - acc: 0.0634 - val_loss: 1.2461 - val_acc: 0.0846\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.2304 - acc: 0.0627 - val_loss: 1.2427 - val_acc: 0.0846\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.2258 - acc: 0.0673 - val_loss: 1.2396 - val_acc: 0.0846\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.2235 - acc: 0.0645 - val_loss: 1.2367 - val_acc: 0.0846\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2208 - acc: 0.0722 - val_loss: 1.2340 - val_acc: 0.0846\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2184 - acc: 0.0662 - val_loss: 1.2314 - val_acc: 0.0846\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.2140 - acc: 0.0715 - val_loss: 1.2289 - val_acc: 0.0846\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.2136 - acc: 0.0690 - val_loss: 1.2265 - val_acc: 0.0846\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2114 - acc: 0.0697 - val_loss: 1.2241 - val_acc: 0.0846\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2086 - acc: 0.0708 - val_loss: 1.2219 - val_acc: 0.0846\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2094 - acc: 0.0712 - val_loss: 1.2197 - val_acc: 0.0846\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2063 - acc: 0.0726 - val_loss: 1.2175 - val_acc: 0.0846\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.2032 - acc: 0.0743 - val_loss: 1.2153 - val_acc: 0.0846\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2026 - acc: 0.0694 - val_loss: 1.2132 - val_acc: 0.0846\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2023 - acc: 0.0747 - val_loss: 1.2111 - val_acc: 0.0876\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1966 - acc: 0.0782 - val_loss: 1.2091 - val_acc: 0.0846\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.1968 - acc: 0.0800 - val_loss: 1.2071 - val_acc: 0.0846\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.1948 - acc: 0.0768 - val_loss: 1.2051 - val_acc: 0.0846\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1957 - acc: 0.0785 - val_loss: 1.2031 - val_acc: 0.0846\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1910 - acc: 0.0793 - val_loss: 1.2011 - val_acc: 0.0876\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1920 - acc: 0.0764 - val_loss: 1.1992 - val_acc: 0.0876\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1879 - acc: 0.0821 - val_loss: 1.1973 - val_acc: 0.0876\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1863 - acc: 0.0852 - val_loss: 1.1954 - val_acc: 0.0906\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1848 - acc: 0.0842 - val_loss: 1.1935 - val_acc: 0.0876\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1833 - acc: 0.0828 - val_loss: 1.1916 - val_acc: 0.0876\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1821 - acc: 0.0902 - val_loss: 1.1897 - val_acc: 0.0876\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1806 - acc: 0.0859 - val_loss: 1.1879 - val_acc: 0.0876\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.1774 - acc: 0.0933 - val_loss: 1.1860 - val_acc: 0.0876\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.1768 - acc: 0.0902 - val_loss: 1.1842 - val_acc: 0.0876\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.1750 - acc: 0.0937 - val_loss: 1.1823 - val_acc: 0.0876\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1714 - acc: 0.1029 - val_loss: 1.1805 - val_acc: 0.0906\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1717 - acc: 0.1032 - val_loss: 1.1787 - val_acc: 0.0906\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1712 - acc: 0.1021 - val_loss: 1.1769 - val_acc: 0.0906\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1692 - acc: 0.0972 - val_loss: 1.1751 - val_acc: 0.0906\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1671 - acc: 0.1036 - val_loss: 1.1733 - val_acc: 0.0906\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1654 - acc: 0.1078 - val_loss: 1.1716 - val_acc: 0.0906\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1647 - acc: 0.1046 - val_loss: 1.1698 - val_acc: 0.0906\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1624 - acc: 0.1078 - val_loss: 1.1681 - val_acc: 0.0937\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1611 - acc: 0.1074 - val_loss: 1.1663 - val_acc: 0.0937\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1600 - acc: 0.1138 - val_loss: 1.1645 - val_acc: 0.0937\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.1577 - acc: 0.1191 - val_loss: 1.1628 - val_acc: 0.0937\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1575 - acc: 0.1176 - val_loss: 1.1610 - val_acc: 0.0937\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1551 - acc: 0.1212 - val_loss: 1.1593 - val_acc: 0.0997\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1526 - acc: 0.1215 - val_loss: 1.1576 - val_acc: 0.0997\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1494 - acc: 0.1229 - val_loss: 1.1559 - val_acc: 0.1027\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.1495 - acc: 0.1247 - val_loss: 1.1542 - val_acc: 0.1027\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1507 - acc: 0.1307 - val_loss: 1.1525 - val_acc: 0.1057\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1494 - acc: 0.1236 - val_loss: 1.1508 - val_acc: 0.1057\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1461 - acc: 0.1374 - val_loss: 1.1491 - val_acc: 0.1057\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1448 - acc: 0.1310 - val_loss: 1.1474 - val_acc: 0.1057\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1443 - acc: 0.1384 - val_loss: 1.1457 - val_acc: 0.1027\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1435 - acc: 0.1430 - val_loss: 1.1441 - val_acc: 0.1057\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1401 - acc: 0.1472 - val_loss: 1.1424 - val_acc: 0.1057\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.1399 - acc: 0.1532 - val_loss: 1.1408 - val_acc: 0.1057\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1377 - acc: 0.1560 - val_loss: 1.1391 - val_acc: 0.1088\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1364 - acc: 0.1508 - val_loss: 1.1374 - val_acc: 0.1148\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1364 - acc: 0.1508 - val_loss: 1.1358 - val_acc: 0.1178\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1349 - acc: 0.1613 - val_loss: 1.1342 - val_acc: 0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1308 - acc: 0.1627 - val_loss: 1.1325 - val_acc: 0.1178\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1317 - acc: 0.1687 - val_loss: 1.1309 - val_acc: 0.1148\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1307 - acc: 0.1761 - val_loss: 1.1293 - val_acc: 0.1148\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1276 - acc: 0.1793 - val_loss: 1.1277 - val_acc: 0.1178\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.1278 - acc: 0.1832 - val_loss: 1.1261 - val_acc: 0.1178\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1243 - acc: 0.1884 - val_loss: 1.1244 - val_acc: 0.1178\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1245 - acc: 0.1810 - val_loss: 1.1228 - val_acc: 0.1269\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1235 - acc: 0.1920 - val_loss: 1.1212 - val_acc: 0.1269\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1217 - acc: 0.1927 - val_loss: 1.1197 - val_acc: 0.1329\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1199 - acc: 0.2050 - val_loss: 1.1181 - val_acc: 0.1329\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1186 - acc: 0.2103 - val_loss: 1.1165 - val_acc: 0.1360\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1179 - acc: 0.2061 - val_loss: 1.1149 - val_acc: 0.1450\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1178 - acc: 0.2173 - val_loss: 1.1134 - val_acc: 0.1511\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1148 - acc: 0.2152 - val_loss: 1.1118 - val_acc: 0.1571\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1121 - acc: 0.2149 - val_loss: 1.1102 - val_acc: 0.1631\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1120 - acc: 0.2342 - val_loss: 1.1087 - val_acc: 0.1692\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1103 - acc: 0.2378 - val_loss: 1.1072 - val_acc: 0.1752\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1108 - acc: 0.2409 - val_loss: 1.1056 - val_acc: 0.1782\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.1087 - acc: 0.2437 - val_loss: 1.1041 - val_acc: 0.1843\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1087 - acc: 0.2434 - val_loss: 1.1026 - val_acc: 0.1903\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.1059 - acc: 0.2550 - val_loss: 1.1011 - val_acc: 0.1903\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1048 - acc: 0.2564 - val_loss: 1.0996 - val_acc: 0.1903\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1034 - acc: 0.2628 - val_loss: 1.0981 - val_acc: 0.1934\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1015 - acc: 0.2670 - val_loss: 1.0966 - val_acc: 0.1994\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.1019 - acc: 0.2754 - val_loss: 1.0951 - val_acc: 0.2085\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0996 - acc: 0.2895 - val_loss: 1.0937 - val_acc: 0.2115\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0981 - acc: 0.2917 - val_loss: 1.0922 - val_acc: 0.2175\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0975 - acc: 0.2945 - val_loss: 1.0908 - val_acc: 0.2236\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0986 - acc: 0.2807 - val_loss: 1.0893 - val_acc: 0.2266\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0957 - acc: 0.3079 - val_loss: 1.0879 - val_acc: 0.2266\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0945 - acc: 0.2966 - val_loss: 1.0864 - val_acc: 0.2326\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0933 - acc: 0.3163 - val_loss: 1.0851 - val_acc: 0.2417\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0905 - acc: 0.3234 - val_loss: 1.0837 - val_acc: 0.2447\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0907 - acc: 0.3209 - val_loss: 1.0822 - val_acc: 0.2508\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0890 - acc: 0.3477 - val_loss: 1.0809 - val_acc: 0.2598\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0887 - acc: 0.3325 - val_loss: 1.0795 - val_acc: 0.2659\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0878 - acc: 0.3427 - val_loss: 1.0781 - val_acc: 0.2749\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0866 - acc: 0.3544 - val_loss: 1.0767 - val_acc: 0.2749\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0859 - acc: 0.3381 - val_loss: 1.0754 - val_acc: 0.2779\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0834 - acc: 0.3635 - val_loss: 1.0740 - val_acc: 0.2900\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0834 - acc: 0.3586 - val_loss: 1.0726 - val_acc: 0.2961\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0811 - acc: 0.3723 - val_loss: 1.0713 - val_acc: 0.3082\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0805 - acc: 0.3783 - val_loss: 1.0700 - val_acc: 0.3112\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0805 - acc: 0.3741 - val_loss: 1.0687 - val_acc: 0.3142\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0769 - acc: 0.4068 - val_loss: 1.0673 - val_acc: 0.3353\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0770 - acc: 0.3804 - val_loss: 1.0660 - val_acc: 0.3414\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0754 - acc: 0.3956 - val_loss: 1.0647 - val_acc: 0.3444\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0753 - acc: 0.4125 - val_loss: 1.0634 - val_acc: 0.3474\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0748 - acc: 0.4008 - val_loss: 1.0622 - val_acc: 0.3505\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0726 - acc: 0.4283 - val_loss: 1.0609 - val_acc: 0.3656\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0720 - acc: 0.4273 - val_loss: 1.0596 - val_acc: 0.3746\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0716 - acc: 0.4259 - val_loss: 1.0583 - val_acc: 0.3807\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0703 - acc: 0.4244 - val_loss: 1.0571 - val_acc: 0.3807\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0698 - acc: 0.4329 - val_loss: 1.0558 - val_acc: 0.3807\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0678 - acc: 0.4442 - val_loss: 1.0545 - val_acc: 0.3897\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0673 - acc: 0.4505 - val_loss: 1.0533 - val_acc: 0.3927\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0651 - acc: 0.4551 - val_loss: 1.0521 - val_acc: 0.3988\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0639 - acc: 0.4664 - val_loss: 1.0508 - val_acc: 0.4018\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0631 - acc: 0.4720 - val_loss: 1.0496 - val_acc: 0.4079\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0625 - acc: 0.4713 - val_loss: 1.0484 - val_acc: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0614 - acc: 0.4723 - val_loss: 1.0472 - val_acc: 0.4260\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0598 - acc: 0.4850 - val_loss: 1.0460 - val_acc: 0.4381\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0595 - acc: 0.4935 - val_loss: 1.0448 - val_acc: 0.4441\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0585 - acc: 0.4900 - val_loss: 1.0436 - val_acc: 0.4441\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0584 - acc: 0.5041 - val_loss: 1.0424 - val_acc: 0.4471\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0575 - acc: 0.4878 - val_loss: 1.0412 - val_acc: 0.4502\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0557 - acc: 0.5065 - val_loss: 1.0400 - val_acc: 0.4592\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0557 - acc: 0.5072 - val_loss: 1.0388 - val_acc: 0.4592\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0538 - acc: 0.5199 - val_loss: 1.0376 - val_acc: 0.4743\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0532 - acc: 0.5343 - val_loss: 1.0365 - val_acc: 0.4804\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0524 - acc: 0.5365 - val_loss: 1.0353 - val_acc: 0.4894\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0505 - acc: 0.5382 - val_loss: 1.0342 - val_acc: 0.4955\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0486 - acc: 0.5488 - val_loss: 1.0330 - val_acc: 0.5076\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0494 - acc: 0.5481 - val_loss: 1.0318 - val_acc: 0.5166\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0470 - acc: 0.5632 - val_loss: 1.0307 - val_acc: 0.5287\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0463 - acc: 0.5594 - val_loss: 1.0296 - val_acc: 0.5347\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0445 - acc: 0.5777 - val_loss: 1.0284 - val_acc: 0.5378\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0463 - acc: 0.5657 - val_loss: 1.0273 - val_acc: 0.5408\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0442 - acc: 0.5720 - val_loss: 1.0262 - val_acc: 0.5438\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0425 - acc: 0.5822 - val_loss: 1.0250 - val_acc: 0.5589\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0426 - acc: 0.5731 - val_loss: 1.0239 - val_acc: 0.5710\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0415 - acc: 0.5928 - val_loss: 1.0228 - val_acc: 0.5710\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0403 - acc: 0.6030 - val_loss: 1.0217 - val_acc: 0.5831\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0384 - acc: 0.6009 - val_loss: 1.0206 - val_acc: 0.5921\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0389 - acc: 0.6009 - val_loss: 1.0195 - val_acc: 0.5952\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0374 - acc: 0.6090 - val_loss: 1.0184 - val_acc: 0.5982\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0365 - acc: 0.6066 - val_loss: 1.0173 - val_acc: 0.6073\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0357 - acc: 0.6108 - val_loss: 1.0162 - val_acc: 0.6163\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0332 - acc: 0.6302 - val_loss: 1.0151 - val_acc: 0.6224\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0331 - acc: 0.6231 - val_loss: 1.0140 - val_acc: 0.6344\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0324 - acc: 0.6309 - val_loss: 1.0129 - val_acc: 0.6435\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0309 - acc: 0.6379 - val_loss: 1.0119 - val_acc: 0.6465\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0318 - acc: 0.6337 - val_loss: 1.0108 - val_acc: 0.6465\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0285 - acc: 0.6520 - val_loss: 1.0097 - val_acc: 0.6465\n",
      "Epoch 155/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0302 - acc: 0.6446 - val_loss: 1.0086 - val_acc: 0.6616\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0276 - acc: 0.6555 - val_loss: 1.0075 - val_acc: 0.6677\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0273 - acc: 0.6583 - val_loss: 1.0064 - val_acc: 0.6767\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0262 - acc: 0.6636 - val_loss: 1.0054 - val_acc: 0.6767\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0242 - acc: 0.6633 - val_loss: 1.0043 - val_acc: 0.6828\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0252 - acc: 0.6604 - val_loss: 1.0033 - val_acc: 0.6888\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0255 - acc: 0.6601 - val_loss: 1.0022 - val_acc: 0.6949\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0234 - acc: 0.6717 - val_loss: 1.0011 - val_acc: 0.6949\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0221 - acc: 0.6805 - val_loss: 1.0001 - val_acc: 0.7009\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0198 - acc: 0.6728 - val_loss: 0.9990 - val_acc: 0.7039\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0211 - acc: 0.6752 - val_loss: 0.9980 - val_acc: 0.7130\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0204 - acc: 0.6862 - val_loss: 0.9969 - val_acc: 0.7160\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0184 - acc: 0.6943 - val_loss: 0.9959 - val_acc: 0.7281\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0169 - acc: 0.6957 - val_loss: 0.9949 - val_acc: 0.7311\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0175 - acc: 0.6950 - val_loss: 0.9938 - val_acc: 0.7372\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0168 - acc: 0.6964 - val_loss: 0.9928 - val_acc: 0.7402\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0149 - acc: 0.7122 - val_loss: 0.9918 - val_acc: 0.7432\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0139 - acc: 0.7112 - val_loss: 0.9907 - val_acc: 0.7523\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0141 - acc: 0.7179 - val_loss: 0.9897 - val_acc: 0.7523\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0128 - acc: 0.7249 - val_loss: 0.9887 - val_acc: 0.7583\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0120 - acc: 0.7172 - val_loss: 0.9877 - val_acc: 0.7613\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0105 - acc: 0.7316 - val_loss: 0.9867 - val_acc: 0.7674\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.0106 - acc: 0.7312 - val_loss: 0.9857 - val_acc: 0.7674\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0101 - acc: 0.7186 - val_loss: 0.9846 - val_acc: 0.7704\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0089 - acc: 0.7274 - val_loss: 0.9836 - val_acc: 0.7825\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0066 - acc: 0.7415 - val_loss: 0.9826 - val_acc: 0.7825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0051 - acc: 0.7432 - val_loss: 0.9816 - val_acc: 0.7825\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0054 - acc: 0.7485 - val_loss: 0.9806 - val_acc: 0.7885\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0061 - acc: 0.7383 - val_loss: 0.9796 - val_acc: 0.7976\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0037 - acc: 0.7450 - val_loss: 0.9786 - val_acc: 0.8006\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0020 - acc: 0.7577 - val_loss: 0.9776 - val_acc: 0.8127\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0021 - acc: 0.7570 - val_loss: 0.9766 - val_acc: 0.8127\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.0012 - acc: 0.7471 - val_loss: 0.9756 - val_acc: 0.8218\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.0024 - acc: 0.7471 - val_loss: 0.9746 - val_acc: 0.8218\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9997 - acc: 0.7566 - val_loss: 0.9737 - val_acc: 0.8248\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9996 - acc: 0.7651 - val_loss: 0.9727 - val_acc: 0.8278\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9983 - acc: 0.7668 - val_loss: 0.9717 - val_acc: 0.8278\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9974 - acc: 0.7675 - val_loss: 0.9707 - val_acc: 0.8278\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9953 - acc: 0.7721 - val_loss: 0.9697 - val_acc: 0.8308\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9945 - acc: 0.7795 - val_loss: 0.9687 - val_acc: 0.8369\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9938 - acc: 0.7827 - val_loss: 0.9677 - val_acc: 0.8369\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9942 - acc: 0.7887 - val_loss: 0.9667 - val_acc: 0.8399\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9915 - acc: 0.7732 - val_loss: 0.9658 - val_acc: 0.8399\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9933 - acc: 0.7756 - val_loss: 0.9648 - val_acc: 0.8459\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9911 - acc: 0.7784 - val_loss: 0.9638 - val_acc: 0.8520\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9901 - acc: 0.7911 - val_loss: 0.9628 - val_acc: 0.8520\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9890 - acc: 0.7918 - val_loss: 0.9619 - val_acc: 0.8550\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9883 - acc: 0.7918 - val_loss: 0.9609 - val_acc: 0.8610\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9861 - acc: 0.7985 - val_loss: 0.9599 - val_acc: 0.8610\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9885 - acc: 0.7915 - val_loss: 0.9589 - val_acc: 0.8610\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9860 - acc: 0.7982 - val_loss: 0.9579 - val_acc: 0.8610\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9848 - acc: 0.7992 - val_loss: 0.9570 - val_acc: 0.8610\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9835 - acc: 0.7996 - val_loss: 0.9560 - val_acc: 0.8610\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9837 - acc: 0.7968 - val_loss: 0.9551 - val_acc: 0.8640\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9823 - acc: 0.8017 - val_loss: 0.9541 - val_acc: 0.8671\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9822 - acc: 0.8003 - val_loss: 0.9531 - val_acc: 0.8671\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9819 - acc: 0.8024 - val_loss: 0.9522 - val_acc: 0.8671\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9805 - acc: 0.8024 - val_loss: 0.9512 - val_acc: 0.8671\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9785 - acc: 0.8140 - val_loss: 0.9503 - val_acc: 0.8731\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9784 - acc: 0.8151 - val_loss: 0.9493 - val_acc: 0.8731\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9788 - acc: 0.8073 - val_loss: 0.9484 - val_acc: 0.8731\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9757 - acc: 0.8140 - val_loss: 0.9474 - val_acc: 0.8761\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9754 - acc: 0.8161 - val_loss: 0.9465 - val_acc: 0.8761\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9744 - acc: 0.8144 - val_loss: 0.9455 - val_acc: 0.8822\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9750 - acc: 0.8161 - val_loss: 0.9446 - val_acc: 0.8822\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9743 - acc: 0.8182 - val_loss: 0.9436 - val_acc: 0.8852\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9734 - acc: 0.8190 - val_loss: 0.9427 - val_acc: 0.8852\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9707 - acc: 0.8271 - val_loss: 0.9418 - val_acc: 0.8852\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9709 - acc: 0.8182 - val_loss: 0.9408 - val_acc: 0.8852\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9704 - acc: 0.8193 - val_loss: 0.9399 - val_acc: 0.8852\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9702 - acc: 0.8207 - val_loss: 0.9390 - val_acc: 0.8852\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9679 - acc: 0.8281 - val_loss: 0.9380 - val_acc: 0.8852\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9680 - acc: 0.8260 - val_loss: 0.9371 - val_acc: 0.8852\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9669 - acc: 0.8292 - val_loss: 0.9362 - val_acc: 0.8852\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9656 - acc: 0.8242 - val_loss: 0.9352 - val_acc: 0.8852\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9652 - acc: 0.8281 - val_loss: 0.9343 - val_acc: 0.8882\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9643 - acc: 0.8352 - val_loss: 0.9334 - val_acc: 0.8882\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9621 - acc: 0.8344 - val_loss: 0.9324 - val_acc: 0.8882\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9642 - acc: 0.8225 - val_loss: 0.9315 - val_acc: 0.8882\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9620 - acc: 0.8281 - val_loss: 0.9306 - val_acc: 0.8882\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9594 - acc: 0.8426 - val_loss: 0.9297 - val_acc: 0.8882\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9610 - acc: 0.8323 - val_loss: 0.9288 - val_acc: 0.8882\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9588 - acc: 0.8327 - val_loss: 0.9278 - val_acc: 0.8882\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9590 - acc: 0.8323 - val_loss: 0.9269 - val_acc: 0.8882\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9573 - acc: 0.8383 - val_loss: 0.9260 - val_acc: 0.8882\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9553 - acc: 0.8408 - val_loss: 0.9251 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9559 - acc: 0.8408 - val_loss: 0.9242 - val_acc: 0.8912\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9545 - acc: 0.8454 - val_loss: 0.9232 - val_acc: 0.8912\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9536 - acc: 0.8418 - val_loss: 0.9223 - val_acc: 0.8912\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9535 - acc: 0.8341 - val_loss: 0.9214 - val_acc: 0.8912\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9525 - acc: 0.8397 - val_loss: 0.9205 - val_acc: 0.8912\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9531 - acc: 0.8429 - val_loss: 0.9196 - val_acc: 0.8912\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9506 - acc: 0.8454 - val_loss: 0.9187 - val_acc: 0.8912\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9500 - acc: 0.8566 - val_loss: 0.9178 - val_acc: 0.8912\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9474 - acc: 0.8549 - val_loss: 0.9168 - val_acc: 0.8912\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9481 - acc: 0.8489 - val_loss: 0.9159 - val_acc: 0.8912\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9472 - acc: 0.8443 - val_loss: 0.9150 - val_acc: 0.8912\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9460 - acc: 0.8503 - val_loss: 0.9141 - val_acc: 0.8912\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9449 - acc: 0.8528 - val_loss: 0.9132 - val_acc: 0.8912\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9457 - acc: 0.8531 - val_loss: 0.9123 - val_acc: 0.8912\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9431 - acc: 0.8552 - val_loss: 0.9114 - val_acc: 0.8912\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9439 - acc: 0.8499 - val_loss: 0.9105 - val_acc: 0.8912\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9428 - acc: 0.8545 - val_loss: 0.9096 - val_acc: 0.8912\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9401 - acc: 0.8507 - val_loss: 0.9087 - val_acc: 0.8912\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9393 - acc: 0.8545 - val_loss: 0.9078 - val_acc: 0.8912\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9401 - acc: 0.8517 - val_loss: 0.9068 - val_acc: 0.8912\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9385 - acc: 0.8584 - val_loss: 0.9059 - val_acc: 0.8912\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9368 - acc: 0.8588 - val_loss: 0.9050 - val_acc: 0.8912\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9365 - acc: 0.8630 - val_loss: 0.9041 - val_acc: 0.8912\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9368 - acc: 0.8577 - val_loss: 0.9032 - val_acc: 0.8912\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9344 - acc: 0.8616 - val_loss: 0.9023 - val_acc: 0.8912\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9352 - acc: 0.8591 - val_loss: 0.9014 - val_acc: 0.8912\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9349 - acc: 0.8570 - val_loss: 0.9005 - val_acc: 0.8912\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9353 - acc: 0.8563 - val_loss: 0.8996 - val_acc: 0.8912\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9326 - acc: 0.8573 - val_loss: 0.8987 - val_acc: 0.8912\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9304 - acc: 0.8609 - val_loss: 0.8978 - val_acc: 0.8912\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9314 - acc: 0.8588 - val_loss: 0.8969 - val_acc: 0.8912\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9299 - acc: 0.8566 - val_loss: 0.8960 - val_acc: 0.8912\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9279 - acc: 0.8658 - val_loss: 0.8951 - val_acc: 0.8912\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9280 - acc: 0.8630 - val_loss: 0.8942 - val_acc: 0.8912\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9264 - acc: 0.8686 - val_loss: 0.8933 - val_acc: 0.8912\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9270 - acc: 0.8633 - val_loss: 0.8924 - val_acc: 0.8912\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.9251 - acc: 0.8686 - val_loss: 0.8915 - val_acc: 0.8912\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9247 - acc: 0.8619 - val_loss: 0.8906 - val_acc: 0.8912\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9243 - acc: 0.8647 - val_loss: 0.8896 - val_acc: 0.8912\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9228 - acc: 0.8676 - val_loss: 0.8887 - val_acc: 0.8912\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9218 - acc: 0.8721 - val_loss: 0.8878 - val_acc: 0.8912\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9221 - acc: 0.8640 - val_loss: 0.8869 - val_acc: 0.8912\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9203 - acc: 0.8700 - val_loss: 0.8860 - val_acc: 0.8912\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9201 - acc: 0.8651 - val_loss: 0.8851 - val_acc: 0.8912\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9212 - acc: 0.8658 - val_loss: 0.8842 - val_acc: 0.8912\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9171 - acc: 0.8707 - val_loss: 0.8833 - val_acc: 0.8912\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9162 - acc: 0.8721 - val_loss: 0.8824 - val_acc: 0.8912\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9157 - acc: 0.8683 - val_loss: 0.8815 - val_acc: 0.8912\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9163 - acc: 0.8707 - val_loss: 0.8806 - val_acc: 0.8912\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9144 - acc: 0.8700 - val_loss: 0.8797 - val_acc: 0.8912\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9121 - acc: 0.8732 - val_loss: 0.8788 - val_acc: 0.8912\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9116 - acc: 0.8711 - val_loss: 0.8779 - val_acc: 0.8912\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9121 - acc: 0.8735 - val_loss: 0.8770 - val_acc: 0.8912\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9111 - acc: 0.8725 - val_loss: 0.8760 - val_acc: 0.8912\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9082 - acc: 0.8721 - val_loss: 0.8751 - val_acc: 0.8912\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9085 - acc: 0.8774 - val_loss: 0.8742 - val_acc: 0.8912\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9070 - acc: 0.8778 - val_loss: 0.8733 - val_acc: 0.8912\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9069 - acc: 0.8767 - val_loss: 0.8724 - val_acc: 0.8912\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9071 - acc: 0.8778 - val_loss: 0.8715 - val_acc: 0.8912\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.9055 - acc: 0.8764 - val_loss: 0.8706 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9039 - acc: 0.8746 - val_loss: 0.8697 - val_acc: 0.8912\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9034 - acc: 0.8753 - val_loss: 0.8687 - val_acc: 0.8912\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9033 - acc: 0.8732 - val_loss: 0.8678 - val_acc: 0.8912\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.9033 - acc: 0.8746 - val_loss: 0.8669 - val_acc: 0.8912\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.9019 - acc: 0.8778 - val_loss: 0.8660 - val_acc: 0.8912\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.9005 - acc: 0.8757 - val_loss: 0.8651 - val_acc: 0.8912\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8995 - acc: 0.8746 - val_loss: 0.8642 - val_acc: 0.8912\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8988 - acc: 0.8760 - val_loss: 0.8633 - val_acc: 0.8912\n",
      "Epoch 309/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8996 - acc: 0.8764 - val_loss: 0.8624 - val_acc: 0.8912\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8978 - acc: 0.8757 - val_loss: 0.8614 - val_acc: 0.8912\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8969 - acc: 0.8767 - val_loss: 0.8605 - val_acc: 0.8912\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8953 - acc: 0.8802 - val_loss: 0.8596 - val_acc: 0.8912\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8945 - acc: 0.8767 - val_loss: 0.8587 - val_acc: 0.8912\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8935 - acc: 0.8746 - val_loss: 0.8578 - val_acc: 0.8912\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8930 - acc: 0.8785 - val_loss: 0.8568 - val_acc: 0.8912\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8923 - acc: 0.8771 - val_loss: 0.8559 - val_acc: 0.8912\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8920 - acc: 0.8781 - val_loss: 0.8550 - val_acc: 0.8912\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8895 - acc: 0.8827 - val_loss: 0.8541 - val_acc: 0.8912\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8886 - acc: 0.8802 - val_loss: 0.8532 - val_acc: 0.8912\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8902 - acc: 0.8764 - val_loss: 0.8522 - val_acc: 0.8912\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8880 - acc: 0.8795 - val_loss: 0.8513 - val_acc: 0.8912\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8871 - acc: 0.8809 - val_loss: 0.8504 - val_acc: 0.8912\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8853 - acc: 0.8788 - val_loss: 0.8495 - val_acc: 0.8912\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8843 - acc: 0.8816 - val_loss: 0.8485 - val_acc: 0.8912\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8815 - acc: 0.8834 - val_loss: 0.8476 - val_acc: 0.8912\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8849 - acc: 0.8809 - val_loss: 0.8467 - val_acc: 0.8912\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8820 - acc: 0.8831 - val_loss: 0.8457 - val_acc: 0.8912\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8785 - acc: 0.8827 - val_loss: 0.8448 - val_acc: 0.8912\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8813 - acc: 0.8778 - val_loss: 0.8439 - val_acc: 0.8912\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8810 - acc: 0.8820 - val_loss: 0.8430 - val_acc: 0.8912\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8793 - acc: 0.8809 - val_loss: 0.8420 - val_acc: 0.8912\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8783 - acc: 0.8795 - val_loss: 0.8411 - val_acc: 0.8912\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8766 - acc: 0.8848 - val_loss: 0.8402 - val_acc: 0.8912\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8757 - acc: 0.8831 - val_loss: 0.8392 - val_acc: 0.8912\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8764 - acc: 0.8834 - val_loss: 0.8383 - val_acc: 0.8912\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 0.8734 - acc: 0.8834 - val_loss: 0.8374 - val_acc: 0.8912\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8724 - acc: 0.8831 - val_loss: 0.8364 - val_acc: 0.8912\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8735 - acc: 0.8845 - val_loss: 0.8355 - val_acc: 0.8912\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8708 - acc: 0.8845 - val_loss: 0.8346 - val_acc: 0.8912\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8713 - acc: 0.8838 - val_loss: 0.8336 - val_acc: 0.8912\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8710 - acc: 0.8838 - val_loss: 0.8327 - val_acc: 0.8912\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8701 - acc: 0.8866 - val_loss: 0.8318 - val_acc: 0.8912\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8687 - acc: 0.8824 - val_loss: 0.8309 - val_acc: 0.8912\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8679 - acc: 0.8848 - val_loss: 0.8299 - val_acc: 0.8912\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8673 - acc: 0.8855 - val_loss: 0.8290 - val_acc: 0.8912\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8687 - acc: 0.8845 - val_loss: 0.8280 - val_acc: 0.8912\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8649 - acc: 0.8838 - val_loss: 0.8271 - val_acc: 0.8912\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8632 - acc: 0.8845 - val_loss: 0.8261 - val_acc: 0.8912\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8634 - acc: 0.8855 - val_loss: 0.8252 - val_acc: 0.8912\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.8622 - acc: 0.8848 - val_loss: 0.8242 - val_acc: 0.8912\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8590 - acc: 0.8845 - val_loss: 0.8233 - val_acc: 0.8912\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8599 - acc: 0.8866 - val_loss: 0.8224 - val_acc: 0.8912\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8608 - acc: 0.8845 - val_loss: 0.8214 - val_acc: 0.8912\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8577 - acc: 0.8869 - val_loss: 0.8205 - val_acc: 0.8912\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8561 - acc: 0.8901 - val_loss: 0.8195 - val_acc: 0.8912\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8569 - acc: 0.8897 - val_loss: 0.8186 - val_acc: 0.8912\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8561 - acc: 0.8852 - val_loss: 0.8176 - val_acc: 0.8912\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8562 - acc: 0.8862 - val_loss: 0.8167 - val_acc: 0.8912\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8526 - acc: 0.8890 - val_loss: 0.8157 - val_acc: 0.8912\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8527 - acc: 0.8876 - val_loss: 0.8148 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8534 - acc: 0.8876 - val_loss: 0.8138 - val_acc: 0.8912\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8500 - acc: 0.8887 - val_loss: 0.8129 - val_acc: 0.8912\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8525 - acc: 0.8855 - val_loss: 0.8119 - val_acc: 0.8912\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8482 - acc: 0.8862 - val_loss: 0.8110 - val_acc: 0.8912\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8503 - acc: 0.8894 - val_loss: 0.8100 - val_acc: 0.8912\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8464 - acc: 0.8890 - val_loss: 0.8090 - val_acc: 0.8912\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8457 - acc: 0.8876 - val_loss: 0.8081 - val_acc: 0.8912\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8470 - acc: 0.8880 - val_loss: 0.8071 - val_acc: 0.8912\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8470 - acc: 0.8887 - val_loss: 0.8062 - val_acc: 0.8912\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8439 - acc: 0.8901 - val_loss: 0.8052 - val_acc: 0.8912\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8441 - acc: 0.8873 - val_loss: 0.8043 - val_acc: 0.8912\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8432 - acc: 0.8890 - val_loss: 0.8033 - val_acc: 0.8912\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8402 - acc: 0.8894 - val_loss: 0.8024 - val_acc: 0.8912\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8397 - acc: 0.8880 - val_loss: 0.8014 - val_acc: 0.8912\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8395 - acc: 0.8876 - val_loss: 0.8005 - val_acc: 0.8912\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8409 - acc: 0.8890 - val_loss: 0.7995 - val_acc: 0.8912\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8397 - acc: 0.8894 - val_loss: 0.7985 - val_acc: 0.8912\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8381 - acc: 0.8883 - val_loss: 0.7976 - val_acc: 0.8912\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8385 - acc: 0.8883 - val_loss: 0.7966 - val_acc: 0.8912\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8358 - acc: 0.8887 - val_loss: 0.7957 - val_acc: 0.8912\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8326 - acc: 0.8897 - val_loss: 0.7947 - val_acc: 0.8912\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8346 - acc: 0.8894 - val_loss: 0.7938 - val_acc: 0.8912\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8316 - acc: 0.8890 - val_loss: 0.7928 - val_acc: 0.8912\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8324 - acc: 0.8897 - val_loss: 0.7918 - val_acc: 0.8912\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8297 - acc: 0.8897 - val_loss: 0.7909 - val_acc: 0.8912\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8278 - acc: 0.8883 - val_loss: 0.7899 - val_acc: 0.8912\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8305 - acc: 0.8905 - val_loss: 0.7890 - val_acc: 0.8912\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8287 - acc: 0.8890 - val_loss: 0.7880 - val_acc: 0.8912\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8271 - acc: 0.8887 - val_loss: 0.7870 - val_acc: 0.8912\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8257 - acc: 0.8883 - val_loss: 0.7861 - val_acc: 0.8912\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8262 - acc: 0.8908 - val_loss: 0.7851 - val_acc: 0.8912\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8241 - acc: 0.8908 - val_loss: 0.7841 - val_acc: 0.8912\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.8235 - acc: 0.8905 - val_loss: 0.7832 - val_acc: 0.8912\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.8227 - acc: 0.8894 - val_loss: 0.7822 - val_acc: 0.8912\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.8229 - acc: 0.8890 - val_loss: 0.7812 - val_acc: 0.8912\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8202 - acc: 0.8890 - val_loss: 0.7803 - val_acc: 0.8912\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8207 - acc: 0.8873 - val_loss: 0.7793 - val_acc: 0.8912\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8204 - acc: 0.8894 - val_loss: 0.7784 - val_acc: 0.8912\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8185 - acc: 0.8894 - val_loss: 0.7774 - val_acc: 0.8912\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8179 - acc: 0.8915 - val_loss: 0.7764 - val_acc: 0.8912\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8165 - acc: 0.8912 - val_loss: 0.7755 - val_acc: 0.8912\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8171 - acc: 0.8905 - val_loss: 0.7745 - val_acc: 0.8912\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8146 - acc: 0.8915 - val_loss: 0.7735 - val_acc: 0.8912\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8119 - acc: 0.8905 - val_loss: 0.7726 - val_acc: 0.8912\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8129 - acc: 0.8901 - val_loss: 0.7716 - val_acc: 0.8912\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8119 - acc: 0.8908 - val_loss: 0.7707 - val_acc: 0.8912\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8127 - acc: 0.8905 - val_loss: 0.7697 - val_acc: 0.8912\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8111 - acc: 0.8894 - val_loss: 0.7687 - val_acc: 0.8912\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8090 - acc: 0.8887 - val_loss: 0.7678 - val_acc: 0.8912\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8105 - acc: 0.8912 - val_loss: 0.7668 - val_acc: 0.8912\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8109 - acc: 0.8905 - val_loss: 0.7659 - val_acc: 0.8912\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8074 - acc: 0.8890 - val_loss: 0.7649 - val_acc: 0.8912\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.8059 - acc: 0.8897 - val_loss: 0.7639 - val_acc: 0.8912\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8075 - acc: 0.8901 - val_loss: 0.7630 - val_acc: 0.8912\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.8029 - acc: 0.8894 - val_loss: 0.7620 - val_acc: 0.8912\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.8049 - acc: 0.8901 - val_loss: 0.7611 - val_acc: 0.8912\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8028 - acc: 0.8901 - val_loss: 0.7601 - val_acc: 0.8912\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7994 - acc: 0.8897 - val_loss: 0.7592 - val_acc: 0.8912\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.8009 - acc: 0.8890 - val_loss: 0.7582 - val_acc: 0.8912\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8009 - acc: 0.8908 - val_loss: 0.7572 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8005 - acc: 0.8901 - val_loss: 0.7563 - val_acc: 0.8912\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7966 - acc: 0.8905 - val_loss: 0.7553 - val_acc: 0.8912\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7947 - acc: 0.8908 - val_loss: 0.7544 - val_acc: 0.8912\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7963 - acc: 0.8901 - val_loss: 0.7534 - val_acc: 0.8912\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7967 - acc: 0.8894 - val_loss: 0.7524 - val_acc: 0.8912\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7924 - acc: 0.8905 - val_loss: 0.7515 - val_acc: 0.8912\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7947 - acc: 0.8890 - val_loss: 0.7505 - val_acc: 0.8912\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7909 - acc: 0.8901 - val_loss: 0.7496 - val_acc: 0.8912\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7903 - acc: 0.8908 - val_loss: 0.7486 - val_acc: 0.8912\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.7905 - acc: 0.8908 - val_loss: 0.7476 - val_acc: 0.8912\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7892 - acc: 0.8905 - val_loss: 0.7467 - val_acc: 0.8912\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7892 - acc: 0.8894 - val_loss: 0.7457 - val_acc: 0.8912\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7897 - acc: 0.8919 - val_loss: 0.7448 - val_acc: 0.8912\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7860 - acc: 0.8908 - val_loss: 0.7438 - val_acc: 0.8912\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.7856 - acc: 0.8908 - val_loss: 0.7428 - val_acc: 0.8912\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7845 - acc: 0.8897 - val_loss: 0.7419 - val_acc: 0.8912\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7866 - acc: 0.8905 - val_loss: 0.7409 - val_acc: 0.8912\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7817 - acc: 0.8919 - val_loss: 0.7400 - val_acc: 0.8912\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7795 - acc: 0.8901 - val_loss: 0.7390 - val_acc: 0.8912\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7806 - acc: 0.8908 - val_loss: 0.7380 - val_acc: 0.8912\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.7795 - acc: 0.8919 - val_loss: 0.7371 - val_acc: 0.8912\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7792 - acc: 0.8908 - val_loss: 0.7361 - val_acc: 0.8912\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7775 - acc: 0.8908 - val_loss: 0.7352 - val_acc: 0.8912\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7785 - acc: 0.8905 - val_loss: 0.7342 - val_acc: 0.8912\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.7785 - acc: 0.8897 - val_loss: 0.7333 - val_acc: 0.8912\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7749 - acc: 0.8915 - val_loss: 0.7323 - val_acc: 0.8912\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7745 - acc: 0.8905 - val_loss: 0.7313 - val_acc: 0.8912\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7743 - acc: 0.8912 - val_loss: 0.7304 - val_acc: 0.8912\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7739 - acc: 0.8919 - val_loss: 0.7294 - val_acc: 0.8912\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.7725 - acc: 0.8922 - val_loss: 0.7285 - val_acc: 0.8912\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7730 - acc: 0.8912 - val_loss: 0.7275 - val_acc: 0.8912\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7695 - acc: 0.8919 - val_loss: 0.7266 - val_acc: 0.8912\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7684 - acc: 0.8908 - val_loss: 0.7256 - val_acc: 0.8912\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7678 - acc: 0.8901 - val_loss: 0.7246 - val_acc: 0.8912\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7692 - acc: 0.8912 - val_loss: 0.7237 - val_acc: 0.8912\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7671 - acc: 0.8915 - val_loss: 0.7228 - val_acc: 0.8912\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7654 - acc: 0.8915 - val_loss: 0.7218 - val_acc: 0.8912\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7669 - acc: 0.8908 - val_loss: 0.7209 - val_acc: 0.8912\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7619 - acc: 0.8915 - val_loss: 0.7199 - val_acc: 0.8912\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7650 - acc: 0.8905 - val_loss: 0.7190 - val_acc: 0.8912\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7645 - acc: 0.8905 - val_loss: 0.7180 - val_acc: 0.8912\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7634 - acc: 0.8901 - val_loss: 0.7171 - val_acc: 0.8912\n",
      "Epoch 463/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7608 - acc: 0.8919 - val_loss: 0.7161 - val_acc: 0.8912\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7622 - acc: 0.8908 - val_loss: 0.7152 - val_acc: 0.8912\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7605 - acc: 0.8908 - val_loss: 0.7142 - val_acc: 0.8912\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7568 - acc: 0.8915 - val_loss: 0.7133 - val_acc: 0.8912\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7588 - acc: 0.8919 - val_loss: 0.7123 - val_acc: 0.8912\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7572 - acc: 0.8908 - val_loss: 0.7114 - val_acc: 0.8912\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7536 - acc: 0.8919 - val_loss: 0.7104 - val_acc: 0.8912\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7539 - acc: 0.8915 - val_loss: 0.7095 - val_acc: 0.8912\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7552 - acc: 0.8908 - val_loss: 0.7085 - val_acc: 0.8912\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7548 - acc: 0.8901 - val_loss: 0.7076 - val_acc: 0.8912\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7527 - acc: 0.8919 - val_loss: 0.7066 - val_acc: 0.8912\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7494 - acc: 0.8922 - val_loss: 0.7057 - val_acc: 0.8912\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7494 - acc: 0.8919 - val_loss: 0.7047 - val_acc: 0.8912\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7499 - acc: 0.8915 - val_loss: 0.7038 - val_acc: 0.8912\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7490 - acc: 0.8915 - val_loss: 0.7029 - val_acc: 0.8912\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7474 - acc: 0.8908 - val_loss: 0.7019 - val_acc: 0.8912\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7475 - acc: 0.8915 - val_loss: 0.7010 - val_acc: 0.8912\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7478 - acc: 0.8915 - val_loss: 0.7000 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7468 - acc: 0.8908 - val_loss: 0.6991 - val_acc: 0.8912\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7442 - acc: 0.8919 - val_loss: 0.6981 - val_acc: 0.8912\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7404 - acc: 0.8919 - val_loss: 0.6972 - val_acc: 0.8912\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7400 - acc: 0.8912 - val_loss: 0.6963 - val_acc: 0.8912\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7419 - acc: 0.8919 - val_loss: 0.6953 - val_acc: 0.8912\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7414 - acc: 0.8915 - val_loss: 0.6944 - val_acc: 0.8912\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7381 - acc: 0.8908 - val_loss: 0.6934 - val_acc: 0.8912\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7405 - acc: 0.8912 - val_loss: 0.6925 - val_acc: 0.8912\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7410 - acc: 0.8915 - val_loss: 0.6916 - val_acc: 0.8912\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7370 - acc: 0.8922 - val_loss: 0.6907 - val_acc: 0.8912\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7350 - acc: 0.8915 - val_loss: 0.6897 - val_acc: 0.8912\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7373 - acc: 0.8915 - val_loss: 0.6888 - val_acc: 0.8912\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 0.7361 - acc: 0.8919 - val_loss: 0.6879 - val_acc: 0.8912\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7357 - acc: 0.8919 - val_loss: 0.6869 - val_acc: 0.8912\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.7324 - acc: 0.8915 - val_loss: 0.6860 - val_acc: 0.8912\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7315 - acc: 0.8915 - val_loss: 0.6851 - val_acc: 0.8912\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7311 - acc: 0.8912 - val_loss: 0.6841 - val_acc: 0.8912\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7323 - acc: 0.8901 - val_loss: 0.6832 - val_acc: 0.8912\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 0.7298 - acc: 0.8922 - val_loss: 0.6823 - val_acc: 0.8912\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7298 - acc: 0.8919 - val_loss: 0.6814 - val_acc: 0.8912\n"
     ]
    }
   ],
   "source": [
    "zillow_model = model.fit(x=X_train, y=y_cat_train, \n",
    "          batch_size=20000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_cat_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njPGypGCMMcbLkoIxxhgvSwrGGGO8/j9CCp+t9/pmhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15cac8668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model.history['acc'])\n",
    "plt.plot(zillow_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 1s 283us/step - loss: 2.0655 - acc: 0.2321 - val_loss: 1.1804 - val_acc: 0.7281\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.1478 - acc: 0.6724 - val_loss: 1.0211 - val_acc: 0.7281\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.0414 - acc: 0.6759 - val_loss: 0.9872 - val_acc: 0.7281\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0273 - acc: 0.6742 - val_loss: 0.9855 - val_acc: 0.7281\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0207 - acc: 0.6696 - val_loss: 0.9742 - val_acc: 0.7281\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0106 - acc: 0.6714 - val_loss: 0.9559 - val_acc: 0.7281\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.0040 - acc: 0.6745 - val_loss: 0.9374 - val_acc: 0.7281\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0122 - acc: 0.6742 - val_loss: 0.9309 - val_acc: 0.7281\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9909 - acc: 0.6731 - val_loss: 0.9282 - val_acc: 0.7281\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9847 - acc: 0.6788 - val_loss: 0.9436 - val_acc: 0.7281\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9953 - acc: 0.6685 - val_loss: 1.0421 - val_acc: 0.7311\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0151 - acc: 0.6495 - val_loss: 0.9302 - val_acc: 0.7281\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9627 - acc: 0.6756 - val_loss: 0.9113 - val_acc: 0.7281\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9665 - acc: 0.6731 - val_loss: 0.9135 - val_acc: 0.7281\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9724 - acc: 0.6752 - val_loss: 0.8980 - val_acc: 0.7281\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9686 - acc: 0.6752 - val_loss: 0.9036 - val_acc: 0.7281\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9666 - acc: 0.6763 - val_loss: 0.9022 - val_acc: 0.7281\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9372 - acc: 0.6802 - val_loss: 0.8945 - val_acc: 0.7281\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9490 - acc: 0.6774 - val_loss: 0.9004 - val_acc: 0.7281\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9698 - acc: 0.6752 - val_loss: 0.9338 - val_acc: 0.7281\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9683 - acc: 0.6763 - val_loss: 0.9286 - val_acc: 0.7311\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9403 - acc: 0.6788 - val_loss: 0.8864 - val_acc: 0.7281\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9233 - acc: 0.6770 - val_loss: 0.8928 - val_acc: 0.7281\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9559 - acc: 0.6759 - val_loss: 0.8801 - val_acc: 0.7281\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9364 - acc: 0.6749 - val_loss: 0.9072 - val_acc: 0.7402\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9278 - acc: 0.6749 - val_loss: 0.9117 - val_acc: 0.7432\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9273 - acc: 0.6798 - val_loss: 0.9134 - val_acc: 0.7462\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9198 - acc: 0.6847 - val_loss: 0.9292 - val_acc: 0.7341\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9258 - acc: 0.6883 - val_loss: 0.9028 - val_acc: 0.7462\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9036 - acc: 0.6837 - val_loss: 0.9173 - val_acc: 0.7462\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9110 - acc: 0.6858 - val_loss: 0.9946 - val_acc: 0.6918\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9404 - acc: 0.6643 - val_loss: 0.8820 - val_acc: 0.7251\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9026 - acc: 0.6809 - val_loss: 0.8830 - val_acc: 0.7432\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8908 - acc: 0.6851 - val_loss: 0.8695 - val_acc: 0.7402\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8973 - acc: 0.6876 - val_loss: 0.9055 - val_acc: 0.7281\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9555 - acc: 0.6809 - val_loss: 0.8710 - val_acc: 0.7402\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8994 - acc: 0.6833 - val_loss: 0.8444 - val_acc: 0.7432\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8907 - acc: 0.6809 - val_loss: 0.8476 - val_acc: 0.7402\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8838 - acc: 0.6855 - val_loss: 0.8469 - val_acc: 0.7311\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8951 - acc: 0.6879 - val_loss: 0.8805 - val_acc: 0.7251\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9081 - acc: 0.6798 - val_loss: 0.8643 - val_acc: 0.7432\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8820 - acc: 0.6890 - val_loss: 0.8606 - val_acc: 0.7341\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9112 - acc: 0.6823 - val_loss: 0.8463 - val_acc: 0.7372\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.8777 - acc: 0.6900 - val_loss: 0.8488 - val_acc: 0.7432\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8746 - acc: 0.6907 - val_loss: 0.8864 - val_acc: 0.7432\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8784 - acc: 0.6936 - val_loss: 0.8918 - val_acc: 0.7432\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8765 - acc: 0.6914 - val_loss: 0.9424 - val_acc: 0.6979\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 0.8824 - acc: 0.6809 - val_loss: 0.8601 - val_acc: 0.7462\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8569 - acc: 0.6953 - val_loss: 0.8547 - val_acc: 0.7613\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.8531 - acc: 0.6943 - val_loss: 0.8775 - val_acc: 0.7462\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8633 - acc: 0.6932 - val_loss: 0.9997 - val_acc: 0.6707\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9081 - acc: 0.6661 - val_loss: 0.8681 - val_acc: 0.7432\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8469 - acc: 0.6967 - val_loss: 0.8673 - val_acc: 0.7523\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8415 - acc: 0.6928 - val_loss: 0.8589 - val_acc: 0.7402\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8599 - acc: 0.6967 - val_loss: 0.9095 - val_acc: 0.7311\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8765 - acc: 0.6939 - val_loss: 0.8545 - val_acc: 0.7553\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8391 - acc: 0.7038 - val_loss: 0.8245 - val_acc: 0.7432\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8704 - acc: 0.6883 - val_loss: 0.8295 - val_acc: 0.7462\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8385 - acc: 0.7013 - val_loss: 0.8353 - val_acc: 0.7553\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8304 - acc: 0.7038 - val_loss: 0.8586 - val_acc: 0.7432\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8325 - acc: 0.6985 - val_loss: 0.9041 - val_acc: 0.7251\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8433 - acc: 0.6925 - val_loss: 0.8742 - val_acc: 0.7553\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8190 - acc: 0.7052 - val_loss: 0.8451 - val_acc: 0.7553\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8206 - acc: 0.7041 - val_loss: 0.8311 - val_acc: 0.7553\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8147 - acc: 0.7087 - val_loss: 0.8386 - val_acc: 0.7553\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8465 - acc: 0.6985 - val_loss: 0.8609 - val_acc: 0.7281\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8803 - acc: 0.6876 - val_loss: 0.8152 - val_acc: 0.7402\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8241 - acc: 0.7020 - val_loss: 0.8305 - val_acc: 0.7492\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8100 - acc: 0.7101 - val_loss: 0.8355 - val_acc: 0.7553\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8059 - acc: 0.7038 - val_loss: 0.8932 - val_acc: 0.7341\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8311 - acc: 0.6950 - val_loss: 0.8731 - val_acc: 0.7372\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8393 - acc: 0.6918 - val_loss: 0.8520 - val_acc: 0.7553\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8160 - acc: 0.7143 - val_loss: 0.8173 - val_acc: 0.7553\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8044 - acc: 0.7091 - val_loss: 0.8009 - val_acc: 0.7553\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8051 - acc: 0.7062 - val_loss: 0.8152 - val_acc: 0.7372\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8231 - acc: 0.7091 - val_loss: 0.8086 - val_acc: 0.7432\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8220 - acc: 0.7055 - val_loss: 0.8143 - val_acc: 0.7492\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8130 - acc: 0.7034 - val_loss: 0.8120 - val_acc: 0.7462\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8119 - acc: 0.7038 - val_loss: 0.8086 - val_acc: 0.7432\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8076 - acc: 0.7052 - val_loss: 0.8335 - val_acc: 0.7613\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7916 - acc: 0.7143 - val_loss: 0.8422 - val_acc: 0.7523\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7894 - acc: 0.7175 - val_loss: 0.8137 - val_acc: 0.7462\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7764 - acc: 0.7189 - val_loss: 0.8700 - val_acc: 0.7311\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8321 - acc: 0.6946 - val_loss: 0.8313 - val_acc: 0.7553\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7907 - acc: 0.7217 - val_loss: 0.8105 - val_acc: 0.7613\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7717 - acc: 0.7189 - val_loss: 0.8322 - val_acc: 0.7402\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8010 - acc: 0.7066 - val_loss: 0.8511 - val_acc: 0.7432\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8102 - acc: 0.7034 - val_loss: 0.8200 - val_acc: 0.7553\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7710 - acc: 0.7168 - val_loss: 0.8149 - val_acc: 0.7523\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7697 - acc: 0.7238 - val_loss: 0.8336 - val_acc: 0.7432\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7959 - acc: 0.7048 - val_loss: 0.8175 - val_acc: 0.7583\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7795 - acc: 0.7246 - val_loss: 0.8079 - val_acc: 0.7462\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7619 - acc: 0.7246 - val_loss: 0.8011 - val_acc: 0.7492\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7425 - acc: 0.7291 - val_loss: 0.8051 - val_acc: 0.7523\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7465 - acc: 0.7221 - val_loss: 0.8130 - val_acc: 0.7432\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7493 - acc: 0.7253 - val_loss: 0.9084 - val_acc: 0.7221\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.8609 - acc: 0.6784 - val_loss: 0.8329 - val_acc: 0.7462\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7763 - acc: 0.7161 - val_loss: 0.8016 - val_acc: 0.7432\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7473 - acc: 0.7323 - val_loss: 0.8033 - val_acc: 0.7492\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7526 - acc: 0.7224 - val_loss: 0.8131 - val_acc: 0.7462\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7634 - acc: 0.7221 - val_loss: 0.8243 - val_acc: 0.7402\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.7607 - acc: 0.7337 - val_loss: 0.8223 - val_acc: 0.7462\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7740 - acc: 0.7140 - val_loss: 0.8191 - val_acc: 0.7462\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.7481 - acc: 0.7362 - val_loss: 0.7951 - val_acc: 0.7492\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7259 - acc: 0.7334 - val_loss: 0.8010 - val_acc: 0.7492\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7391 - acc: 0.7337 - val_loss: 0.8409 - val_acc: 0.7372\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7623 - acc: 0.7168 - val_loss: 0.8104 - val_acc: 0.7462\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.7262 - acc: 0.7291 - val_loss: 0.8134 - val_acc: 0.7462\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7404 - acc: 0.7341 - val_loss: 0.8059 - val_acc: 0.7432\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7342 - acc: 0.7235 - val_loss: 0.8281 - val_acc: 0.7372\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7575 - acc: 0.7126 - val_loss: 0.8135 - val_acc: 0.7432\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.7293 - acc: 0.7348 - val_loss: 0.7948 - val_acc: 0.7462\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7099 - acc: 0.7393 - val_loss: 0.8088 - val_acc: 0.7432\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7340 - acc: 0.7319 - val_loss: 0.8453 - val_acc: 0.7251\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7768 - acc: 0.7010 - val_loss: 0.8086 - val_acc: 0.7432\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7191 - acc: 0.7379 - val_loss: 0.8029 - val_acc: 0.7432\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7002 - acc: 0.7400 - val_loss: 0.8145 - val_acc: 0.7372\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7119 - acc: 0.7351 - val_loss: 0.8866 - val_acc: 0.7372\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7858 - acc: 0.7076 - val_loss: 0.8257 - val_acc: 0.7402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7381 - acc: 0.7238 - val_loss: 0.8318 - val_acc: 0.7432\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7329 - acc: 0.7302 - val_loss: 0.8228 - val_acc: 0.7372\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7007 - acc: 0.7327 - val_loss: 0.8931 - val_acc: 0.7251\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7409 - acc: 0.7214 - val_loss: 0.8499 - val_acc: 0.7311\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7151 - acc: 0.7429 - val_loss: 0.8580 - val_acc: 0.7190\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7079 - acc: 0.7443 - val_loss: 0.8304 - val_acc: 0.7311\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.6852 - acc: 0.7411 - val_loss: 0.8538 - val_acc: 0.7281\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7141 - acc: 0.7274 - val_loss: 0.9452 - val_acc: 0.7341\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7891 - acc: 0.7147 - val_loss: 0.8270 - val_acc: 0.7372\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6837 - acc: 0.7464 - val_loss: 0.8362 - val_acc: 0.7341\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6885 - acc: 0.7365 - val_loss: 0.8894 - val_acc: 0.7251\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7342 - acc: 0.7214 - val_loss: 0.8610 - val_acc: 0.7221\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7093 - acc: 0.7277 - val_loss: 0.8306 - val_acc: 0.7402\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6912 - acc: 0.7425 - val_loss: 0.8237 - val_acc: 0.7372\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6826 - acc: 0.7450 - val_loss: 0.8373 - val_acc: 0.7402\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6949 - acc: 0.7425 - val_loss: 0.8364 - val_acc: 0.7432\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6865 - acc: 0.7397 - val_loss: 0.8742 - val_acc: 0.7160\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7523 - acc: 0.7105 - val_loss: 0.8400 - val_acc: 0.7190\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6754 - acc: 0.7570 - val_loss: 0.8395 - val_acc: 0.7281\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6496 - acc: 0.7591 - val_loss: 0.8377 - val_acc: 0.7251\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6611 - acc: 0.7513 - val_loss: 0.8431 - val_acc: 0.7402\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6904 - acc: 0.7464 - val_loss: 0.8855 - val_acc: 0.7100\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7464 - acc: 0.7101 - val_loss: 0.8410 - val_acc: 0.7130\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6683 - acc: 0.7566 - val_loss: 0.8457 - val_acc: 0.7251\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6637 - acc: 0.7552 - val_loss: 0.8597 - val_acc: 0.7251\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6673 - acc: 0.7570 - val_loss: 0.8640 - val_acc: 0.7069\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6616 - acc: 0.7584 - val_loss: 0.8486 - val_acc: 0.7341\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6745 - acc: 0.7446 - val_loss: 0.8601 - val_acc: 0.7221\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6871 - acc: 0.7400 - val_loss: 0.8515 - val_acc: 0.7221\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6589 - acc: 0.7517 - val_loss: 0.8399 - val_acc: 0.7341\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6591 - acc: 0.7601 - val_loss: 0.8560 - val_acc: 0.7341\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6751 - acc: 0.7379 - val_loss: 0.8459 - val_acc: 0.7341\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6779 - acc: 0.7365 - val_loss: 0.8969 - val_acc: 0.6949\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7040 - acc: 0.7474 - val_loss: 0.8679 - val_acc: 0.7160\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6402 - acc: 0.7580 - val_loss: 0.8696 - val_acc: 0.7221\n",
      "Epoch 155/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6290 - acc: 0.7545 - val_loss: 0.9269 - val_acc: 0.7069\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6573 - acc: 0.7482 - val_loss: 0.9878 - val_acc: 0.7100\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7123 - acc: 0.7228 - val_loss: 0.9303 - val_acc: 0.7069\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6723 - acc: 0.7443 - val_loss: 0.8670 - val_acc: 0.7281\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6175 - acc: 0.7629 - val_loss: 0.8861 - val_acc: 0.7251\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6234 - acc: 0.7612 - val_loss: 0.9376 - val_acc: 0.7130\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6644 - acc: 0.7411 - val_loss: 0.9969 - val_acc: 0.7251\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.7385 - acc: 0.713 - 0s 29us/step - loss: 0.7123 - acc: 0.7302 - val_loss: 0.9052 - val_acc: 0.7221\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6251 - acc: 0.7612 - val_loss: 0.9146 - val_acc: 0.7130\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6392 - acc: 0.7559 - val_loss: 0.9925 - val_acc: 0.7039\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6644 - acc: 0.7555 - val_loss: 0.9424 - val_acc: 0.7130\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6402 - acc: 0.7517 - val_loss: 0.9818 - val_acc: 0.7251\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6898 - acc: 0.7263 - val_loss: 0.9284 - val_acc: 0.7100\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6469 - acc: 0.7485 - val_loss: 0.9148 - val_acc: 0.7221\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6176 - acc: 0.7686 - val_loss: 0.9145 - val_acc: 0.7069\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6122 - acc: 0.7679 - val_loss: 0.9595 - val_acc: 0.7130\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6162 - acc: 0.7640 - val_loss: 0.9650 - val_acc: 0.7130\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6159 - acc: 0.7760 - val_loss: 0.9904 - val_acc: 0.7100\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6395 - acc: 0.7464 - val_loss: 1.0967 - val_acc: 0.7130\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7313 - acc: 0.7189 - val_loss: 0.8918 - val_acc: 0.7221\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5994 - acc: 0.7749 - val_loss: 0.9154 - val_acc: 0.7160\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5981 - acc: 0.7739 - val_loss: 0.9557 - val_acc: 0.7221\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6392 - acc: 0.7552 - val_loss: 0.9971 - val_acc: 0.7160\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6630 - acc: 0.7341 - val_loss: 1.0219 - val_acc: 0.7100\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.6635 - acc: 0.7390 - val_loss: 0.9807 - val_acc: 0.7009\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6177 - acc: 0.7615 - val_loss: 0.9605 - val_acc: 0.7009\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5941 - acc: 0.7644 - val_loss: 0.9577 - val_acc: 0.7100\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5830 - acc: 0.7820 - val_loss: 0.9727 - val_acc: 0.7130\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5903 - acc: 0.7791 - val_loss: 1.0679 - val_acc: 0.6979\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6412 - acc: 0.7443 - val_loss: 1.0551 - val_acc: 0.7130\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6787 - acc: 0.7281 - val_loss: 0.9429 - val_acc: 0.7190\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6100 - acc: 0.7619 - val_loss: 0.9584 - val_acc: 0.7039\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6069 - acc: 0.7700 - val_loss: 0.9493 - val_acc: 0.7160\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6005 - acc: 0.7735 - val_loss: 1.0103 - val_acc: 0.7130\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.6081 - acc: 0.755 - 0s 29us/step - loss: 0.6204 - acc: 0.7555 - val_loss: 1.0823 - val_acc: 0.7039\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6630 - acc: 0.7446 - val_loss: 0.9902 - val_acc: 0.6949\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5933 - acc: 0.7728 - val_loss: 0.9876 - val_acc: 0.7069\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5774 - acc: 0.7795 - val_loss: 1.0272 - val_acc: 0.6979\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5995 - acc: 0.7661 - val_loss: 1.0613 - val_acc: 0.6949\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6145 - acc: 0.7580 - val_loss: 1.0027 - val_acc: 0.7039\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6057 - acc: 0.7566 - val_loss: 1.0794 - val_acc: 0.7160\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6644 - acc: 0.7439 - val_loss: 0.9509 - val_acc: 0.7160\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5647 - acc: 0.7872 - val_loss: 0.9636 - val_acc: 0.7160\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5643 - acc: 0.7908 - val_loss: 1.0255 - val_acc: 0.7069\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.5903 - acc: 0.7665 - val_loss: 1.0990 - val_acc: 0.7069\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6665 - acc: 0.7436 - val_loss: 1.0029 - val_acc: 0.7039\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5946 - acc: 0.7644 - val_loss: 0.9809 - val_acc: 0.7130\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5754 - acc: 0.7753 - val_loss: 1.0097 - val_acc: 0.7160\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5684 - acc: 0.7788 - val_loss: 0.9804 - val_acc: 0.7251\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5785 - acc: 0.7770 - val_loss: 0.9666 - val_acc: 0.7251\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6142 - acc: 0.7672 - val_loss: 0.9674 - val_acc: 0.6858\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6266 - acc: 0.7541 - val_loss: 0.9717 - val_acc: 0.6828\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5647 - acc: 0.7939 - val_loss: 0.9630 - val_acc: 0.7160\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5551 - acc: 0.7848 - val_loss: 0.9770 - val_acc: 0.7069\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5725 - acc: 0.7901 - val_loss: 1.0060 - val_acc: 0.6798\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6206 - acc: 0.7689 - val_loss: 0.9822 - val_acc: 0.6828\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5684 - acc: 0.7964 - val_loss: 0.9986 - val_acc: 0.6888\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5443 - acc: 0.7982 - val_loss: 1.0444 - val_acc: 0.7100\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5507 - acc: 0.7844 - val_loss: 1.1327 - val_acc: 0.6888\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6034 - acc: 0.7774 - val_loss: 1.1848 - val_acc: 0.6949\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6356 - acc: 0.7675 - val_loss: 1.0576 - val_acc: 0.7039\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5984 - acc: 0.7629 - val_loss: 1.0512 - val_acc: 0.7069\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5879 - acc: 0.7644 - val_loss: 1.0248 - val_acc: 0.7039\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5476 - acc: 0.7887 - val_loss: 1.0426 - val_acc: 0.7100\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5312 - acc: 0.7929 - val_loss: 1.0929 - val_acc: 0.7009\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5622 - acc: 0.7795 - val_loss: 1.1477 - val_acc: 0.6949\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6318 - acc: 0.7499 - val_loss: 1.0810 - val_acc: 0.6979\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5768 - acc: 0.7746 - val_loss: 1.0696 - val_acc: 0.7009\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5435 - acc: 0.7936 - val_loss: 1.0638 - val_acc: 0.7100\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5356 - acc: 0.7946 - val_loss: 1.1108 - val_acc: 0.6828\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5431 - acc: 0.7929 - val_loss: 1.1405 - val_acc: 0.6737\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5525 - acc: 0.7908 - val_loss: 1.1332 - val_acc: 0.6979\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5509 - acc: 0.7911 - val_loss: 1.1387 - val_acc: 0.6949\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5598 - acc: 0.7813 - val_loss: 1.1856 - val_acc: 0.7039\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6272 - acc: 0.7506 - val_loss: 1.0137 - val_acc: 0.7130\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5552 - acc: 0.7858 - val_loss: 1.0625 - val_acc: 0.7100\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5699 - acc: 0.7725 - val_loss: 1.0482 - val_acc: 0.7069\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5272 - acc: 0.7968 - val_loss: 1.0619 - val_acc: 0.7100\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5097 - acc: 0.8056 - val_loss: 1.0992 - val_acc: 0.7039\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5245 - acc: 0.7954 - val_loss: 1.1584 - val_acc: 0.6949\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5696 - acc: 0.7746 - val_loss: 1.1948 - val_acc: 0.6918\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5993 - acc: 0.7605 - val_loss: 1.0555 - val_acc: 0.6979\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5054 - acc: 0.8049 - val_loss: 1.0476 - val_acc: 0.6858\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.5296 - acc: 0.7950 - val_loss: 1.0574 - val_acc: 0.6737\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5698 - acc: 0.7834 - val_loss: 1.0322 - val_acc: 0.6918\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5309 - acc: 0.8151 - val_loss: 1.0638 - val_acc: 0.6858\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5098 - acc: 0.8207 - val_loss: 1.1281 - val_acc: 0.6556\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5724 - acc: 0.7918 - val_loss: 1.0889 - val_acc: 0.6586\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5068 - acc: 0.8154 - val_loss: 1.0690 - val_acc: 0.6918\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5005 - acc: 0.8172 - val_loss: 1.0571 - val_acc: 0.6767\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6080 - acc: 0.7538 - val_loss: 1.0280 - val_acc: 0.6858\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5279 - acc: 0.8049 - val_loss: 1.0644 - val_acc: 0.6798\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4961 - acc: 0.8235 - val_loss: 1.0639 - val_acc: 0.6949\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5349 - acc: 0.7943 - val_loss: 1.0806 - val_acc: 0.6647\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5447 - acc: 0.7936 - val_loss: 1.0705 - val_acc: 0.6828\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5168 - acc: 0.8084 - val_loss: 1.0643 - val_acc: 0.6918\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5069 - acc: 0.8073 - val_loss: 1.0566 - val_acc: 0.6979\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5138 - acc: 0.8049 - val_loss: 1.0549 - val_acc: 0.6979\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5257 - acc: 0.8006 - val_loss: 1.0489 - val_acc: 0.7069\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5172 - acc: 0.7985 - val_loss: 1.0633 - val_acc: 0.6858\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5466 - acc: 0.7830 - val_loss: 1.0913 - val_acc: 0.6495\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5531 - acc: 0.7908 - val_loss: 1.0792 - val_acc: 0.6798\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4962 - acc: 0.8221 - val_loss: 1.1136 - val_acc: 0.6828\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4891 - acc: 0.8225 - val_loss: 1.1749 - val_acc: 0.6647\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5040 - acc: 0.8147 - val_loss: 1.2391 - val_acc: 0.6647\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5127 - acc: 0.8165 - val_loss: 1.2047 - val_acc: 0.6918\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5021 - acc: 0.8013 - val_loss: 1.2626 - val_acc: 0.6888\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5587 - acc: 0.7781 - val_loss: 1.1827 - val_acc: 0.6979\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5690 - acc: 0.7693 - val_loss: 1.1080 - val_acc: 0.7069\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4777 - acc: 0.8179 - val_loss: 1.1594 - val_acc: 0.6949\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4726 - acc: 0.8151 - val_loss: 1.1911 - val_acc: 0.6918\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4803 - acc: 0.8108 - val_loss: 1.2422 - val_acc: 0.7009\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5590 - acc: 0.7742 - val_loss: 1.2223 - val_acc: 0.6949\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5550 - acc: 0.7703 - val_loss: 1.1591 - val_acc: 0.6979\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4838 - acc: 0.8066 - val_loss: 1.1748 - val_acc: 0.6858\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4781 - acc: 0.8260 - val_loss: 1.2659 - val_acc: 0.6556\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4966 - acc: 0.8161 - val_loss: 1.2104 - val_acc: 0.6858\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4706 - acc: 0.8179 - val_loss: 1.2506 - val_acc: 0.6828\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4991 - acc: 0.7982 - val_loss: 1.2924 - val_acc: 0.7009\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5895 - acc: 0.7665 - val_loss: 1.1679 - val_acc: 0.6918\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 0.5220 - acc: 0.7851 - val_loss: 1.1445 - val_acc: 0.7069\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.4762 - acc: 0.8211 - val_loss: 1.1518 - val_acc: 0.6949\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.4760 - acc: 0.8228 - val_loss: 1.1732 - val_acc: 0.7100\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4850 - acc: 0.8137 - val_loss: 1.1657 - val_acc: 0.6949\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4614 - acc: 0.8256 - val_loss: 1.1332 - val_acc: 0.6858\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5435 - acc: 0.7844 - val_loss: 1.1430 - val_acc: 0.6526\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5233 - acc: 0.7904 - val_loss: 1.1535 - val_acc: 0.6526\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4563 - acc: 0.8334 - val_loss: 1.2184 - val_acc: 0.6495\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4757 - acc: 0.8242 - val_loss: 1.1989 - val_acc: 0.6647\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4557 - acc: 0.8330 - val_loss: 1.1934 - val_acc: 0.6556\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.4600 - acc: 0.8366 - val_loss: 1.1773 - val_acc: 0.6586\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4821 - acc: 0.8200 - val_loss: 1.1795 - val_acc: 0.6435\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5527 - acc: 0.7749 - val_loss: 1.1032 - val_acc: 0.6858\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4772 - acc: 0.8271 - val_loss: 1.1325 - val_acc: 0.6949\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.4650 - acc: 0.8281 - val_loss: 1.1378 - val_acc: 0.6949\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4699 - acc: 0.8299 - val_loss: 1.1458 - val_acc: 0.6949\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4608 - acc: 0.8274 - val_loss: 1.1642 - val_acc: 0.6798\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4915 - acc: 0.8154 - val_loss: 1.1540 - val_acc: 0.6798\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4773 - acc: 0.8204 - val_loss: 1.1820 - val_acc: 0.6586\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4671 - acc: 0.8341 - val_loss: 1.2137 - val_acc: 0.6556\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4695 - acc: 0.8271 - val_loss: 1.1896 - val_acc: 0.6737\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4524 - acc: 0.8323 - val_loss: 1.1872 - val_acc: 0.6586\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4764 - acc: 0.8214 - val_loss: 1.1709 - val_acc: 0.6647\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5081 - acc: 0.8006 - val_loss: 1.1402 - val_acc: 0.6888\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4573 - acc: 0.8323 - val_loss: 1.1875 - val_acc: 0.6767\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4254 - acc: 0.8450 - val_loss: 1.2353 - val_acc: 0.6858\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4208 - acc: 0.846 - 0s 29us/step - loss: 0.4301 - acc: 0.8426 - val_loss: 1.2196 - val_acc: 0.6918\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4522 - acc: 0.8369 - val_loss: 1.2700 - val_acc: 0.6979\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4526 - acc: 0.8211 - val_loss: 1.3799 - val_acc: 0.6918\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5363 - acc: 0.7781 - val_loss: 1.3579 - val_acc: 0.6798\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5295 - acc: 0.7897 - val_loss: 1.2087 - val_acc: 0.6767\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4178 - acc: 0.8514 - val_loss: 1.2449 - val_acc: 0.6586\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.4315 - acc: 0.8426 - val_loss: 1.2886 - val_acc: 0.6616\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4328 - acc: 0.8401 - val_loss: 1.3926 - val_acc: 0.6163\n",
      "Epoch 309/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4669 - acc: 0.8411 - val_loss: 1.3341 - val_acc: 0.6616\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4332 - acc: 0.8387 - val_loss: 1.4049 - val_acc: 0.6888\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5030 - acc: 0.7918 - val_loss: 1.3818 - val_acc: 0.6888\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5412 - acc: 0.7813 - val_loss: 1.2309 - val_acc: 0.6798\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4215 - acc: 0.8380 - val_loss: 1.2585 - val_acc: 0.6888\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4141 - acc: 0.8464 - val_loss: 1.2736 - val_acc: 0.6798\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4107 - acc: 0.8492 - val_loss: 1.2748 - val_acc: 0.6858\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4048 - acc: 0.8591 - val_loss: 1.3018 - val_acc: 0.6979\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4679 - acc: 0.8263 - val_loss: 1.3291 - val_acc: 0.7130\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4970 - acc: 0.8140 - val_loss: 1.4449 - val_acc: 0.6918\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5245 - acc: 0.7802 - val_loss: 1.3791 - val_acc: 0.6767\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4841 - acc: 0.8056 - val_loss: 1.2768 - val_acc: 0.6707\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4153 - acc: 0.8401 - val_loss: 1.3121 - val_acc: 0.6677\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4143 - acc: 0.8418 - val_loss: 1.3515 - val_acc: 0.6586\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4387 - acc: 0.8292 - val_loss: 1.4167 - val_acc: 0.6737\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4832 - acc: 0.8080 - val_loss: 1.3268 - val_acc: 0.6918\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4399 - acc: 0.8249 - val_loss: 1.3090 - val_acc: 0.7100\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.4055 - acc: 0.8454 - val_loss: 1.3179 - val_acc: 0.6979\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4054 - acc: 0.8489 - val_loss: 1.3570 - val_acc: 0.6858\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4293 - acc: 0.8330 - val_loss: 1.4000 - val_acc: 0.6858\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4772 - acc: 0.8003 - val_loss: 1.3876 - val_acc: 0.6828\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4576 - acc: 0.8182 - val_loss: 1.3372 - val_acc: 0.6616\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4042 - acc: 0.8461 - val_loss: 1.3820 - val_acc: 0.6677\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4082 - acc: 0.8471 - val_loss: 1.4201 - val_acc: 0.6616\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4485 - acc: 0.8235 - val_loss: 1.4234 - val_acc: 0.6737\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4373 - acc: 0.8366 - val_loss: 1.3764 - val_acc: 0.6495\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4343 - acc: 0.8341 - val_loss: 1.3979 - val_acc: 0.6616\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4551 - acc: 0.8168 - val_loss: 1.3559 - val_acc: 0.6979\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4533 - acc: 0.8249 - val_loss: 1.3557 - val_acc: 0.7039\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.4307 - acc: 0.8316 - val_loss: 1.3459 - val_acc: 0.6918\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.4121 - acc: 0.8373 - val_loss: 1.3329 - val_acc: 0.6798\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3942 - acc: 0.8517 - val_loss: 1.3672 - val_acc: 0.6767\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4063 - acc: 0.8433 - val_loss: 1.4235 - val_acc: 0.6616\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4194 - acc: 0.8352 - val_loss: 1.4729 - val_acc: 0.6888\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4917 - acc: 0.7978 - val_loss: 1.3838 - val_acc: 0.6707\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4468 - acc: 0.8175 - val_loss: 1.3290 - val_acc: 0.6979\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3891 - acc: 0.8517 - val_loss: 1.3894 - val_acc: 0.6737\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3949 - acc: 0.8440 - val_loss: 1.3835 - val_acc: 0.6767\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3962 - acc: 0.8482 - val_loss: 1.4105 - val_acc: 0.6918\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4293 - acc: 0.8397 - val_loss: 1.4220 - val_acc: 0.7039\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4386 - acc: 0.8281 - val_loss: 1.3668 - val_acc: 0.6737\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3825 - acc: 0.8552 - val_loss: 1.4301 - val_acc: 0.6858\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4214 - acc: 0.8348 - val_loss: 1.5570 - val_acc: 0.6858\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5065 - acc: 0.7932 - val_loss: 1.3783 - val_acc: 0.6526\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4000 - acc: 0.8485 - val_loss: 1.3578 - val_acc: 0.6647\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3739 - acc: 0.8693 - val_loss: 1.4116 - val_acc: 0.6465\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3870 - acc: 0.8644 - val_loss: 1.4101 - val_acc: 0.6495\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3926 - acc: 0.8612 - val_loss: 1.3849 - val_acc: 0.6707\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3755 - acc: 0.8580 - val_loss: 1.4609 - val_acc: 0.6647\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4201 - acc: 0.8359 - val_loss: 1.6013 - val_acc: 0.6888\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5502 - acc: 0.7872 - val_loss: 1.3329 - val_acc: 0.6828\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4223 - acc: 0.8292 - val_loss: 1.3468 - val_acc: 0.6888\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3706 - acc: 0.8640 - val_loss: 1.4088 - val_acc: 0.6677\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3648 - acc: 0.8644 - val_loss: 1.4083 - val_acc: 0.6798\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3694 - acc: 0.8584 - val_loss: 1.4422 - val_acc: 0.6828\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4092 - acc: 0.8390 - val_loss: 1.5286 - val_acc: 0.6949\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4542 - acc: 0.8197 - val_loss: 1.4238 - val_acc: 0.6858\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4151 - acc: 0.8309 - val_loss: 1.4660 - val_acc: 0.6677\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4164 - acc: 0.8337 - val_loss: 1.4595 - val_acc: 0.6556\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4069 - acc: 0.8394 - val_loss: 1.4646 - val_acc: 0.6556\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3943 - acc: 0.8450 - val_loss: 1.4552 - val_acc: 0.6526\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3713 - acc: 0.8595 - val_loss: 1.4369 - val_acc: 0.6647\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3756 - acc: 0.8573 - val_loss: 1.5191 - val_acc: 0.6888\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4269 - acc: 0.8309 - val_loss: 1.5071 - val_acc: 0.6858\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4137 - acc: 0.8359 - val_loss: 1.4401 - val_acc: 0.6586\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3682 - acc: 0.8584 - val_loss: 1.4162 - val_acc: 0.6707\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3486 - acc: 0.8721 - val_loss: 1.4875 - val_acc: 0.6677\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3649 - acc: 0.8746 - val_loss: 1.4935 - val_acc: 0.6435\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4013 - acc: 0.8552 - val_loss: 1.4833 - val_acc: 0.6495\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4084 - acc: 0.8507 - val_loss: 1.3836 - val_acc: 0.6707\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3491 - acc: 0.8714 - val_loss: 1.3926 - val_acc: 0.6616\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3664 - acc: 0.8598 - val_loss: 1.4111 - val_acc: 0.6405\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5537 - acc: 0.7591 - val_loss: 1.2565 - val_acc: 0.6495\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3756 - acc: 0.8760 - val_loss: 1.3826 - val_acc: 0.6798\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3450 - acc: 0.8732 - val_loss: 1.4670 - val_acc: 0.6616\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3425 - acc: 0.8728 - val_loss: 1.5276 - val_acc: 0.6707\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3642 - acc: 0.8563 - val_loss: 1.5905 - val_acc: 0.6647\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3787 - acc: 0.8545 - val_loss: 1.4876 - val_acc: 0.6556\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.3532 - acc: 0.8640 - val_loss: 1.5182 - val_acc: 0.6798\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3760 - acc: 0.8499 - val_loss: 1.5178 - val_acc: 0.6949\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.4023 - acc: 0.8426 - val_loss: 1.5438 - val_acc: 0.6888\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4000 - acc: 0.8394 - val_loss: 1.5088 - val_acc: 0.6707\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3809 - acc: 0.8552 - val_loss: 1.5470 - val_acc: 0.6677\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3997 - acc: 0.8457 - val_loss: 1.5710 - val_acc: 0.6828\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4075 - acc: 0.8369 - val_loss: 1.4986 - val_acc: 0.6707\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3701 - acc: 0.8626 - val_loss: 1.5140 - val_acc: 0.6918\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3450 - acc: 0.8707 - val_loss: 1.5078 - val_acc: 0.6767\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3585 - acc: 0.8595 - val_loss: 1.5495 - val_acc: 0.6737\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4123 - acc: 0.8348 - val_loss: 1.5476 - val_acc: 0.6556\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3865 - acc: 0.8485 - val_loss: 1.5329 - val_acc: 0.6556\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3857 - acc: 0.8528 - val_loss: 1.5696 - val_acc: 0.6586\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3787 - acc: 0.8545 - val_loss: 1.5045 - val_acc: 0.6677\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3389 - acc: 0.8739 - val_loss: 1.5426 - val_acc: 0.6828\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3458 - acc: 0.8693 - val_loss: 1.5542 - val_acc: 0.6888\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3519 - acc: 0.8644 - val_loss: 1.6151 - val_acc: 0.6737\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3923 - acc: 0.8418 - val_loss: 1.5831 - val_acc: 0.6586\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3876 - acc: 0.8475 - val_loss: 1.5703 - val_acc: 0.6375\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3816 - acc: 0.8528 - val_loss: 1.5545 - val_acc: 0.6767\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3572 - acc: 0.8707 - val_loss: 1.5352 - val_acc: 0.6798\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3231 - acc: 0.8809 - val_loss: 1.5269 - val_acc: 0.6586\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3261 - acc: 0.8831 - val_loss: 1.5701 - val_acc: 0.6405\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3367 - acc: 0.8831 - val_loss: 1.5659 - val_acc: 0.6495\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3325 - acc: 0.8859 - val_loss: 1.6273 - val_acc: 0.6767\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3854 - acc: 0.8436 - val_loss: 1.7993 - val_acc: 0.6888\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5391 - acc: 0.7890 - val_loss: 1.4225 - val_acc: 0.6767\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3582 - acc: 0.8566 - val_loss: 1.4819 - val_acc: 0.6918\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3149 - acc: 0.8852 - val_loss: 1.5277 - val_acc: 0.6526\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3090 - acc: 0.8820 - val_loss: 1.5163 - val_acc: 0.6495\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3200 - acc: 0.8912 - val_loss: 1.5370 - val_acc: 0.6556\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3457 - acc: 0.8774 - val_loss: 1.5660 - val_acc: 0.6284\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3675 - acc: 0.8654 - val_loss: 1.5538 - val_acc: 0.6526\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3117 - acc: 0.8873 - val_loss: 1.7101 - val_acc: 0.6798\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3812 - acc: 0.8433 - val_loss: 1.7533 - val_acc: 0.6888\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4984 - acc: 0.7999 - val_loss: 1.4905 - val_acc: 0.6737\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3432 - acc: 0.8651 - val_loss: 1.5476 - val_acc: 0.6707\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3223 - acc: 0.8771 - val_loss: 1.5796 - val_acc: 0.6677\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3222 - acc: 0.8788 - val_loss: 1.6637 - val_acc: 0.6677\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3405 - acc: 0.8693 - val_loss: 1.6375 - val_acc: 0.6586\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3487 - acc: 0.8679 - val_loss: 1.6220 - val_acc: 0.6707\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3422 - acc: 0.8658 - val_loss: 1.6674 - val_acc: 0.6647\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3840 - acc: 0.8457 - val_loss: 1.6536 - val_acc: 0.6949\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3537 - acc: 0.8637 - val_loss: 1.5917 - val_acc: 0.6616\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3105 - acc: 0.8841 - val_loss: 1.6578 - val_acc: 0.6616\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3266 - acc: 0.8746 - val_loss: 1.7093 - val_acc: 0.6495\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3916 - acc: 0.8415 - val_loss: 1.6549 - val_acc: 0.6798\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3925 - acc: 0.8457 - val_loss: 1.5718 - val_acc: 0.6828\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3227 - acc: 0.8813 - val_loss: 1.6202 - val_acc: 0.6888\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3187 - acc: 0.8778 - val_loss: 1.7158 - val_acc: 0.6828\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3962 - acc: 0.8489 - val_loss: 1.7236 - val_acc: 0.6556\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3767 - acc: 0.8584 - val_loss: 1.6309 - val_acc: 0.6828\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3191 - acc: 0.8753 - val_loss: 1.6262 - val_acc: 0.6707\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3194 - acc: 0.8778 - val_loss: 1.7072 - val_acc: 0.6888\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3441 - acc: 0.8630 - val_loss: 1.6881 - val_acc: 0.6767\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3619 - acc: 0.8556 - val_loss: 1.6380 - val_acc: 0.6737\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3280 - acc: 0.8711 - val_loss: 1.5921 - val_acc: 0.6647\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3037 - acc: 0.8866 - val_loss: 1.6247 - val_acc: 0.6737\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2924 - acc: 0.8936 - val_loss: 1.6175 - val_acc: 0.6949\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3245 - acc: 0.8834 - val_loss: 1.6128 - val_acc: 0.6949\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3299 - acc: 0.8760 - val_loss: 1.5396 - val_acc: 0.6767\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3516 - acc: 0.8665 - val_loss: 1.5653 - val_acc: 0.6405\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4307 - acc: 0.8246 - val_loss: 1.4407 - val_acc: 0.6465\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3587 - acc: 0.8735 - val_loss: 1.5350 - val_acc: 0.6616\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2903 - acc: 0.9014 - val_loss: 1.6000 - val_acc: 0.6586\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2896 - acc: 0.8933 - val_loss: 1.5916 - val_acc: 0.6707\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2922 - acc: 0.8950 - val_loss: 1.5975 - val_acc: 0.6526\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3134 - acc: 0.8859 - val_loss: 1.5449 - val_acc: 0.6647\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3476 - acc: 0.8686 - val_loss: 1.5475 - val_acc: 0.6616\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3908 - acc: 0.842 - 0s 30us/step - loss: 0.3968 - acc: 0.8362 - val_loss: 1.4766 - val_acc: 0.6495\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3239 - acc: 0.8908 - val_loss: 1.5543 - val_acc: 0.6465\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3042 - acc: 0.8912 - val_loss: 1.5919 - val_acc: 0.6526\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3130 - acc: 0.8866 - val_loss: 1.6185 - val_acc: 0.6405\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3248 - acc: 0.8922 - val_loss: 1.6061 - val_acc: 0.6405\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2990 - acc: 0.8986 - val_loss: 1.5957 - val_acc: 0.6556\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2937 - acc: 0.8901 - val_loss: 1.6207 - val_acc: 0.6556\n",
      "Epoch 463/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3101 - acc: 0.8887 - val_loss: 1.5848 - val_acc: 0.6647\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4744 - acc: 0.7943 - val_loss: 1.4931 - val_acc: 0.6435\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3498 - acc: 0.8809 - val_loss: 1.5844 - val_acc: 0.6616\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2817 - acc: 0.9007 - val_loss: 1.6199 - val_acc: 0.6647\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2816 - acc: 0.8968 - val_loss: 1.6205 - val_acc: 0.6586\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2917 - acc: 0.8950 - val_loss: 1.5933 - val_acc: 0.6556\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3456 - acc: 0.8566 - val_loss: 1.5763 - val_acc: 0.6465\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3523 - acc: 0.8616 - val_loss: 1.5706 - val_acc: 0.6556\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3155 - acc: 0.8848 - val_loss: 1.6036 - val_acc: 0.6677\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2742 - acc: 0.9116 - val_loss: 1.6373 - val_acc: 0.6556\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2758 - acc: 0.9035 - val_loss: 1.6603 - val_acc: 0.6556\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3089 - acc: 0.8947 - val_loss: 1.5605 - val_acc: 0.6435\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3505 - acc: 0.8662 - val_loss: 1.5701 - val_acc: 0.6586\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3714 - acc: 0.8514 - val_loss: 1.5625 - val_acc: 0.6707\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3171 - acc: 0.8859 - val_loss: 1.6753 - val_acc: 0.6888\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2864 - acc: 0.8926 - val_loss: 1.6597 - val_acc: 0.6586\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2712 - acc: 0.9038 - val_loss: 1.7270 - val_acc: 0.6707\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2700 - acc: 0.9003 - val_loss: 1.6959 - val_acc: 0.6616\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2672 - acc: 0.9091 - val_loss: 1.7315 - val_acc: 0.6495\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2626 - acc: 0.9049 - val_loss: 1.7631 - val_acc: 0.6616\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2682 - acc: 0.9045 - val_loss: 1.7853 - val_acc: 0.6556\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3597 - acc: 0.8764 - val_loss: 1.7744 - val_acc: 0.6526\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3195 - acc: 0.8869 - val_loss: 1.7469 - val_acc: 0.6526\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2863 - acc: 0.9017 - val_loss: 2.0021 - val_acc: 0.6798\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4794 - acc: 0.7968 - val_loss: 1.8452 - val_acc: 0.6979\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4066 - acc: 0.8313 - val_loss: 1.6035 - val_acc: 0.6828\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2749 - acc: 0.8940 - val_loss: 1.6775 - val_acc: 0.6405\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2605 - acc: 0.9091 - val_loss: 1.7580 - val_acc: 0.6767\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2546 - acc: 0.9024 - val_loss: 1.7520 - val_acc: 0.6677\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.2613 - acc: 0.9045 - val_loss: 1.7543 - val_acc: 0.6767\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2644 - acc: 0.9070 - val_loss: 1.7392 - val_acc: 0.6647\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2937 - acc: 0.8936 - val_loss: 1.6836 - val_acc: 0.6586\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4321 - acc: 0.8151 - val_loss: 1.5914 - val_acc: 0.6314\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3185 - acc: 0.9010 - val_loss: 1.6608 - val_acc: 0.6586\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2579 - acc: 0.9130 - val_loss: 1.7431 - val_acc: 0.6586\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2555 - acc: 0.9074 - val_loss: 1.7856 - val_acc: 0.6767\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2636 - acc: 0.9042 - val_loss: 1.8347 - val_acc: 0.6798\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2681 - acc: 0.8964 - val_loss: 1.9249 - val_acc: 0.6888\n"
     ]
    }
   ],
   "source": [
    "business_model = model.fit(x=X_train_business, y=y_cat_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_cat_test_business),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VFXegN8zfZJMekhIo/femwoICoJiV+y69rquu3bX\n1f3Wtbv2utZVwbairqgUQQTpTXpvSQikkN4z9/vj3DYlECCh3vd5eDL33nPvnJmQ8zu/LhRFwcLC\nwsLCAsB2tCdgYWFhYXHsYAkFCwsLCwsdSyhYWFhYWOhYQsHCwsLCQscSChYWFhYWOpZQsLCwsLDQ\nsYSCxUmFEOIDIcQ/Gjl2uxBidHPPycLiWMISChYWFhYWOpZQsLA4DhFCOI72HCxOTCyhYHHMoZpt\n7hVC/C6EKBdCvCuESBZC/CCEKBVCzBBCxJnGTxBCrBFCFAkhZgshupiu9RFCLFPv+wzwBL3X2UKI\nFeq9vwkhejZyjuOFEMuFECVCiF1CiMeCrp+iPq9IvX6tet4rhHheCLFDCFEshJirnhshhMgK8z2M\nVl8/JoT4UgjxsRCiBLhWCDFQCDFffY/dQohXhRAu0/3dhBDThRCFQog9QoiHhBApQogKIUSCaVxf\nIUSeEMLZmM9ucWJjCQWLY5ULgTOAjsA5wA/AQ0AS8v/tXQBCiI7AJOBu9dpU4DshhEtdIKcA/wHi\ngS/U56Le2wd4D7gZSADeAr4VQrgbMb9y4GogFhgP3CqEOE99bit1vq+oc+oNrFDvew7oBwxV53Qf\n4G/kd3Iu8KX6np8A9cCfgERgCDAKuE2dgw+YAfwIpALtgZmKouQCs4FLTM+9CpisKEptI+dhcQJj\nCQWLY5VXFEXZoyhKNvArsFBRlOWKolQBXwN91HGXAt8rijJdXdSeA7zIRXcw4AReVBSlVlGUL4HF\npve4CXhLUZSFiqLUK4ryIVCt3rdfFEWZrSjKKkVR/Iqi/I4UTMPVy5cDMxRFmaS+b4GiKCuEEDbg\nD8AfFUXJVt/zN0VRqhv5ncxXFGWK+p6ViqIsVRRlgaIodYqibEcKNW0OZwO5iqI8ryhKlaIopYqi\nLFSvfQhcCSCEsAOXIQWnhYUlFCyOWfaYXleGOY5SX6cCO7QLiqL4gV1AmnotWwms+rjD9LoV8GfV\n/FIkhCgCMtT79osQYpAQYpZqdikGbkHu2FGfsSXMbYlI81W4a41hV9AcOgoh/ieEyFVNSv9sxBwA\nvgG6CiHaILWxYkVRFh3inCxOMCyhYHG8k4Nc3AEQQgjkgpgN7AbS1HMamabXu4AnFEWJNf2LUBRl\nUiPe91PgWyBDUZQY4E1Ae59dQLsw9+QDVQ1cKwciTJ/DjjQ9mQkuafwGsB7ooChKNNK8Zp5D23AT\nV7Wtz5HawlVYWoKFCUsoWBzvfA6MF0KMUh2lf0aagH4D5gN1wF1CCKcQ4gJgoOned4Bb1F2/EEJE\nqg5kXyPe1wcUKopSJYQYiDQZaXwCjBZCXCKEcAghEoQQvVUt5j3gBSFEqhDCLoQYovowNgIe9f2d\nwCPAgXwbPqAEKBNCdAZuNV37H9BSCHG3EMIthPAJIQaZrn8EXAtMwBIKFiYsoWBxXKMoygbkjvcV\n5E78HOAcRVFqFEWpAS5ALn6FSP/Df033LgFuBF4F9gGb1bGN4Tbg70KIUuBRpHDSnrsTGIcUUIVI\nJ3Mv9fJfgFVI30Yh8DRgUxSlWH3mv5FaTjkQEI0Uhr8ghVEpUsB9ZppDKdI0dA6QC2wCRpquz0M6\nuJcpimI2qVmc5AiryY6FxcmJEOJn4FNFUf59tOdicexgCQULi5MQIcQAYDrSJ1J6tOdjcexgmY8s\nLE4yhBAfInMY7rYEgkUwlqZgYWFhYaFjaQoWFhYWFjrHXVGtxMREpXXr1kd7GhYWFhbHFUuXLs1X\nFCU49yWE404otG7dmiVLlhztaVhYWFgcVwghGhV6bJmPLCwsLCx0LKFgYWFhYaFjCQULCwsLC53j\nzqcQjtraWrKysqiqqjraU2l2PB4P6enpOJ1WPxQLC4um54QQCllZWfh8Plq3bk1gQcwTC0VRKCgo\nICsrizZt2hzt6VhYWJyAnBDmo6qqKhISEk5ogQAghCAhIeGk0IgsLCyODieEUABOeIGgcbJ8TgsL\ni6PDCSMULCwsLI5V6ur9HGpJoYVbC/g9q6iJZ9QwllBoAoqKinj99dcP+r5x48ZRVHTkftkWFhZH\nnuq6egb+cyZfLcsOOJ9fVs3KXaF//wu3FlBZU68fX/r2Aia8Ou+QhcrB0qxCQQgxVgixQQixWQjx\nQJjrcUKIr4UQvwshFgkhujfnfJqLhoRCXV3dfu+bOnUqsbGxzTUtCwuLY4C80moKy2uYtiY34Pwf\nJy/n3NfmsWlPacDYS99ewDmvzuXWj5eys6BCv7Zga+ERmW+zCQW1x+xrwFlAV+AyIUTXoGEPASsU\nRekJXA281FzzaU4eeOABtmzZQu/evRkwYACnnnoqEyZMoGtX+XHPO+88+vXrR7du3Xj77bf1+1q3\nbk1+fj7bt2+nS5cu3HjjjXTr1o0zzzyTysrKo/VxLCws9kNNnZ+6en+jxxeU1QCwcFshfr/c7f9r\n+kbmbS4AYMyLc8guqmRvSRXbC8oB2Ly3jB9W5/L+b9v05zz+3Zqm+gj7pTlDUgcCmxVF2QoghJgM\nnAusNY3pCjwFoCjKeiFEayFEsqIoew71TR//bg1rc0oOY9qhdE2N5m/ndGvw+lNPPcXq1atZsWIF\ns2fPZvz48axevVoPG33vvfeIj4+nsrKSAQMGcOGFF5KQkBDwjE2bNjFp0iTeeecdLrnkEr766iuu\nvPLKJv0cFhYWh0+vx6fRNTWar24dGnB+d3ElAkFKjIeXZmxia34ZL03sQ2G5FArFlbWszy2la2o0\nL83cBIDLYaOmzs+EV+ZSUF7Dcxf30p9nE/DTaqldXDesNe/P286OgnJaJUQ26+drTvNRGrDLdJyl\nnjOzEtlDF7X5eSsgPfhBQoibhBBLhBBL8vLymmm6TcfAgQMD8ghefvllevXqxeDBg9m1axebNm0K\nuadNmzb07t0bgH79+rF9+/YjNV0LC4uDoLK2nqU79rG7OFCbH/Lkzwx7+mcA/jVjI9+syGHK8mzy\ny6r1MQu2FrC31Agpf/WyPgAUqIJja14Zdptgwz/GkhkfQU6xHHtOr1QA5mzKb74PpnK0k9eeAl4S\nQqxANjNfDtQHD1IU5W3gbYD+/fvv19uyvx39kSIy0pDks2fPZsaMGcyfP5+IiAhGjBgRNs/A7Xbr\nr+12u2U+srBoAmrr/dTU+Yl0H/pS9+PqXL5cmsU7V/fDb1p9hjz5M9ueHEdJVR3rd0vrRL1foay6\njrgIJ/sqanngv79z5+kdAEiIdLFs5z7atYgCYNKNg0mN9QS819a8clJjPbgddtq3iGK76lPomOyj\nT2bsQZmtDpXmFArZQIbpOF09p6MoSglwHYCQAfjbgK3NOKdmwefzUVoavqthcXExcXFxREREsH79\nehYsWHCEZ2dhcfJy00dLmLUhj+1PjT/kZ9zy8VIAsvZVhgiXxdv3cfk7C6gzSYsPf9tOcWUtUW4H\nZdV17Cgox+2w0SYxkvyyahZsLcBhE3RLiyY4oKiwooZYrwuA+EiXft5lt/H1bcMO+TMcDM1pPloM\ndBBCtBFCuICJwLfmAUKIWPUawA3AHFVQHFckJCQwbNgwunfvzr333htwbezYsdTV1dGlSxceeOAB\nBg8efJRmaWFx4lNQVs3TP66noqaOVVnFzNogzc2nPvMzl741P+w91XX1DYZ7llbV6q9XZhWxr0Ka\neW46rS0A363M0QVCjNdJ+xZRPPvTBvwKukawo6CCxCg3sREuiipqmbYml8FtE4j2OIn2BAqZsqo6\nPE65LLscxvLstB+5pNVm0xQURakTQtwB/ATYgfcURVkjhLhFvf4m0AX4UAihAGuA65trPs3Np59+\nGva82+3mhx9+CHtN8xskJiayevVq/fxf/vKXJp+fhcWJzrcrc7hr0nIAhrRN4Or3FunXdhVWsqsw\n1CRbUVNH10d/4k+jO3LN0FaUVNaRmRChX9+8t0x/vXJXESnRHv35783dxgo1z+C0jkn8+YyOzFi3\nh1d+3gxA+6QoVu4qYkdBBUk+N3ERTpbvrKagvIYJvaR7NbhCQVl1na4huOx29aftiFYyaFafgqIo\nU4GpQefeNL2eD3RszjlYWFic+BSUVXPPZyv044qaENekzvS1e3DaBSM6tSCnSPr3/jVjI6uyi5ix\nbi+LHhpFpNtBXmk1OwulTT8xysXczQUMbCOjBhOiXLSM9bAlTwqN+8Z0ontaDL9sNAJh2iZJ32Ju\nSRWdW/qIi3TpDuW4yPBVjsurDU3B6ZCC4EhqCWBlNFtYWBwl9pZWsSanWD/+x//W8sOq3Y26V1EU\nSkymnRW7iqjzKzx7UU9ALq4Om+Dm4W31RRZk9M+NHy3h2vcXA5BbbAR9aJrEp4t20ufv0xnx3Gx2\nqI7eKwa1Yt3uEjbkSut2XISLtFivLnw8Trmrd5gW8BY+I3gkPtJFbIQhCHye8Pvx0uo63A75LLdd\nEw5Hdpm2hIKFhcURp7y6joFPzGT8y3NZn1vC5r2l/HvuNm79ZBnP/rQ+7D25xVXU1Mnom9kb8+j/\nfzPYkCsDPFZmFWMTMEjdye8praLOr5AQ6aK9atsHWLzNyAreU1IVEFaq7cxnrd9LjRrls3znPpKj\n3Yzq0gKQWgZAbISTtFjDzOR1GaYeDbOjODHKTVyEcRztMQTEB9cNYHzPloBMjHMH+RSOdAlMSyhY\nWFgcFoqicOek5czb3PgY+kXbjcV57Iu/MvqFOfrx/34P1RZKq2oZ/ORMPat3Y24pNfV+/v2rDFZc\nm1NCu6QoEn1y4c3eJxf72AgXHVr49OesN5WU+M/8HQGaQpZ6z6psQ3uZsymfVvGRdGkZjcdpY2WW\nvBbpcpAW59XHedQF3GkSCnEmoRAf6SLWawiCaNPrEZ1aMK57S/1Y0xRcR1hD0LCEgoWFxWFRWF7D\ndytzuOLfC/Uont3FlXy3Moeq2vC2/a155Q0+L6eokl2FFQHmocWqEPl2RY76fLmYf7Mih7zSarL2\nVdAqIQKv045NQHaRXODjIgI1hXU5JZzeuQUjOiXx6qzNvDjTSCQtqpDvZ85FqPcrZMRH4LTb6JEW\nA4DHacNmE7rTGQxNwSwUEkxCISHSRaxJUwg2H5nNTnr0kfqsI1MGz8ASChYWFofFnhIjY/d71Sfw\n589Xcuek5fxn/o6w92zNKwt7PjnaTW29wqnPzOKyt42cnvlbZJ0gj7r47impIsJlp6bez6wNe8kp\nqiQ11osQgkiXQ9/1x0U4GdMtxXjf/HJaJ0Ty7jUDaJUQQb0//JJrXrRbqdFILWOkZhDpktdiTLt9\njyPUp2C+nhDlCkhUM5uPINCZrPknjrQvQcMSCk3AoZbOBnjxxRepqKg48EALi8Mgr7SaS96cz67C\npv+/tsdUtuHRb9awr7yGfeque8oKI191a14Zpzz9MzPW7mFrXjm+MFnGrU11fdaYaphpUUB5pdWU\nVNWyu7iK7qly574tv5ySqjpSY9VF2+0wmY9k7sBTF/TQn+V12bDbBJnxcrFPjQnMKgZokxipz08T\nCpFuu3q//BntNeZvs8lF3exT0MxAAG0To0iLNcxNIZqCzXxfkKZwhFUFSyg0AZZQsDjW+c/87Sza\nXsjkxTub7Jnrdpfwj/+tZY9qynn5Mln8be7mfMqqpVBYk1OiO4eX7NhH1r5Kbvl4KdlFlQxsEx/y\nzLZJUQHHa3NKeOzbNeSrlUZBOpy35ZfTKiECn8ehN6DRhEKE206laraKUbODI0wCSFusW/ikMOiU\nYvgcNNokRtI7U5a1T1bNRJqGEKEKBbMmoGE2H5l3/60TI3GYrmnP0nCE0RQ0n8KR6qOgYQmFJsBc\nOvvee+/l2WefZcCAAfTs2ZO//e1vAJSXlzN+/Hh69epF9+7d+eyzz3j55ZfJyclh5MiRjBw58ih/\nCosTgbLqOl6euYnqukBb/pZ8acPXFsKDYeHWAl5Wbe+/ZxXx7E/rURSFGz5cwr/nbtMds4PVRT6v\ntJqyqjp9x7unRAqN7eocXA4beaXVehy/mXZJkdx4qlFM8uOFO/jgt+2syirWQzof/noVxZW19G0V\nR5LPzcpd8v3TVPNMlEkAaAt4pMvYtWvz0p5n9jlo9EqP5fmLe3HzaW3p1ypOPkN9rrZohxMK5sXd\nbhNM/9NpLHlkdMg4TbPQCNQwbAE/jzRHuyBe0/PDA5C7qmmfmdIDznqqwcvm0tnTpk3jyy+/ZNGi\nRSiKwoQJE5gzZw55eXmkpqby/fffA7ImUkxMDC+88AKzZs0iMTGxaedscVIyaeFOXpi+Eafdxq0j\n2gEyzFHr8FVeE9r46duVOXyxZBcfXjeQvLJqdhVW0L+1sYufvHgXXy/P5vJBmdw9eQVb88tZuauY\nkkqpDazOKSE+0kWSz43TLthbWk1ZdR0dk32sySkht6SKjPgIvVeAFtufGOXm0bO78vf/GdX0nXYb\nD4/vyuC2CVz/4RI9BLSm3k+vFjEs3r6Pxdv3cW7vVCYOyGDK8my25pUT43XSTTUnmXfh2sIa6Q49\np2F2ANuEdDR3TvHRItrDg+O66NeigsxdwX4BCFzchRB0SA7UQh6f0I3lO/eF3GfWIoI1hSONpSk0\nMdOmTWPatGn06dOHvn37sn79ejZt2kSPHj2YPn06999/P7/++isxMTFHe6oWJwh/+2Y136thnNru\nd4kp5PPzJbt0x2txZW3AvVW19dw1aTm/bsonu6iSQf+cyUVvzqe4whi3Td3hL9haQItomZA1d3M+\npdVSwGzeU0qM14kQgqQoN1n7KqitV+ig7sC1sM/giKMkn5s/nNKGhQ+N0s/Z1R10/9bx2G2CvFLD\niW1eYCcOyEQIQaKaIHZ+nzR9MdVs/3ab0Bdbs6DQxiVGudWfhlB46oKePHhWZwa3Dex3Ip8rn6FZ\nc6IPYD4KxzVDW/PixD4h5x220Ogj51GKPjrxNIX97OiPBIqi8OCDD3LzzTeHXFu2bBlTp07lkUce\nYdSoUTz66KNHYYYWJxLFlbV8OH8HH87fQc/0kfqCNXP9Xp74fi33je3MvM35pMd5qar1U1IpF/K3\n52xh894ybji1rf6sZaYd7N7SKmJUAaMJhflbCgISsjTKa+rxqgttks+tj9cW8dziKnYVVrA+t5Qu\nLaNZp5aZTlIXdI/JIavZ4WO8TvpmxrJ4uzGn9iZ/g2bySVIX9kv6GwWZtcXbrBFEuE3mI3XRvf6U\nNvg8Di7ql8H9X0nrwpjuKWHNQvK58hl+9Uu220LTyhyHWJLCGcZBrWsdlqP5+MNcOnvMmDG89957\nlJXJkLvs7Gz27t1LTk4OERERXHnlldx7770sW7Ys5F4Li2BWZxfrjtpwmAu2fbk0K8CX8M6v23ht\n1mYWbitkUJsEYrwOSqpq2VVYwT+nrufzJVl6RjCg2+YBpq/bQ71fYV95ja5dzN9aQGlVHX0yYxne\nMSlgHlpETpLPowuFlGgPES47u4ur+K/atP76Uwx/gSYUtExiALspCufm06T5S4vUSTKVjdB29xf3\nT+fBszrTNTXamIsqoMxCISqMo9nlsHHl4FbYbYKHx3XhX5f2alAggKFtNBDFKj/LATSFhgibp2D5\nFI5fzKWzzzrrLC6//HKGDBkCQFRUFB9//DGbN2/m3nvvxWaz4XQ6eeONNwC46aabGDt2LKmpqcya\nNetofgyLY4jfs4pYt7uE+79axaNnd+UPpsV0xa4itueXc3bPlnrT95RoD7M37OXsnrJD16/3jeSa\n9xexbGcRheU1dEyOYmt+GSWVteSZOoHNNXXyWqlG8QA88+MGNuSWMlaN8R/RKYnZG/KorvXTvkUU\nPYKKv2kLWZLPpfsMfB4HKTEedhdXMmPdHoa0TdATwMBwepvDMc0RO6O7JvPlLUNw2G1MfHt+QJSQ\nVjW0W2qM7ksw5qIJBUM7iAjjaDZz42ltQ84FY5iPAqWCec6uQxQKTlsYTcFhmY+Oa4JLZ//xj38M\nOG7Xrh1jxowJue/OO+/kzjvvbNa5WRx/THh1nv46a18liqIwf2sBPdJiOO81ee3uz1Zwcb903A4b\nIzsn8ePqXD2DOCXGg8/toLBcCgCvy060x0lRRY3uIAbpGwCZ5LXaVN4BZLZwRU09ydFuJg7IYPaG\nPLKLKumTGRsSxqntzs078iiPg5YxHn5Q+wzfO6ZTQHVQzRRlXlTNAgLQHd5rHx+LzSZ4/uJeB+yi\npmktblMhvIgwPoWDRftsfpNQWPTwqIAF/VDNR+E0BfdRCkm1hIKFxVEiXBP26rp6RFAJtKx9Fdz+\n6TKmrsplQOu4gGuzNuSRGOWmdUIk+ypqyS+rxm4TOO02IlwOdqgRPx6nnRivk52FFZRUGRFI2UWV\nxEY4SY72sD431Iz5y4Y8Lh+Uqcf7g3SwBoeTagut17T4+txOPca/b2YsZ/dsiaLA+J4tuWpwK32c\nuVdAODs9GCGcF/YLaeEegiagzM+y2wQep42qWv8hh3pqQsa8RgeH+DaF+cjrlN+h1k/BKnNhYXEc\nUV1Xz38W7AhbLmFPSZUeox/MrA17Gf7sbH5Ud9EA63NL6ProT5z2TKAZcdraPUxdJceZHa8A+WXV\nRHudenbupr1l+qIX4bLr9fs9TjtxEU7yS6t1TUHb+bbwuRu0pdfU+xneKSkgAzfa46Rry2juHdOJ\ntolSOGgLsdlME+Vx6H6APplxCCGw2QSvXd43bHQPNE3vAG0uwatplO6APjRNQYsQMn/GYA7VfGS+\nT3Pwm30tR5ITRigcaRXraHGyfM5jmRemb2SRWoL5tVlb+OuU1fzv95yAMbsKKxj0z5mMfG52WIGh\nhWfOWr8XgK+XZzH2xV+p9yvkmgTJhF6p+uunLzRKNTxzUU/S1SqdMV4HGapQ2LinTN+1R7gdVKtO\naq9TNoIvra7TndNau8i0WK8eXhntcTCiUxK9MmQ2r8thY3CbhACzkM/jQAjB7SPb01GNMPKEEwpu\nB5Wqf8HcW2B/NKQpHAxafSR/0N+KZkIym5UOhjaJkdxzRkdevbxvg2MOdSE35yloAvhQBczhckII\nBY/HQ0FBwQm/YCqKQkFBAR7PwWelWjQNG3JLeXnmJq56dyGPTFnFb6pNvro2MEJIywuoqKnn6R9l\nBvBdk5bz+mzZqlGz/X+2ZBfztxTw68bQstP/urQX7UxhmNpCDdA7I5Y26i49xuvUd+T5ZdV6GecI\nk+3c47TpIaJLdhTisAlaqYIkLc6rJ2LFRbr44LqBvHtNfwAGt03A67IHagomrUKz72t2fK/pPX0e\nB6O7JAOyPHRjOFTzixltDsGyWBNYh2o+EkJw16gOugAOR7BPpLGY8xSiVOFllLk4pEceMieETyE9\nPZ2srCzy8vIOPPg4x+PxkJ5+YLuqRfPwvaoRVNf5+XhBw3WEzElib8/ZygV90/h2ZQ7froRT2ycF\nNHeZtjY3wM6vEeFy6LHxAAmRxm67Y7JPt2fHeJ0BO3RDUzDOeZ12va7Q6myZgawt6GmxEXqSmOYD\nSIh0cVrHJC4fmAlIU5AxD8O/oM3P0BQCM4dP65jE1n+OCynr0BCOptAUVE0gWFOICipT0RwccvSR\n6T7tu9LOdTOF2x4JTgih4HQ6adOmzYEHWlgcJruLw/sI9lXUUFlTr++YNbv9BX3S+O/ybLaZsnlf\nn72Z2no/nZJ9lFXXUVheQ2lVLTFeZ4AwiXI7AiJtvC47v943Un+PZDW72OdxBi7GWmZvUMRNfKSL\nCJedipp6fB6Hnv8Q43Xq+Q2aUBBC8NEfBhrPNNnhU0xVRbWFS1uIzcJJcyA3ViDAoUfvmNE0heAd\ndkSYpLam5lDNR+HMZh6nnc9uGkznlCMrFJrVfCSEGCuE2CCE2CyEeCDM9RghxHdCiJVCiDVCiOua\ncz4WFgdL1r4K8suqURSF2np/QOMXM+/O3UaXR3/UC8dpi/tfxnQCYIOp49fGPaXsLq4iNdZDaqyH\n3OIqSqvqGNA6jtvUekUgF1jzIut12smIj9DLM2jtHev9CnabCEna8obRHjQzUbTHqReQS45267vo\n4Po+4TA3l9EWM5sqALz7ccI2hkM1v5gxhEKgVIjUzUfNpyk0xfzNDGqboDuejxTNJhSEEHbgNeAs\noCtwmRCia9Cw24G1iqL0AkYAzwshQvPoLSyOEqc8PYvRL/zCLxvz6P34ND1bN5i9qvnlhekb+WVj\nHsWVtdhtgpYxHuIjXazfbQiF0qo6CspqSIxykxLjZU9JFaXVtfg8zgDNIMrtCNjtB+8mtd25tss3\nqnhq9X7sIWO1HgDRXge3n96ely/rw+mdW+gO6YYaypsxZxZrwkBzpgeXhD5YmtbRHHg+XPmLpqYp\noqeONs2pKQwENiuKslVRlBpgMnBu0BgF8AmpZ0YBhUCocdXCogmo9ytUhKkS2hBaIbeiilq25ZdT\nXlPPxj3hO4aBtP2mxXp5cuo6sosqiVajdDLjI1ifK+v9RHsclFXXUVpVS7TXSUq0m9wSqSlEuR2B\nZZ/djgC/QDBadU9t57s/+743SFOIi3DhdtiZ0CsVIQS19YYp6UCY7d+aD8CvrsCHqyk0raM5VFNw\n2W0HZc46WMw5F8crzelTSAN2mY6zgEFBY14FvgVyAB9wqaIoIYVehBA3ATcBZGZmNstkLU5syqrr\nGPLkTFolRPC/O08Nua4oCkUVtQHN1hebKo2aaww1RIcWUZzTK5XrP1zC+txSWqsdu1KiPXoJieRo\nD5vUZ0W5Hfg8Dqpq/VTV+vF5An0IUS5HwMIezFndU7jnjI5cO6w1YOzStQJzAY5mvVuYXPQ1E5TG\ndcPasKekmmuGtj7g5zSjLbD16gK8vxj+xtCUPoVgTeF0NRLKYv8cbUfzGGAFcDrQDpguhPhVUZQS\n8yBFUd4G3gbo37//iR13anHIKIoSslN7YfpG1uYUc+XgVpRW1bE6u4TqunrcDju7iyv5ZMFO7h7d\ngT9/sZJ/crTxAAAgAElEQVRvVuRw/9jOXD2kFZFuIxsYYOmO0Br4wbRKiGRUl2RaxnjYXVyl77oT\nfS7d6WkWCj6PI6iZu5Mo00Ie4bYHmICCcdht3DWqg36saQruME5fTVBoC2ZwtdMYr5MnTS0rwzHj\nnuEhu29nkKZw2EKhCXbx3gbyFIZ3TAop5Ndc7O/31hAPntWZLi2PrFM5HM0pFLKBDNNxunrOzHXA\nU4r0CG0WQmwDOgOLmnFeFicgK3cVcfFb8/n85iH0NsXza47fGev26ud2FFTQMdnHpW8tYGdhBSM7\nt+C7lTLU9Okf1/P67M0sfnh0QAvIrSZfQquECHYUGC1UL+ybjs/j4Lw+aQBkxkdIoaAu+OZduTmJ\nK9rjDDDX+DwOotzGsdNuC2gjeSB0n4Ij0FQExo6+zi8V8XAlsA9EuA5l1wxrzZa8Mq4/RRaUO2xH\ncxOYjzQTVLBQOFJ8fvMQMuK9Bx4YxM3D2x140BGgOX0Ki4EOQog2qvN4ItJUZGYnMApACJEMdAK2\nNuOcLE5QHpmympo6f0BzmYbYsrcMv1/Rm8Ev3FaAX4H/O7cbY7olU1pVx6RFO/l00U4y4r0IQUD5\n6uuGtmblo2cSrTpl+7aK5bEJ3fRksgS1rHN3Nb48QCiYInd8HkeIUIgM8iEczI5Ti3zR3r9jmN7D\ntfVyoTwUoRCOaI+TFyf20SNktDj9xmYwB9MUmoLmLL9/bOfDftahMLBNPC1jDl4oHCs0m6agKEqd\nEOIO4CfADrynKMoaIcQt6vU3gf8DPhBCrAIEcL+iKKGpnRYnNb9szKNNQiSZCQ1nkmptJrWyzRrx\nkS4Ky2sCzq3LLWWQqfaOVj46Lc7L4xO689OaPTz+nWwRmRLtobLGT76p3HRMhJOYCKduEvIGJUNp\n2c1aY3qzUNByC0Cai8xCIcZrHF+r2vb351MIJrdEJsRpJohw7SI1h7LnEEs9HAghBO9d2/+QY+ub\nQig47Ta2PzX+sJ9zstKsPgVFUaYCU4POvWl6nQOc2ZxzsDi+URSFa96T1sT1/zc2IBv1rV+2kBbn\n5eyeqfpOPr+smrp6P58u2snITi3wOGxEuWXED8jyEL9szOOcni315/y2pQCAlGgvKTEeknxuPcPX\nYbORHO0mv6yari2jObNbMiPVkg3+BpyrD43vQmqsl2HtZd/tJJ+xKzdX1QzWFFrGeGmbFMV3d5yi\nZ7EeTKOVnapJy2yX1vwbGlqnMl8YgdFUnN750B26TWE+sjg8rN+AxTGBoij8c+o61uQUM33tHgrU\nnXmBaZe/cY851r+WJ39Yzx2fLgcMDaGgrIZPFu7k0W/WMO6lXympqmNoO0MrGNW5BSt3FenOXnNc\neUs1UzfJtLMvrqzVs3xjvE7uHt1Rdw5rETfBZRPaJUXxf+d1123bKSZTgllTiAoWCmoyWY/0mEMK\nmzxf9Wm0NmlUM+4ZztJHRuvHj53bjSfO707/VnEh9x8LNIWmYHF4HO3oIwsLAHYVVvL2nK28PUe6\nlNwOGxv+cRY5RUaNoNKqOn7ZmMcdny7j9pHtA+7XNIG8smq+WCojobXG8pqtH2CAatKZsW4PIBfw\n9bmluBw2vel9rCmDtLK2XhcKwfZ+fwPmo2BSTWUhUmMNAeHzOALMOOHMPRrjeqTs9z0AHj2nG/eN\n7Ryw244MKpUR7XFyxaBW4W4/JmiKkFSLw8MSChZHnR9X7+aLJVkB56rr/NTV+8neZxYKtdz6yTIU\nBf67zBifX1atm49yi6vILa5idJdkfeE3h332SIvBJmCmGo2kCYWkKLcezmrevb94aW8WbpPmJc1J\nq6Ho5qP9/xmZw2RbxniIjXBSVFFLtMfZqGSnxtrH7TZxwK5kxzpNXSbC4uA5vv8HWZwQ3DV5hb6o\n24SxA88rqybbpCls2lOmO3fNmcW/m3oLaxFF5/RqqQuFKI+DO09vT7ukKCLdDrq0jGZNTgk2Aa0T\npanF3CZSEwq3jmhHr4xYvYSF9lND1xRcB17Ivrp1KHM25iGE4Jd7R7Imu7hZq3UerzRFmQuLw8MS\ny83N+u+h4sBhkgdEUWDVl1BTIV+v+Roqiw5831FAURS9X4CZGz5cwuPfrSGvtJr5qnO33q9QV2+E\ne5qzUHOKKvluZY7ubP1pbW7A87QaNnPUXgRpJtNM15bReonnKLedP5/ZSc8jmDhAps+08HmIV8tR\nm0sea4u1FtqomZ/ySgMrpGqOZm8jIoT6tYrjT2d0BKTQGao6oQE+vXEQ/7vzlAM+w8LiSGAJheak\nNBcmXw5f3XD4z8pZBl9dD1PvhW2/wBfXwi9Py2vFWbDgjSPajWNrXhk3frSEbfnl+P2ygugH87bx\ne1YR/5q+kc5//ZGq2nq+WZFNdlElFTV1zFi3h/fnbeeSt+Zz2TsLyNpXQUFZNX4FHjirM93TAsMY\n52zMZ2VWMX89uytCyD4AdpvQF+mOyT46tIjSTUmtTA7WlrFevcSzOSEM4JIBGTwyvgtf3DKEWFUr\nMJsttCJvWkN2rdXlkHaJAc9pKCT1YBnaLpHuaTGH9QwLi6bCMh81J4Xb5M89q41zy/4DrgjI2wCt\nhsGKT6E8DzzRMOEVWPoBJLSHzTPk/b0vhx4XQZnaQGj7HHCpjtPS3TDldtj5GxRuhQ5nQsKRyYp8\n8L+rWLitkHZJURRX1jBpkXTuju2Wwo9r5I5+3e4S/jh5BQA//3m4fq9WafTStxbwj/O6A3I33rGF\nj9XZRoWTVdnFAHRJ8RHldlBaVUe0x0F6nJdt+eXERbrolxnHv2ZsBGSZCS28NMrtoGWMhzU5JQGJ\nZyALyN1wqszA1SKazKZszYKhaQIuh425948MqRekcbilHSzgm9uHNaqUiEXzYwmF5qTQlJy9cjLk\nLIeFb4aOi0qGsj3Q7XyY9kjgtbpqKRRKVMdqcZYhZNZ8HTh22iMQ1QLOeanpPkMDaP0CftuST6na\nNaxVQgSb8wxb/6wNRic8TVCYyS6q5KGvVwGyJpDZIQywWhUKST430R6nFApeJ20TI/l1Uz4xXid3\njWpvEgqByW0TB2QyY91eOiSHlmfQ0CJ1zLZsLRzUbMpKjwtNnJvQK5VvV+Y0aynmk4VeGbEB7UYt\njh7W/+aDob4Wqorlz8awT9UU/HXw9c3hBQLAkNvlz6UfBJ53+WDfdnh7BMx7WZ5T/LBjXvjnbJgK\nSz+Eyn2w4E14e6Sc76/PwxOp8Nsrhn9DUaC+cWWkK2tC/QNaXsDvWcXsLq5kVOcWjO2WElBNdPYG\no97Q+/O2B9zfv1UcZ3ZN1hOrWvjcxJlCQZN8bt2xmxjl1u37Po+DbqnS1FJSWRsQvdMqqHfu6K7J\nbHriLL25fDgS1ZIQfTKMuH2taNrANvuP5X/+kl4s++sZJ0S5ZAsLDUtTaCyz/mnY8NMHwBVfgM0p\nTTnleXKHXl4A7ii5m68sgrz1cnxFwf6fHa+afLb8HHg+c5A0I2lagicWaiugPrBsg47DA3VV8FxH\nY8xTplLj0x6R/874O+z+HXJ/hyu/koIjuTtUq6YbTwy/bJS7/EiXnYvenM8nNwyibVIkL/+0mluH\nJFNRU8+ZXZP5ef1eqmr9RLgdtE2KDJjO71nFZMR7SYpys2yndIq77DZq6v3ERjgD2jom+dzEqo5h\nIaQdP6+0mkiXnUi3I6BjWCe1po+Ww9BCFSDhdvMHqs/fLTWGKbcP0+sUAQxrnxiSPR0Op93WZDWE\nLCyOFSyh0Bh2zIdfnjGOsxbDO6OkJjD0Lpj3Ilz1NfznfIhrDUW7QAndXQcg7MaYhvwAGYOlUHBH\ng9sHSZ2kwMnfaIxpP1qOSR8I45+Ht04LFRrpAyAmA9b8Vx5Pf9S49qIsl1xwxsskLHsFIhNZOmqS\nXlriOrVW/7dLNuMp3MBf9jxMxNpa8qveo320n5LIPBaUJhLhtNMnM3Rn3T01RrfNR7pkO8n1uaVE\ne536ghrjdeK023RNweu06y0ftS5fWshotMdJl5bRDG2XwN2jZTTP3aM78tDXq/TKlON7GCUsGkPv\nMGYLK1zU4mTFMh81hl+fM5y7IHfshVukKWfei/LcTw/Ln/u2y8Xesx/76Gn3wjWmgrE+0yIWbxIQ\nKWp9+85nw40/w3lvgkeNUklQ6+iPeRLuWArX/g9a9oRItV58q1Pg3NcBqB//L6o9auRMlwn640sV\nI4QzYfpdULAJds4na+ta/Xze6p9pJXLpvmsSj++9iwRRipcqQOG6jbcyufYuQNb+75jsIy3WS7Qp\nU7d7Wowe9pkc4yFDNfHEeJ16yKhWaiLWK4+9TrueRawJBU0L8HkcuBw2Pr1xsF5w7vJBmWx7chyx\nES5WPXYmL07s3fB3b2FhsV8sodAY9qyBjmON46qg/IDYTNhrLKSk9ZMaQ0O0O13u3DXc0YHXAOwu\nSOkuhUu/a8GXAr5kcKlO09Mfhvt3QFJHSGwPDjUyxqvu1tuNhD5XsOnaVdzzSx0Tf5Mx+rv73kN+\nTHdWp17IbkUuqtWKVBi3pJ4DgHPbLISAYVHZvFr9CLNcfyaqZHPAR4iikqQKec5Njez6tWYKMy6P\nZeHw1fw78TP6iQ0MaB2vL/4tfG46qfZ9l92mCwstHFQrL+Fx2qlX6/5ru/iMOCnAautDGvMBRtaw\nz+NskpaOFhYnK5b5qHSP1ARO+RNEpxrnq0vh539A9wtl6GfLXoACG36E2qDm7f3/ADMeM47Pfwu+\nu7vh9/TEBr6XOR6y71Wwcz6c/SLEpMMDO4LuVQWIooA3UBupq/djEzZswLQd9dz20FTq9BCaDrSu\n+hTezQEeokdaDM+zAID7a2/iB/9ALk5qx0O7ZzJu57M85R7DpXU/yekJhfPtc9nkT6N20B10Xfwg\nscJwKEdTLpurfHENmu5xCtCvWw3eNvewJkdGEXmddt3Es7u4ipGdpbDQIn+0Vpgep43z+qQxd3O+\nHjraUk1M06KeLCwsmoeTRyhsngHT/hp6vjwfyvfC6q9kaKhGVYl08C58Sx636ArD7oK5L8KMvwU+\no89VhlD401qISTPMTZ4Y6cgFuPhDWPuNzEOwN1D8rGUvuLWB6CKAM5+QZqsOoRXH75y0nLvzKukE\nfLau2iQQQlmVXQyqj3S3kkA1Lqat3csdfjcRooJLkQLhp/r+nGpbRYSoJkdJoGOSLMz2uOND/Vkx\nopyokI8j8Pql8IyPdDHGtphrC1aR2e4DAMb1aElcRKD5KM6kKfTJjGPmn0foT9O0DasXq4VF83Ly\nCAWXL7xDN6EdRKXIPIHgJafjGBk55IqCVkPkOacpwuWCd2T4Z6Qp09WnVrPUhII3zhAKLXtBt/PC\nz++KL6WAOhCxGXDpx/qhoih88Nt2Vu4q4ofVudzmAmywTwkMw+zfKo4lQclBubYWdCSbfKJJifaQ\nW1LFPlcUKcIY93TdRHyOCoba17JXiWVYstRwRtmX62Oedb5Nnxn3Bc4zY6DUtlQz0O2OKfQs2wav\ntWVb/3MQ3cZR+f2DvORcydbeMq/C67TjcggiHEJqQqZQzz6Zcdw6oh1XDMrkgFQWwZunSCF/48wD\nj7ewsNA5eYRC5iD573BxmtrsdZkATjWs8o4lsHsl2NSoFZcqPLxx0vkMMmTUzB9+Ar8agdThjEa9\nvaIoFJTXcNEbv3HDqW3pnRGrdwkDWOtvTQ/bdkoIDM80N2uJdNkpr6nnvaT7mZozgy1KKgMTIsgt\nqeKN5Md4Oe96ALYOfIytc1L53j2OoXVrqXJE44gKbXzexxbob8AdI53n2Uvh73EMGPIYWxV1PvU1\niNVfQbfz8S55g3PtwLwBMHIvwuFmivMRuu7dAi+0lFqXzUguu/+UBIgI+g7DseM3KN4l/9VVG/4W\nCwuLA2J55A4Ws1BwmhaoxA4y81jDoY7zmsI0gxenzMHQelij39rvV7jq3UX0/8cMthdU8MiU1Uwz\nZQrfeXp7NvR7lGtq7mezks6EXqlc1C8dIMCUdGY3qc0kJ6cxuf50QJCuOnKj0zqxtJvMqo5vLaN4\ndqWO4fuerzD8+qcgIl5/zobRH4ROsuu5MvfBHSUXZSB1/YcMbhGUKLdpeuBx0U6oLqOrskUel+6G\nXQuM6/mb4Ln28NNDoQUGc5bDuu+gOFse75xvXCvcJkOELSwsGoUlFA4WZ8N9ggPQTB/m0NSD2LH+\nnlXEjR8tCcgm/mpZFnM3B5qYPltiLHjJ0R5Gds/kF38vAM7omsyFfaVQsAm4eXhbzuiaTA+1+Fr7\nFkb5B61KaEZcBP0u+gvc/CsxXUYQ43US63Uy/oKryczIkFoAsMTfkZqUvqETP+VPkDEgMKLKl4Kj\nPKjMxfKPA4+nPwoL3wg8t+pL+XPrbJj/mny98A14pg3UqbkYNRXw7pnw2ZUya7yySPqHNF4fBC92\nD53n/qivle9d10CS4PFKcRbsXHi0Z2FxjGMJhYPFrCnsF1UouExCxN6wUNirlmX+ZkU2i7YV8s6v\n25i+dg8fL9jBLrVHwE9r9oTct6fEqPHfMsYT0PAlxuukX6s4LuybzpMX9OTBs7rwztX9GdgmHiGg\nr6klo9a5LMnnlgKtZU+EEDx7UU9uOq2t8YY2G1clTObimkepcQRmMAPgVTUJt8mnsXO+9Kuk9ZfH\nfa4MTe7bMFVGewHcuUzWgVo7Bbb9Ch+dC0vfDxy/dbb8mbdeJuvFZsqkwpWToSQbht4ZOL4sT2Zx\nb/jROLf8E8hXTV+r/wt71Qz09d/LirRTbjmy1WdXTg6sl9XUvDoQ3gsKUNi5MDST3uKkplmFghBi\nrBBigxBisxDigTDX7xVCrFD/rRZC1Ash4sM965jhYDUFu6kMgj3UhVNX7+etX7Yw8ImZrNhVxB8n\nr+CSt+YTr0biPDF1Hac+M4vsokqW7ihkdJeGm6InR3sCKnZGqYlez1/SK6AlZfe0GJY9cgb9TEJB\ny+CNCyrbcGa3lJCyzo9NPJVzeqXTIz2e0oyRvOO43LgYofZDdoUpQtf7MnisGLqbzGzxJoGT1g/O\ne0M6/7ueK538394Z+hyA5R/JiK89a+Rxv2tliY8f75cOZi3fQ2PXAnjrVJh0qTQ/TboMvrkNJk2U\n2saX18H7Z8mxO1Wz1eqv4McHIGtJ+DmEY8vPsOid0PPZS2HOs+HvqamAb+6Qms77jeuydkhoodS1\nRuMiZv4dvv9z872nxXFHszmahRB24DXgDCALWCyE+FZRFN0rqijKs8Cz6vhzgD8pitIEHWmakYPV\nFOyBi2x5dR0Pf72KcT1kZ7CUGC8vz9wEwHtzt+njtFpBGsOfmUWdX+HMrkabSY/TRlWtkczVItpN\nVY1xHO1p+NcbvPg/PK4LbRIjOa1DqCM5mHZJUbx8WR8AXNdP4UaAbZfD758ZUVeaphCTKf0QDrex\nUKf3Nx5213KY8bj0yfQ2CZfMofLnPuM70YnJkD4EgDbDpQO/33Xw++dSc4hK1s1cOgUmZ/gP90vN\nBKQvI3upfF2jLpo750sB5Y2Tocyrv5Imscbwn/Plz4E3Bp5/R/3sA24I9DOBLD+y/D/ydWlO497n\ncCjbYyRXFu+S30FNeWDWPkjN6pen4cJ3A/1nIEvAl++FUy2BcqLRnNFHA4HNiqJsBRBCTAbOBdY2\nMP4yYFIzzqdpOGhNITCAf8qKbKasyGHKCvnHb+749e1KY0FYlV3MwDbxfHbTYGZvzOPVnzczsE08\n5/dN476vfgfguztO4W/fruGJ83uQta+CFj4PeaaWkcHNZfZHXKSL20e2b/T4ENqcKv9paJ+71RC4\n4O3AsW4fnPkPNSEQGB2U9wEye9uXGrhIDrpV5n1Ul8IC1cew7RdploqIh1vnw6wnZD0od5CmYnZO\nr/ocotPlc6qLYcUn8nxCe3kud5X0jYz6K/znAvkeQSGyYak1dWZrKOrpi2ulqevsl2Rk1dbZ8M3t\n+39uU1BtJBtSmiuFgt8PJTmAIvt7pAX5iD6+UC78ub/LEGMz394hf1pC4YSjOc1HaYA57CNLPReC\nECICGAt81cD1m4QQS4QQS/Ly8sINOXJomoLtAPJULWOxx26Ye+6evJyHv14dMKym3s/YbimcorZn\nTI526+Wck3yymfzITi346tah3D+2c0AJhw7JPj69cTBtEiM5Vd3hR7oDzUcH4pMbBvH1bUMPOO6g\nqZF+kJDdp8bQO6HNaft/xjkvyXH9ZYgs7UfDyAdDQ4szB8ufNptcyFsNCfRpQGil2tF/gz+o/oWV\n6l6kqhieTJf+Du2ZmYNlCZPHY6V/IRyawHnL9HnKTP4fc/TT1tmw7CP4e5x0ZJuLE2r4g/wtigIF\nW+TC7Q9f5oNPJ0oB1hBmX0Wp6vQv3wt+NUN8b9Beze+X1wH2rlM/Ux48FiM1ssZSVXLoDvvyA1QX\nbgoqG9HYx18v/U2NLZl/qDyZAd/e1bzv0QiOFUfzOcC8hkxHiqK8rShKf0VR+iclHdi80axoQmE/\nTmO/X+HR3GF83/lpRv+crp/XtAONUztIQdAxOUq326fGehnUVtrlHYfQxNzjMIRCRCMqfQ5rnxi2\nuulhE6vWdkrrd+jP6Him1CjGPgWXfATtR8nzGYMDx2UODr03WCgEO3AzB0NyV1ky3NcSup5nlCgH\nWVkWoJVJYP7ytDSp+P1ygSzNhbXfymio5R9D/gZjbKkqFOprYfG/w3++gs1SGwqmKKi0yfa58Epf\neG0gLPswdHx5Pmz8AbbMNBb8YPLMc1PHFJs+r7bwa5hLuWjXtOq8Pz5oXGtISIEUZk9lwBfXNDym\nIbbMgmfbwmY1+bBynzRzNZb6WiNwoCE2/ABPt5ZVkPfHby/LKDZzKZumpr5Olq4P9/s9wjSnUMgG\nTFXfSFfPhWMix4HpSFEUNu1Td3G9L9PPgWxAv7e0is+X7OKKfy/ko4VZ3L4ig7L6wN36uB4p+uv7\nxnQmLdbLkHaJephoTZ2f20dIM07XloE9izV+vW8kM03tLc3YwnQQOyp0Ogtumg29rzj8Zzlc0vGs\nmW98yXDLPHg4F66fDp3COGedQRrKnqCdcKyaGX3ZZPkMc7b7mH8adaUyhxrVamvKpbN61j9kzsTz\nnWCdWu12znOAkDkaIPMsQEY1aZV0T1OzvgffJn/uXQs1qlknOl0KPoBdiwPnunW2LLXujDQc6yAX\n3Q0/BIbgbppmvN61SAqrzTNlYyZhl3MsUf8M1TySkOeC3OFr7F0jd/vrv5fHFaaw6OriwPtKcmTE\n2IYfDW1J89+AzBtpjON+t2zjqkedvT1SL/NuzGt9qDAD2LcD3hkpF3JN21DUumV1hnmVrb/In5pP\nqWin8d2X5srvDwx/lLlk/eGwfV5ork1ZA8LczKJ3IGtp08xhPzSnT2Ex0EEI0QYpDCYClwcPEkLE\nAMOBK5txLk3Cxwt38tcpqxnV6nMeGzSU5yYvZ3t+Of+9bRiXvDU/oMfsuB4pTF2Vi2KSu8M7JvH6\nFf24+r1FzNmYR/e0aOY9IB2Q29W+xe2SouiaGs2ih0cRH9SeUiMjvpF+jaNNap/me3aKmnsQbOvW\nMBcZdHgCF6/h9xuvNY1Gi5oCaDcq8DnXz5BRTVpnvPmvG9dXfSF/7tsGLbpBSk95rC2I2h97m+Gy\nsm3/6yAiERa9Lftzb/9V1rG6+EPpg3BHy0ipXpca77FroSqYlECNZ8c8GT0FkKj22jALv08vCTSP\ntOgqd9Bahr2mKbQdARu+lxn5mp9Ha7jkipIL7y9PG34cM9/9EYb90dAIJ02UzwEY+7QxrqpEFnP8\n4hp5/fZFsj9IQ5Sppivt82gBB7WVUltXFLnog4xoM/NST+N1dQlEJsDWWTLybPj9MPIheU1RtRyh\n/l958xRpQnxot4xEK9wKjxaG16wOldoq+GAcZAyC600C3Pzs+trQ2mjVpfDDfdKHk34Y2ncjaDZN\nQVGUOuAO4CdgHfC5oihrhBC3CCFuMQ09H5imKEp5uOccK9TU+XlxutwpzNxRx8R/L+abFTmszCqm\n3UNTQ5qOP39xaE3/GK/8Rb99VT8WPzw6oI1j68RI3r92AE+cLxe7Fj6P3j/Y4jDRIm2i0+CvBTDi\nwdAxZqEQ1SLwmtMDrU1O9LpKwpI5yHhOwWb44QF1lyngqinqHFKl5hObKc09IIWEK0KWSEnuFmjq\nAXmc0kOG75qFgnk33/VcaNFZ7ur160GLZWpf9RnqAlucLRd9LRP/4wsNIaI9O2OQ7CyY3cDufu03\nMM/UE7zEZCLdbMpa13wWmsN7namfSDi0z1mSLSOdNDSBpgmeA6FpYtr4EpOxQhcKQi782vf19U3G\n+xduM0yBxQ0ZOg4C7f1zA32LAUIhnJksa4mcb7DptBlo1lVHUZSpiqJ0VBSlnaIoT6jn3lQU5U3T\nmA8URZnYnPPYH/M257M+1/jjqqnzc+37i/jPgh1SC1iWhd+vMHXVbgrKa7jnDNntK7uoUq/cGcxF\n/dJlKekgzP0CtOYxZkZ2boHP0/iIIYsDcMtcaDvS2JH2vVrmioSLIoptZbwO1yCpRdcDv1/LXnJh\nd/lkP+6Fb0jzTWRSoOYCRpIfyGQ+8/ngxbymTEZdxbWRO2YtG9zc16P1MGjRRS42dTVyR6oE2fu7\nToB49RmKIs1HMenQ/QLZObA8zzClaJpCploIcn/2efN8zX1ENs8wfG/aoqftyoPNJyAbVW2eIV9r\ngquuyoh0AmOx1kw7IAXZ/NdlL/KaoL1ldan8qZmstAAIQC+AWVshKyhrwSNauDNIYaaZAquLQ383\nB4v2PQQHYJiFgqYlmdk2BxCND40+DE6egnhAVW09z/60gfE9W9I6IZINuaVc8e+F2AQ8NqEbAAu2\nFjB7Qx6zNxhRTpMX72JtTgltEiO5Y2R7pq7azfrcUsb1aMmlAzKo8yskRLr43++76dcqTu8I9tsD\np1NeXQdq0Eqk+8h83YlRbl0AndSk9ICrp8gQU18qnHJPw2NTTZpd8AIOMlzV5gB/Xeg1Da1xkica\naqf5szgAAByuSURBVNTFSPEH1IvS0XIVOp4VWP/KXGodZORLbYXc0Xc5G+a+IP0Ufa4MXDzS+kuz\nw/KPpTDqcbE832mcrNxrd8k8kX3bpZAp3S0Xomg1IFBbzLVdsSYU2p0OS94LzZ9I7g571N2ueb7l\nefIzbfxBHp/3uswO1xa9cvXvKjgaTFFg/qvy32PFUuOIyYTioF1zzgroPD5QY1r/Pfykan9tRwSO\n14SCpmGY79OS+CqLZMJit/Pl4muOHNs+V/pQEjtKn0JxttH98FDQNAVXkAnY/Lt8f6z8/3HavTDk\ndvk7WfC69NMdzns3kpNKKLwzZyvvzt3Gu3O3kRzt1ktE+BV49BtD7b6oXzo7CyvIL6tmaLsEflqz\nh7LqOh44qzM2m9C1gIx4b0C2760jAktzp8YGJrodqWoJix8edeBBJxMpPeCsp/Y/5kBJiQ4XJHU2\nFkKAyBZw62/S6Qxy1w1q3SeTqcFsmtLQhEJwIluwUNB2vu4o+Tk6jZetYB8zLQ7nvyWvdzhDtmnN\nWmIkCva6TGoIGtrOf8MPcqFuqdrfo9QAiLJceKm3YcP3pcCAPxglSDQG32rkV1SqGkttpXxmp3HG\nuFbDZCJhSbbUYDTtpkitYGt3qQLIpL1VFEqh2v70UKHw2ysw9A45P2GTQnfDD8b1EnVXnzkUdv5m\nCAVNCOVvks5nb6x0SIP8viv3SY3OGx8oFBap/VSSu0uhUFlo3HMoC7RZY6qtMpICK4M0p8p9svjj\nkNvl/7m6Kvn6CHBSCYVF2wtxO2xU1/nZU1LNJf3Tmbe5gOwiuWNIjnYz457h+DxOFEXRbf6Pnt2N\nwvIakqOlKlxTJ9VyrW9wY1GOkFQQB0qysgjPbQvkH19DnPe6DF/8UXVUn/4wmEuJa7tuT1DU2P40\nhXBCobpEagg2u2ET18wNvmTpFNaIyYReJutrbIZceLRFMFggpfSQTum5/5I74Lg26vMj5OK9ZVZg\nFrknOrBvOMiIrU5nybmvmWKYfP7VTWpSkabvxJcihWVxVmDU0s7fpPA57S/w/T1wtcnH8Iw6p9S+\n0meh0fVceVy4Tf5rO1L6Zcz+hQJZHYAz/g7vjpZCQVFk2G770TLi6LMrpWa0Y64cW1EghZA3Tgp/\njd5XGImNrYbKzPPqUhkN9tG5cO330PoUDkjlPikwo1MNf0HhVnh9MPxxhTGHiIRQDcrvNwSJFjHX\nzJxUnky/otA9LYa/n9uNN6/sxzMX9eK1K4wszifO66Hb9M0Lq8thIyXGo5/ThEJabONKXnw+7Hv6\nV71h9Q4+1mnRZf8RUy17Gc2WINT3oGVRByc2htMU9M58QQJE231WFMjy4ppj1qXmXUSlBI43N3gC\nuQCXZJuEQpBAEgJGP2aEo5prTyn1MhpKH2uTZqv4Nsa5u1dLgQDSjBObIXe5u1ca7ymEnK9N9d/E\nZshduWY60kq/lObAdDWbfb1J0GkkdTIiwa6aAsPUFreFW6XgSlFzTIpNyYGaAzdO9RFVl6pCtlaa\nlk5/RAqklZ8a92gag1lA9/+DTJ7U0AINqkoMzWTOs6G+kfIC6e/I2yjNlgCvD4UXusjXeSbfzL5t\nRqJiRUGgX0ujeKf8fQqb/KxHgJNqlVIUqaRePaQ1Y7vLP67UGKOmS3xUeMdxMON7yl+O1oPgQJwz\nfAgThvXm5uFtDzzY4tjGvHBoC3ib0wILAGp/6JqPIbFjw88TQX+C2jN//gd8cpHcnYIhcHxBQiEm\nPfA4Ol2aP1aoaT/hBFLHscZrs1CoKQsc5/bJRT3OJBRiMwLHaPM1Z3OnD4R71sJ9qsaR1Enu4LXF\n19xsql7NG9g6K3SekUmyI+Gf1kK7kcb3uf57WRk3fUDg3EAuxA6PjOhCSKGgdTSMSIRT7jb8LRp7\n1MXbLOQ7jJFhoekDpXalfY9562QQAUiN4aXegXbhd0bCu2fAawNkiKvfb/hjqstC8ypmPyUr9VYU\nBGoCWvmQHfOlphCV0nAL3ybm5BMKQZaVxCgjCqihvIBg7jq9A8v/egYJUQ1nNZvxuuw8ek5XK7Lo\nRCCcULjmO3jQFD2ilQUf8wTcu8VIVjPTkIlPS5rTQjhnPyl/6uajIKEQ3LFPC6fVwkHDRVKZHelm\nLWDkI0FziTfmFJsJY54MfVbw8896RjrOPdGGFtSiq1zE1/9PfZ7pO6xXS2CESwyLTJRzjUkzju1u\nWK322cgYHCjUQGaVRyTI+9w+KRQ0DUbTqjShkDEoMDzZPC/t9R9+gpvmGBnyc/8V+H7VxYHO6+Bs\ndC3sGOTvJFjwznkGXu0HFfsCNYEeF0shOPcFacIKFv7NyMklFFAQBP4xmrN+G6sp2GwipMqoxUmC\nWSMwL0jmRV6LUPLGy4UonACwqRsEW1DosiZoghOltPfVsqtBJr11C6p31HaE8druCrSRm5n4KfS6\nPLAcyPB7ZeTPuOfkcZSpTPvdq2BIGOEWXPQvOkx5My2c9/fP5DMvek9GKNnCbJLuMZlXzL4JkN9j\ntFoWJGOQ9Odou2tPjKF1aSYzVxT8Phm+U81O2m6/9anyuzvrGRhhqujvjTO0GG1XbrPJf05PSMVj\nHU2Az30x8LzLJ7U9jS+ulT/HPReYIAlSuJhNfZ4Y+bvUhGWHoD4YzchJJRT8CtDABg3Ad4RCRi2O\nY4SQoYJXfGXs6oPR8gOCww7NDLlN5k0MCCqxrQkFLTZeQ1u8o1Nl9vOoR+GKL0Krwca3MQoINlSM\nEKQ/4PwGCvxp7xXsrwiHttPXCNZkQAqFzmfL13a3LJ1++WRjgTfjjYUbfpbhw+HmP/g2+azz3gh8\nv7oaQ4hpi7/bJ528WkKf9nlcEfK7M4cha+99/lsw8GYjs9uM1k0wuFfHDw/AVzeEdhM843HjtVmg\ndJkAV/039PlmoeCONoSisEuH/BHipBIKKLItZUNYUTsWjeL0R6DD6Iava3Zud3TDYzwxMOGVUEdz\nUhcpLEBGy2iYNZRu5+2/ZLW2mIZrdNQYtPDclJ77HwfQ81LocYlxHE4o2B0w8ROY8Cpc9K5xXhOA\nZse80yvLOIQrpw4w6Cb5LK1WlS4UKg0howmF9kG/o4gGhFyGWi7DGyeF6rhnQjU4MH5XcW3ghplw\n0fvydUmWLHdSsElGSGmYs+BvMJmRNBNfpPpz4iS5OTDX8HJFGp/D7jxw2fYm5KTaGkvzUagcnPWX\nEewp2U8oooXFwTDhFeh+oWwcdLDYHfL+TuNl2YqX1B3r/nb9wWjC4CB6ggfQ+Ry5Y+5+4YHHOtxw\nzouyR0VEYnjzkUbfqwKPc2VfEHpcLMuXu3yh9xwIsxByqMJMM1eNfkzWkdKytBvS3C6bDDt+Cx86\nbEbLhk5oJ7Wd9P7Sh2Cunpo51Aij1X7/USmBwQbaAn/jTJk30X4UdDbldmhjtPkcqQQnlZNKU2io\nT0qbxEgGtw0TpWFhcSh4ogMTxg6FTmNlLH3X8+TxQQkFbewh7i5tNpn70NhoF1ek3An/ccXB7Wg7\nqqGtml/EXCKjsZhDdLXQVK2UusMli/UdiIh4mS1+ILTihu1Nzv1hdweGrrZQQ09bnSK/i9sXwS2/\nGklqAZFcmUY5+LDzOjprUqOEghDiv0KI8UIEx88dXygcUS3MwuLwueAd+POG8OaMhtifL6O5SO8f\n2sPiQFz0Hvxls9SIoHELeDBmv0e/a+XPVFMHuaZcWDuNlz6RpKBdf5+rDVNYiy7yM12pRkgldTLM\nRfdtkwJif6T1N/wPR0koNNZ89DpwHfCyEOIL4H1FUTYc4J5jDr+iYLOkgsXxhMMV3k6/P/6/vfsP\nsqus7zj+/rBA+Dn8kChOwo+gqTZWQFhSi9iCDDWAbciUDgFFrGCKYyjWdkoYFGz5izpDbcdoTCkW\nCyVUIZKhkRgohTLWkgUCkkAkRpCkaBYKKIyAYb/94zz3cnLZe87ZZc/+uOfzmrlzz3nuufc+z87s\nfvd5nvN8n9HOJYy33fd6PYB9frD7nVJFdunLbt086uxsC9XjL9q5h7NnyZDQSCy8YfjcV7vsAp97\nNHutKPVF2fAUZHt7dF4/zn+zKgWFiLgDuCPtfXB2On4K+Efg+oioeZ+6sTHOQ3NmE2MkQ02TxWgC\nQsuf5/JRdQ55jeV/21L3IbWx+pnn15C0AlrBLo91qDwcJOktwCeAC4AHgb8HjgHWFrxtUsmGj9xT\nsB43FYNCXVr/bU+rP7vomNtjP/idxXDereXXjqFKPQVJK4F3Af8C/EFEtG6ivklShb31JomI0U69\nmU0dU2X4aDz07QanX73z7aFThZStih9nVecU/iEihklOAhHRP4b1qZUnmq0Rdpsi27WOl+POn+ga\nTClVh4/mSGov35R0gKRh1rxPbp5otkYYyZ1KZh2qBoVPRUR777+IeA74VMH1k1IrS6pZT2vdApnf\n5tOsoqrDR32SFGmXGEl9wJTLCNdt8ZpZT9nzgOwWz3FKtWy9pWpP4XaySeWTJZ0M3JjKCkmaJ2mT\npM2SlnS55kRJ6yVtkHR39aqPXHZHqqOCNcCuu/s/IBuVqj2FS4A/BT6dztcC1xS9IfUmlgKnAFuB\ndZJWRcTG3DX7ky2MmxcRP5X01hHWf0QiojAhnplZ01VdvDYEfC09qpoLbI6ILQCSVgDzgY25a84B\nbomIn6bv2T6Czx8xDx+ZmRWrmvtotqRvS9ooaUvrUfK2GUBu81S2prK83wAOkPSfku6X9PEu379I\n0oCkgcHBwSpVHtZwm+yYmdnrqs4pfIOsl7ADOAn4JnB94Tuq2RU4Fjgd+DDwBUlv2NA2IpZHRH9E\n9E+fPr3z5crcUzAzK1Y1KOwZEXcCiognI+KLZH/Ii2wD8rt8z0xleVuBNRHxUkQ8A9wDDLPl0djw\n4jUzs2JVg8IrKW3245IWS1oAlK2lXwfMljRL0u7AQmBVxzW3AidI2lXSXsBvA4+OoP4jMhTh3Edm\nZgWq3n10MbAX8GfAlWRDSOcVvSEidkhaDKwB+oBrI2KDpAvT68si4lFJtwMPA0PANRHxSPdPfZO8\neM3MrFBpUEi3lp4VEX8JvEi2r0IlEbEaWN1Rtqzj/EvAl6p+5pvhLKlmZsVKh48i4jXghHGoS+3C\nWVLNzApVHT56UNIq4FvAS63CiLilllrVZCjw4jUzswJVg8IewLPAh3JlAUypoBB4otnMrEjVFc2V\n5xEmM2dJNTMrVnXntW/QyieXExGfHPMa1SgCRwUzswJVh49uyx3vASwA/nfsq1M/p7kwM+uu6vDR\nzflzSTcC99ZSoxoNOUuqmVmhqiuaO80Gak1zXQfnPjIzK1Z1TuGX7Dyn8DOyPRamFGdJNTMrVnX4\naN+6KzIe3FMwMytWdT+FBZL2y53vL+mM+qpVj6FwmgszsyJV5xSuiIgXWicR8TxwRT1VqlO4p2Bm\nVqBqUBjuuqq3s04aXrxmZlasalAYkHS1pHekx9XA/XVWrA7eZMfMrFjVoHAR8CpwE7ACeBn4TF2V\nqktEsIujgplZV1XvPnoJWFJzXWo35OEjM7NCVe8+Witp/9z5AZLW1FeteoS34zQzK1R1+OigdMcR\nABHxHFNxRfNEV8DMbJKrGhSGJB3aOpF0OFPxb6wXr5mZFap6W+llwL2S7iYblv8gsKi2WtVkyBPN\nZmaFKvUUIuJ2oB/YBNwI/AXwq7L3SZonaZOkzZLeMFEt6URJL0hanx6Xj7D+I+LtFMzMilVNiHcB\ncDEwE1gPvB/4b3benrPzPX3AUuAUYCuwTtKqiNjYcel/RcRHRlH3EXPuIzOzYlXnFC4GjgOejIiT\ngPcBzxe/hbnA5ojYEhGvkq1vmD/qmo4B79FsZlasalB4OSJeBpA0LSIeA95V8p4ZwFO5862prNPx\nkh6W9F1J7xnugyQtkjQgaWBwcLBild/IPQUzs2JVJ5q3pnUK3wHWSnoOeHIMvv8B4NCIeFHSaenz\nZ3deFBHLgeUA/f39o77rKct95KhgZtZN1RXNC9LhFyXdBewH3F7ytm3AIbnzmaks/7m/yB2vlvRV\nSQdFxDNV6jVS4SypZmaFRpzpNCLurnjpOmC2pFlkwWAhcE7+AkkHAz+PiJA0l2w469mR1qkqZ0k1\nMytWW/rriNghaTGwBugDro2IDZIuTK8vA84EPi1pB9ktrgsjorZFcc6SamZWrNY9ESJiNbC6o2xZ\n7vgrwFfqrEOeF6+ZmRWrevdRT/DwkZlZsUYFBcDjR2ZmBRoTFFpTFQ4JZmbdNSgoZM+eUzAz664x\nQWGo1VNwTDAz66oxQaF1n6tjgplZd80JCikquKdgZtZdc4ICreEjRwUzs26aExTcUzAzK9W8oOBZ\nBTOzrpoTFPDdR2ZmZZoTFNo9BTMz66Y5QSE9e/GamVl3jQkKXrxmZlauMUGhvl0azMx6R2OCAu1b\nUt1VMDPrpjFBoX330QTXw8xsMmtMUBhqZ0md2HqYmU1mjQkK7f0UPHxkZtZVc4JCenZMMDPrrtag\nIGmepE2SNktaUnDdcZJ2SDqzrrp48ZqZWbnagoKkPmApcCowBzhb0pwu110FfK+uuoCzpJqZVVFn\nT2EusDkitkTEq8AKYP4w110E3Axsr7EuzpJqZlZBnUFhBvBU7nxrKmuTNANYAHyt6IMkLZI0IGlg\ncHBwVJVxllQzs3ITPdH8ZeCSiBgquigilkdEf0T0T58+fVRf5CypZmbldq3xs7cBh+TOZ6ayvH5g\nRRrnPwg4TdKOiPjOWFfGE81mZuXqDArrgNmSZpEFg4XAOfkLImJW61jSPwO31REQ4PWEeM6SambW\nXW1BISJ2SFoMrAH6gGsjYoOkC9Pry+r67uHrkw4cE8zMuqqzp0BErAZWd5QNGwwi4hN11qXFMcHM\nrLuJnmgeN+EsqWZmpZoTFGjNKUxwRczMJrHGBIUhL14zMyvVmKDQzpLqWQUzs66aExTSs3sKZmbd\nNScoeI9mM7NSDQoKXrxmZlamOUEhPTsmmJl115yg4CypZmalmhMUnCXVzKxUc4JC6il48ZqZWXeN\nCQpDzohnZlaqMUHB23GamZVrTFBocUwwM+uuMUHBWVLNzMo1Jyg4S6qZWanGBAVnSTUzK9eYoOAs\nqWZm5ZoTFFoHjglmZl01Jyi0F685KpiZdVNrUJA0T9ImSZslLRnm9fmSHpa0XtKApBPqqsvrw0dm\nZtbNrnV9sKQ+YClwCrAVWCdpVURszF12J7AqIkLSkcC/Ae+uoz7OkmpmVq7OnsJcYHNEbImIV4EV\nwPz8BRHxYkQ7/8Te5Ib+x5qzpJqZlaszKMwAnsqdb01lO5G0QNJjwL8DnxzugyQtSsNLA4ODg6Oq\nTHv4yDHBzKyrCZ9ojoiVEfFu4Azgyi7XLI+I/ojonz59+ui+Jz07KJiZdVdnUNgGHJI7n5nKhhUR\n9wBHSDqojsoMeZ2CmVmpOoPCOmC2pFmSdgcWAqvyF0h6p1IyIknHANOAZ2upjVc0m5mVqu3uo4jY\nIWkxsAboA66NiA2SLkyvLwP+CPi4pF8DvwLOyk08j2190rNjgplZd7UFBYCIWA2s7ihblju+Criq\nzjq8/l3Z8y7OiGdm1tWETzSPlyEvXjMzK9WYoOC7j8zMyjUnKHiPZjOzUs0JCunZPQUzs+4aExRw\nllQzs1KNCQqeaDYzK9eYoBBevGZmVqo5QSE9O82FmVl3zQkKzpJqZlaqMUFhyMNHZmalGhMUWgNI\nHj4yM+uuMUHBE81mZuWaExTSs4OCmVl3zQkKXrxmZlaqMUHh4P2mcdp7D2afabVmCzczm9Ia8xfy\n2MMO5NjDDpzoapiZTWqN6SmYmVk5BwUzM2tzUDAzszYHBTMza6s1KEiaJ2mTpM2Slgzz+kclPSzp\nh5K+L+moOutjZmbFagsKkvqApcCpwBzgbElzOi77CfB7EfFe4EpgeV31MTOzcnX2FOYCmyNiS0S8\nCqwA5ucviIjvR8Rz6fQHwMwa62NmZiXqDAozgKdy51tTWTfnA98d7gVJiyQNSBoYHBwcwyqamVne\npFi8JukksqBwwnCvR8Ry0tCSpEFJT47yqw4Cnhnle6cqt7kZ3OZmeDNtPqzKRXUGhW3AIbnzmals\nJ5KOBK4BTo2IZ8s+NCKmj7ZCkgYion+075+K3OZmcJubYTzaXOfw0TpgtqRZknYHFgKr8hdIOhS4\nBTg3In5UY13MzKyC2noKEbFD0mJgDdAHXBsRGyRdmF5fBlwOvAX4qrLspTuaFvnNzCaTWucUImI1\nsLqjbFnu+ALggjrr0KGJt7y6zc3gNjdD7W1Wa0N7MzMzp7kwM7M2BwUzM2trTFAoy8M0VUm6VtJ2\nSY/kyg6UtFbS4+n5gNxrl6afwSZJH56YWr85kg6RdJekjZI2SLo4lfdsuyXtIek+SQ+lNv91Ku/Z\nNkOWLkfSg5JuS+c93V4ASU+kfHDrJQ2ksvFrd0T0/IPs7qcfA0cAuwMPAXMmul5j1LbfBY4BHsmV\n/S2wJB0vAa5Kx3NS26cBs9LPpG+i2zCKNr8dOCYd7wv8KLWtZ9sNCNgnHe8G/A/w/l5uc2rH54B/\nBW5L5z3d3tSWJ4CDOsrGrd1N6SmU5mGaqiLiHuD/OornA9el4+uAM3LlKyLilYj4CbCZ7GczpUTE\n0xHxQDr+JfAoWQqVnm13ZF5Mp7ulR9DDbZY0EzidbHFrS8+2t8S4tbspQWGkeZimurdFxNPp+GfA\n29Jxz/0cJB0OvI/sP+eebncaSlkPbAfWRkSvt/nLwF8BQ7myXm5vSwB3SLpf0qJUNm7tnhS5j6w+\nERGSevK+Y0n7ADcDn42IX6QFkEBvtjsiXgOOlrQ/sFLSb3W83jNtlvQRYHtE3C/pxOGu6aX2djgh\nIrZJeiuwVtJj+RfrbndTegqV8jD1kJ9LejtAet6eynvm5yBpN7KAcENE3JKKe77dABHxPHAXMI/e\nbfMHgD+U9ATZcO+HJF1P77a3LSK2peftwEqy4aBxa3dTgkJpHqYeswo4Lx2fB9yaK18oaZqkWcBs\n4L4JqN+boqxL8E/AoxFxde6lnm23pOmph4CkPYFTgMfo0TZHxKURMTMiDif7ff2PiPgYPdreFkl7\nS9q3dQz8PvAI49nuiZ5pH8cZ/dPI7lL5MXDZRNdnDNt1I/A08Guy8cTzyfJJ3Qk8DtwBHJi7/rL0\nM9hElpl2wtswijafQDbu+jCwPj1O6+V2A0cCD6Y2PwJcnsp7ts25dpzI63cf9XR7ye6QfCg9NrT+\nVo1nu53mwszM2poyfGRmZhU4KJiZWZuDgpmZtTkomJlZm4OCmZm1OSiYjSNJJ7YyfppNRg4KZmbW\n5qBgNgxJH0v7F6yX9PWUjO5FSX+X9jO4U9L0dO3Rkn4g6WFJK1u57iW9U9IdaQ+EByS9I338PpK+\nLekxSTcon7TJbII5KJh1kPSbwFnAByLiaOA14KPA3sBARLwHuBu4Ir3lm8AlEXEk8MNc+Q3A0og4\nCjiebOU5ZFldP0uWC/8Isjw/ZpOCs6SavdHJwLHAuvRP/J5kCciGgJvSNdcDt0jaD9g/Iu5O5dcB\n30r5a2ZExEqAiHgZIH3efRGxNZ2vBw4H7q2/WWblHBTM3kjAdRFx6U6F0hc6rhttjphXcsev4d9D\nm0Q8fGT2RncCZ6Z89q39cQ8j+305M11zDnBvRLwAPCfpg6n8XODuyHaE2yrpjPQZ0yTtNa6tMBsF\n/4di1iEiNkr6PPA9SbuQZaD9DPASMDe9tp1s3gGyVMbL0h/9LcCfpPJzga9L+pv0GX88js0wGxVn\nSTWrSNKLEbHPRNfDrE4ePjIzszb3FMzMrM09BTMza3NQMDOzNgcFMzNrc1AwM7M2BwUzM2v7f4kr\nVLUPmGnaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1862742b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(business_model.history['acc'])\n",
    "plt.plot(business_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 2s 792us/step - loss: 1.7219 - acc: 0.4421 - val_loss: 1.5104 - val_acc: 0.4532\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.5249 - acc: 0.4540 - val_loss: 1.3789 - val_acc: 0.4653\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.3835 - acc: 0.4871 - val_loss: 1.3666 - val_acc: 0.4653\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.3781 - acc: 0.4762 - val_loss: 1.3491 - val_acc: 0.4653\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.3643 - acc: 0.4833 - val_loss: 1.3416 - val_acc: 0.4653\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.3404 - acc: 0.4815 - val_loss: 1.3416 - val_acc: 0.4653\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.3350 - acc: 0.4822 - val_loss: 1.3372 - val_acc: 0.4653\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.3245 - acc: 0.4833 - val_loss: 1.3480 - val_acc: 0.4653\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.3561 - acc: 0.4720 - val_loss: 1.4028 - val_acc: 0.4653\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.3459 - acc: 0.4808 - val_loss: 1.3358 - val_acc: 0.4683\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.3045 - acc: 0.4801 - val_loss: 1.3197 - val_acc: 0.4683\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.3221 - acc: 0.4822 - val_loss: 1.3303 - val_acc: 0.4653\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.3331 - acc: 0.4752 - val_loss: 1.3643 - val_acc: 0.4622\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.3037 - acc: 0.4857 - val_loss: 1.3251 - val_acc: 0.4653\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.2888 - acc: 0.4847 - val_loss: 1.3224 - val_acc: 0.4653\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.3124 - acc: 0.4886 - val_loss: 1.3207 - val_acc: 0.4622\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2962 - acc: 0.4829 - val_loss: 1.3266 - val_acc: 0.4653\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2735 - acc: 0.4868 - val_loss: 1.3209 - val_acc: 0.4653\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2628 - acc: 0.4790 - val_loss: 1.4190 - val_acc: 0.4592\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.3060 - acc: 0.4769 - val_loss: 1.3503 - val_acc: 0.4622\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.2668 - acc: 0.4914 - val_loss: 1.3226 - val_acc: 0.4653\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.2562 - acc: 0.4921 - val_loss: 1.4063 - val_acc: 0.4592\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2834 - acc: 0.4889 - val_loss: 1.2984 - val_acc: 0.4562\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2733 - acc: 0.4896 - val_loss: 1.3205 - val_acc: 0.4562\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2924 - acc: 0.4959 - val_loss: 1.3172 - val_acc: 0.4532\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.2418 - acc: 0.4935 - val_loss: 1.3077 - val_acc: 0.4502\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.2288 - acc: 0.4907 - val_loss: 1.3468 - val_acc: 0.4743\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.2471 - acc: 0.4907 - val_loss: 1.3857 - val_acc: 0.4502\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2429 - acc: 0.4952 - val_loss: 1.2904 - val_acc: 0.4773\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.2117 - acc: 0.5037 - val_loss: 1.3377 - val_acc: 0.4834\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2131 - acc: 0.5012 - val_loss: 1.3740 - val_acc: 0.4230\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 1.2508 - acc: 0.5002 - val_loss: 1.3812 - val_acc: 0.4350\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.2845 - acc: 0.4974 - val_loss: 1.2842 - val_acc: 0.4713\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.2378 - acc: 0.4917 - val_loss: 1.2790 - val_acc: 0.4743\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.2061 - acc: 0.5114 - val_loss: 1.2875 - val_acc: 0.4713\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.1927 - acc: 0.5160 - val_loss: 1.3464 - val_acc: 0.4411\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 1.2315 - acc: 0.5012 - val_loss: 1.3736 - val_acc: 0.4562\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.2191 - acc: 0.5023 - val_loss: 1.3295 - val_acc: 0.4713\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.1917 - acc: 0.5093 - val_loss: 1.3564 - val_acc: 0.4743\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1919 - acc: 0.5129 - val_loss: 1.3565 - val_acc: 0.4713\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.2112 - acc: 0.5097 - val_loss: 1.2792 - val_acc: 0.4864\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 1.1883 - acc: 0.5157 - val_loss: 1.2865 - val_acc: 0.4683\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.2991 - acc: 0.4959 - val_loss: 1.2772 - val_acc: 0.4622\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1804 - acc: 0.5111 - val_loss: 1.3111 - val_acc: 0.4622\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1698 - acc: 0.5160 - val_loss: 1.3009 - val_acc: 0.4713\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.1674 - acc: 0.5252 - val_loss: 1.3151 - val_acc: 0.4592\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1609 - acc: 0.5248 - val_loss: 1.3240 - val_acc: 0.4381\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.1888 - acc: 0.5188 - val_loss: 1.3531 - val_acc: 0.4109\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2013 - acc: 0.5174 - val_loss: 1.2528 - val_acc: 0.4924\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1818 - acc: 0.5234 - val_loss: 1.2410 - val_acc: 0.5196\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2067 - acc: 0.5065 - val_loss: 1.2721 - val_acc: 0.4773\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.1413 - acc: 0.5266 - val_loss: 1.3143 - val_acc: 0.4502\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1678 - acc: 0.5291 - val_loss: 1.3548 - val_acc: 0.4320\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1626 - acc: 0.5217 - val_loss: 1.3104 - val_acc: 0.4653\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1410 - acc: 0.5280 - val_loss: 1.4056 - val_acc: 0.4532\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.2126 - acc: 0.5146 - val_loss: 1.3810 - val_acc: 0.4441\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1876 - acc: 0.5347 - val_loss: 1.2469 - val_acc: 0.4955\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.1506 - acc: 0.5277 - val_loss: 1.2362 - val_acc: 0.5227\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1595 - acc: 0.5315 - val_loss: 1.2852 - val_acc: 0.4411\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1357 - acc: 0.5305 - val_loss: 1.3376 - val_acc: 0.4290\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1398 - acc: 0.5428 - val_loss: 1.3216 - val_acc: 0.4532\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1385 - acc: 0.5375 - val_loss: 1.4189 - val_acc: 0.4230\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1598 - acc: 0.5301 - val_loss: 1.3308 - val_acc: 0.4743\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1149 - acc: 0.5534 - val_loss: 1.3027 - val_acc: 0.4773\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1056 - acc: 0.5495 - val_loss: 1.3274 - val_acc: 0.4864\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1173 - acc: 0.5460 - val_loss: 1.4048 - val_acc: 0.4411\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1756 - acc: 0.5336 - val_loss: 1.3612 - val_acc: 0.4622\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1261 - acc: 0.5421 - val_loss: 1.4410 - val_acc: 0.3927\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.1961 - acc: 0.5072 - val_loss: 1.2797 - val_acc: 0.4773\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.1081 - acc: 0.5386 - val_loss: 1.2795 - val_acc: 0.4864\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0955 - acc: 0.5463 - val_loss: 1.4024 - val_acc: 0.4381\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.1526 - acc: 0.5414 - val_loss: 1.3746 - val_acc: 0.4653\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1121 - acc: 0.5502 - val_loss: 1.2772 - val_acc: 0.4834\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.1066 - acc: 0.5393 - val_loss: 1.2567 - val_acc: 0.4864\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.1553 - acc: 0.5372 - val_loss: 1.2469 - val_acc: 0.4773\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0962 - acc: 0.5509 - val_loss: 1.2258 - val_acc: 0.4743\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0786 - acc: 0.5541 - val_loss: 1.2262 - val_acc: 0.5257\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1239 - acc: 0.5424 - val_loss: 1.2200 - val_acc: 0.5015\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1490 - acc: 0.5277 - val_loss: 1.2705 - val_acc: 0.5045\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1146 - acc: 0.5586 - val_loss: 1.2773 - val_acc: 0.4743\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0887 - acc: 0.5685 - val_loss: 1.3010 - val_acc: 0.4743\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1216 - acc: 0.5424 - val_loss: 1.2790 - val_acc: 0.4924\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0601 - acc: 0.5615 - val_loss: 1.4501 - val_acc: 0.4471\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1481 - acc: 0.5354 - val_loss: 1.3412 - val_acc: 0.4713\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0735 - acc: 0.5586 - val_loss: 1.3120 - val_acc: 0.4653\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0648 - acc: 0.5586 - val_loss: 1.4666 - val_acc: 0.4320\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 1.1322 - acc: 0.5488 - val_loss: 1.3093 - val_acc: 0.4743\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0634 - acc: 0.5534 - val_loss: 1.3431 - val_acc: 0.4532\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.0996 - acc: 0.5636 - val_loss: 1.3266 - val_acc: 0.4290\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0595 - acc: 0.5689 - val_loss: 1.2993 - val_acc: 0.4683\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 1.0662 - acc: 0.5685 - val_loss: 1.3084 - val_acc: 0.4683\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.0486 - acc: 0.5844 - val_loss: 1.3858 - val_acc: 0.4109\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.0931 - acc: 0.5442 - val_loss: 1.3845 - val_acc: 0.4592\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.1055 - acc: 0.5495 - val_loss: 1.3684 - val_acc: 0.4804\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 1.1125 - acc: 0.5590 - val_loss: 1.2791 - val_acc: 0.4804\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.0492 - acc: 0.5632 - val_loss: 1.2583 - val_acc: 0.4985\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0229 - acc: 0.5805 - val_loss: 1.2428 - val_acc: 0.4743\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0013 - acc: 0.5840 - val_loss: 1.2648 - val_acc: 0.5015\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0532 - acc: 0.5551 - val_loss: 1.2624 - val_acc: 0.5076\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1481 - acc: 0.5308 - val_loss: 1.2579 - val_acc: 0.4985\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.0887 - acc: 0.5516 - val_loss: 1.2490 - val_acc: 0.4622\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0545 - acc: 0.5741 - val_loss: 1.2257 - val_acc: 0.5347\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0696 - acc: 0.5636 - val_loss: 1.2292 - val_acc: 0.5196\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0426 - acc: 0.5699 - val_loss: 1.2389 - val_acc: 0.5045\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0358 - acc: 0.5678 - val_loss: 1.2394 - val_acc: 0.4804\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0167 - acc: 0.5844 - val_loss: 1.2350 - val_acc: 0.4864\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0251 - acc: 0.5770 - val_loss: 1.2940 - val_acc: 0.4924\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1517 - acc: 0.5555 - val_loss: 1.2268 - val_acc: 0.5136\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9895 - acc: 0.5977 - val_loss: 1.3177 - val_acc: 0.4471\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0477 - acc: 0.5689 - val_loss: 1.5022 - val_acc: 0.4532\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.1472 - acc: 0.5527 - val_loss: 1.2822 - val_acc: 0.4864\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9967 - acc: 0.5879 - val_loss: 1.2427 - val_acc: 0.4834\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0090 - acc: 0.5925 - val_loss: 1.2388 - val_acc: 0.5196\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0387 - acc: 0.5749 - val_loss: 1.2294 - val_acc: 0.5076\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0113 - acc: 0.5830 - val_loss: 1.2655 - val_acc: 0.4864\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0869 - acc: 0.5523 - val_loss: 1.2385 - val_acc: 0.5196\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9917 - acc: 0.6041 - val_loss: 1.2383 - val_acc: 0.4834\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9566 - acc: 0.6044 - val_loss: 1.2903 - val_acc: 0.4683\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0247 - acc: 0.5777 - val_loss: 1.3633 - val_acc: 0.4713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0734 - acc: 0.5766 - val_loss: 1.3216 - val_acc: 0.4683\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0078 - acc: 0.5822 - val_loss: 1.2495 - val_acc: 0.4985\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0208 - acc: 0.5773 - val_loss: 1.2429 - val_acc: 0.5438\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0722 - acc: 0.5629 - val_loss: 1.2434 - val_acc: 0.5166\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9914 - acc: 0.5970 - val_loss: 1.2270 - val_acc: 0.5378\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9858 - acc: 0.6087 - val_loss: 1.2268 - val_acc: 0.5317\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9791 - acc: 0.6073 - val_loss: 1.2942 - val_acc: 0.5136\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0047 - acc: 0.5875 - val_loss: 1.3078 - val_acc: 0.4924\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0078 - acc: 0.6013 - val_loss: 1.3083 - val_acc: 0.4773\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9965 - acc: 0.5981 - val_loss: 1.4179 - val_acc: 0.4320\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0308 - acc: 0.5791 - val_loss: 1.2940 - val_acc: 0.4804\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9757 - acc: 0.6016 - val_loss: 1.2594 - val_acc: 0.5015\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9681 - acc: 0.5946 - val_loss: 1.3587 - val_acc: 0.4834\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9955 - acc: 0.6006 - val_loss: 1.4951 - val_acc: 0.4260\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0723 - acc: 0.5544 - val_loss: 1.2616 - val_acc: 0.5166\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9507 - acc: 0.6256 - val_loss: 1.2554 - val_acc: 0.5529\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9553 - acc: 0.6242 - val_loss: 1.3269 - val_acc: 0.4924\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0355 - acc: 0.5840 - val_loss: 1.2401 - val_acc: 0.5347\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9445 - acc: 0.6316 - val_loss: 1.2506 - val_acc: 0.5317\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9691 - acc: 0.6073 - val_loss: 1.2902 - val_acc: 0.5227\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0573 - acc: 0.5611 - val_loss: 1.2676 - val_acc: 0.5317\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9522 - acc: 0.6192 - val_loss: 1.2791 - val_acc: 0.5347\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9573 - acc: 0.6161 - val_loss: 1.3101 - val_acc: 0.5015\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9718 - acc: 0.6150 - val_loss: 1.2691 - val_acc: 0.5529\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9111 - acc: 0.6485 - val_loss: 1.2686 - val_acc: 0.5378\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9752 - acc: 0.6055 - val_loss: 1.2970 - val_acc: 0.5136\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0251 - acc: 0.5696 - val_loss: 1.2480 - val_acc: 0.5378\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9531 - acc: 0.6157 - val_loss: 1.2607 - val_acc: 0.5378\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9225 - acc: 0.6361 - val_loss: 1.2768 - val_acc: 0.5257\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9592 - acc: 0.6185 - val_loss: 1.2777 - val_acc: 0.5378\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9622 - acc: 0.6139 - val_loss: 1.3593 - val_acc: 0.4532\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 1.0342 - acc: 0.5886 - val_loss: 1.2910 - val_acc: 0.4985\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9695 - acc: 0.6263 - val_loss: 1.2796 - val_acc: 0.5106\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8834 - acc: 0.6626 - val_loss: 1.3155 - val_acc: 0.4743\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9039 - acc: 0.6411 - val_loss: 1.4743 - val_acc: 0.4773\n",
      "Epoch 155/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0050 - acc: 0.6108 - val_loss: 1.3511 - val_acc: 0.4864\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9334 - acc: 0.6259 - val_loss: 1.3484 - val_acc: 0.4622\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9471 - acc: 0.6094 - val_loss: 1.3510 - val_acc: 0.4622\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9214 - acc: 0.6379 - val_loss: 1.3641 - val_acc: 0.5015\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9436 - acc: 0.6266 - val_loss: 1.3568 - val_acc: 0.4713\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9993 - acc: 0.5914 - val_loss: 1.2746 - val_acc: 0.5106\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9480 - acc: 0.6333 - val_loss: 1.2866 - val_acc: 0.5257\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8979 - acc: 0.6400 - val_loss: 1.2982 - val_acc: 0.5227\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9237 - acc: 0.6302 - val_loss: 1.3120 - val_acc: 0.5227\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9577 - acc: 0.6185 - val_loss: 1.3101 - val_acc: 0.5196\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9221 - acc: 0.6379 - val_loss: 1.3123 - val_acc: 0.4924\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9144 - acc: 0.6287 - val_loss: 1.3639 - val_acc: 0.4985\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9640 - acc: 0.6125 - val_loss: 1.3120 - val_acc: 0.5015\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9367 - acc: 0.6027 - val_loss: 1.3294 - val_acc: 0.5166\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8987 - acc: 0.6523 - val_loss: 1.3709 - val_acc: 0.4773\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9458 - acc: 0.6365 - val_loss: 1.3692 - val_acc: 0.4804\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9209 - acc: 0.6495 - val_loss: 1.3740 - val_acc: 0.4683\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9093 - acc: 0.6418 - val_loss: 1.3832 - val_acc: 0.4592\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8819 - acc: 0.6467 - val_loss: 1.3273 - val_acc: 0.5106\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8453 - acc: 0.6788 - val_loss: 1.4047 - val_acc: 0.4713\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9375 - acc: 0.6139 - val_loss: 1.3412 - val_acc: 0.4834\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8792 - acc: 0.6661 - val_loss: 1.3221 - val_acc: 0.5317\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8898 - acc: 0.6312 - val_loss: 1.4501 - val_acc: 0.4924\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.0221 - acc: 0.5889 - val_loss: 1.3908 - val_acc: 0.4713\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9281 - acc: 0.6245 - val_loss: 1.4810 - val_acc: 0.4411\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9409 - acc: 0.6210 - val_loss: 1.3085 - val_acc: 0.5196\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8275 - acc: 0.6766 - val_loss: 1.3472 - val_acc: 0.5076\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8474 - acc: 0.6742 - val_loss: 1.4064 - val_acc: 0.4834\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9546 - acc: 0.6256 - val_loss: 1.2886 - val_acc: 0.5196\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8612 - acc: 0.6552 - val_loss: 1.3259 - val_acc: 0.5438\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8887 - acc: 0.6545 - val_loss: 1.3329 - val_acc: 0.5378\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8719 - acc: 0.6590 - val_loss: 1.4201 - val_acc: 0.4683\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9381 - acc: 0.6238 - val_loss: 1.3908 - val_acc: 0.4955\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9135 - acc: 0.6298 - val_loss: 1.4144 - val_acc: 0.4502\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9100 - acc: 0.6270 - val_loss: 1.3276 - val_acc: 0.5136\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8095 - acc: 0.6756 - val_loss: 1.3968 - val_acc: 0.4834\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8659 - acc: 0.6590 - val_loss: 1.4550 - val_acc: 0.4834\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9071 - acc: 0.6305 - val_loss: 1.3748 - val_acc: 0.5166\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.8530 - acc: 0.6552 - val_loss: 1.3670 - val_acc: 0.5045\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8747 - acc: 0.6509 - val_loss: 1.4322 - val_acc: 0.4713\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9191 - acc: 0.6143 - val_loss: 1.3673 - val_acc: 0.4894\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8752 - acc: 0.6523 - val_loss: 1.3913 - val_acc: 0.5136\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8408 - acc: 0.6703 - val_loss: 1.4324 - val_acc: 0.4683\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8724 - acc: 0.6460 - val_loss: 1.3427 - val_acc: 0.5227\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8270 - acc: 0.6812 - val_loss: 1.3840 - val_acc: 0.4924\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8760 - acc: 0.6566 - val_loss: 1.4612 - val_acc: 0.4743\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9025 - acc: 0.6464 - val_loss: 1.3788 - val_acc: 0.4804\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8601 - acc: 0.6675 - val_loss: 1.4105 - val_acc: 0.4894\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8632 - acc: 0.6714 - val_loss: 1.3835 - val_acc: 0.5106\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8562 - acc: 0.6400 - val_loss: 1.3894 - val_acc: 0.4955\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8701 - acc: 0.6361 - val_loss: 1.3778 - val_acc: 0.5106\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8485 - acc: 0.6534 - val_loss: 1.3535 - val_acc: 0.5438\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8438 - acc: 0.6664 - val_loss: 1.4424 - val_acc: 0.4622\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9413 - acc: 0.6196 - val_loss: 1.3394 - val_acc: 0.5378\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8475 - acc: 0.6756 - val_loss: 1.4733 - val_acc: 0.4592\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8930 - acc: 0.6326 - val_loss: 1.3508 - val_acc: 0.5317\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7994 - acc: 0.6985 - val_loss: 1.3796 - val_acc: 0.5196\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8003 - acc: 0.6837 - val_loss: 1.4315 - val_acc: 0.4864\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8364 - acc: 0.6492 - val_loss: 1.3690 - val_acc: 0.5227\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7732 - acc: 0.7013 - val_loss: 1.5032 - val_acc: 0.4592\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8929 - acc: 0.6358 - val_loss: 1.3986 - val_acc: 0.4955\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.8335 - acc: 0.684 - 0s 70us/step - loss: 0.8315 - acc: 0.6816 - val_loss: 1.4343 - val_acc: 0.5076\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8842 - acc: 0.6435 - val_loss: 1.3692 - val_acc: 0.5347\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8301 - acc: 0.6781 - val_loss: 1.3783 - val_acc: 0.5559\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8058 - acc: 0.6876 - val_loss: 1.4489 - val_acc: 0.4743\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8427 - acc: 0.6456 - val_loss: 1.4306 - val_acc: 0.4804\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8198 - acc: 0.6636 - val_loss: 1.3852 - val_acc: 0.5227\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7876 - acc: 0.7024 - val_loss: 1.4433 - val_acc: 0.4894\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8219 - acc: 0.6872 - val_loss: 1.4234 - val_acc: 0.4924\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8448 - acc: 0.6664 - val_loss: 1.4204 - val_acc: 0.4924\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8559 - acc: 0.6481 - val_loss: 1.3598 - val_acc: 0.5378\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7536 - acc: 0.7112 - val_loss: 1.3906 - val_acc: 0.5257\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7750 - acc: 0.6957 - val_loss: 1.4840 - val_acc: 0.5227\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8804 - acc: 0.6439 - val_loss: 1.4002 - val_acc: 0.5227\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7909 - acc: 0.7024 - val_loss: 1.5091 - val_acc: 0.4773\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8764 - acc: 0.6506 - val_loss: 1.3392 - val_acc: 0.5136\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7605 - acc: 0.7108 - val_loss: 1.3649 - val_acc: 0.5408\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7337 - acc: 0.7136 - val_loss: 1.5000 - val_acc: 0.4683\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8331 - acc: 0.6478 - val_loss: 1.4100 - val_acc: 0.5045\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7776 - acc: 0.6928 - val_loss: 1.4703 - val_acc: 0.5045\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8115 - acc: 0.6869 - val_loss: 1.4987 - val_acc: 0.4622\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7970 - acc: 0.6918 - val_loss: 1.4155 - val_acc: 0.5076\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.7398 - acc: 0.713 - 0s 69us/step - loss: 0.7499 - acc: 0.7034 - val_loss: 1.4754 - val_acc: 0.4834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8595 - acc: 0.6520 - val_loss: 1.5766 - val_acc: 0.4804\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9101 - acc: 0.6390 - val_loss: 1.3913 - val_acc: 0.4985\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7480 - acc: 0.6978 - val_loss: 1.3964 - val_acc: 0.4894\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7358 - acc: 0.7115 - val_loss: 1.4776 - val_acc: 0.4985\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8076 - acc: 0.6770 - val_loss: 1.4728 - val_acc: 0.5106\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8722 - acc: 0.6506 - val_loss: 1.5141 - val_acc: 0.4622\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8346 - acc: 0.6576 - val_loss: 1.3805 - val_acc: 0.5166\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7662 - acc: 0.7027 - val_loss: 1.4210 - val_acc: 0.5045\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7246 - acc: 0.7270 - val_loss: 1.5045 - val_acc: 0.4743\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8094 - acc: 0.6858 - val_loss: 1.4860 - val_acc: 0.4924\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.7780 - acc: 0.7083 - val_loss: 1.4662 - val_acc: 0.4985\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7650 - acc: 0.6876 - val_loss: 1.4478 - val_acc: 0.4985\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7732 - acc: 0.6974 - val_loss: 1.4754 - val_acc: 0.4773\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7990 - acc: 0.6950 - val_loss: 1.4571 - val_acc: 0.4985\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7787 - acc: 0.6795 - val_loss: 1.4198 - val_acc: 0.5196\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7180 - acc: 0.7319 - val_loss: 1.5000 - val_acc: 0.4924\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7659 - acc: 0.6766 - val_loss: 1.5131 - val_acc: 0.4743\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7891 - acc: 0.6738 - val_loss: 1.5099 - val_acc: 0.4773\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7447 - acc: 0.7295 - val_loss: 1.4791 - val_acc: 0.5196\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7087 - acc: 0.7393 - val_loss: 1.4662 - val_acc: 0.4834\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.7595 - acc: 0.713 - 0s 70us/step - loss: 0.8045 - acc: 0.6879 - val_loss: 1.7097 - val_acc: 0.4441\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9381 - acc: 0.6418 - val_loss: 1.3770 - val_acc: 0.5317\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.6974 - acc: 0.7450 - val_loss: 1.4483 - val_acc: 0.5106\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7126 - acc: 0.7270 - val_loss: 1.5390 - val_acc: 0.4743\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8185 - acc: 0.6608 - val_loss: 1.4374 - val_acc: 0.5076\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7248 - acc: 0.7327 - val_loss: 1.4338 - val_acc: 0.5227\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7221 - acc: 0.7172 - val_loss: 1.6162 - val_acc: 0.4924\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8925 - acc: 0.6294 - val_loss: 1.4708 - val_acc: 0.5166\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7886 - acc: 0.6876 - val_loss: 1.4857 - val_acc: 0.5015\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7374 - acc: 0.7154 - val_loss: 1.4499 - val_acc: 0.5227\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6930 - acc: 0.7450 - val_loss: 1.4892 - val_acc: 0.4985\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7189 - acc: 0.7108 - val_loss: 1.5103 - val_acc: 0.5136\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7744 - acc: 0.6777 - val_loss: 1.4610 - val_acc: 0.5076\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7144 - acc: 0.7066 - val_loss: 1.4693 - val_acc: 0.5106\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7231 - acc: 0.7164 - val_loss: 1.6271 - val_acc: 0.4622\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8433 - acc: 0.6763 - val_loss: 1.5449 - val_acc: 0.4773\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7450 - acc: 0.7126 - val_loss: 1.5208 - val_acc: 0.4804\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7095 - acc: 0.7305 - val_loss: 1.5716 - val_acc: 0.4773\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7650 - acc: 0.6914 - val_loss: 1.5575 - val_acc: 0.4471\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7423 - acc: 0.6985 - val_loss: 1.4921 - val_acc: 0.4924\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6795 - acc: 0.7563 - val_loss: 1.5781 - val_acc: 0.5166\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7779 - acc: 0.6865 - val_loss: 1.4965 - val_acc: 0.5136\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7105 - acc: 0.7129 - val_loss: 1.4722 - val_acc: 0.5227\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6576 - acc: 0.7545 - val_loss: 1.6268 - val_acc: 0.4743\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7771 - acc: 0.6897 - val_loss: 1.5590 - val_acc: 0.4834\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7543 - acc: 0.6950 - val_loss: 1.5546 - val_acc: 0.4773\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7309 - acc: 0.7224 - val_loss: 1.5151 - val_acc: 0.5106\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6775 - acc: 0.7489 - val_loss: 1.5057 - val_acc: 0.5136\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6380 - acc: 0.7513 - val_loss: 1.6241 - val_acc: 0.4713\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7943 - acc: 0.6728 - val_loss: 1.5128 - val_acc: 0.4804\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7162 - acc: 0.7334 - val_loss: 1.5485 - val_acc: 0.4864\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7224 - acc: 0.7161 - val_loss: 1.5102 - val_acc: 0.4985\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6792 - acc: 0.7365 - val_loss: 1.4951 - val_acc: 0.5257\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6623 - acc: 0.7418 - val_loss: 1.5503 - val_acc: 0.4894\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7327 - acc: 0.6971 - val_loss: 1.5307 - val_acc: 0.5015\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7592 - acc: 0.6703 - val_loss: 1.6394 - val_acc: 0.4743\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8067 - acc: 0.6664 - val_loss: 1.4972 - val_acc: 0.5136\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6643 - acc: 0.7587 - val_loss: 1.5974 - val_acc: 0.4653\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6973 - acc: 0.7277 - val_loss: 1.5311 - val_acc: 0.4924\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6584 - acc: 0.7644 - val_loss: 1.5805 - val_acc: 0.4894\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6826 - acc: 0.7425 - val_loss: 1.5945 - val_acc: 0.4924\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6926 - acc: 0.7260 - val_loss: 1.5123 - val_acc: 0.5106\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6725 - acc: 0.7274 - val_loss: 1.5861 - val_acc: 0.4894\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7584 - acc: 0.6840 - val_loss: 1.6044 - val_acc: 0.4985\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7323 - acc: 0.7217 - val_loss: 1.6297 - val_acc: 0.4743\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7349 - acc: 0.7013 - val_loss: 1.5487 - val_acc: 0.5045\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6797 - acc: 0.7464 - val_loss: 1.5835 - val_acc: 0.4562\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6893 - acc: 0.7351 - val_loss: 1.5815 - val_acc: 0.4894\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6621 - acc: 0.7397 - val_loss: 1.5719 - val_acc: 0.4955\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6556 - acc: 0.7492 - val_loss: 1.5972 - val_acc: 0.5227\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6978 - acc: 0.7189 - val_loss: 1.5709 - val_acc: 0.4834\n",
      "Epoch 309/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6876 - acc: 0.7277 - val_loss: 1.5887 - val_acc: 0.4955\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7199 - acc: 0.7059 - val_loss: 1.5671 - val_acc: 0.5045\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6736 - acc: 0.7295 - val_loss: 1.6010 - val_acc: 0.5045\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6464 - acc: 0.7587 - val_loss: 1.6595 - val_acc: 0.4653\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6234 - acc: 0.7682 - val_loss: 1.6348 - val_acc: 0.4834\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6559 - acc: 0.7545 - val_loss: 1.7336 - val_acc: 0.4562\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7030 - acc: 0.7277 - val_loss: 1.7352 - val_acc: 0.4411\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7439 - acc: 0.7027 - val_loss: 1.6313 - val_acc: 0.4985\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7460 - acc: 0.7013 - val_loss: 1.5450 - val_acc: 0.4864\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6186 - acc: 0.7591 - val_loss: 1.5737 - val_acc: 0.4985\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6376 - acc: 0.7365 - val_loss: 1.6792 - val_acc: 0.4924\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7284 - acc: 0.6967 - val_loss: 1.5293 - val_acc: 0.5227\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6181 - acc: 0.7640 - val_loss: 1.6111 - val_acc: 0.4894\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6680 - acc: 0.7386 - val_loss: 1.6512 - val_acc: 0.4864\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7330 - acc: 0.7277 - val_loss: 1.5431 - val_acc: 0.5317\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5957 - acc: 0.7753 - val_loss: 1.5609 - val_acc: 0.5227\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5682 - acc: 0.7862 - val_loss: 1.5744 - val_acc: 0.5106\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6192 - acc: 0.7570 - val_loss: 1.7372 - val_acc: 0.4441\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7748 - acc: 0.6985 - val_loss: 1.6731 - val_acc: 0.4773\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7041 - acc: 0.7157 - val_loss: 1.7432 - val_acc: 0.4562\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6805 - acc: 0.7203 - val_loss: 1.5332 - val_acc: 0.5287\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5642 - acc: 0.8003 - val_loss: 1.6176 - val_acc: 0.4985\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5504 - acc: 0.7862 - val_loss: 1.7289 - val_acc: 0.4834\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6344 - acc: 0.7474 - val_loss: 1.7487 - val_acc: 0.4955\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6755 - acc: 0.7400 - val_loss: 1.6441 - val_acc: 0.4894\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6687 - acc: 0.7341 - val_loss: 1.6698 - val_acc: 0.4773\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6915 - acc: 0.7182 - val_loss: 1.6158 - val_acc: 0.5076\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5897 - acc: 0.7827 - val_loss: 1.6713 - val_acc: 0.5106\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6106 - acc: 0.7541 - val_loss: 1.6687 - val_acc: 0.4924\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6086 - acc: 0.7668 - val_loss: 1.8280 - val_acc: 0.4502\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6920 - acc: 0.7157 - val_loss: 1.7012 - val_acc: 0.4683\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7562 - acc: 0.6925 - val_loss: 1.6982 - val_acc: 0.4622\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6937 - acc: 0.7379 - val_loss: 1.5776 - val_acc: 0.5196\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5438 - acc: 0.8038 - val_loss: 1.6582 - val_acc: 0.5257\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5858 - acc: 0.7552 - val_loss: 1.7517 - val_acc: 0.5015\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7146 - acc: 0.6939 - val_loss: 1.6899 - val_acc: 0.4834\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6628 - acc: 0.7348 - val_loss: 1.7012 - val_acc: 0.4834\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6226 - acc: 0.7555 - val_loss: 1.6951 - val_acc: 0.4804\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6000 - acc: 0.7806 - val_loss: 1.7610 - val_acc: 0.4592\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6690 - acc: 0.7510 - val_loss: 1.6547 - val_acc: 0.4622\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5955 - acc: 0.7823 - val_loss: 1.7775 - val_acc: 0.4653\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6341 - acc: 0.7453 - val_loss: 1.6978 - val_acc: 0.4743\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6115 - acc: 0.7654 - val_loss: 1.6781 - val_acc: 0.4713\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5918 - acc: 0.7809 - val_loss: 1.7143 - val_acc: 0.4653\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6501 - acc: 0.7489 - val_loss: 1.6328 - val_acc: 0.4894\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6011 - acc: 0.7802 - val_loss: 1.6577 - val_acc: 0.5136\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5753 - acc: 0.7721 - val_loss: 1.8157 - val_acc: 0.4955\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6950 - acc: 0.7231 - val_loss: 1.6389 - val_acc: 0.5076\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5915 - acc: 0.7636 - val_loss: 1.6580 - val_acc: 0.4864\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5797 - acc: 0.7781 - val_loss: 1.9001 - val_acc: 0.4955\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7588 - acc: 0.6918 - val_loss: 1.6310 - val_acc: 0.4713\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6257 - acc: 0.7594 - val_loss: 1.7265 - val_acc: 0.4773\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6029 - acc: 0.7672 - val_loss: 1.6615 - val_acc: 0.5076\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.5403 - acc: 0.7932 - val_loss: 1.6704 - val_acc: 0.5227\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5695 - acc: 0.7788 - val_loss: 1.8475 - val_acc: 0.4924\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7160 - acc: 0.7126 - val_loss: 1.6528 - val_acc: 0.4985\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5937 - acc: 0.7735 - val_loss: 1.7584 - val_acc: 0.4713\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5849 - acc: 0.7718 - val_loss: 1.8342 - val_acc: 0.4411\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6149 - acc: 0.7471 - val_loss: 1.7197 - val_acc: 0.4804\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5622 - acc: 0.7943 - val_loss: 1.7382 - val_acc: 0.4834\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5969 - acc: 0.7735 - val_loss: 1.7476 - val_acc: 0.4834\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5837 - acc: 0.7791 - val_loss: 1.6861 - val_acc: 0.5045\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5698 - acc: 0.7844 - val_loss: 1.7388 - val_acc: 0.4985\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6318 - acc: 0.7679 - val_loss: 1.7185 - val_acc: 0.4894\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5716 - acc: 0.7816 - val_loss: 1.7899 - val_acc: 0.5136\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6541 - acc: 0.7249 - val_loss: 1.8163 - val_acc: 0.5015\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7424 - acc: 0.6957 - val_loss: 1.6520 - val_acc: 0.5015\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5060 - acc: 0.8214 - val_loss: 1.7178 - val_acc: 0.5076\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5381 - acc: 0.7971 - val_loss: 1.8207 - val_acc: 0.4743\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6542 - acc: 0.7510 - val_loss: 1.7616 - val_acc: 0.5076\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5615 - acc: 0.7795 - val_loss: 1.7538 - val_acc: 0.4924\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.5760 - acc: 0.7661 - val_loss: 1.7502 - val_acc: 0.5106\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5341 - acc: 0.7890 - val_loss: 1.7470 - val_acc: 0.4894\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.5491 - acc: 0.7806 - val_loss: 1.8405 - val_acc: 0.5015\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6347 - acc: 0.7661 - val_loss: 1.8418 - val_acc: 0.4713\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5885 - acc: 0.7725 - val_loss: 1.9482 - val_acc: 0.4743\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6897 - acc: 0.7242 - val_loss: 1.7439 - val_acc: 0.4592\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.5419 - acc: 0.8084 - val_loss: 1.7998 - val_acc: 0.4773\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5170 - acc: 0.8108 - val_loss: 1.9419 - val_acc: 0.4169\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6456 - acc: 0.7112 - val_loss: 1.7800 - val_acc: 0.4804\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.5428 - acc: 0.7992 - val_loss: 1.7629 - val_acc: 0.5076\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4728 - acc: 0.8281 - val_loss: 1.8867 - val_acc: 0.4381\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5468 - acc: 0.7954 - val_loss: 2.0437 - val_acc: 0.4260\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6883 - acc: 0.7217 - val_loss: 1.6961 - val_acc: 0.4773\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5562 - acc: 0.7925 - val_loss: 1.7916 - val_acc: 0.4955\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5494 - acc: 0.7788 - val_loss: 1.8394 - val_acc: 0.5015\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5334 - acc: 0.7883 - val_loss: 1.8273 - val_acc: 0.5015\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5107 - acc: 0.8108 - val_loss: 1.9704 - val_acc: 0.4532\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 101us/step - loss: 0.6322 - acc: 0.7563 - val_loss: 1.7946 - val_acc: 0.4773\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5001 - acc: 0.8168 - val_loss: 1.8162 - val_acc: 0.5045\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4900 - acc: 0.8179 - val_loss: 1.9771 - val_acc: 0.4502\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6308 - acc: 0.7351 - val_loss: 1.8011 - val_acc: 0.4622\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5336 - acc: 0.8119 - val_loss: 1.8508 - val_acc: 0.4955\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5036 - acc: 0.8087 - val_loss: 2.1442 - val_acc: 0.4139\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6574 - acc: 0.7429 - val_loss: 1.7336 - val_acc: 0.4894\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5587 - acc: 0.7915 - val_loss: 1.8214 - val_acc: 0.4773\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5038 - acc: 0.8161 - val_loss: 1.8856 - val_acc: 0.5136\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5552 - acc: 0.7770 - val_loss: 1.9137 - val_acc: 0.5136\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6558 - acc: 0.7210 - val_loss: 1.8559 - val_acc: 0.5136\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5876 - acc: 0.7725 - val_loss: 1.8277 - val_acc: 0.5015\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.5177 - acc: 0.8084 - val_loss: 1.7977 - val_acc: 0.4773\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4919 - acc: 0.8214 - val_loss: 1.8667 - val_acc: 0.4773\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4699 - acc: 0.8271 - val_loss: 1.9808 - val_acc: 0.4773\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5140 - acc: 0.8126 - val_loss: 2.0966 - val_acc: 0.4199\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6034 - acc: 0.7559 - val_loss: 1.8810 - val_acc: 0.4713\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5756 - acc: 0.7784 - val_loss: 1.9137 - val_acc: 0.4653\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5967 - acc: 0.7665 - val_loss: 1.9016 - val_acc: 0.4320\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6605 - acc: 0.7425 - val_loss: 1.7537 - val_acc: 0.4985\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4732 - acc: 0.8401 - val_loss: 1.8367 - val_acc: 0.4834\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4874 - acc: 0.8108 - val_loss: 1.9274 - val_acc: 0.4683\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5656 - acc: 0.7696 - val_loss: 1.8502 - val_acc: 0.4622\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4666 - acc: 0.8369 - val_loss: 1.9370 - val_acc: 0.4471\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4872 - acc: 0.8179 - val_loss: 2.0769 - val_acc: 0.4290\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6016 - acc: 0.7566 - val_loss: 1.8263 - val_acc: 0.4683\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4952 - acc: 0.8249 - val_loss: 1.8596 - val_acc: 0.4773\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4681 - acc: 0.8292 - val_loss: 2.0077 - val_acc: 0.4804\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5877 - acc: 0.7696 - val_loss: 1.8859 - val_acc: 0.4834\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5321 - acc: 0.7918 - val_loss: 1.8766 - val_acc: 0.4653\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4656 - acc: 0.8246 - val_loss: 2.0491 - val_acc: 0.4290\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5799 - acc: 0.7799 - val_loss: 1.8710 - val_acc: 0.4381\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4958 - acc: 0.8274 - val_loss: 1.8847 - val_acc: 0.4864\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4265 - acc: 0.8545 - val_loss: 1.9495 - val_acc: 0.4653\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4507 - acc: 0.8397 - val_loss: 2.0926 - val_acc: 0.4260\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6470 - acc: 0.7358 - val_loss: 2.0861 - val_acc: 0.4169\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6345 - acc: 0.7471 - val_loss: 1.8750 - val_acc: 0.4622\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5131 - acc: 0.8193 - val_loss: 1.8732 - val_acc: 0.4562\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4262 - acc: 0.8468 - val_loss: 1.9265 - val_acc: 0.4804\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4270 - acc: 0.8415 - val_loss: 1.9805 - val_acc: 0.4743\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5026 - acc: 0.8017 - val_loss: 2.0629 - val_acc: 0.5076\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6587 - acc: 0.7119 - val_loss: 1.8721 - val_acc: 0.4653\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6185 - acc: 0.7647 - val_loss: 1.8173 - val_acc: 0.5076\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4781 - acc: 0.8239 - val_loss: 1.8862 - val_acc: 0.4713\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.4436 - acc: 0.8380 - val_loss: 1.9441 - val_acc: 0.4955\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4856 - acc: 0.8094 - val_loss: 1.9699 - val_acc: 0.4562\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4675 - acc: 0.8316 - val_loss: 2.0619 - val_acc: 0.4622\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4706 - acc: 0.8309 - val_loss: 2.0784 - val_acc: 0.4804\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5459 - acc: 0.7816 - val_loss: 2.0671 - val_acc: 0.4924\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6280 - acc: 0.7422 - val_loss: 1.9411 - val_acc: 0.4864\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5024 - acc: 0.8070 - val_loss: 1.9696 - val_acc: 0.4713\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4519 - acc: 0.8359 - val_loss: 1.9951 - val_acc: 0.4471\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4341 - acc: 0.8514 - val_loss: 2.0229 - val_acc: 0.4562\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4767 - acc: 0.8190 - val_loss: 2.0426 - val_acc: 0.4502\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4465 - acc: 0.8278 - val_loss: 2.0418 - val_acc: 0.4683\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4508 - acc: 0.8179 - val_loss: 2.1154 - val_acc: 0.4894\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6445 - acc: 0.7221 - val_loss: 1.8904 - val_acc: 0.4773\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6030 - acc: 0.7619 - val_loss: 1.8996 - val_acc: 0.4924\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4436 - acc: 0.8401 - val_loss: 1.9635 - val_acc: 0.4834\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4364 - acc: 0.8415 - val_loss: 2.0521 - val_acc: 0.4864\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4474 - acc: 0.8436 - val_loss: 2.2315 - val_acc: 0.4381\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4904 - acc: 0.8197 - val_loss: 2.0746 - val_acc: 0.4381\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4675 - acc: 0.8211 - val_loss: 2.3510 - val_acc: 0.4199\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6227 - acc: 0.7348 - val_loss: 1.9128 - val_acc: 0.4592\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4692 - acc: 0.8352 - val_loss: 2.0788 - val_acc: 0.4653\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4753 - acc: 0.8144 - val_loss: 1.9722 - val_acc: 0.4653\n",
      "Epoch 463/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4250 - acc: 0.8418 - val_loss: 2.0263 - val_acc: 0.4804\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3997 - acc: 0.8545 - val_loss: 2.1135 - val_acc: 0.4471\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4764 - acc: 0.8066 - val_loss: 2.0098 - val_acc: 0.4713\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4477 - acc: 0.8299 - val_loss: 2.1509 - val_acc: 0.4441\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5115 - acc: 0.7964 - val_loss: 2.0555 - val_acc: 0.4683\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5596 - acc: 0.7622 - val_loss: 2.0765 - val_acc: 0.4411\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5021 - acc: 0.8056 - val_loss: 2.0196 - val_acc: 0.4502\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4431 - acc: 0.8362 - val_loss: 2.1193 - val_acc: 0.4199\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4732 - acc: 0.8204 - val_loss: 2.0628 - val_acc: 0.4320\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4595 - acc: 0.8263 - val_loss: 2.1304 - val_acc: 0.4683\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4447 - acc: 0.8306 - val_loss: 2.0008 - val_acc: 0.4713\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3885 - acc: 0.8665 - val_loss: 2.0613 - val_acc: 0.4502\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4339 - acc: 0.8383 - val_loss: 2.0401 - val_acc: 0.4532\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5068 - acc: 0.8080 - val_loss: 2.0342 - val_acc: 0.4924\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5033 - acc: 0.8073 - val_loss: 2.3026 - val_acc: 0.4864\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6542 - acc: 0.7267 - val_loss: 2.0380 - val_acc: 0.4834\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5212 - acc: 0.7848 - val_loss: 1.9089 - val_acc: 0.4713\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4024 - acc: 0.8538 - val_loss: 2.0577 - val_acc: 0.4683\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3688 - acc: 0.8732 - val_loss: 2.0898 - val_acc: 0.4985\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3885 - acc: 0.8580 - val_loss: 2.1629 - val_acc: 0.5136\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5262 - acc: 0.7693 - val_loss: 2.0190 - val_acc: 0.4773\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4804 - acc: 0.8063 - val_loss: 2.0948 - val_acc: 0.4653\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4222 - acc: 0.8397 - val_loss: 2.2089 - val_acc: 0.4441\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5406 - acc: 0.7813 - val_loss: 2.0594 - val_acc: 0.4683\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4600 - acc: 0.8263 - val_loss: 2.0482 - val_acc: 0.4804\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4120 - acc: 0.8468 - val_loss: 2.0887 - val_acc: 0.4773\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3973 - acc: 0.8507 - val_loss: 2.2904 - val_acc: 0.4018\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5048 - acc: 0.7904 - val_loss: 2.2082 - val_acc: 0.4290\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5235 - acc: 0.8161 - val_loss: 2.0384 - val_acc: 0.4653\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3830 - acc: 0.8669 - val_loss: 2.1750 - val_acc: 0.4381\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3842 - acc: 0.8623 - val_loss: 2.1030 - val_acc: 0.4622\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3701 - acc: 0.8647 - val_loss: 2.2363 - val_acc: 0.4502\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4383 - acc: 0.8362 - val_loss: 2.4140 - val_acc: 0.4230\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6327 - acc: 0.7580 - val_loss: 2.1185 - val_acc: 0.4350\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5479 - acc: 0.7756 - val_loss: 1.9927 - val_acc: 0.4743\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3879 - acc: 0.8672 - val_loss: 2.0849 - val_acc: 0.4622\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3484 - acc: 0.8873 - val_loss: 2.1724 - val_acc: 0.4924\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.4073 - acc: 0.8517 - val_loss: 2.2478 - val_acc: 0.4924\n"
     ]
    }
   ],
   "source": [
    "w2v_model = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181999be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model.history['acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>loss</th>\n",
       "      <th>gain</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>gain_true_true</th>\n",
       "      <th>gain_stay</th>\n",
       "      <th>loss_true_true</th>\n",
       "      <th>loss_stay</th>\n",
       "      <th>gain_large</th>\n",
       "      <th>loss_large</th>\n",
       "      <th>gain_large_true</th>\n",
       "      <th>loss_large_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.386394e-03</td>\n",
       "      <td>1.050091e-01</td>\n",
       "      <td>1.591386e-01</td>\n",
       "      <td>0.356899</td>\n",
       "      <td>3.745667e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.575360e-10</td>\n",
       "      <td>2.015372e-06</td>\n",
       "      <td>9.907100e-01</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>5.487662e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.422529e-10</td>\n",
       "      <td>2.247291e-07</td>\n",
       "      <td>9.999537e-01</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>4.702748e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.420212e-11</td>\n",
       "      <td>1.134737e-06</td>\n",
       "      <td>1.622263e-06</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>9.164789e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.406993e-33</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.781700e-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2         3             4  loss  \\\n",
       "0  4.386394e-03  1.050091e-01  1.591386e-01  0.356899  3.745667e-01     0   \n",
       "1  2.575360e-10  2.015372e-06  9.907100e-01  0.009283  5.487662e-06     0   \n",
       "2  1.422529e-10  2.247291e-07  9.999537e-01  0.000046  4.702748e-07     0   \n",
       "3  2.420212e-11  1.134737e-06  1.622263e-06  0.083518  9.164789e-01     0   \n",
       "4  5.406993e-33  1.000000e+00  7.781700e-19  0.000000  0.000000e+00     1   \n",
       "\n",
       "   gain  1  2  3  4  5  gain_true_true  gain_stay  loss_true_true  loss_stay  \\\n",
       "0     1  0  0  0  1  0               1          0               0          0   \n",
       "1     1  0  0  0  1  0               1          0               0          0   \n",
       "2     1  0  0  1  0  0               0          1               0          0   \n",
       "3     1  0  0  1  0  0               0          1               0          0   \n",
       "4     0  0  0  0  1  0               0          0               0          0   \n",
       "\n",
       "   gain_large  loss_large  gain_large_true  loss_large_true  \n",
       "0           1           0                0                0  \n",
       "1           0           0                0                0  \n",
       "2           0           0                0                0  \n",
       "3           1           0                0                0  \n",
       "4           0           0                0                0  "
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_cat_mod_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure there are no duplicates in predictions\n",
    "one = X_test_cat_mod_df_2['1'].sum()\n",
    "two = X_test_cat_mod_df_2['2'].sum()\n",
    "three = X_test_cat_mod_df_2['3'].sum()\n",
    "four = X_test_cat_mod_df_2['4'].sum()\n",
    "five = X_test_cat_mod_df_2['5'].sum()\n",
    "one + two + three + four + five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_metrics(predictions, y_test):\n",
    "    df = pd.DataFrame(predictions)\n",
    "    # predicting a loss 3% or larger by seeing if max loss probability is higher then slight gain\n",
    "    df['loss'] = np.where(df[0] > df[3], 1, 0)\n",
    "    # predicting a gain 3% or larger by seeing if max gain probability is higher then slight loss\n",
    "    df['gain'] = np.where(df[4] > df[1], 1, 0)\n",
    "    df = pd.merge(df, y_test, left_index=True, right_index=True, how='inner')\n",
    "    # predicting a loss 3% or larger by seeing if max loss probability is higher then mean probibility \n",
    "    df['loss_large'] = np.where(df[0] > df[2], 1, 0)\n",
    "    # predicting a gain 3% or larger by seeing if max gain probability is higher then mean probibility \n",
    "    df['gain_large'] = np.where(df[4] > df[2], 1, 0)\n",
    "    # Cheching if loss is predicted and a loss of 3% or more occurs\n",
    "    df['loss_true_true'] = np.where((df['loss'] == 1) & (df['2'] == 1) | (df['1'] == 1), 1, 0)\n",
    "    # Checking if loss is predicted and price stays at the mean\n",
    "    df['loss_stay'] = np.where((df['loss'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if large loss is predicted and a loss of 3% or more occurs\n",
    "    df['loss_large_true'] = np.where((df['loss_large'] == 1) & (df['2'] == 1) | (df['1'] == 1), 1, 0)\n",
    "    # Cheching if large loss is predicted and price stays at the mean\n",
    "    df['loss_large_stay'] = np.where((df['loss_large'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if gain is predicted and a loss of 3% or more occurs\n",
    "    df['gain_true_true'] = np.where((df['gain'] == 1) & (df['4'] == 1) | (df['5'] == 1), 1, 0)\n",
    "    # Checking if gain is predicted and price stays at the mean\n",
    "    df['gain_stay'] = np.where((df['gain'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if large gain is predicted and a gain of 3% or more occurs\n",
    "    df['gain_large_true'] = np.where((df['gain_large'] == 1) & (df['4'] == 1) | (df['5'] == 1), 1, 0)\n",
    "    # Cheching if large gain is predicted and price stays at the mean\n",
    "    df['gain_large_stay'] = np.where((df['gain_large'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    #df['gain_large_large'] = np.where((df['gain_large'] == 1) & (df['5'] == 1), 1, 0)\n",
    "    # Checking if both loss and gain are selected. This appears to mean high volitility\n",
    "    df['volitile'] = np.where((df['loss'] == 1) & (df['gain'] == 1), 1, 0)\n",
    "    \n",
    "    \n",
    "    gain_pred = df['gain'].sum()\n",
    "    gain_large_pred = df['gain_large'].sum()\n",
    "    gain_stay_true = (df['gain_true_true'].sum() + df['gain_stay'].sum()) / df['gain'].sum()\n",
    "    gain_true = df['gain_true_true'].sum() / df['gain'].sum()\n",
    "    loss_stay_true = (df['loss_true_true'].sum() + df['loss_stay'].sum()) / df['loss'].sum()\n",
    "    loss_stay_true = df['loss_true_true'].sum() / df['loss'].sum()\n",
    "    gain_stay_large_true = (df['gain_large_true'].sum() + df['gain_large_stay'].sum()) / df['gain_large'].sum()\n",
    "    gain_large_true = df['gain_large_true'].sum() / df['gain_large'].sum()\n",
    "    loss_stay_large_true = (df['loss_large_true'].sum() + df['loss_large_stay']) / df['loss_large'].sum()\n",
    "    loss_large_true = df['loss_large_true'].sum() / df['loss_large'].sum()\n",
    "    volitile = df['volitile'].sum()\n",
    "    print(gain_pred)\n",
    "    print(gain_true)\n",
    "    print(gain_stay_true)\n",
    "    print(gain_large_pred)\n",
    "    print(gain_large_true)\n",
    "    print(gain_stay_large_true)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.00001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 3s 1ms/step - loss: 1.5620 - acc: 0.1828 - val_loss: 1.6732 - val_acc: 0.0665\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5574 - acc: 0.1832 - val_loss: 1.6712 - val_acc: 0.0665\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5727 - acc: 0.1775 - val_loss: 1.6697 - val_acc: 0.0665\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5649 - acc: 0.1892 - val_loss: 1.6682 - val_acc: 0.0665\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5585 - acc: 0.1825 - val_loss: 1.6668 - val_acc: 0.0665\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5694 - acc: 0.1744 - val_loss: 1.6657 - val_acc: 0.0665\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5605 - acc: 0.1825 - val_loss: 1.6644 - val_acc: 0.0665\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5609 - acc: 0.1835 - val_loss: 1.6633 - val_acc: 0.0665\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5536 - acc: 0.1835 - val_loss: 1.6624 - val_acc: 0.0695\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5551 - acc: 0.1874 - val_loss: 1.6614 - val_acc: 0.0695\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5464 - acc: 0.1990 - val_loss: 1.6605 - val_acc: 0.0695\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5464 - acc: 0.1895 - val_loss: 1.6595 - val_acc: 0.0665\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5633 - acc: 0.1758 - val_loss: 1.6586 - val_acc: 0.0665\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5416 - acc: 0.1951 - val_loss: 1.6579 - val_acc: 0.0665\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5447 - acc: 0.1965 - val_loss: 1.6570 - val_acc: 0.0665\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5586 - acc: 0.1789 - val_loss: 1.6562 - val_acc: 0.0665\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5448 - acc: 0.1951 - val_loss: 1.6553 - val_acc: 0.0634\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5475 - acc: 0.1944 - val_loss: 1.6545 - val_acc: 0.0634\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5467 - acc: 0.1969 - val_loss: 1.6536 - val_acc: 0.0634\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5336 - acc: 0.1951 - val_loss: 1.6529 - val_acc: 0.0634\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5488 - acc: 0.1899 - val_loss: 1.6521 - val_acc: 0.0634\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5367 - acc: 0.1994 - val_loss: 1.6512 - val_acc: 0.0634\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5532 - acc: 0.1906 - val_loss: 1.6506 - val_acc: 0.0634\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5449 - acc: 0.1937 - val_loss: 1.6499 - val_acc: 0.0634\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5493 - acc: 0.1814 - val_loss: 1.6491 - val_acc: 0.0604\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5384 - acc: 0.1899 - val_loss: 1.6485 - val_acc: 0.0604\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5448 - acc: 0.1877 - val_loss: 1.6480 - val_acc: 0.0604\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5541 - acc: 0.1955 - val_loss: 1.6473 - val_acc: 0.0634\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5439 - acc: 0.1930 - val_loss: 1.6466 - val_acc: 0.0634\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5351 - acc: 0.2099 - val_loss: 1.6459 - val_acc: 0.0634\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5429 - acc: 0.2001 - val_loss: 1.6454 - val_acc: 0.0634\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5380 - acc: 0.1892 - val_loss: 1.6447 - val_acc: 0.0634\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5424 - acc: 0.1892 - val_loss: 1.6440 - val_acc: 0.0665\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5346 - acc: 0.1983 - val_loss: 1.6433 - val_acc: 0.0665\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5300 - acc: 0.1994 - val_loss: 1.6426 - val_acc: 0.0665\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5396 - acc: 0.2057 - val_loss: 1.6419 - val_acc: 0.0665\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5322 - acc: 0.2046 - val_loss: 1.6411 - val_acc: 0.0665\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5360 - acc: 0.2046 - val_loss: 1.6405 - val_acc: 0.0665\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5314 - acc: 0.2075 - val_loss: 1.6399 - val_acc: 0.0665\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5296 - acc: 0.2068 - val_loss: 1.6393 - val_acc: 0.0695\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5342 - acc: 0.2103 - val_loss: 1.6386 - val_acc: 0.0755\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5338 - acc: 0.2022 - val_loss: 1.6380 - val_acc: 0.0755\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5352 - acc: 0.1969 - val_loss: 1.6373 - val_acc: 0.0755\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5368 - acc: 0.1958 - val_loss: 1.6369 - val_acc: 0.0755\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5302 - acc: 0.1944 - val_loss: 1.6363 - val_acc: 0.0755\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5383 - acc: 0.2089 - val_loss: 1.6357 - val_acc: 0.0785\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5377 - acc: 0.2050 - val_loss: 1.6351 - val_acc: 0.0785\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5283 - acc: 0.2089 - val_loss: 1.6344 - val_acc: 0.0785\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5360 - acc: 0.2011 - val_loss: 1.6338 - val_acc: 0.0785\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5185 - acc: 0.2061 - val_loss: 1.6333 - val_acc: 0.0816\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5356 - acc: 0.2032 - val_loss: 1.6327 - val_acc: 0.0816\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5264 - acc: 0.2156 - val_loss: 1.6321 - val_acc: 0.0846\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5236 - acc: 0.2131 - val_loss: 1.6314 - val_acc: 0.0846\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5224 - acc: 0.2124 - val_loss: 1.6309 - val_acc: 0.0816\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5239 - acc: 0.1962 - val_loss: 1.6303 - val_acc: 0.0816\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5170 - acc: 0.2085 - val_loss: 1.6296 - val_acc: 0.0816\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5251 - acc: 0.2113 - val_loss: 1.6289 - val_acc: 0.0846\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5085 - acc: 0.2180 - val_loss: 1.6284 - val_acc: 0.0846\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5226 - acc: 0.2054 - val_loss: 1.6277 - val_acc: 0.0846\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5157 - acc: 0.2258 - val_loss: 1.6271 - val_acc: 0.0846\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5290 - acc: 0.2039 - val_loss: 1.6265 - val_acc: 0.0846\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5104 - acc: 0.2135 - val_loss: 1.6260 - val_acc: 0.0846\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5373 - acc: 0.1990 - val_loss: 1.6254 - val_acc: 0.0846\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5130 - acc: 0.2057 - val_loss: 1.6249 - val_acc: 0.0906\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5239 - acc: 0.2240 - val_loss: 1.6244 - val_acc: 0.0937\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5250 - acc: 0.2032 - val_loss: 1.6239 - val_acc: 0.1027\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5138 - acc: 0.2230 - val_loss: 1.6234 - val_acc: 0.1088\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5187 - acc: 0.2184 - val_loss: 1.6229 - val_acc: 0.1148\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5249 - acc: 0.2096 - val_loss: 1.6224 - val_acc: 0.1148\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5191 - acc: 0.2180 - val_loss: 1.6219 - val_acc: 0.1208\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5038 - acc: 0.2307 - val_loss: 1.6212 - val_acc: 0.1208\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5108 - acc: 0.2240 - val_loss: 1.6207 - val_acc: 0.1208\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5101 - acc: 0.2282 - val_loss: 1.6202 - val_acc: 0.1239\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5017 - acc: 0.2325 - val_loss: 1.6197 - val_acc: 0.1239\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5011 - acc: 0.2300 - val_loss: 1.6193 - val_acc: 0.1299\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5175 - acc: 0.2089 - val_loss: 1.6188 - val_acc: 0.1299\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4996 - acc: 0.2293 - val_loss: 1.6182 - val_acc: 0.1269\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5126 - acc: 0.2209 - val_loss: 1.6178 - val_acc: 0.1299\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5077 - acc: 0.2244 - val_loss: 1.6173 - val_acc: 0.1329\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4978 - acc: 0.2272 - val_loss: 1.6168 - val_acc: 0.1329\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4958 - acc: 0.2342 - val_loss: 1.6163 - val_acc: 0.1329\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5069 - acc: 0.2124 - val_loss: 1.6158 - val_acc: 0.1390\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5051 - acc: 0.2135 - val_loss: 1.6153 - val_acc: 0.1420\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5212 - acc: 0.2082 - val_loss: 1.6147 - val_acc: 0.1450\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5081 - acc: 0.2219 - val_loss: 1.6142 - val_acc: 0.1420\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4904 - acc: 0.2437 - val_loss: 1.6137 - val_acc: 0.1450\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4985 - acc: 0.2268 - val_loss: 1.6132 - val_acc: 0.1480\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5079 - acc: 0.2198 - val_loss: 1.6127 - val_acc: 0.1480\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4989 - acc: 0.2247 - val_loss: 1.6123 - val_acc: 0.1480\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4928 - acc: 0.2212 - val_loss: 1.6118 - val_acc: 0.1450\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5049 - acc: 0.2272 - val_loss: 1.6112 - val_acc: 0.1450\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4935 - acc: 0.2420 - val_loss: 1.6107 - val_acc: 0.1480\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5039 - acc: 0.2356 - val_loss: 1.6102 - val_acc: 0.1571\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4993 - acc: 0.2258 - val_loss: 1.6098 - val_acc: 0.1601\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4893 - acc: 0.2469 - val_loss: 1.6094 - val_acc: 0.1631\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5068 - acc: 0.2272 - val_loss: 1.6089 - val_acc: 0.1722\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4944 - acc: 0.2339 - val_loss: 1.6084 - val_acc: 0.1722\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4973 - acc: 0.2353 - val_loss: 1.6079 - val_acc: 0.1752\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4989 - acc: 0.2395 - val_loss: 1.6075 - val_acc: 0.1813\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4988 - acc: 0.2353 - val_loss: 1.6070 - val_acc: 0.1873\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4962 - acc: 0.2346 - val_loss: 1.6066 - val_acc: 0.1934\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4966 - acc: 0.2318 - val_loss: 1.6061 - val_acc: 0.2024\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4986 - acc: 0.2374 - val_loss: 1.6057 - val_acc: 0.1994\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4864 - acc: 0.2356 - val_loss: 1.6052 - val_acc: 0.2085\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4967 - acc: 0.2371 - val_loss: 1.6048 - val_acc: 0.2115\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4883 - acc: 0.2430 - val_loss: 1.6043 - val_acc: 0.2145\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5021 - acc: 0.2328 - val_loss: 1.6038 - val_acc: 0.2145\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4803 - acc: 0.2504 - val_loss: 1.6033 - val_acc: 0.2145\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4754 - acc: 0.2543 - val_loss: 1.6029 - val_acc: 0.2145\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4885 - acc: 0.2445 - val_loss: 1.6024 - val_acc: 0.2115\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4923 - acc: 0.2395 - val_loss: 1.6020 - val_acc: 0.2145\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4809 - acc: 0.2631 - val_loss: 1.6014 - val_acc: 0.2175\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4776 - acc: 0.2529 - val_loss: 1.6010 - val_acc: 0.2175\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4890 - acc: 0.2483 - val_loss: 1.6006 - val_acc: 0.2205\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4918 - acc: 0.2349 - val_loss: 1.6001 - val_acc: 0.2175\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4747 - acc: 0.2670 - val_loss: 1.5996 - val_acc: 0.2205\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4818 - acc: 0.2445 - val_loss: 1.5993 - val_acc: 0.2175\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4849 - acc: 0.2395 - val_loss: 1.5989 - val_acc: 0.2205\n",
      "Epoch 119/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4882 - acc: 0.2399 - val_loss: 1.5984 - val_acc: 0.2205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4851 - acc: 0.2416 - val_loss: 1.5979 - val_acc: 0.2205\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4924 - acc: 0.2452 - val_loss: 1.5975 - val_acc: 0.2175\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4896 - acc: 0.2416 - val_loss: 1.5969 - val_acc: 0.2175\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4845 - acc: 0.2430 - val_loss: 1.5965 - val_acc: 0.2236\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4851 - acc: 0.2497 - val_loss: 1.5961 - val_acc: 0.2266\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4854 - acc: 0.2430 - val_loss: 1.5957 - val_acc: 0.2326\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4786 - acc: 0.2469 - val_loss: 1.5952 - val_acc: 0.2296\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4765 - acc: 0.2462 - val_loss: 1.5948 - val_acc: 0.2447\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4899 - acc: 0.2452 - val_loss: 1.5944 - val_acc: 0.2417\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4814 - acc: 0.2638 - val_loss: 1.5940 - val_acc: 0.2417\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4854 - acc: 0.2441 - val_loss: 1.5936 - val_acc: 0.2477\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4784 - acc: 0.2522 - val_loss: 1.5931 - val_acc: 0.2477\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4892 - acc: 0.2448 - val_loss: 1.5926 - val_acc: 0.2508\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4729 - acc: 0.2561 - val_loss: 1.5921 - val_acc: 0.2538\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4731 - acc: 0.2730 - val_loss: 1.5915 - val_acc: 0.2538\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4762 - acc: 0.2550 - val_loss: 1.5911 - val_acc: 0.2508\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4724 - acc: 0.2712 - val_loss: 1.5907 - val_acc: 0.2538\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4789 - acc: 0.2497 - val_loss: 1.5903 - val_acc: 0.2538\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4833 - acc: 0.2378 - val_loss: 1.5899 - val_acc: 0.2538\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4692 - acc: 0.2617 - val_loss: 1.5895 - val_acc: 0.2538\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4804 - acc: 0.2568 - val_loss: 1.5891 - val_acc: 0.2568\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4820 - acc: 0.2533 - val_loss: 1.5888 - val_acc: 0.2628\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4630 - acc: 0.2688 - val_loss: 1.5883 - val_acc: 0.2628\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4683 - acc: 0.2656 - val_loss: 1.5879 - val_acc: 0.2659\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4704 - acc: 0.2596 - val_loss: 1.5874 - val_acc: 0.2689\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4661 - acc: 0.2543 - val_loss: 1.5870 - val_acc: 0.2719\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4796 - acc: 0.2508 - val_loss: 1.5866 - val_acc: 0.2749\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4627 - acc: 0.2719 - val_loss: 1.5863 - val_acc: 0.2810\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4737 - acc: 0.2585 - val_loss: 1.5859 - val_acc: 0.2900\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4645 - acc: 0.2642 - val_loss: 1.5855 - val_acc: 0.2870\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4756 - acc: 0.2596 - val_loss: 1.5852 - val_acc: 0.2840\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4678 - acc: 0.2578 - val_loss: 1.5848 - val_acc: 0.2870\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4531 - acc: 0.2821 - val_loss: 1.5844 - val_acc: 0.2900\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4683 - acc: 0.2617 - val_loss: 1.5840 - val_acc: 0.2870\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4651 - acc: 0.2631 - val_loss: 1.5836 - val_acc: 0.2900\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4687 - acc: 0.2557 - val_loss: 1.5833 - val_acc: 0.2900\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4751 - acc: 0.2705 - val_loss: 1.5830 - val_acc: 0.2900\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4682 - acc: 0.2518 - val_loss: 1.5826 - val_acc: 0.2931\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4663 - acc: 0.2631 - val_loss: 1.5822 - val_acc: 0.2931\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4647 - acc: 0.2571 - val_loss: 1.5817 - val_acc: 0.2931\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4639 - acc: 0.2712 - val_loss: 1.5813 - val_acc: 0.2931\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4643 - acc: 0.2698 - val_loss: 1.5809 - val_acc: 0.2991\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4611 - acc: 0.2730 - val_loss: 1.5806 - val_acc: 0.2991\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4549 - acc: 0.2751 - val_loss: 1.5802 - val_acc: 0.3021\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4576 - acc: 0.2688 - val_loss: 1.5798 - val_acc: 0.3021\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4722 - acc: 0.2536 - val_loss: 1.5794 - val_acc: 0.3051\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4608 - acc: 0.2723 - val_loss: 1.5790 - val_acc: 0.3051\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4643 - acc: 0.2571 - val_loss: 1.5786 - val_acc: 0.3051\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4593 - acc: 0.2723 - val_loss: 1.5782 - val_acc: 0.3082\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4618 - acc: 0.2652 - val_loss: 1.5778 - val_acc: 0.3082\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4640 - acc: 0.2691 - val_loss: 1.5774 - val_acc: 0.3082\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4470 - acc: 0.2920 - val_loss: 1.5770 - val_acc: 0.3082\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4482 - acc: 0.2737 - val_loss: 1.5766 - val_acc: 0.3082\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4570 - acc: 0.2730 - val_loss: 1.5761 - val_acc: 0.3082\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4634 - acc: 0.2702 - val_loss: 1.5757 - val_acc: 0.3112\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4564 - acc: 0.2776 - val_loss: 1.5754 - val_acc: 0.3112\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4438 - acc: 0.2821 - val_loss: 1.5750 - val_acc: 0.3112\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4596 - acc: 0.2804 - val_loss: 1.5746 - val_acc: 0.3172\n",
      "Epoch 178/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4451 - acc: 0.2867 - val_loss: 1.5741 - val_acc: 0.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4644 - acc: 0.2719 - val_loss: 1.5738 - val_acc: 0.3112\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4503 - acc: 0.2874 - val_loss: 1.5734 - val_acc: 0.3112\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4567 - acc: 0.2754 - val_loss: 1.5731 - val_acc: 0.3112\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4581 - acc: 0.2769 - val_loss: 1.5727 - val_acc: 0.3112\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4572 - acc: 0.2702 - val_loss: 1.5724 - val_acc: 0.3112\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4639 - acc: 0.2758 - val_loss: 1.5721 - val_acc: 0.3172\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4575 - acc: 0.2709 - val_loss: 1.5719 - val_acc: 0.3172\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4484 - acc: 0.2867 - val_loss: 1.5715 - val_acc: 0.3202\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4480 - acc: 0.2765 - val_loss: 1.5710 - val_acc: 0.3233\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4557 - acc: 0.2758 - val_loss: 1.5707 - val_acc: 0.3233\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4443 - acc: 0.2786 - val_loss: 1.5703 - val_acc: 0.3233\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4412 - acc: 0.2790 - val_loss: 1.5699 - val_acc: 0.3263\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4587 - acc: 0.2688 - val_loss: 1.5695 - val_acc: 0.3293\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4396 - acc: 0.2994 - val_loss: 1.5691 - val_acc: 0.3293\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4414 - acc: 0.2864 - val_loss: 1.5686 - val_acc: 0.3293\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4444 - acc: 0.2878 - val_loss: 1.5683 - val_acc: 0.3293\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4470 - acc: 0.2793 - val_loss: 1.5679 - val_acc: 0.3293\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4432 - acc: 0.2969 - val_loss: 1.5675 - val_acc: 0.3293\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4380 - acc: 0.2881 - val_loss: 1.5671 - val_acc: 0.3293\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4465 - acc: 0.2850 - val_loss: 1.5668 - val_acc: 0.3293\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4557 - acc: 0.2751 - val_loss: 1.5664 - val_acc: 0.3293\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4503 - acc: 0.2909 - val_loss: 1.5660 - val_acc: 0.3293\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4504 - acc: 0.2917 - val_loss: 1.5657 - val_acc: 0.3293\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4580 - acc: 0.2688 - val_loss: 1.5653 - val_acc: 0.3293\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4492 - acc: 0.2814 - val_loss: 1.5650 - val_acc: 0.3293\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4363 - acc: 0.3022 - val_loss: 1.5646 - val_acc: 0.3263\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4496 - acc: 0.2828 - val_loss: 1.5642 - val_acc: 0.3263\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4451 - acc: 0.2888 - val_loss: 1.5639 - val_acc: 0.3263\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4517 - acc: 0.2828 - val_loss: 1.5635 - val_acc: 0.3293\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4434 - acc: 0.2850 - val_loss: 1.5631 - val_acc: 0.3293\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4410 - acc: 0.2836 - val_loss: 1.5627 - val_acc: 0.3263\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4310 - acc: 0.2973 - val_loss: 1.5623 - val_acc: 0.3263\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4335 - acc: 0.3015 - val_loss: 1.5620 - val_acc: 0.3263\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4428 - acc: 0.2938 - val_loss: 1.5616 - val_acc: 0.3293\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4473 - acc: 0.2913 - val_loss: 1.5613 - val_acc: 0.3293\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4337 - acc: 0.2934 - val_loss: 1.5611 - val_acc: 0.3293\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4404 - acc: 0.2941 - val_loss: 1.5607 - val_acc: 0.3293\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4441 - acc: 0.2888 - val_loss: 1.5604 - val_acc: 0.3293\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4355 - acc: 0.2860 - val_loss: 1.5600 - val_acc: 0.3293\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4295 - acc: 0.2945 - val_loss: 1.5597 - val_acc: 0.3293\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4325 - acc: 0.3061 - val_loss: 1.5593 - val_acc: 0.3293\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4338 - acc: 0.2945 - val_loss: 1.5590 - val_acc: 0.3293\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4376 - acc: 0.2962 - val_loss: 1.5587 - val_acc: 0.3293\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4237 - acc: 0.3008 - val_loss: 1.5582 - val_acc: 0.3293\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4436 - acc: 0.2857 - val_loss: 1.5580 - val_acc: 0.3293\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4272 - acc: 0.3075 - val_loss: 1.5576 - val_acc: 0.3293\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4427 - acc: 0.2931 - val_loss: 1.5573 - val_acc: 0.3293\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4257 - acc: 0.3033 - val_loss: 1.5569 - val_acc: 0.3323\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4417 - acc: 0.2917 - val_loss: 1.5566 - val_acc: 0.3323\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4268 - acc: 0.2934 - val_loss: 1.5561 - val_acc: 0.3323\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4291 - acc: 0.3033 - val_loss: 1.5559 - val_acc: 0.3323\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4386 - acc: 0.3019 - val_loss: 1.5556 - val_acc: 0.3323\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4346 - acc: 0.3001 - val_loss: 1.5552 - val_acc: 0.3323\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4302 - acc: 0.2962 - val_loss: 1.5548 - val_acc: 0.3323\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4311 - acc: 0.3131 - val_loss: 1.5545 - val_acc: 0.3323\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4249 - acc: 0.3075 - val_loss: 1.5540 - val_acc: 0.3323\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4212 - acc: 0.3160 - val_loss: 1.5537 - val_acc: 0.3323\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4382 - acc: 0.2934 - val_loss: 1.5533 - val_acc: 0.3323\n",
      "Epoch 237/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4201 - acc: 0.3100 - val_loss: 1.5528 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4338 - acc: 0.3086 - val_loss: 1.5525 - val_acc: 0.3323\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4424 - acc: 0.2998 - val_loss: 1.5522 - val_acc: 0.3323\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4206 - acc: 0.3019 - val_loss: 1.5520 - val_acc: 0.3323\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4272 - acc: 0.3008 - val_loss: 1.5517 - val_acc: 0.3323\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4313 - acc: 0.3012 - val_loss: 1.5513 - val_acc: 0.3323\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4187 - acc: 0.3110 - val_loss: 1.5509 - val_acc: 0.3323\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4242 - acc: 0.3075 - val_loss: 1.5505 - val_acc: 0.3323\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4162 - acc: 0.3170 - val_loss: 1.5501 - val_acc: 0.3323\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4263 - acc: 0.3128 - val_loss: 1.5499 - val_acc: 0.3323\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4277 - acc: 0.2941 - val_loss: 1.5497 - val_acc: 0.3323\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4322 - acc: 0.2998 - val_loss: 1.5492 - val_acc: 0.3323\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4200 - acc: 0.3075 - val_loss: 1.5488 - val_acc: 0.3323\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4367 - acc: 0.3117 - val_loss: 1.5486 - val_acc: 0.3323\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4214 - acc: 0.3128 - val_loss: 1.5482 - val_acc: 0.3323\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4368 - acc: 0.2969 - val_loss: 1.5478 - val_acc: 0.3323\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4260 - acc: 0.3082 - val_loss: 1.5475 - val_acc: 0.3323\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4307 - acc: 0.2994 - val_loss: 1.5471 - val_acc: 0.3323\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4247 - acc: 0.3262 - val_loss: 1.5467 - val_acc: 0.3323\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4212 - acc: 0.3117 - val_loss: 1.5464 - val_acc: 0.3323\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4339 - acc: 0.2983 - val_loss: 1.5460 - val_acc: 0.3323\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4260 - acc: 0.3110 - val_loss: 1.5458 - val_acc: 0.3323\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4222 - acc: 0.3068 - val_loss: 1.5455 - val_acc: 0.3323\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4097 - acc: 0.3170 - val_loss: 1.5451 - val_acc: 0.3323\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4125 - acc: 0.3237 - val_loss: 1.5447 - val_acc: 0.3323\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4152 - acc: 0.3156 - val_loss: 1.5443 - val_acc: 0.3323\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4209 - acc: 0.3121 - val_loss: 1.5440 - val_acc: 0.3323\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4283 - acc: 0.3117 - val_loss: 1.5437 - val_acc: 0.3323\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4228 - acc: 0.3244 - val_loss: 1.5434 - val_acc: 0.3323\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4289 - acc: 0.3100 - val_loss: 1.5431 - val_acc: 0.3323\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4291 - acc: 0.3064 - val_loss: 1.5429 - val_acc: 0.3323\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4101 - acc: 0.3202 - val_loss: 1.5425 - val_acc: 0.3323\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4094 - acc: 0.3174 - val_loss: 1.5422 - val_acc: 0.3323\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4258 - acc: 0.2955 - val_loss: 1.5418 - val_acc: 0.3323\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4220 - acc: 0.3064 - val_loss: 1.5415 - val_acc: 0.3323\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4204 - acc: 0.3114 - val_loss: 1.5412 - val_acc: 0.3323\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4196 - acc: 0.3244 - val_loss: 1.5408 - val_acc: 0.3323\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4106 - acc: 0.3100 - val_loss: 1.5405 - val_acc: 0.3323\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4176 - acc: 0.3079 - val_loss: 1.5402 - val_acc: 0.3323\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4116 - acc: 0.3279 - val_loss: 1.5398 - val_acc: 0.3323\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4144 - acc: 0.3124 - val_loss: 1.5397 - val_acc: 0.3323\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4221 - acc: 0.3135 - val_loss: 1.5394 - val_acc: 0.3323\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4074 - acc: 0.3255 - val_loss: 1.5390 - val_acc: 0.3323\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4081 - acc: 0.3262 - val_loss: 1.5387 - val_acc: 0.3323\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4096 - acc: 0.3251 - val_loss: 1.5385 - val_acc: 0.3323\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4034 - acc: 0.3286 - val_loss: 1.5381 - val_acc: 0.3323\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4160 - acc: 0.3103 - val_loss: 1.5377 - val_acc: 0.3323\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4063 - acc: 0.3202 - val_loss: 1.5374 - val_acc: 0.3323\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4158 - acc: 0.3181 - val_loss: 1.5370 - val_acc: 0.3323\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4085 - acc: 0.3269 - val_loss: 1.5367 - val_acc: 0.3323\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4040 - acc: 0.3138 - val_loss: 1.5363 - val_acc: 0.3323\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4163 - acc: 0.3223 - val_loss: 1.5360 - val_acc: 0.3323\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4121 - acc: 0.3272 - val_loss: 1.5357 - val_acc: 0.3323\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4165 - acc: 0.3237 - val_loss: 1.5354 - val_acc: 0.3323\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4154 - acc: 0.3117 - val_loss: 1.5351 - val_acc: 0.3323\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4184 - acc: 0.3209 - val_loss: 1.5348 - val_acc: 0.3323\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4118 - acc: 0.3258 - val_loss: 1.5346 - val_acc: 0.3323\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3973 - acc: 0.3336 - val_loss: 1.5343 - val_acc: 0.3323\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3991 - acc: 0.3283 - val_loss: 1.5338 - val_acc: 0.3323\n",
      "Epoch 296/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4120 - acc: 0.3329 - val_loss: 1.5335 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4045 - acc: 0.3325 - val_loss: 1.5332 - val_acc: 0.3323\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4069 - acc: 0.3244 - val_loss: 1.5330 - val_acc: 0.3323\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4084 - acc: 0.3093 - val_loss: 1.5329 - val_acc: 0.3323\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4111 - acc: 0.3265 - val_loss: 1.5327 - val_acc: 0.3323\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4120 - acc: 0.3167 - val_loss: 1.5324 - val_acc: 0.3323\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4041 - acc: 0.3343 - val_loss: 1.5322 - val_acc: 0.3323\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4096 - acc: 0.3293 - val_loss: 1.5318 - val_acc: 0.3323\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4057 - acc: 0.3269 - val_loss: 1.5315 - val_acc: 0.3323\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4055 - acc: 0.3234 - val_loss: 1.5312 - val_acc: 0.3323\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4096 - acc: 0.3346 - val_loss: 1.5309 - val_acc: 0.3323\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4060 - acc: 0.3251 - val_loss: 1.5307 - val_acc: 0.3323\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4053 - acc: 0.3378 - val_loss: 1.5303 - val_acc: 0.3323\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4015 - acc: 0.3360 - val_loss: 1.5300 - val_acc: 0.3323\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4051 - acc: 0.3350 - val_loss: 1.5296 - val_acc: 0.3323\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4214 - acc: 0.3325 - val_loss: 1.5293 - val_acc: 0.3323\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4082 - acc: 0.3234 - val_loss: 1.5290 - val_acc: 0.3323\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4080 - acc: 0.3265 - val_loss: 1.5288 - val_acc: 0.3323\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3982 - acc: 0.3279 - val_loss: 1.5285 - val_acc: 0.3323\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4003 - acc: 0.3276 - val_loss: 1.5282 - val_acc: 0.3323\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4058 - acc: 0.3219 - val_loss: 1.5280 - val_acc: 0.3323\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4067 - acc: 0.3371 - val_loss: 1.5277 - val_acc: 0.3323\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3968 - acc: 0.3297 - val_loss: 1.5274 - val_acc: 0.3323\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3978 - acc: 0.3374 - val_loss: 1.5271 - val_acc: 0.3323\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4008 - acc: 0.3265 - val_loss: 1.5269 - val_acc: 0.3323\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4079 - acc: 0.3216 - val_loss: 1.5267 - val_acc: 0.3323\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4002 - acc: 0.3332 - val_loss: 1.5263 - val_acc: 0.3323\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4070 - acc: 0.3322 - val_loss: 1.5260 - val_acc: 0.3323\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3975 - acc: 0.3308 - val_loss: 1.5257 - val_acc: 0.3323\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4020 - acc: 0.3163 - val_loss: 1.5255 - val_acc: 0.3323\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4013 - acc: 0.3198 - val_loss: 1.5253 - val_acc: 0.3323\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4066 - acc: 0.3325 - val_loss: 1.5251 - val_acc: 0.3323\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3907 - acc: 0.3501 - val_loss: 1.5248 - val_acc: 0.3323\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4094 - acc: 0.3269 - val_loss: 1.5246 - val_acc: 0.3323\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3953 - acc: 0.3322 - val_loss: 1.5244 - val_acc: 0.3323\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3954 - acc: 0.3371 - val_loss: 1.5242 - val_acc: 0.3323\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4032 - acc: 0.3322 - val_loss: 1.5238 - val_acc: 0.3323\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4007 - acc: 0.3360 - val_loss: 1.5235 - val_acc: 0.3323\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3999 - acc: 0.3392 - val_loss: 1.5232 - val_acc: 0.3323\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3930 - acc: 0.3343 - val_loss: 1.5230 - val_acc: 0.3323\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3890 - acc: 0.3498 - val_loss: 1.5227 - val_acc: 0.3323\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3945 - acc: 0.3473 - val_loss: 1.5224 - val_acc: 0.3323\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3949 - acc: 0.3378 - val_loss: 1.5222 - val_acc: 0.3323\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3995 - acc: 0.3248 - val_loss: 1.5220 - val_acc: 0.3323\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4006 - acc: 0.3413 - val_loss: 1.5217 - val_acc: 0.3323\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3924 - acc: 0.3300 - val_loss: 1.5216 - val_acc: 0.3323\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3879 - acc: 0.3399 - val_loss: 1.5213 - val_acc: 0.3323\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3935 - acc: 0.3374 - val_loss: 1.5210 - val_acc: 0.3323\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3844 - acc: 0.3491 - val_loss: 1.5209 - val_acc: 0.3323\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3803 - acc: 0.3466 - val_loss: 1.5205 - val_acc: 0.3323\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.4053 - acc: 0.3343 - val_loss: 1.5204 - val_acc: 0.3323\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3977 - acc: 0.3353 - val_loss: 1.5201 - val_acc: 0.3323\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3907 - acc: 0.3413 - val_loss: 1.5198 - val_acc: 0.3323\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3941 - acc: 0.3385 - val_loss: 1.5194 - val_acc: 0.3323\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3863 - acc: 0.3392 - val_loss: 1.5191 - val_acc: 0.3323\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3852 - acc: 0.3484 - val_loss: 1.5187 - val_acc: 0.3323\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3762 - acc: 0.3529 - val_loss: 1.5186 - val_acc: 0.3323\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3939 - acc: 0.3392 - val_loss: 1.5183 - val_acc: 0.3323\n",
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3867 - acc: 0.3473 - val_loss: 1.5181 - val_acc: 0.3323\n",
      "Epoch 355/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3983 - acc: 0.3332 - val_loss: 1.5180 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3827 - acc: 0.3431 - val_loss: 1.5176 - val_acc: 0.3323\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3984 - acc: 0.3378 - val_loss: 1.5173 - val_acc: 0.3323\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3959 - acc: 0.3371 - val_loss: 1.5171 - val_acc: 0.3323\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3826 - acc: 0.3385 - val_loss: 1.5168 - val_acc: 0.3323\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3833 - acc: 0.3427 - val_loss: 1.5165 - val_acc: 0.3323\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3818 - acc: 0.3466 - val_loss: 1.5163 - val_acc: 0.3323\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3999 - acc: 0.3381 - val_loss: 1.5162 - val_acc: 0.3323\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3804 - acc: 0.3477 - val_loss: 1.5159 - val_acc: 0.3323\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3787 - acc: 0.3565 - val_loss: 1.5156 - val_acc: 0.3323\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3723 - acc: 0.3505 - val_loss: 1.5154 - val_acc: 0.3323\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3924 - acc: 0.3381 - val_loss: 1.5153 - val_acc: 0.3323\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3875 - acc: 0.3434 - val_loss: 1.5150 - val_acc: 0.3323\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3916 - acc: 0.3297 - val_loss: 1.5149 - val_acc: 0.3323\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3921 - acc: 0.3322 - val_loss: 1.5145 - val_acc: 0.3323\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3878 - acc: 0.3396 - val_loss: 1.5142 - val_acc: 0.3323\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3958 - acc: 0.3448 - val_loss: 1.5140 - val_acc: 0.3323\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3855 - acc: 0.3536 - val_loss: 1.5138 - val_acc: 0.3323\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3841 - acc: 0.3575 - val_loss: 1.5135 - val_acc: 0.3323\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3968 - acc: 0.3374 - val_loss: 1.5133 - val_acc: 0.3323\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3794 - acc: 0.3413 - val_loss: 1.5132 - val_acc: 0.3323\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3809 - acc: 0.3477 - val_loss: 1.5130 - val_acc: 0.3323\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3820 - acc: 0.3413 - val_loss: 1.5127 - val_acc: 0.3323\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3857 - acc: 0.3565 - val_loss: 1.5125 - val_acc: 0.3323\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3803 - acc: 0.3413 - val_loss: 1.5121 - val_acc: 0.3323\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3903 - acc: 0.3473 - val_loss: 1.5119 - val_acc: 0.3323\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3914 - acc: 0.3417 - val_loss: 1.5118 - val_acc: 0.3323\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3846 - acc: 0.3455 - val_loss: 1.5113 - val_acc: 0.3323\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3941 - acc: 0.3420 - val_loss: 1.5111 - val_acc: 0.3323\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3817 - acc: 0.3424 - val_loss: 1.5108 - val_acc: 0.3323\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3924 - acc: 0.3410 - val_loss: 1.5107 - val_acc: 0.3323\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3871 - acc: 0.3484 - val_loss: 1.5105 - val_acc: 0.3323\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3852 - acc: 0.3431 - val_loss: 1.5103 - val_acc: 0.3323\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3973 - acc: 0.3385 - val_loss: 1.5101 - val_acc: 0.3323\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3919 - acc: 0.3424 - val_loss: 1.5099 - val_acc: 0.3323\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3688 - acc: 0.3614 - val_loss: 1.5096 - val_acc: 0.3323\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3769 - acc: 0.3529 - val_loss: 1.5092 - val_acc: 0.3323\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3872 - acc: 0.3462 - val_loss: 1.5091 - val_acc: 0.3323\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3887 - acc: 0.3427 - val_loss: 1.5087 - val_acc: 0.3323\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3789 - acc: 0.3434 - val_loss: 1.5085 - val_acc: 0.3323\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3814 - acc: 0.3536 - val_loss: 1.5083 - val_acc: 0.3323\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3860 - acc: 0.3544 - val_loss: 1.5079 - val_acc: 0.3323\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3875 - acc: 0.3547 - val_loss: 1.5077 - val_acc: 0.3323\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3828 - acc: 0.3424 - val_loss: 1.5074 - val_acc: 0.3323\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3689 - acc: 0.3515 - val_loss: 1.5072 - val_acc: 0.3323\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3856 - acc: 0.3487 - val_loss: 1.5070 - val_acc: 0.3323\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3722 - acc: 0.3491 - val_loss: 1.5068 - val_acc: 0.3323\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3913 - acc: 0.3459 - val_loss: 1.5068 - val_acc: 0.3323\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3707 - acc: 0.3610 - val_loss: 1.5065 - val_acc: 0.3323\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3748 - acc: 0.3600 - val_loss: 1.5063 - val_acc: 0.3323\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4001 - acc: 0.3371 - val_loss: 1.5062 - val_acc: 0.3323\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3879 - acc: 0.3413 - val_loss: 1.5060 - val_acc: 0.3323\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3735 - acc: 0.3508 - val_loss: 1.5057 - val_acc: 0.3323\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3807 - acc: 0.3466 - val_loss: 1.5054 - val_acc: 0.3323\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3728 - acc: 0.3529 - val_loss: 1.5051 - val_acc: 0.3323\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3714 - acc: 0.3674 - val_loss: 1.5050 - val_acc: 0.3323\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3712 - acc: 0.3533 - val_loss: 1.5047 - val_acc: 0.3323\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3793 - acc: 0.3480 - val_loss: 1.5043 - val_acc: 0.3323\n",
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3813 - acc: 0.3572 - val_loss: 1.5043 - val_acc: 0.3323\n",
      "Epoch 414/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3777 - acc: 0.3508 - val_loss: 1.5041 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3794 - acc: 0.3522 - val_loss: 1.5039 - val_acc: 0.3323\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3742 - acc: 0.3554 - val_loss: 1.5036 - val_acc: 0.3323\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3975 - acc: 0.3480 - val_loss: 1.5033 - val_acc: 0.3323\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3670 - acc: 0.3568 - val_loss: 1.5031 - val_acc: 0.3323\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3801 - acc: 0.3572 - val_loss: 1.5029 - val_acc: 0.3323\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3724 - acc: 0.3565 - val_loss: 1.5028 - val_acc: 0.3323\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3646 - acc: 0.3579 - val_loss: 1.5026 - val_acc: 0.3323\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3789 - acc: 0.3540 - val_loss: 1.5024 - val_acc: 0.3323\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3754 - acc: 0.3625 - val_loss: 1.5022 - val_acc: 0.3323\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3678 - acc: 0.3614 - val_loss: 1.5019 - val_acc: 0.3323\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3771 - acc: 0.3505 - val_loss: 1.5017 - val_acc: 0.3323\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3769 - acc: 0.3554 - val_loss: 1.5014 - val_acc: 0.3323\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3676 - acc: 0.3628 - val_loss: 1.5012 - val_acc: 0.3323\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3722 - acc: 0.3603 - val_loss: 1.5010 - val_acc: 0.3323\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3824 - acc: 0.3522 - val_loss: 1.5008 - val_acc: 0.3323\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3757 - acc: 0.3505 - val_loss: 1.5005 - val_acc: 0.3323\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3704 - acc: 0.3536 - val_loss: 1.5006 - val_acc: 0.3323\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3729 - acc: 0.3547 - val_loss: 1.5005 - val_acc: 0.3323\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3691 - acc: 0.3554 - val_loss: 1.5002 - val_acc: 0.3323\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3788 - acc: 0.3586 - val_loss: 1.5000 - val_acc: 0.3323\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3675 - acc: 0.3625 - val_loss: 1.4998 - val_acc: 0.3323\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3880 - acc: 0.3406 - val_loss: 1.4997 - val_acc: 0.3323\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3691 - acc: 0.3642 - val_loss: 1.4994 - val_acc: 0.3323\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3764 - acc: 0.3586 - val_loss: 1.4992 - val_acc: 0.3323\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3789 - acc: 0.3579 - val_loss: 1.4990 - val_acc: 0.3323\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3858 - acc: 0.3501 - val_loss: 1.4988 - val_acc: 0.3323\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3835 - acc: 0.3427 - val_loss: 1.4986 - val_acc: 0.3323\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3847 - acc: 0.3480 - val_loss: 1.4984 - val_acc: 0.3323\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3741 - acc: 0.3639 - val_loss: 1.4982 - val_acc: 0.3323\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3754 - acc: 0.3473 - val_loss: 1.4981 - val_acc: 0.3323\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3798 - acc: 0.3536 - val_loss: 1.4978 - val_acc: 0.3323\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3791 - acc: 0.3501 - val_loss: 1.4976 - val_acc: 0.3323\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3656 - acc: 0.3642 - val_loss: 1.4975 - val_acc: 0.3323\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3756 - acc: 0.3501 - val_loss: 1.4974 - val_acc: 0.3323\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3714 - acc: 0.3533 - val_loss: 1.4972 - val_acc: 0.3323\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3621 - acc: 0.3614 - val_loss: 1.4970 - val_acc: 0.3323\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3708 - acc: 0.3558 - val_loss: 1.4968 - val_acc: 0.3323\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3675 - acc: 0.3561 - val_loss: 1.4966 - val_acc: 0.3323\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3647 - acc: 0.3586 - val_loss: 1.4965 - val_acc: 0.3323\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3765 - acc: 0.3561 - val_loss: 1.4963 - val_acc: 0.3323\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3681 - acc: 0.3646 - val_loss: 1.4962 - val_acc: 0.3323\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3754 - acc: 0.3448 - val_loss: 1.4960 - val_acc: 0.3323\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3731 - acc: 0.3522 - val_loss: 1.4958 - val_acc: 0.3323\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3550 - acc: 0.3695 - val_loss: 1.4956 - val_acc: 0.3323\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3605 - acc: 0.3603 - val_loss: 1.4955 - val_acc: 0.3323\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3682 - acc: 0.3610 - val_loss: 1.4954 - val_acc: 0.3323\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3758 - acc: 0.3544 - val_loss: 1.4953 - val_acc: 0.3323\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3756 - acc: 0.3417 - val_loss: 1.4951 - val_acc: 0.3323\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3672 - acc: 0.3670 - val_loss: 1.4949 - val_acc: 0.3323\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3821 - acc: 0.3466 - val_loss: 1.4946 - val_acc: 0.3323\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3761 - acc: 0.3572 - val_loss: 1.4944 - val_acc: 0.3323\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3683 - acc: 0.3625 - val_loss: 1.4943 - val_acc: 0.3323\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3782 - acc: 0.3515 - val_loss: 1.4940 - val_acc: 0.3323\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3647 - acc: 0.3565 - val_loss: 1.4938 - val_acc: 0.3323\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3744 - acc: 0.3470 - val_loss: 1.4937 - val_acc: 0.3323\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3655 - acc: 0.3593 - val_loss: 1.4935 - val_acc: 0.3323\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3754 - acc: 0.3589 - val_loss: 1.4933 - val_acc: 0.3323\n",
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3626 - acc: 0.3663 - val_loss: 1.4932 - val_acc: 0.3323\n",
      "Epoch 473/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3684 - acc: 0.3720 - val_loss: 1.4930 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3608 - acc: 0.3734 - val_loss: 1.4927 - val_acc: 0.3323\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3705 - acc: 0.3610 - val_loss: 1.4926 - val_acc: 0.3323\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3673 - acc: 0.3533 - val_loss: 1.4925 - val_acc: 0.3323\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3552 - acc: 0.3695 - val_loss: 1.4923 - val_acc: 0.3323\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3775 - acc: 0.3470 - val_loss: 1.4922 - val_acc: 0.3323\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3707 - acc: 0.3544 - val_loss: 1.4919 - val_acc: 0.3323\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3730 - acc: 0.3593 - val_loss: 1.4918 - val_acc: 0.3323\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3630 - acc: 0.3554 - val_loss: 1.4916 - val_acc: 0.3323\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3627 - acc: 0.3621 - val_loss: 1.4916 - val_acc: 0.3323\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3613 - acc: 0.3716 - val_loss: 1.4913 - val_acc: 0.3323\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3629 - acc: 0.3579 - val_loss: 1.4911 - val_acc: 0.3323\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3677 - acc: 0.3575 - val_loss: 1.4910 - val_acc: 0.3323\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3661 - acc: 0.3610 - val_loss: 1.4909 - val_acc: 0.3323\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3699 - acc: 0.3727 - val_loss: 1.4909 - val_acc: 0.3323\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3641 - acc: 0.3593 - val_loss: 1.4907 - val_acc: 0.3323\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3592 - acc: 0.3698 - val_loss: 1.4905 - val_acc: 0.3323\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3659 - acc: 0.3501 - val_loss: 1.4904 - val_acc: 0.3323\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3613 - acc: 0.3568 - val_loss: 1.4902 - val_acc: 0.3323\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3681 - acc: 0.3586 - val_loss: 1.4901 - val_acc: 0.3323\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3656 - acc: 0.3607 - val_loss: 1.4898 - val_acc: 0.3323\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3775 - acc: 0.3512 - val_loss: 1.4897 - val_acc: 0.3323\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3708 - acc: 0.3688 - val_loss: 1.4896 - val_acc: 0.3323\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3664 - acc: 0.3572 - val_loss: 1.4895 - val_acc: 0.3323\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3504 - acc: 0.3758 - val_loss: 1.4894 - val_acc: 0.3323\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3707 - acc: 0.3582 - val_loss: 1.4892 - val_acc: 0.3323\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3685 - acc: 0.3568 - val_loss: 1.4889 - val_acc: 0.3323\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3692 - acc: 0.3501 - val_loss: 1.4887 - val_acc: 0.3323\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3633 - acc: 0.3653 - val_loss: 1.4886 - val_acc: 0.3323\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3715 - acc: 0.3610 - val_loss: 1.4884 - val_acc: 0.3323\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3613 - acc: 0.3610 - val_loss: 1.4884 - val_acc: 0.3323\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3604 - acc: 0.3621 - val_loss: 1.4882 - val_acc: 0.3323\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3583 - acc: 0.3677 - val_loss: 1.4880 - val_acc: 0.3323\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3641 - acc: 0.3667 - val_loss: 1.4879 - val_acc: 0.3323\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3655 - acc: 0.3593 - val_loss: 1.4878 - val_acc: 0.3323\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3648 - acc: 0.3625 - val_loss: 1.4877 - val_acc: 0.3323\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3631 - acc: 0.3596 - val_loss: 1.4875 - val_acc: 0.3323\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3785 - acc: 0.3547 - val_loss: 1.4873 - val_acc: 0.3323\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3613 - acc: 0.3720 - val_loss: 1.4872 - val_acc: 0.3323\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3672 - acc: 0.3544 - val_loss: 1.4871 - val_acc: 0.3323\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3612 - acc: 0.3660 - val_loss: 1.4870 - val_acc: 0.3323\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3723 - acc: 0.3526 - val_loss: 1.4867 - val_acc: 0.3323\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3670 - acc: 0.3512 - val_loss: 1.4866 - val_acc: 0.3323\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3614 - acc: 0.3649 - val_loss: 1.4866 - val_acc: 0.3323\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3580 - acc: 0.3572 - val_loss: 1.4863 - val_acc: 0.3323\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3505 - acc: 0.3727 - val_loss: 1.4861 - val_acc: 0.3323\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3499 - acc: 0.3688 - val_loss: 1.4859 - val_acc: 0.3323\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3706 - acc: 0.3625 - val_loss: 1.4858 - val_acc: 0.3323\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3567 - acc: 0.3663 - val_loss: 1.4856 - val_acc: 0.3323\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3661 - acc: 0.3610 - val_loss: 1.4855 - val_acc: 0.3323\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3609 - acc: 0.3667 - val_loss: 1.4853 - val_acc: 0.3323\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3500 - acc: 0.3706 - val_loss: 1.4852 - val_acc: 0.3323\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3479 - acc: 0.3674 - val_loss: 1.4850 - val_acc: 0.3323\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3674 - acc: 0.3642 - val_loss: 1.4848 - val_acc: 0.3323\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3517 - acc: 0.3684 - val_loss: 1.4846 - val_acc: 0.3323\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3607 - acc: 0.3533 - val_loss: 1.4843 - val_acc: 0.3323\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3442 - acc: 0.3681 - val_loss: 1.4842 - val_acc: 0.3323\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3556 - acc: 0.3670 - val_loss: 1.4839 - val_acc: 0.3323\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3505 - acc: 0.3765 - val_loss: 1.4838 - val_acc: 0.3323\n",
      "Epoch 532/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3648 - acc: 0.3635 - val_loss: 1.4837 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3547 - acc: 0.3734 - val_loss: 1.4835 - val_acc: 0.3323\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3724 - acc: 0.3639 - val_loss: 1.4833 - val_acc: 0.3323\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3675 - acc: 0.3649 - val_loss: 1.4833 - val_acc: 0.3323\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3561 - acc: 0.3628 - val_loss: 1.4832 - val_acc: 0.3323\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3657 - acc: 0.3614 - val_loss: 1.4830 - val_acc: 0.3323\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3673 - acc: 0.3589 - val_loss: 1.4829 - val_acc: 0.3323\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3603 - acc: 0.3607 - val_loss: 1.4827 - val_acc: 0.3323\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3680 - acc: 0.3610 - val_loss: 1.4825 - val_acc: 0.3323\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3589 - acc: 0.3755 - val_loss: 1.4822 - val_acc: 0.3323\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3592 - acc: 0.3667 - val_loss: 1.4823 - val_acc: 0.3323\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3598 - acc: 0.3684 - val_loss: 1.4821 - val_acc: 0.3323\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3580 - acc: 0.3727 - val_loss: 1.4820 - val_acc: 0.3323\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3545 - acc: 0.3677 - val_loss: 1.4819 - val_acc: 0.3323\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3643 - acc: 0.3674 - val_loss: 1.4817 - val_acc: 0.3323\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3710 - acc: 0.3565 - val_loss: 1.4816 - val_acc: 0.3323\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3560 - acc: 0.3582 - val_loss: 1.4815 - val_acc: 0.3323\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3570 - acc: 0.3632 - val_loss: 1.4813 - val_acc: 0.3323\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3517 - acc: 0.3660 - val_loss: 1.4811 - val_acc: 0.3323\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3591 - acc: 0.3653 - val_loss: 1.4809 - val_acc: 0.3323\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3580 - acc: 0.3617 - val_loss: 1.4808 - val_acc: 0.3323\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3527 - acc: 0.3695 - val_loss: 1.4807 - val_acc: 0.3323\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3624 - acc: 0.3653 - val_loss: 1.4807 - val_acc: 0.3323\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3666 - acc: 0.3656 - val_loss: 1.4807 - val_acc: 0.3323\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3559 - acc: 0.3614 - val_loss: 1.4805 - val_acc: 0.3323\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3693 - acc: 0.3586 - val_loss: 1.4804 - val_acc: 0.3323\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3459 - acc: 0.3709 - val_loss: 1.4802 - val_acc: 0.3323\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3464 - acc: 0.3839 - val_loss: 1.4800 - val_acc: 0.3323\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3437 - acc: 0.3723 - val_loss: 1.4799 - val_acc: 0.3323\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3633 - acc: 0.3621 - val_loss: 1.4798 - val_acc: 0.3323\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3530 - acc: 0.3769 - val_loss: 1.4796 - val_acc: 0.3323\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3680 - acc: 0.3554 - val_loss: 1.4794 - val_acc: 0.3323\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3511 - acc: 0.3656 - val_loss: 1.4793 - val_acc: 0.3323\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3554 - acc: 0.3713 - val_loss: 1.4791 - val_acc: 0.3323\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3480 - acc: 0.3702 - val_loss: 1.4790 - val_acc: 0.3323\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3481 - acc: 0.3653 - val_loss: 1.4789 - val_acc: 0.3323\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3488 - acc: 0.3811 - val_loss: 1.4788 - val_acc: 0.3323\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3590 - acc: 0.3818 - val_loss: 1.4787 - val_acc: 0.3323\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3506 - acc: 0.3667 - val_loss: 1.4787 - val_acc: 0.3323\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3531 - acc: 0.3695 - val_loss: 1.4785 - val_acc: 0.3323\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3613 - acc: 0.3600 - val_loss: 1.4783 - val_acc: 0.3323\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3524 - acc: 0.3702 - val_loss: 1.4780 - val_acc: 0.3323\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3583 - acc: 0.3723 - val_loss: 1.4778 - val_acc: 0.3323\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3554 - acc: 0.3706 - val_loss: 1.4776 - val_acc: 0.3323\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3448 - acc: 0.3691 - val_loss: 1.4774 - val_acc: 0.3323\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3558 - acc: 0.3709 - val_loss: 1.4772 - val_acc: 0.3323\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3477 - acc: 0.3765 - val_loss: 1.4770 - val_acc: 0.3323\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3369 - acc: 0.3667 - val_loss: 1.4769 - val_acc: 0.3323\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3501 - acc: 0.3737 - val_loss: 1.4768 - val_acc: 0.3323\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3556 - acc: 0.3751 - val_loss: 1.4767 - val_acc: 0.3323\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3511 - acc: 0.3621 - val_loss: 1.4766 - val_acc: 0.3323\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3329 - acc: 0.3899 - val_loss: 1.4764 - val_acc: 0.3323\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3563 - acc: 0.3698 - val_loss: 1.4762 - val_acc: 0.3323\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3640 - acc: 0.3526 - val_loss: 1.4760 - val_acc: 0.3323\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3462 - acc: 0.3684 - val_loss: 1.4758 - val_acc: 0.3323\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3523 - acc: 0.3688 - val_loss: 1.4757 - val_acc: 0.3323\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3563 - acc: 0.3691 - val_loss: 1.4756 - val_acc: 0.3323\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3402 - acc: 0.3769 - val_loss: 1.4755 - val_acc: 0.3323\n",
      "Epoch 590/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3568 - acc: 0.3713 - val_loss: 1.4753 - val_acc: 0.3323\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3529 - acc: 0.3779 - val_loss: 1.4753 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3461 - acc: 0.3779 - val_loss: 1.4752 - val_acc: 0.3323\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3448 - acc: 0.3600 - val_loss: 1.4752 - val_acc: 0.3323\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3406 - acc: 0.3787 - val_loss: 1.4750 - val_acc: 0.3323\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3618 - acc: 0.3691 - val_loss: 1.4749 - val_acc: 0.3323\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3686 - acc: 0.3653 - val_loss: 1.4748 - val_acc: 0.3323\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3582 - acc: 0.3649 - val_loss: 1.4746 - val_acc: 0.3323\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3483 - acc: 0.3649 - val_loss: 1.4746 - val_acc: 0.3323\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3475 - acc: 0.3642 - val_loss: 1.4745 - val_acc: 0.3323\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3546 - acc: 0.3660 - val_loss: 1.4744 - val_acc: 0.3323\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3580 - acc: 0.3713 - val_loss: 1.4743 - val_acc: 0.3323\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3524 - acc: 0.3653 - val_loss: 1.4742 - val_acc: 0.3323\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3451 - acc: 0.3755 - val_loss: 1.4741 - val_acc: 0.3323\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3603 - acc: 0.3625 - val_loss: 1.4739 - val_acc: 0.3323\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3499 - acc: 0.3702 - val_loss: 1.4738 - val_acc: 0.3323\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3506 - acc: 0.3684 - val_loss: 1.4736 - val_acc: 0.3323\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3509 - acc: 0.3691 - val_loss: 1.4735 - val_acc: 0.3323\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3539 - acc: 0.3632 - val_loss: 1.4734 - val_acc: 0.3323\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3532 - acc: 0.3762 - val_loss: 1.4734 - val_acc: 0.3323\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3490 - acc: 0.3674 - val_loss: 1.4732 - val_acc: 0.3323\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3307 - acc: 0.3853 - val_loss: 1.4732 - val_acc: 0.3323\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3517 - acc: 0.3667 - val_loss: 1.4731 - val_acc: 0.3323\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3458 - acc: 0.3709 - val_loss: 1.4729 - val_acc: 0.3323\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3514 - acc: 0.3734 - val_loss: 1.4729 - val_acc: 0.3323\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3520 - acc: 0.3670 - val_loss: 1.4728 - val_acc: 0.3323\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3559 - acc: 0.3621 - val_loss: 1.4728 - val_acc: 0.3323\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3450 - acc: 0.3688 - val_loss: 1.4726 - val_acc: 0.3323\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3443 - acc: 0.3709 - val_loss: 1.4724 - val_acc: 0.3323\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3423 - acc: 0.3713 - val_loss: 1.4722 - val_acc: 0.3323\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3514 - acc: 0.3723 - val_loss: 1.4720 - val_acc: 0.3323\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3492 - acc: 0.3758 - val_loss: 1.4720 - val_acc: 0.3323\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3579 - acc: 0.3639 - val_loss: 1.4719 - val_acc: 0.3323\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3462 - acc: 0.3797 - val_loss: 1.4717 - val_acc: 0.3323\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3580 - acc: 0.3670 - val_loss: 1.4716 - val_acc: 0.3323\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3404 - acc: 0.3667 - val_loss: 1.4714 - val_acc: 0.3323\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3513 - acc: 0.3632 - val_loss: 1.4713 - val_acc: 0.3323\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3532 - acc: 0.3670 - val_loss: 1.4710 - val_acc: 0.3323\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3463 - acc: 0.3741 - val_loss: 1.4709 - val_acc: 0.3323\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3394 - acc: 0.3783 - val_loss: 1.4709 - val_acc: 0.3323\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3604 - acc: 0.3610 - val_loss: 1.4707 - val_acc: 0.3323\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3595 - acc: 0.3494 - val_loss: 1.4706 - val_acc: 0.3323\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3416 - acc: 0.3720 - val_loss: 1.4704 - val_acc: 0.3323\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3541 - acc: 0.3621 - val_loss: 1.4703 - val_acc: 0.3323\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3514 - acc: 0.3748 - val_loss: 1.4702 - val_acc: 0.3323\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3589 - acc: 0.3586 - val_loss: 1.4703 - val_acc: 0.3323\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3451 - acc: 0.3829 - val_loss: 1.4702 - val_acc: 0.3323\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3438 - acc: 0.3723 - val_loss: 1.4700 - val_acc: 0.3323\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3376 - acc: 0.3825 - val_loss: 1.4699 - val_acc: 0.3323\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3537 - acc: 0.3674 - val_loss: 1.4698 - val_acc: 0.3323\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3512 - acc: 0.3790 - val_loss: 1.4697 - val_acc: 0.3323\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3536 - acc: 0.3621 - val_loss: 1.4696 - val_acc: 0.3323\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3355 - acc: 0.3829 - val_loss: 1.4696 - val_acc: 0.3323\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3467 - acc: 0.3744 - val_loss: 1.4694 - val_acc: 0.3323\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3587 - acc: 0.3695 - val_loss: 1.4693 - val_acc: 0.3323\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3536 - acc: 0.3706 - val_loss: 1.4693 - val_acc: 0.3323\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3488 - acc: 0.3681 - val_loss: 1.4692 - val_acc: 0.3323\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3443 - acc: 0.3755 - val_loss: 1.4691 - val_acc: 0.3323\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 21us/step - loss: 1.3488 - acc: 0.3709 - val_loss: 1.4688 - val_acc: 0.3323\n",
      "Epoch 649/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3521 - acc: 0.3695 - val_loss: 1.4687 - val_acc: 0.3323\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3489 - acc: 0.3653 - val_loss: 1.4685 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3517 - acc: 0.3625 - val_loss: 1.4684 - val_acc: 0.3323\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3505 - acc: 0.3772 - val_loss: 1.4683 - val_acc: 0.3323\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3475 - acc: 0.3758 - val_loss: 1.4683 - val_acc: 0.3323\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3568 - acc: 0.3660 - val_loss: 1.4682 - val_acc: 0.3323\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3533 - acc: 0.3617 - val_loss: 1.4681 - val_acc: 0.3323\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3416 - acc: 0.3836 - val_loss: 1.4680 - val_acc: 0.3323\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3401 - acc: 0.3762 - val_loss: 1.4678 - val_acc: 0.3323\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3521 - acc: 0.3688 - val_loss: 1.4677 - val_acc: 0.3323\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3480 - acc: 0.3797 - val_loss: 1.4675 - val_acc: 0.3323\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3554 - acc: 0.3706 - val_loss: 1.4673 - val_acc: 0.3323\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3423 - acc: 0.3727 - val_loss: 1.4672 - val_acc: 0.3323\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3541 - acc: 0.3691 - val_loss: 1.4671 - val_acc: 0.3323\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3376 - acc: 0.3765 - val_loss: 1.4670 - val_acc: 0.3323\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3417 - acc: 0.3864 - val_loss: 1.4668 - val_acc: 0.3323\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3446 - acc: 0.3748 - val_loss: 1.4667 - val_acc: 0.3323\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3492 - acc: 0.3723 - val_loss: 1.4667 - val_acc: 0.3323\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3487 - acc: 0.3691 - val_loss: 1.4665 - val_acc: 0.3323\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3538 - acc: 0.3776 - val_loss: 1.4666 - val_acc: 0.3323\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3474 - acc: 0.3684 - val_loss: 1.4666 - val_acc: 0.3323\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3473 - acc: 0.3709 - val_loss: 1.4663 - val_acc: 0.3323\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3440 - acc: 0.3653 - val_loss: 1.4663 - val_acc: 0.3323\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3374 - acc: 0.3871 - val_loss: 1.4661 - val_acc: 0.3323\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3317 - acc: 0.3769 - val_loss: 1.4661 - val_acc: 0.3323\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3456 - acc: 0.3649 - val_loss: 1.4659 - val_acc: 0.3323\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3431 - acc: 0.3751 - val_loss: 1.4658 - val_acc: 0.3323\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3400 - acc: 0.3716 - val_loss: 1.4657 - val_acc: 0.3323\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3492 - acc: 0.3667 - val_loss: 1.4657 - val_acc: 0.3323\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3441 - acc: 0.3748 - val_loss: 1.4655 - val_acc: 0.3323\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3510 - acc: 0.3681 - val_loss: 1.4652 - val_acc: 0.3323\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3352 - acc: 0.3744 - val_loss: 1.4651 - val_acc: 0.3323\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3272 - acc: 0.3734 - val_loss: 1.4650 - val_acc: 0.3323\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3435 - acc: 0.3730 - val_loss: 1.4649 - val_acc: 0.3323\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3388 - acc: 0.3695 - val_loss: 1.4649 - val_acc: 0.3323\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3356 - acc: 0.3779 - val_loss: 1.4648 - val_acc: 0.3323\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3387 - acc: 0.3702 - val_loss: 1.4648 - val_acc: 0.3323\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3415 - acc: 0.3744 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3418 - acc: 0.3709 - val_loss: 1.4646 - val_acc: 0.3323\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3523 - acc: 0.3716 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3320 - acc: 0.3783 - val_loss: 1.4645 - val_acc: 0.3323\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3236 - acc: 0.3815 - val_loss: 1.4645 - val_acc: 0.3323\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3571 - acc: 0.3677 - val_loss: 1.4644 - val_acc: 0.3323\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3479 - acc: 0.3727 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3380 - acc: 0.3723 - val_loss: 1.4642 - val_acc: 0.3323\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3497 - acc: 0.3741 - val_loss: 1.4642 - val_acc: 0.3323\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3407 - acc: 0.3783 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3491 - acc: 0.3625 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3405 - acc: 0.3646 - val_loss: 1.4637 - val_acc: 0.3323\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3389 - acc: 0.3815 - val_loss: 1.4636 - val_acc: 0.3323\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3500 - acc: 0.3610 - val_loss: 1.4634 - val_acc: 0.3323\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3380 - acc: 0.3691 - val_loss: 1.4633 - val_acc: 0.3323\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3431 - acc: 0.3744 - val_loss: 1.4631 - val_acc: 0.3323\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3374 - acc: 0.3797 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3313 - acc: 0.3850 - val_loss: 1.4629 - val_acc: 0.3323\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3387 - acc: 0.3713 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3396 - acc: 0.3755 - val_loss: 1.4626 - val_acc: 0.3323\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3409 - acc: 0.3734 - val_loss: 1.4624 - val_acc: 0.3323\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3427 - acc: 0.3769 - val_loss: 1.4623 - val_acc: 0.3323\n",
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3371 - acc: 0.3892 - val_loss: 1.4622 - val_acc: 0.3323\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3355 - acc: 0.3709 - val_loss: 1.4622 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3411 - acc: 0.3642 - val_loss: 1.4620 - val_acc: 0.3323\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3382 - acc: 0.3741 - val_loss: 1.4620 - val_acc: 0.3323\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3419 - acc: 0.3758 - val_loss: 1.4618 - val_acc: 0.3323\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3269 - acc: 0.3882 - val_loss: 1.4617 - val_acc: 0.3323\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3458 - acc: 0.3702 - val_loss: 1.4617 - val_acc: 0.3323\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3455 - acc: 0.3787 - val_loss: 1.4615 - val_acc: 0.3323\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3313 - acc: 0.3850 - val_loss: 1.4614 - val_acc: 0.3323\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3520 - acc: 0.3758 - val_loss: 1.4613 - val_acc: 0.3323\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3310 - acc: 0.3825 - val_loss: 1.4613 - val_acc: 0.3323\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3373 - acc: 0.3734 - val_loss: 1.4612 - val_acc: 0.3323\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3280 - acc: 0.3772 - val_loss: 1.4611 - val_acc: 0.3323\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3390 - acc: 0.3737 - val_loss: 1.4611 - val_acc: 0.3323\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3428 - acc: 0.3769 - val_loss: 1.4609 - val_acc: 0.3323\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3274 - acc: 0.3787 - val_loss: 1.4610 - val_acc: 0.3323\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3396 - acc: 0.3695 - val_loss: 1.4607 - val_acc: 0.3323\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3452 - acc: 0.3755 - val_loss: 1.4606 - val_acc: 0.3323\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3398 - acc: 0.3804 - val_loss: 1.4605 - val_acc: 0.3323\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3428 - acc: 0.3625 - val_loss: 1.4603 - val_acc: 0.3323\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3361 - acc: 0.3825 - val_loss: 1.4602 - val_acc: 0.3323\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3462 - acc: 0.3713 - val_loss: 1.4602 - val_acc: 0.3323\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3360 - acc: 0.3765 - val_loss: 1.4601 - val_acc: 0.3323\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3319 - acc: 0.3695 - val_loss: 1.4600 - val_acc: 0.3323\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3390 - acc: 0.3776 - val_loss: 1.4598 - val_acc: 0.3323\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3353 - acc: 0.3695 - val_loss: 1.4597 - val_acc: 0.3323\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3392 - acc: 0.3649 - val_loss: 1.4596 - val_acc: 0.3323\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3317 - acc: 0.3751 - val_loss: 1.4595 - val_acc: 0.3323\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3349 - acc: 0.3769 - val_loss: 1.4594 - val_acc: 0.3323\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3352 - acc: 0.3751 - val_loss: 1.4594 - val_acc: 0.3323\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3350 - acc: 0.3794 - val_loss: 1.4593 - val_acc: 0.3323\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3411 - acc: 0.3751 - val_loss: 1.4592 - val_acc: 0.3323\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3195 - acc: 0.3853 - val_loss: 1.4591 - val_acc: 0.3323\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3442 - acc: 0.3684 - val_loss: 1.4589 - val_acc: 0.3323\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3383 - acc: 0.3751 - val_loss: 1.4588 - val_acc: 0.3323\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3430 - acc: 0.3730 - val_loss: 1.4587 - val_acc: 0.3323\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3289 - acc: 0.3779 - val_loss: 1.4586 - val_acc: 0.3323\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3409 - acc: 0.3674 - val_loss: 1.4585 - val_acc: 0.3323\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3322 - acc: 0.3734 - val_loss: 1.4583 - val_acc: 0.3323\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3295 - acc: 0.3734 - val_loss: 1.4582 - val_acc: 0.3323\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3449 - acc: 0.3695 - val_loss: 1.4582 - val_acc: 0.3323\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3249 - acc: 0.3843 - val_loss: 1.4581 - val_acc: 0.3323\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3300 - acc: 0.3783 - val_loss: 1.4580 - val_acc: 0.3323\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.3315 - acc: 0.3779 - val_loss: 1.4578 - val_acc: 0.3323\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3355 - acc: 0.3734 - val_loss: 1.4577 - val_acc: 0.3323\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3378 - acc: 0.3769 - val_loss: 1.4574 - val_acc: 0.3323\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3421 - acc: 0.3744 - val_loss: 1.4575 - val_acc: 0.3323\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3339 - acc: 0.3861 - val_loss: 1.4574 - val_acc: 0.3323\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3239 - acc: 0.3794 - val_loss: 1.4573 - val_acc: 0.3323\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3364 - acc: 0.3787 - val_loss: 1.4572 - val_acc: 0.3323\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3431 - acc: 0.3751 - val_loss: 1.4572 - val_acc: 0.3323\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3251 - acc: 0.3956 - val_loss: 1.4571 - val_acc: 0.3323\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3334 - acc: 0.3931 - val_loss: 1.4570 - val_acc: 0.3323\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3343 - acc: 0.3787 - val_loss: 1.4570 - val_acc: 0.3323\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3231 - acc: 0.3934 - val_loss: 1.4569 - val_acc: 0.3323\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3333 - acc: 0.3811 - val_loss: 1.4568 - val_acc: 0.3323\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3371 - acc: 0.3684 - val_loss: 1.4566 - val_acc: 0.3323\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3408 - acc: 0.3744 - val_loss: 1.4565 - val_acc: 0.3323\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3288 - acc: 0.3853 - val_loss: 1.4565 - val_acc: 0.3323\n",
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3305 - acc: 0.3861 - val_loss: 1.4563 - val_acc: 0.3323\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3344 - acc: 0.3748 - val_loss: 1.4563 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3316 - acc: 0.3794 - val_loss: 1.4562 - val_acc: 0.3323\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3401 - acc: 0.3790 - val_loss: 1.4562 - val_acc: 0.3323\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3349 - acc: 0.3751 - val_loss: 1.4562 - val_acc: 0.3323\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3413 - acc: 0.3698 - val_loss: 1.4562 - val_acc: 0.3323\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3299 - acc: 0.3804 - val_loss: 1.4560 - val_acc: 0.3323\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3198 - acc: 0.3737 - val_loss: 1.4559 - val_acc: 0.3323\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3371 - acc: 0.3628 - val_loss: 1.4558 - val_acc: 0.3323\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3361 - acc: 0.3681 - val_loss: 1.4557 - val_acc: 0.3323\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3350 - acc: 0.3684 - val_loss: 1.4556 - val_acc: 0.3323\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3342 - acc: 0.3790 - val_loss: 1.4555 - val_acc: 0.3323\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3341 - acc: 0.3765 - val_loss: 1.4553 - val_acc: 0.3323\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3295 - acc: 0.3797 - val_loss: 1.4552 - val_acc: 0.3323\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3240 - acc: 0.3931 - val_loss: 1.4552 - val_acc: 0.3323\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3284 - acc: 0.3779 - val_loss: 1.4552 - val_acc: 0.3323\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3318 - acc: 0.3758 - val_loss: 1.4550 - val_acc: 0.3323\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3401 - acc: 0.3765 - val_loss: 1.4550 - val_acc: 0.3323\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3321 - acc: 0.3663 - val_loss: 1.4550 - val_acc: 0.3323\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3232 - acc: 0.3920 - val_loss: 1.4548 - val_acc: 0.3323\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3368 - acc: 0.3748 - val_loss: 1.4548 - val_acc: 0.3323\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3387 - acc: 0.3730 - val_loss: 1.4547 - val_acc: 0.3323\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3241 - acc: 0.3794 - val_loss: 1.4547 - val_acc: 0.3323\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3378 - acc: 0.3674 - val_loss: 1.4545 - val_acc: 0.3323\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3390 - acc: 0.3744 - val_loss: 1.4544 - val_acc: 0.3323\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3274 - acc: 0.3815 - val_loss: 1.4543 - val_acc: 0.3323\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3332 - acc: 0.3794 - val_loss: 1.4542 - val_acc: 0.3323\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3390 - acc: 0.3808 - val_loss: 1.4540 - val_acc: 0.3323\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3318 - acc: 0.3723 - val_loss: 1.4539 - val_acc: 0.3323\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3348 - acc: 0.3758 - val_loss: 1.4539 - val_acc: 0.3323\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3264 - acc: 0.3744 - val_loss: 1.4538 - val_acc: 0.3323\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3217 - acc: 0.3794 - val_loss: 1.4537 - val_acc: 0.3323\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3307 - acc: 0.3751 - val_loss: 1.4536 - val_acc: 0.3323\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3231 - acc: 0.3772 - val_loss: 1.4536 - val_acc: 0.3323\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3352 - acc: 0.3797 - val_loss: 1.4535 - val_acc: 0.3323\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3367 - acc: 0.3787 - val_loss: 1.4535 - val_acc: 0.3323\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3403 - acc: 0.3734 - val_loss: 1.4534 - val_acc: 0.3323\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3292 - acc: 0.3744 - val_loss: 1.4534 - val_acc: 0.3323\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3231 - acc: 0.3737 - val_loss: 1.4533 - val_acc: 0.3323\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3300 - acc: 0.3716 - val_loss: 1.4533 - val_acc: 0.3323\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3185 - acc: 0.3850 - val_loss: 1.4532 - val_acc: 0.3323\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3318 - acc: 0.3741 - val_loss: 1.4530 - val_acc: 0.3323\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3402 - acc: 0.3744 - val_loss: 1.4528 - val_acc: 0.3323\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3276 - acc: 0.3861 - val_loss: 1.4528 - val_acc: 0.3323\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3296 - acc: 0.3903 - val_loss: 1.4526 - val_acc: 0.3323\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3290 - acc: 0.3779 - val_loss: 1.4525 - val_acc: 0.3323\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3219 - acc: 0.3758 - val_loss: 1.4525 - val_acc: 0.3323\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3221 - acc: 0.3779 - val_loss: 1.4524 - val_acc: 0.3323\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3238 - acc: 0.3836 - val_loss: 1.4524 - val_acc: 0.3323\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3360 - acc: 0.3698 - val_loss: 1.4524 - val_acc: 0.3323\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3340 - acc: 0.3691 - val_loss: 1.4523 - val_acc: 0.3323\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3379 - acc: 0.3790 - val_loss: 1.4522 - val_acc: 0.3323\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3252 - acc: 0.3797 - val_loss: 1.4521 - val_acc: 0.3323\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3306 - acc: 0.3737 - val_loss: 1.4520 - val_acc: 0.3323\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3253 - acc: 0.3878 - val_loss: 1.4521 - val_acc: 0.3323\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3362 - acc: 0.3825 - val_loss: 1.4521 - val_acc: 0.3323\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3288 - acc: 0.3706 - val_loss: 1.4520 - val_acc: 0.3323\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3277 - acc: 0.3815 - val_loss: 1.4519 - val_acc: 0.3323\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3324 - acc: 0.3720 - val_loss: 1.4519 - val_acc: 0.3323\n",
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3370 - acc: 0.3801 - val_loss: 1.4519 - val_acc: 0.3323\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3291 - acc: 0.3839 - val_loss: 1.4518 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3259 - acc: 0.3783 - val_loss: 1.4516 - val_acc: 0.3323\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3291 - acc: 0.3720 - val_loss: 1.4515 - val_acc: 0.3323\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3187 - acc: 0.3861 - val_loss: 1.4514 - val_acc: 0.3323\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3264 - acc: 0.3829 - val_loss: 1.4514 - val_acc: 0.3323\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3289 - acc: 0.3741 - val_loss: 1.4513 - val_acc: 0.3323\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3401 - acc: 0.3695 - val_loss: 1.4513 - val_acc: 0.3323\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3290 - acc: 0.3691 - val_loss: 1.4514 - val_acc: 0.3323\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3252 - acc: 0.3861 - val_loss: 1.4513 - val_acc: 0.3323\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3308 - acc: 0.3741 - val_loss: 1.4512 - val_acc: 0.3323\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3137 - acc: 0.3801 - val_loss: 1.4512 - val_acc: 0.3323\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3299 - acc: 0.3698 - val_loss: 1.4510 - val_acc: 0.3323\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3352 - acc: 0.3801 - val_loss: 1.4511 - val_acc: 0.3323\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3383 - acc: 0.3744 - val_loss: 1.4511 - val_acc: 0.3323\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3211 - acc: 0.3787 - val_loss: 1.4511 - val_acc: 0.3323\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3249 - acc: 0.3723 - val_loss: 1.4510 - val_acc: 0.3323\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3314 - acc: 0.3755 - val_loss: 1.4509 - val_acc: 0.3323\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3291 - acc: 0.3709 - val_loss: 1.4509 - val_acc: 0.3323\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3279 - acc: 0.3804 - val_loss: 1.4509 - val_acc: 0.3323\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3298 - acc: 0.3713 - val_loss: 1.4508 - val_acc: 0.3323\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3194 - acc: 0.3762 - val_loss: 1.4508 - val_acc: 0.3323\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3320 - acc: 0.3709 - val_loss: 1.4507 - val_acc: 0.3323\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3219 - acc: 0.3931 - val_loss: 1.4507 - val_acc: 0.3323\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3159 - acc: 0.3843 - val_loss: 1.4506 - val_acc: 0.3323\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3256 - acc: 0.3994 - val_loss: 1.4507 - val_acc: 0.3323\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3248 - acc: 0.3783 - val_loss: 1.4506 - val_acc: 0.3323\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3151 - acc: 0.3790 - val_loss: 1.4505 - val_acc: 0.3323\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3297 - acc: 0.3737 - val_loss: 1.4505 - val_acc: 0.3323\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3183 - acc: 0.3836 - val_loss: 1.4504 - val_acc: 0.3323\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3301 - acc: 0.3727 - val_loss: 1.4502 - val_acc: 0.3323\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3189 - acc: 0.3822 - val_loss: 1.4502 - val_acc: 0.3323\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3234 - acc: 0.3878 - val_loss: 1.4500 - val_acc: 0.3323\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3325 - acc: 0.3829 - val_loss: 1.4499 - val_acc: 0.3323\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3252 - acc: 0.3776 - val_loss: 1.4499 - val_acc: 0.3323\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3242 - acc: 0.3889 - val_loss: 1.4498 - val_acc: 0.3323\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3249 - acc: 0.3808 - val_loss: 1.4497 - val_acc: 0.3323\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3311 - acc: 0.3727 - val_loss: 1.4496 - val_acc: 0.3323\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3334 - acc: 0.3804 - val_loss: 1.4495 - val_acc: 0.3323\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3274 - acc: 0.3751 - val_loss: 1.4496 - val_acc: 0.3323\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3274 - acc: 0.3744 - val_loss: 1.4495 - val_acc: 0.3323\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3220 - acc: 0.3829 - val_loss: 1.4495 - val_acc: 0.3323\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3402 - acc: 0.3839 - val_loss: 1.4495 - val_acc: 0.3323\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3341 - acc: 0.3681 - val_loss: 1.4494 - val_acc: 0.3323\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3162 - acc: 0.3818 - val_loss: 1.4493 - val_acc: 0.3323\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3278 - acc: 0.3811 - val_loss: 1.4492 - val_acc: 0.3323\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3206 - acc: 0.3776 - val_loss: 1.4491 - val_acc: 0.3323\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3280 - acc: 0.3832 - val_loss: 1.4489 - val_acc: 0.3323\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3251 - acc: 0.3762 - val_loss: 1.4490 - val_acc: 0.3323\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3350 - acc: 0.3723 - val_loss: 1.4489 - val_acc: 0.3323\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3164 - acc: 0.3839 - val_loss: 1.4488 - val_acc: 0.3323\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3181 - acc: 0.3832 - val_loss: 1.4488 - val_acc: 0.3323\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3240 - acc: 0.3762 - val_loss: 1.4487 - val_acc: 0.3323\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3233 - acc: 0.3748 - val_loss: 1.4486 - val_acc: 0.3323\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3274 - acc: 0.3621 - val_loss: 1.4485 - val_acc: 0.3323\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3235 - acc: 0.3861 - val_loss: 1.4483 - val_acc: 0.3323\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3222 - acc: 0.3836 - val_loss: 1.4483 - val_acc: 0.3323\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3357 - acc: 0.3723 - val_loss: 1.4482 - val_acc: 0.3323\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3311 - acc: 0.3744 - val_loss: 1.4480 - val_acc: 0.3323\n",
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3187 - acc: 0.3709 - val_loss: 1.4479 - val_acc: 0.3323\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3278 - acc: 0.3706 - val_loss: 1.4480 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3083 - acc: 0.3868 - val_loss: 1.4479 - val_acc: 0.3323\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3237 - acc: 0.3751 - val_loss: 1.4478 - val_acc: 0.3323\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3068 - acc: 0.3832 - val_loss: 1.4477 - val_acc: 0.3323\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3249 - acc: 0.3822 - val_loss: 1.4476 - val_acc: 0.3323\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3212 - acc: 0.3899 - val_loss: 1.4476 - val_acc: 0.3323\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3369 - acc: 0.3656 - val_loss: 1.4477 - val_acc: 0.3323\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3414 - acc: 0.3741 - val_loss: 1.4478 - val_acc: 0.3323\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3217 - acc: 0.3755 - val_loss: 1.4478 - val_acc: 0.3323\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3188 - acc: 0.3818 - val_loss: 1.4476 - val_acc: 0.3323\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3257 - acc: 0.3755 - val_loss: 1.4476 - val_acc: 0.3323\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3235 - acc: 0.3832 - val_loss: 1.4477 - val_acc: 0.3323\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3069 - acc: 0.3931 - val_loss: 1.4476 - val_acc: 0.3323\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3266 - acc: 0.3797 - val_loss: 1.4475 - val_acc: 0.3323\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3083 - acc: 0.3748 - val_loss: 1.4475 - val_acc: 0.3323\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3244 - acc: 0.3829 - val_loss: 1.4472 - val_acc: 0.3323\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3200 - acc: 0.3758 - val_loss: 1.4472 - val_acc: 0.3323\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3146 - acc: 0.3741 - val_loss: 1.4471 - val_acc: 0.3323\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3320 - acc: 0.3783 - val_loss: 1.4470 - val_acc: 0.3323\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3297 - acc: 0.3642 - val_loss: 1.4469 - val_acc: 0.3323\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3237 - acc: 0.3871 - val_loss: 1.4468 - val_acc: 0.3323\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3205 - acc: 0.3772 - val_loss: 1.4466 - val_acc: 0.3323\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3126 - acc: 0.3811 - val_loss: 1.4466 - val_acc: 0.3323\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3293 - acc: 0.3656 - val_loss: 1.4465 - val_acc: 0.3323\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3175 - acc: 0.3801 - val_loss: 1.4465 - val_acc: 0.3323\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3218 - acc: 0.3765 - val_loss: 1.4464 - val_acc: 0.3323\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3286 - acc: 0.3688 - val_loss: 1.4464 - val_acc: 0.3323\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3250 - acc: 0.3727 - val_loss: 1.4464 - val_acc: 0.3323\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3305 - acc: 0.3790 - val_loss: 1.4463 - val_acc: 0.3323\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3164 - acc: 0.3762 - val_loss: 1.4463 - val_acc: 0.3323\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3212 - acc: 0.3723 - val_loss: 1.4462 - val_acc: 0.3323\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3183 - acc: 0.3868 - val_loss: 1.4462 - val_acc: 0.3323\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3144 - acc: 0.3899 - val_loss: 1.4461 - val_acc: 0.3323\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3251 - acc: 0.3730 - val_loss: 1.4460 - val_acc: 0.3323\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3200 - acc: 0.3741 - val_loss: 1.4459 - val_acc: 0.3323\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3058 - acc: 0.3861 - val_loss: 1.4459 - val_acc: 0.3323\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3274 - acc: 0.3878 - val_loss: 1.4459 - val_acc: 0.3323\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3152 - acc: 0.3801 - val_loss: 1.4458 - val_acc: 0.3323\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3206 - acc: 0.3875 - val_loss: 1.4458 - val_acc: 0.3323\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3136 - acc: 0.3871 - val_loss: 1.4457 - val_acc: 0.3323\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3324 - acc: 0.3688 - val_loss: 1.4455 - val_acc: 0.3323\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3182 - acc: 0.3790 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3377 - acc: 0.3614 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3204 - acc: 0.3818 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3184 - acc: 0.3850 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3207 - acc: 0.3741 - val_loss: 1.4455 - val_acc: 0.3323\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3213 - acc: 0.3811 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3215 - acc: 0.3783 - val_loss: 1.4455 - val_acc: 0.3323\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3073 - acc: 0.3832 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3114 - acc: 0.3882 - val_loss: 1.4454 - val_acc: 0.3323\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3104 - acc: 0.3783 - val_loss: 1.4453 - val_acc: 0.3323\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3179 - acc: 0.3751 - val_loss: 1.4452 - val_acc: 0.3323\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3208 - acc: 0.3758 - val_loss: 1.4450 - val_acc: 0.3323\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3166 - acc: 0.3797 - val_loss: 1.4449 - val_acc: 0.3323\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3160 - acc: 0.3864 - val_loss: 1.4448 - val_acc: 0.3323\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3219 - acc: 0.3730 - val_loss: 1.4447 - val_acc: 0.3323\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3228 - acc: 0.3853 - val_loss: 1.4449 - val_acc: 0.3323\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3312 - acc: 0.3741 - val_loss: 1.4449 - val_acc: 0.3323\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3027 - acc: 0.3825 - val_loss: 1.4449 - val_acc: 0.3323\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3207 - acc: 0.3843 - val_loss: 1.4448 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3160 - acc: 0.3832 - val_loss: 1.4448 - val_acc: 0.3323\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3155 - acc: 0.3846 - val_loss: 1.4447 - val_acc: 0.3323\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3184 - acc: 0.3889 - val_loss: 1.4445 - val_acc: 0.3323\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3122 - acc: 0.3783 - val_loss: 1.4444 - val_acc: 0.3323\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3180 - acc: 0.3758 - val_loss: 1.4444 - val_acc: 0.3323\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3177 - acc: 0.3885 - val_loss: 1.4444 - val_acc: 0.3323\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3178 - acc: 0.3815 - val_loss: 1.4443 - val_acc: 0.3323\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3199 - acc: 0.3836 - val_loss: 1.4443 - val_acc: 0.3323\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3084 - acc: 0.3794 - val_loss: 1.4443 - val_acc: 0.3323\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3050 - acc: 0.3871 - val_loss: 1.4442 - val_acc: 0.3323\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3250 - acc: 0.3790 - val_loss: 1.4441 - val_acc: 0.3323\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3256 - acc: 0.3681 - val_loss: 1.4439 - val_acc: 0.3323\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3156 - acc: 0.3723 - val_loss: 1.4439 - val_acc: 0.3323\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3217 - acc: 0.3815 - val_loss: 1.4438 - val_acc: 0.3323\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3103 - acc: 0.3772 - val_loss: 1.4437 - val_acc: 0.3323\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3157 - acc: 0.3839 - val_loss: 1.4435 - val_acc: 0.3323\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3176 - acc: 0.3864 - val_loss: 1.4433 - val_acc: 0.3323\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3066 - acc: 0.3818 - val_loss: 1.4433 - val_acc: 0.3323\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3234 - acc: 0.3737 - val_loss: 1.4433 - val_acc: 0.3323\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3182 - acc: 0.3818 - val_loss: 1.4433 - val_acc: 0.3323\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3180 - acc: 0.3670 - val_loss: 1.4433 - val_acc: 0.3323\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3084 - acc: 0.3850 - val_loss: 1.4433 - val_acc: 0.3323\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3111 - acc: 0.3839 - val_loss: 1.4431 - val_acc: 0.3323\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3234 - acc: 0.3702 - val_loss: 1.4430 - val_acc: 0.3323\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3094 - acc: 0.3861 - val_loss: 1.4430 - val_acc: 0.3323\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.2975 - acc: 0.3882 - val_loss: 1.4428 - val_acc: 0.3323\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3172 - acc: 0.3818 - val_loss: 1.4429 - val_acc: 0.3323\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3246 - acc: 0.3737 - val_loss: 1.4427 - val_acc: 0.3323\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3191 - acc: 0.3660 - val_loss: 1.4427 - val_acc: 0.3323\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3087 - acc: 0.3868 - val_loss: 1.4427 - val_acc: 0.3323\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3109 - acc: 0.3748 - val_loss: 1.4426 - val_acc: 0.3323\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3077 - acc: 0.3776 - val_loss: 1.4425 - val_acc: 0.3323\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3105 - acc: 0.3875 - val_loss: 1.4426 - val_acc: 0.3323\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3257 - acc: 0.3744 - val_loss: 1.4425 - val_acc: 0.3323\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3308 - acc: 0.3762 - val_loss: 1.4424 - val_acc: 0.3323\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3211 - acc: 0.3818 - val_loss: 1.4424 - val_acc: 0.3323\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3289 - acc: 0.3723 - val_loss: 1.4423 - val_acc: 0.3323\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3185 - acc: 0.3698 - val_loss: 1.4421 - val_acc: 0.3323\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3050 - acc: 0.3811 - val_loss: 1.4420 - val_acc: 0.3323\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3011 - acc: 0.3861 - val_loss: 1.4420 - val_acc: 0.3323\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3108 - acc: 0.3804 - val_loss: 1.4419 - val_acc: 0.3323\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3143 - acc: 0.3864 - val_loss: 1.4418 - val_acc: 0.3323\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3135 - acc: 0.3741 - val_loss: 1.4417 - val_acc: 0.3323\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3175 - acc: 0.3822 - val_loss: 1.4417 - val_acc: 0.3323\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3189 - acc: 0.3797 - val_loss: 1.4417 - val_acc: 0.3323\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3105 - acc: 0.3787 - val_loss: 1.4417 - val_acc: 0.3323\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3169 - acc: 0.3779 - val_loss: 1.4417 - val_acc: 0.3323\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3054 - acc: 0.3903 - val_loss: 1.4415 - val_acc: 0.3323\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3186 - acc: 0.3797 - val_loss: 1.4413 - val_acc: 0.3323\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3144 - acc: 0.3787 - val_loss: 1.4413 - val_acc: 0.3323\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3086 - acc: 0.3818 - val_loss: 1.4412 - val_acc: 0.3323\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3267 - acc: 0.3832 - val_loss: 1.4413 - val_acc: 0.3323\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3053 - acc: 0.3755 - val_loss: 1.4413 - val_acc: 0.3323\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3174 - acc: 0.3804 - val_loss: 1.4413 - val_acc: 0.3323\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3064 - acc: 0.3734 - val_loss: 1.4413 - val_acc: 0.3323\n"
     ]
    }
   ],
   "source": [
    "zillow_model = model.fit(x=X_train, y=y_cat_train, \n",
    "          batch_size=20000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_cat_test),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-679-1f3e600bf831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-650-5270cbbd249a>\u001b[0m in \u001b[0;36mmodel_metrics\u001b[0;34m(predictions, X_test, y_test)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mgain_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mgain_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mloss_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgain_stay_large_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model_metrics(predictions, X_test, y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x173f584a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model.history['acc'])\n",
    "plt.plot(zillow_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 1.7115 - acc: 0.2015 - val_loss: 1.4891 - val_acc: 0.3323\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4305 - acc: 0.3269 - val_loss: 1.4700 - val_acc: 0.3323\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3943 - acc: 0.3603 - val_loss: 1.4461 - val_acc: 0.3323\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3899 - acc: 0.3364 - val_loss: 1.4939 - val_acc: 0.3323\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3655 - acc: 0.3575 - val_loss: 1.4586 - val_acc: 0.3323\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3419 - acc: 0.3660 - val_loss: 1.5016 - val_acc: 0.3323\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3497 - acc: 0.3639 - val_loss: 1.4938 - val_acc: 0.3323\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3446 - acc: 0.3646 - val_loss: 1.4510 - val_acc: 0.3323\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3397 - acc: 0.3568 - val_loss: 1.4705 - val_acc: 0.3323\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3148 - acc: 0.3892 - val_loss: 1.4422 - val_acc: 0.3263\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3264 - acc: 0.3656 - val_loss: 1.4464 - val_acc: 0.3263\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3180 - acc: 0.3702 - val_loss: 1.4550 - val_acc: 0.3263\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3117 - acc: 0.3660 - val_loss: 1.4038 - val_acc: 0.3293\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2936 - acc: 0.3829 - val_loss: 1.4211 - val_acc: 0.3233\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2986 - acc: 0.3868 - val_loss: 1.4440 - val_acc: 0.3263\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2793 - acc: 0.3927 - val_loss: 1.4050 - val_acc: 0.3323\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2902 - acc: 0.3945 - val_loss: 1.4997 - val_acc: 0.3293\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2963 - acc: 0.3839 - val_loss: 1.4035 - val_acc: 0.3233\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2606 - acc: 0.4001 - val_loss: 1.4071 - val_acc: 0.3233\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2490 - acc: 0.4044 - val_loss: 1.4259 - val_acc: 0.3263\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2488 - acc: 0.3956 - val_loss: 1.3592 - val_acc: 0.3414\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2507 - acc: 0.4033 - val_loss: 1.3780 - val_acc: 0.3172\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2389 - acc: 0.4206 - val_loss: 1.3977 - val_acc: 0.3202\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2431 - acc: 0.4149 - val_loss: 1.4987 - val_acc: 0.3142\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2480 - acc: 0.3949 - val_loss: 1.4434 - val_acc: 0.3142\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2325 - acc: 0.4097 - val_loss: 1.4116 - val_acc: 0.3202\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2402 - acc: 0.4089 - val_loss: 1.3896 - val_acc: 0.3293\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2206 - acc: 0.3994 - val_loss: 1.3877 - val_acc: 0.3323\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2276 - acc: 0.4030 - val_loss: 1.4046 - val_acc: 0.3323\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2175 - acc: 0.4005 - val_loss: 1.3383 - val_acc: 0.3414\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2240 - acc: 0.4185 - val_loss: 1.4241 - val_acc: 0.3414\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2045 - acc: 0.4287 - val_loss: 1.3718 - val_acc: 0.3384\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1989 - acc: 0.4206 - val_loss: 1.3513 - val_acc: 0.3444\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1991 - acc: 0.4248 - val_loss: 1.3124 - val_acc: 0.3625\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1948 - acc: 0.4237 - val_loss: 1.3005 - val_acc: 0.3746\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1939 - acc: 0.4234 - val_loss: 1.3271 - val_acc: 0.3565\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1764 - acc: 0.4301 - val_loss: 1.4078 - val_acc: 0.3535\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1893 - acc: 0.4160 - val_loss: 1.4208 - val_acc: 0.3384\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1887 - acc: 0.4160 - val_loss: 1.3962 - val_acc: 0.3444\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1599 - acc: 0.4308 - val_loss: 1.4167 - val_acc: 0.3474\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1896 - acc: 0.4156 - val_loss: 1.4100 - val_acc: 0.3384\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1769 - acc: 0.4181 - val_loss: 1.3930 - val_acc: 0.3323\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1751 - acc: 0.4170 - val_loss: 1.3221 - val_acc: 0.3716\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1647 - acc: 0.4364 - val_loss: 1.2832 - val_acc: 0.4320\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1532 - acc: 0.4470 - val_loss: 1.3260 - val_acc: 0.3807\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1547 - acc: 0.4385 - val_loss: 1.2973 - val_acc: 0.4532\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1538 - acc: 0.4516 - val_loss: 1.2620 - val_acc: 0.4894\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1737 - acc: 0.4290 - val_loss: 1.2631 - val_acc: 0.3988\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1479 - acc: 0.4442 - val_loss: 1.2980 - val_acc: 0.3746\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1315 - acc: 0.4480 - val_loss: 1.3403 - val_acc: 0.3686\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1353 - acc: 0.4410 - val_loss: 1.3573 - val_acc: 0.3595\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1367 - acc: 0.4424 - val_loss: 1.3703 - val_acc: 0.3535\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1388 - acc: 0.4311 - val_loss: 1.2953 - val_acc: 0.3776\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1175 - acc: 0.4403 - val_loss: 1.2157 - val_acc: 0.4622\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1287 - acc: 0.4414 - val_loss: 1.2766 - val_acc: 0.4622\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1263 - acc: 0.4519 - val_loss: 1.2838 - val_acc: 0.4320\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1065 - acc: 0.4547 - val_loss: 1.2249 - val_acc: 0.4743\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1137 - acc: 0.4628 - val_loss: 1.2061 - val_acc: 0.4894\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1233 - acc: 0.4586 - val_loss: 1.2180 - val_acc: 0.4834\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1104 - acc: 0.4635 - val_loss: 1.2309 - val_acc: 0.4471\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1042 - acc: 0.4618 - val_loss: 1.2745 - val_acc: 0.4441\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1012 - acc: 0.4597 - val_loss: 1.2683 - val_acc: 0.4653\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0969 - acc: 0.4646 - val_loss: 1.3028 - val_acc: 0.4199\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0958 - acc: 0.4480 - val_loss: 1.3507 - val_acc: 0.3776\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1113 - acc: 0.4516 - val_loss: 1.2818 - val_acc: 0.4199\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0769 - acc: 0.4632 - val_loss: 1.2468 - val_acc: 0.4502\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0842 - acc: 0.4709 - val_loss: 1.1788 - val_acc: 0.5015\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0794 - acc: 0.4829 - val_loss: 1.1973 - val_acc: 0.4804\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1061 - acc: 0.4628 - val_loss: 1.1661 - val_acc: 0.5196\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1032 - acc: 0.4720 - val_loss: 1.2307 - val_acc: 0.4834\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0919 - acc: 0.4685 - val_loss: 1.2308 - val_acc: 0.4773\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0812 - acc: 0.4745 - val_loss: 1.2467 - val_acc: 0.4532\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0604 - acc: 0.4685 - val_loss: 1.2096 - val_acc: 0.4743\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0735 - acc: 0.4723 - val_loss: 1.1939 - val_acc: 0.5045\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0543 - acc: 0.4748 - val_loss: 1.1606 - val_acc: 0.5166\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0718 - acc: 0.4780 - val_loss: 1.1716 - val_acc: 0.5498\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0809 - acc: 0.4893 - val_loss: 1.2445 - val_acc: 0.4350\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0548 - acc: 0.4639 - val_loss: 1.2457 - val_acc: 0.4532\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0394 - acc: 0.4797 - val_loss: 1.2787 - val_acc: 0.4109\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0524 - acc: 0.4593 - val_loss: 1.2258 - val_acc: 0.4622\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0370 - acc: 0.4815 - val_loss: 1.1545 - val_acc: 0.5468\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0863 - acc: 0.4836 - val_loss: 1.2067 - val_acc: 0.5045\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0654 - acc: 0.4727 - val_loss: 1.2009 - val_acc: 0.4894\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0601 - acc: 0.4868 - val_loss: 1.1597 - val_acc: 0.5136\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0484 - acc: 0.4790 - val_loss: 1.1782 - val_acc: 0.4924\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0299 - acc: 0.4871 - val_loss: 1.1738 - val_acc: 0.4924\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0240 - acc: 0.4875 - val_loss: 1.1521 - val_acc: 0.5166\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0413 - acc: 0.4850 - val_loss: 1.1811 - val_acc: 0.5227\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0422 - acc: 0.4871 - val_loss: 1.1650 - val_acc: 0.5076\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0246 - acc: 0.5005 - val_loss: 1.2146 - val_acc: 0.4471\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0267 - acc: 0.4836 - val_loss: 1.2564 - val_acc: 0.3958\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0143 - acc: 0.4776 - val_loss: 1.2093 - val_acc: 0.4502\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0076 - acc: 0.4889 - val_loss: 1.1325 - val_acc: 0.5347\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0345 - acc: 0.4738 - val_loss: 1.1268 - val_acc: 0.5227\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0372 - acc: 0.4970 - val_loss: 1.1692 - val_acc: 0.5166\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0218 - acc: 0.4917 - val_loss: 1.1615 - val_acc: 0.5287\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0195 - acc: 0.4931 - val_loss: 1.2195 - val_acc: 0.4441\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0059 - acc: 0.4974 - val_loss: 1.2200 - val_acc: 0.4471\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0115 - acc: 0.4864 - val_loss: 1.2047 - val_acc: 0.4532\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0144 - acc: 0.4981 - val_loss: 1.1365 - val_acc: 0.5287\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0185 - acc: 0.4914 - val_loss: 1.1491 - val_acc: 0.5196\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9990 - acc: 0.4995 - val_loss: 1.1477 - val_acc: 0.4985\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9952 - acc: 0.5002 - val_loss: 1.1567 - val_acc: 0.5136\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9875 - acc: 0.4942 - val_loss: 1.1071 - val_acc: 0.5408\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9972 - acc: 0.4998 - val_loss: 1.1587 - val_acc: 0.4804\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9947 - acc: 0.4910 - val_loss: 1.1817 - val_acc: 0.4773\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0160 - acc: 0.4952 - val_loss: 1.2078 - val_acc: 0.4773\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0057 - acc: 0.4833 - val_loss: 1.1224 - val_acc: 0.5257\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0058 - acc: 0.4959 - val_loss: 1.1222 - val_acc: 0.5136\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9864 - acc: 0.5157 - val_loss: 1.1868 - val_acc: 0.4532\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9670 - acc: 0.5072 - val_loss: 1.1632 - val_acc: 0.4773\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9639 - acc: 0.5005 - val_loss: 1.1700 - val_acc: 0.4622\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9580 - acc: 0.5146 - val_loss: 1.1578 - val_acc: 0.4894\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9635 - acc: 0.4977 - val_loss: 1.1381 - val_acc: 0.4804\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.0127 - acc: 0.5033 - val_loss: 1.1466 - val_acc: 0.4834\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9925 - acc: 0.5136 - val_loss: 1.1201 - val_acc: 0.5136\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9775 - acc: 0.4956 - val_loss: 1.1150 - val_acc: 0.5287\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9702 - acc: 0.5192 - val_loss: 1.1389 - val_acc: 0.4924\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9579 - acc: 0.5005 - val_loss: 1.1309 - val_acc: 0.4985\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9681 - acc: 0.5136 - val_loss: 1.1704 - val_acc: 0.4773\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9568 - acc: 0.5227 - val_loss: 1.1592 - val_acc: 0.4743\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9829 - acc: 0.5146 - val_loss: 1.1425 - val_acc: 0.4804\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9339 - acc: 0.5231 - val_loss: 1.1294 - val_acc: 0.4924\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9482 - acc: 0.4963 - val_loss: 1.1095 - val_acc: 0.4955\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9722 - acc: 0.5245 - val_loss: 1.1298 - val_acc: 0.4864\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9597 - acc: 0.5139 - val_loss: 1.1602 - val_acc: 0.4683\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9329 - acc: 0.5100 - val_loss: 1.0901 - val_acc: 0.5287\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9433 - acc: 0.5114 - val_loss: 1.1620 - val_acc: 0.4713\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9211 - acc: 0.5192 - val_loss: 1.1532 - val_acc: 0.4864\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9231 - acc: 0.5308 - val_loss: 1.1754 - val_acc: 0.4683\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9402 - acc: 0.5252 - val_loss: 1.1710 - val_acc: 0.4834\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.9522 - acc: 0.5224 - val_loss: 1.1965 - val_acc: 0.4653\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9226 - acc: 0.5312 - val_loss: 1.1528 - val_acc: 0.4864\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9235 - acc: 0.5291 - val_loss: 1.1210 - val_acc: 0.4955\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9391 - acc: 0.5273 - val_loss: 1.1346 - val_acc: 0.4864\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9323 - acc: 0.5269 - val_loss: 1.1183 - val_acc: 0.4955\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9423 - acc: 0.5195 - val_loss: 1.1193 - val_acc: 0.4864\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9212 - acc: 0.5322 - val_loss: 1.1849 - val_acc: 0.4622\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9534 - acc: 0.5217 - val_loss: 1.1974 - val_acc: 0.4713\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9188 - acc: 0.5347 - val_loss: 1.1920 - val_acc: 0.4622\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8948 - acc: 0.5467 - val_loss: 1.2237 - val_acc: 0.4441\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8970 - acc: 0.5192 - val_loss: 1.1817 - val_acc: 0.4713\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8974 - acc: 0.5280 - val_loss: 1.0997 - val_acc: 0.5136\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9235 - acc: 0.5280 - val_loss: 1.1153 - val_acc: 0.4955\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9354 - acc: 0.5340 - val_loss: 1.1407 - val_acc: 0.4985\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9115 - acc: 0.5389 - val_loss: 1.2150 - val_acc: 0.4562\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8885 - acc: 0.5350 - val_loss: 1.1933 - val_acc: 0.4713\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8860 - acc: 0.5365 - val_loss: 1.1374 - val_acc: 0.4924\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8976 - acc: 0.5428 - val_loss: 1.1272 - val_acc: 0.4894\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9701 - acc: 0.5280 - val_loss: 1.1714 - val_acc: 0.4804\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8911 - acc: 0.5354 - val_loss: 1.1942 - val_acc: 0.4592\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8748 - acc: 0.5220 - val_loss: 1.2052 - val_acc: 0.4471\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8836 - acc: 0.5291 - val_loss: 1.3022 - val_acc: 0.3867\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9065 - acc: 0.5129 - val_loss: 1.2686 - val_acc: 0.4048\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8836 - acc: 0.5312 - val_loss: 1.2416 - val_acc: 0.4230\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8817 - acc: 0.5294 - val_loss: 1.2350 - val_acc: 0.4230\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8787 - acc: 0.5396 - val_loss: 1.2398 - val_acc: 0.4381\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9376 - acc: 0.5125 - val_loss: 1.1830 - val_acc: 0.4653\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8714 - acc: 0.5474 - val_loss: 1.1830 - val_acc: 0.4683\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8472 - acc: 0.5477 - val_loss: 1.1766 - val_acc: 0.4894\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8770 - acc: 0.5277 - val_loss: 1.0922 - val_acc: 0.5196\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.9233 - acc: 0.5291 - val_loss: 1.1474 - val_acc: 0.4864\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8670 - acc: 0.5604 - val_loss: 1.2411 - val_acc: 0.4411\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8608 - acc: 0.5382 - val_loss: 1.2032 - val_acc: 0.4653\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8596 - acc: 0.5477 - val_loss: 1.2133 - val_acc: 0.4683\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8941 - acc: 0.5421 - val_loss: 1.1725 - val_acc: 0.4864\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8703 - acc: 0.5625 - val_loss: 1.2008 - val_acc: 0.4804\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8615 - acc: 0.5558 - val_loss: 1.1605 - val_acc: 0.4924\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8565 - acc: 0.5470 - val_loss: 1.1009 - val_acc: 0.5227\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9009 - acc: 0.5410 - val_loss: 1.1781 - val_acc: 0.4743\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8644 - acc: 0.5502 - val_loss: 1.2092 - val_acc: 0.4713\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8770 - acc: 0.5481 - val_loss: 1.2181 - val_acc: 0.4653\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8627 - acc: 0.5608 - val_loss: 1.2197 - val_acc: 0.4592\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8416 - acc: 0.5586 - val_loss: 1.2154 - val_acc: 0.4683\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8339 - acc: 0.5629 - val_loss: 1.2575 - val_acc: 0.4411\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8524 - acc: 0.5516 - val_loss: 1.3268 - val_acc: 0.4018\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8880 - acc: 0.5079 - val_loss: 1.2725 - val_acc: 0.4048\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8429 - acc: 0.5414 - val_loss: 1.1790 - val_acc: 0.4864\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8349 - acc: 0.5576 - val_loss: 1.1491 - val_acc: 0.5045\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8343 - acc: 0.5597 - val_loss: 1.1821 - val_acc: 0.4955\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8612 - acc: 0.5379 - val_loss: 1.3030 - val_acc: 0.4441\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9193 - acc: 0.5118 - val_loss: 1.2922 - val_acc: 0.4109\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8573 - acc: 0.5343 - val_loss: 1.2237 - val_acc: 0.4471\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8239 - acc: 0.5477 - val_loss: 1.2253 - val_acc: 0.4502\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8106 - acc: 0.5657 - val_loss: 1.2690 - val_acc: 0.4350\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8488 - acc: 0.5498 - val_loss: 1.3082 - val_acc: 0.4109\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8908 - acc: 0.5287 - val_loss: 1.3195 - val_acc: 0.4079\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8601 - acc: 0.5252 - val_loss: 1.2412 - val_acc: 0.4350\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8038 - acc: 0.5583 - val_loss: 1.2536 - val_acc: 0.4350\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8094 - acc: 0.5523 - val_loss: 1.1935 - val_acc: 0.4653\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8506 - acc: 0.5393 - val_loss: 1.1724 - val_acc: 0.4864\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8222 - acc: 0.5534 - val_loss: 1.2070 - val_acc: 0.4743\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7961 - acc: 0.5692 - val_loss: 1.2741 - val_acc: 0.4290\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8395 - acc: 0.5488 - val_loss: 1.2876 - val_acc: 0.4169\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8409 - acc: 0.5463 - val_loss: 1.3251 - val_acc: 0.4109\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8380 - acc: 0.5393 - val_loss: 1.3067 - val_acc: 0.4290\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8217 - acc: 0.5509 - val_loss: 1.2578 - val_acc: 0.4562\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7965 - acc: 0.5724 - val_loss: 1.3069 - val_acc: 0.4230\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8356 - acc: 0.5498 - val_loss: 1.3125 - val_acc: 0.4139\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8440 - acc: 0.5287 - val_loss: 1.2585 - val_acc: 0.4441\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8141 - acc: 0.5551 - val_loss: 1.2618 - val_acc: 0.4411\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8022 - acc: 0.5738 - val_loss: 1.3922 - val_acc: 0.4018\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8396 - acc: 0.5396 - val_loss: 1.2620 - val_acc: 0.4350\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7809 - acc: 0.5611 - val_loss: 1.2455 - val_acc: 0.4502\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7858 - acc: 0.5727 - val_loss: 1.2138 - val_acc: 0.4773\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7627 - acc: 0.5826 - val_loss: 1.2369 - val_acc: 0.4713\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7962 - acc: 0.5734 - val_loss: 1.2860 - val_acc: 0.4411\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8470 - acc: 0.5400 - val_loss: 1.2720 - val_acc: 0.4502\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8025 - acc: 0.5579 - val_loss: 1.2913 - val_acc: 0.4260\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7848 - acc: 0.5597 - val_loss: 1.3286 - val_acc: 0.4199\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8187 - acc: 0.5488 - val_loss: 1.3928 - val_acc: 0.3927\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8423 - acc: 0.5322 - val_loss: 1.2714 - val_acc: 0.4471\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7833 - acc: 0.5727 - val_loss: 1.2406 - val_acc: 0.4562\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7723 - acc: 0.5784 - val_loss: 1.2095 - val_acc: 0.4713\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7914 - acc: 0.5756 - val_loss: 1.2361 - val_acc: 0.4502\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7713 - acc: 0.5678 - val_loss: 1.2317 - val_acc: 0.4622\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7813 - acc: 0.5777 - val_loss: 1.2654 - val_acc: 0.4290\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7975 - acc: 0.5667 - val_loss: 1.3177 - val_acc: 0.4199\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8029 - acc: 0.5558 - val_loss: 1.3922 - val_acc: 0.4018\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8375 - acc: 0.5329 - val_loss: 1.3348 - val_acc: 0.4199\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7848 - acc: 0.5632 - val_loss: 1.3726 - val_acc: 0.4109\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.7926 - acc: 0.5597 - val_loss: 1.3352 - val_acc: 0.4320\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.7742 - acc: 0.5727 - val_loss: 1.2911 - val_acc: 0.4622\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7864 - acc: 0.5794 - val_loss: 1.2230 - val_acc: 0.4985\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7874 - acc: 0.5956 - val_loss: 1.2120 - val_acc: 0.5136\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7927 - acc: 0.5879 - val_loss: 1.2430 - val_acc: 0.4864\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7812 - acc: 0.5837 - val_loss: 1.2340 - val_acc: 0.4924\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7879 - acc: 0.5759 - val_loss: 1.2053 - val_acc: 0.4894\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7643 - acc: 0.6002 - val_loss: 1.2330 - val_acc: 0.4834\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7411 - acc: 0.5932 - val_loss: 1.2040 - val_acc: 0.4864\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7799 - acc: 0.5837 - val_loss: 1.1985 - val_acc: 0.4834\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7754 - acc: 0.5770 - val_loss: 1.2004 - val_acc: 0.5076\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7550 - acc: 0.5903 - val_loss: 1.1756 - val_acc: 0.5106\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8519 - acc: 0.5703 - val_loss: 1.2458 - val_acc: 0.4834\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7722 - acc: 0.5787 - val_loss: 1.2970 - val_acc: 0.4773\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7726 - acc: 0.5882 - val_loss: 1.3262 - val_acc: 0.4411\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7708 - acc: 0.5861 - val_loss: 1.2583 - val_acc: 0.4864\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7425 - acc: 0.6013 - val_loss: 1.2220 - val_acc: 0.4985\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7527 - acc: 0.5840 - val_loss: 1.2000 - val_acc: 0.5076\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7745 - acc: 0.5896 - val_loss: 1.2092 - val_acc: 0.5076\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7560 - acc: 0.6055 - val_loss: 1.3039 - val_acc: 0.4713\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7482 - acc: 0.6069 - val_loss: 1.3142 - val_acc: 0.4381\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7713 - acc: 0.5900 - val_loss: 1.3135 - val_acc: 0.4532\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7448 - acc: 0.6055 - val_loss: 1.2686 - val_acc: 0.4804\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7151 - acc: 0.6076 - val_loss: 1.2895 - val_acc: 0.4773\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7273 - acc: 0.6090 - val_loss: 1.3189 - val_acc: 0.4713\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7432 - acc: 0.5992 - val_loss: 1.2289 - val_acc: 0.5015\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8458 - acc: 0.5766 - val_loss: 1.2337 - val_acc: 0.4894\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7544 - acc: 0.5925 - val_loss: 1.2754 - val_acc: 0.4773\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7096 - acc: 0.6115 - val_loss: 1.3070 - val_acc: 0.4743\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7120 - acc: 0.6238 - val_loss: 1.3602 - val_acc: 0.4683\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7221 - acc: 0.6206 - val_loss: 1.3899 - val_acc: 0.4230\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7487 - acc: 0.5956 - val_loss: 1.3657 - val_acc: 0.4471\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7230 - acc: 0.6073 - val_loss: 1.3684 - val_acc: 0.4471\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7555 - acc: 0.5865 - val_loss: 1.5101 - val_acc: 0.3746\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8518 - acc: 0.5312 - val_loss: 1.3594 - val_acc: 0.4290\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7468 - acc: 0.5815 - val_loss: 1.2892 - val_acc: 0.4592\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6927 - acc: 0.6136 - val_loss: 1.3047 - val_acc: 0.4713\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7024 - acc: 0.6185 - val_loss: 1.3093 - val_acc: 0.4773\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6910 - acc: 0.6094 - val_loss: 1.3436 - val_acc: 0.4713\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7181 - acc: 0.6115 - val_loss: 1.3236 - val_acc: 0.4743\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7866 - acc: 0.6027 - val_loss: 1.3046 - val_acc: 0.4834\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7676 - acc: 0.6020 - val_loss: 1.2873 - val_acc: 0.4864\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6991 - acc: 0.6108 - val_loss: 1.2931 - val_acc: 0.4834\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7105 - acc: 0.6073 - val_loss: 1.3156 - val_acc: 0.4834\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6895 - acc: 0.6161 - val_loss: 1.2816 - val_acc: 0.5015\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7517 - acc: 0.6073 - val_loss: 1.2078 - val_acc: 0.5287\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7689 - acc: 0.5865 - val_loss: 1.2373 - val_acc: 0.4955\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6891 - acc: 0.6192 - val_loss: 1.3024 - val_acc: 0.4683\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6987 - acc: 0.6147 - val_loss: 1.2614 - val_acc: 0.4894\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7122 - acc: 0.5953 - val_loss: 1.2399 - val_acc: 0.5015\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6843 - acc: 0.6217 - val_loss: 1.2797 - val_acc: 0.5045\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6774 - acc: 0.6323 - val_loss: 1.3283 - val_acc: 0.4773\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7349 - acc: 0.6058 - val_loss: 1.3523 - val_acc: 0.4743\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7792 - acc: 0.6125 - val_loss: 1.3529 - val_acc: 0.4653\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6778 - acc: 0.6270 - val_loss: 1.3843 - val_acc: 0.4622\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6228 - val_loss: 1.4532 - val_acc: 0.4411\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7054 - acc: 0.6076 - val_loss: 1.4770 - val_acc: 0.4260\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7182 - acc: 0.6101 - val_loss: 1.3932 - val_acc: 0.4381\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6924 - acc: 0.6076 - val_loss: 1.4868 - val_acc: 0.3958\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7725 - acc: 0.5667 - val_loss: 1.3395 - val_acc: 0.4502\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6974 - acc: 0.5977 - val_loss: 1.3604 - val_acc: 0.4411\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7025 - acc: 0.5963 - val_loss: 1.4454 - val_acc: 0.4018\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6836 - acc: 0.6101 - val_loss: 1.4545 - val_acc: 0.4350\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6875 - acc: 0.6217 - val_loss: 1.3984 - val_acc: 0.4653\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6514 - acc: 0.6344 - val_loss: 1.5061 - val_acc: 0.4199\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7370 - acc: 0.5963 - val_loss: 1.5232 - val_acc: 0.3988\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7514 - acc: 0.5808 - val_loss: 1.3737 - val_acc: 0.4502\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6911 - acc: 0.6150 - val_loss: 1.3757 - val_acc: 0.4441\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6753 - acc: 0.6164 - val_loss: 1.3811 - val_acc: 0.4441\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7237 - acc: 0.5981 - val_loss: 1.3675 - val_acc: 0.4441\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6878 - acc: 0.5886 - val_loss: 1.3537 - val_acc: 0.4562\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6591 - acc: 0.6312 - val_loss: 1.4220 - val_acc: 0.4260\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7385 - acc: 0.5918 - val_loss: 1.4841 - val_acc: 0.4018\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7322 - acc: 0.5812 - val_loss: 1.4112 - val_acc: 0.4260\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6475 - acc: 0.6333 - val_loss: 1.3554 - val_acc: 0.4804\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6537 - acc: 0.6294 - val_loss: 1.2974 - val_acc: 0.4864\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7067 - acc: 0.6058 - val_loss: 1.2744 - val_acc: 0.5015\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6965 - acc: 0.6143 - val_loss: 1.3315 - val_acc: 0.5045\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6961 - acc: 0.6249 - val_loss: 1.3159 - val_acc: 0.5045\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7536 - acc: 0.6231 - val_loss: 1.3719 - val_acc: 0.4713\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6465 - acc: 0.6312 - val_loss: 1.3994 - val_acc: 0.4804\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6305 - acc: 0.6481 - val_loss: 1.3683 - val_acc: 0.4924\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6866 - acc: 0.6365 - val_loss: 1.3305 - val_acc: 0.5106\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7112 - acc: 0.6323 - val_loss: 1.3129 - val_acc: 0.4894\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6735 - acc: 0.6266 - val_loss: 1.3126 - val_acc: 0.5015\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6559 - acc: 0.6404 - val_loss: 1.3354 - val_acc: 0.4924\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6320 - acc: 0.6383 - val_loss: 1.3470 - val_acc: 0.4804\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6544 - acc: 0.6330 - val_loss: 1.3637 - val_acc: 0.4713\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7104 - acc: 0.5960 - val_loss: 1.4346 - val_acc: 0.4320\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7263 - acc: 0.5875 - val_loss: 1.4202 - val_acc: 0.4109\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6595 - acc: 0.6252 - val_loss: 1.4714 - val_acc: 0.4199\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6639 - acc: 0.6122 - val_loss: 1.5006 - val_acc: 0.4381\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6750 - acc: 0.6189 - val_loss: 1.5405 - val_acc: 0.4230\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6902 - acc: 0.6108 - val_loss: 1.4720 - val_acc: 0.4502\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6433 - acc: 0.6418 - val_loss: 1.4572 - val_acc: 0.4713\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6480 - acc: 0.6456 - val_loss: 1.4103 - val_acc: 0.4713\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6446 - acc: 0.6372 - val_loss: 1.3905 - val_acc: 0.4985\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6378 - acc: 0.6527 - val_loss: 1.3633 - val_acc: 0.4864\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6380 - acc: 0.6418 - val_loss: 1.3249 - val_acc: 0.4713\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7090 - acc: 0.5981 - val_loss: 1.3095 - val_acc: 0.4864\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6531 - acc: 0.6411 - val_loss: 1.3892 - val_acc: 0.4713\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6078 - acc: 0.6432 - val_loss: 1.5756 - val_acc: 0.4018\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.8075 - acc: 0.5777 - val_loss: 1.5391 - val_acc: 0.3595\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6849 - acc: 0.5830 - val_loss: 1.4004 - val_acc: 0.4622\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6186 - acc: 0.6390 - val_loss: 1.3650 - val_acc: 0.4864\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6214 - acc: 0.6513 - val_loss: 1.3463 - val_acc: 0.5076\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6360 - acc: 0.6368 - val_loss: 1.3275 - val_acc: 0.5106\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6429 - acc: 0.6421 - val_loss: 1.3332 - val_acc: 0.5106\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6756 - acc: 0.6330 - val_loss: 1.3245 - val_acc: 0.5076\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6573 - acc: 0.6400 - val_loss: 1.4117 - val_acc: 0.4894\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6390 - acc: 0.6573 - val_loss: 1.4593 - val_acc: 0.4471\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6833 - acc: 0.6337 - val_loss: 1.4330 - val_acc: 0.4804\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6418 - acc: 0.6506 - val_loss: 1.3811 - val_acc: 0.4955\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6227 - acc: 0.6492 - val_loss: 1.3460 - val_acc: 0.5045\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.6391 - acc: 0.6439 - val_loss: 1.3624 - val_acc: 0.5076\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6303 - acc: 0.6566 - val_loss: 1.4055 - val_acc: 0.4894\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.6362 - acc: 0.6619 - val_loss: 1.4463 - val_acc: 0.4713\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7034 - acc: 0.6347 - val_loss: 1.4733 - val_acc: 0.4683\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6428 - acc: 0.6432 - val_loss: 1.4475 - val_acc: 0.4713\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6076 - acc: 0.6601 - val_loss: 1.3816 - val_acc: 0.5136\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6298 - acc: 0.6513 - val_loss: 1.3545 - val_acc: 0.5166\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6734 - acc: 0.6368 - val_loss: 1.3530 - val_acc: 0.5106\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6359 - acc: 0.6485 - val_loss: 1.3088 - val_acc: 0.5257\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6427 - acc: 0.6390 - val_loss: 1.3496 - val_acc: 0.4955\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6055 - acc: 0.6499 - val_loss: 1.3724 - val_acc: 0.5045\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6234 - acc: 0.6548 - val_loss: 1.4119 - val_acc: 0.4924\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6744 - acc: 0.6347 - val_loss: 1.4680 - val_acc: 0.4653\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6871 - acc: 0.6435 - val_loss: 1.4602 - val_acc: 0.4773\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6368 - acc: 0.6456 - val_loss: 1.4213 - val_acc: 0.4924\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6252 - acc: 0.6619 - val_loss: 1.4707 - val_acc: 0.4773\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6165 - acc: 0.6675 - val_loss: 1.5002 - val_acc: 0.4743\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6257 - acc: 0.6573 - val_loss: 1.6077 - val_acc: 0.4048\n",
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6546 - acc: 0.6453 - val_loss: 1.5008 - val_acc: 0.4592\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6053 - acc: 0.6654 - val_loss: 1.4601 - val_acc: 0.4804\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5873 - acc: 0.6619 - val_loss: 1.4641 - val_acc: 0.4955\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6137 - acc: 0.6474 - val_loss: 1.4120 - val_acc: 0.5166\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6424 - acc: 0.6351 - val_loss: 1.3969 - val_acc: 0.5076\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8014 - acc: 0.6009 - val_loss: 1.3836 - val_acc: 0.4773\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6144 - acc: 0.6523 - val_loss: 1.3894 - val_acc: 0.4804\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6086 - acc: 0.6499 - val_loss: 1.3846 - val_acc: 0.5166\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5991 - acc: 0.6530 - val_loss: 1.4588 - val_acc: 0.4864\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5976 - acc: 0.6640 - val_loss: 1.4267 - val_acc: 0.4985\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6466 - acc: 0.6587 - val_loss: 1.4062 - val_acc: 0.5106\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6289 - acc: 0.6555 - val_loss: 1.4486 - val_acc: 0.5015\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5818 - acc: 0.6647 - val_loss: 1.5513 - val_acc: 0.4411\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6285 - acc: 0.6590 - val_loss: 1.6132 - val_acc: 0.4018\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6415 - acc: 0.6495 - val_loss: 1.4668 - val_acc: 0.4773\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5859 - acc: 0.6770 - val_loss: 1.4547 - val_acc: 0.5196\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5809 - acc: 0.6766 - val_loss: 1.4503 - val_acc: 0.5076\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5895 - acc: 0.6826 - val_loss: 1.3994 - val_acc: 0.5015\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6450 - acc: 0.6372 - val_loss: 1.3758 - val_acc: 0.5257\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6782 - acc: 0.6464 - val_loss: 1.4528 - val_acc: 0.4924\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6152 - acc: 0.6735 - val_loss: 1.5180 - val_acc: 0.4592\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5866 - acc: 0.6745 - val_loss: 1.5675 - val_acc: 0.4441\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5686 - acc: 0.6862 - val_loss: 1.5127 - val_acc: 0.4592\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6316 - acc: 0.6576 - val_loss: 1.4881 - val_acc: 0.4773\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6208 - acc: 0.6707 - val_loss: 1.4876 - val_acc: 0.4713\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6162 - acc: 0.6710 - val_loss: 1.4640 - val_acc: 0.4955\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5832 - acc: 0.6710 - val_loss: 1.4205 - val_acc: 0.5136\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5824 - acc: 0.6721 - val_loss: 1.4130 - val_acc: 0.5287\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6192 - acc: 0.6601 - val_loss: 1.4029 - val_acc: 0.5257\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6114 - acc: 0.6619 - val_loss: 1.4361 - val_acc: 0.5015\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6085 - acc: 0.6721 - val_loss: 1.4691 - val_acc: 0.4864\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6155 - acc: 0.6587 - val_loss: 1.5871 - val_acc: 0.4290\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6428 - acc: 0.6643 - val_loss: 1.5087 - val_acc: 0.4713\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5592 - acc: 0.6928 - val_loss: 1.4866 - val_acc: 0.4773\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5798 - acc: 0.6823 - val_loss: 1.4892 - val_acc: 0.4864\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5797 - acc: 0.6774 - val_loss: 1.4427 - val_acc: 0.5136\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6367 - acc: 0.6580 - val_loss: 1.3988 - val_acc: 0.5287\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6248 - acc: 0.6555 - val_loss: 1.4220 - val_acc: 0.5136\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5638 - acc: 0.6830 - val_loss: 1.4553 - val_acc: 0.4985\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5540 - acc: 0.6770 - val_loss: 1.4537 - val_acc: 0.5015\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5848 - acc: 0.6629 - val_loss: 1.4681 - val_acc: 0.4834\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5954 - acc: 0.6421 - val_loss: 1.4938 - val_acc: 0.4502\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5901 - acc: 0.6548 - val_loss: 1.5726 - val_acc: 0.4411\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5773 - acc: 0.6703 - val_loss: 1.6240 - val_acc: 0.4381\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5975 - acc: 0.6576 - val_loss: 1.6494 - val_acc: 0.4139\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6203 - acc: 0.6421 - val_loss: 1.5982 - val_acc: 0.4350\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5702 - acc: 0.6700 - val_loss: 1.6194 - val_acc: 0.4502\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5740 - acc: 0.6692 - val_loss: 1.6531 - val_acc: 0.4260\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5798 - acc: 0.6717 - val_loss: 1.6891 - val_acc: 0.3958\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5936 - acc: 0.6626 - val_loss: 1.5347 - val_acc: 0.4502\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5839 - acc: 0.6791 - val_loss: 1.5795 - val_acc: 0.4471\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5988 - acc: 0.6678 - val_loss: 1.4984 - val_acc: 0.4743\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5593 - acc: 0.6893 - val_loss: 1.4983 - val_acc: 0.4985\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5635 - acc: 0.6840 - val_loss: 1.4556 - val_acc: 0.5166\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6678 - acc: 0.6390 - val_loss: 1.4294 - val_acc: 0.5257\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6135 - acc: 0.6689 - val_loss: 1.4904 - val_acc: 0.4864\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5541 - acc: 0.6812 - val_loss: 1.5503 - val_acc: 0.4713\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5512 - acc: 0.6971 - val_loss: 1.6767 - val_acc: 0.4139\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5743 - acc: 0.6788 - val_loss: 1.6412 - val_acc: 0.4411\n",
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5641 - acc: 0.6798 - val_loss: 1.5701 - val_acc: 0.4381\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5801 - acc: 0.6766 - val_loss: 1.5636 - val_acc: 0.4592\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6331 - acc: 0.6668 - val_loss: 1.4874 - val_acc: 0.4743\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6134 - acc: 0.6833 - val_loss: 1.4811 - val_acc: 0.5045\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5585 - acc: 0.6943 - val_loss: 1.4803 - val_acc: 0.5076\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5466 - acc: 0.6847 - val_loss: 1.4540 - val_acc: 0.5106\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5581 - acc: 0.6795 - val_loss: 1.4814 - val_acc: 0.4924\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5830 - acc: 0.6538 - val_loss: 1.5353 - val_acc: 0.4683\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5453 - acc: 0.6770 - val_loss: 1.6943 - val_acc: 0.4199\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6342 - acc: 0.6432 - val_loss: 1.7819 - val_acc: 0.3625\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6315 - acc: 0.6122 - val_loss: 1.5692 - val_acc: 0.4743\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5210 - acc: 0.7045 - val_loss: 1.5646 - val_acc: 0.4834\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5318 - acc: 0.6784 - val_loss: 1.5589 - val_acc: 0.4622\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5665 - acc: 0.6569 - val_loss: 1.5520 - val_acc: 0.4562\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5705 - acc: 0.6530 - val_loss: 1.5527 - val_acc: 0.4622\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5403 - acc: 0.6823 - val_loss: 1.5987 - val_acc: 0.4683\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5391 - acc: 0.6678 - val_loss: 1.5791 - val_acc: 0.4683\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5315 - acc: 0.6876 - val_loss: 1.6369 - val_acc: 0.4350\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5836 - acc: 0.6650 - val_loss: 1.7016 - val_acc: 0.4199\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5878 - acc: 0.6523 - val_loss: 1.6564 - val_acc: 0.4320\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5518 - acc: 0.6664 - val_loss: 1.5820 - val_acc: 0.4773\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5093 - acc: 0.7020 - val_loss: 1.7007 - val_acc: 0.4502\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5375 - acc: 0.6897 - val_loss: 1.7707 - val_acc: 0.4109\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5647 - acc: 0.6886 - val_loss: 1.8612 - val_acc: 0.3656\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6221 - acc: 0.6538 - val_loss: 1.6363 - val_acc: 0.4350\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5339 - acc: 0.7013 - val_loss: 1.5677 - val_acc: 0.4864\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5035 - acc: 0.7080 - val_loss: 1.5773 - val_acc: 0.4955\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5238 - acc: 0.6897 - val_loss: 1.5682 - val_acc: 0.4804\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6100 - acc: 0.6724 - val_loss: 1.5526 - val_acc: 0.4894\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7042 - acc: 0.6587 - val_loss: 1.5075 - val_acc: 0.5015\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5206 - acc: 0.7013 - val_loss: 1.5300 - val_acc: 0.4804\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5331 - acc: 0.6936 - val_loss: 1.5146 - val_acc: 0.4924\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5518 - acc: 0.6650 - val_loss: 1.4938 - val_acc: 0.5015\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5342 - acc: 0.6883 - val_loss: 1.5138 - val_acc: 0.5166\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5150 - acc: 0.6865 - val_loss: 1.5196 - val_acc: 0.5106\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5158 - acc: 0.6985 - val_loss: 1.5529 - val_acc: 0.5045\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5097 - acc: 0.7034 - val_loss: 1.5856 - val_acc: 0.4985\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6070 - acc: 0.6728 - val_loss: 1.6372 - val_acc: 0.4773\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6061 - acc: 0.6816 - val_loss: 1.5753 - val_acc: 0.4924\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5028 - acc: 0.7045 - val_loss: 1.6040 - val_acc: 0.4743\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5592 - acc: 0.6988 - val_loss: 1.6460 - val_acc: 0.4743\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6226 - acc: 0.6840 - val_loss: 1.5876 - val_acc: 0.4773\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5371 - acc: 0.7034 - val_loss: 1.6402 - val_acc: 0.4592\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5097 - acc: 0.7129 - val_loss: 1.7495 - val_acc: 0.4139\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5424 - acc: 0.6855 - val_loss: 1.7561 - val_acc: 0.3897\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5517 - acc: 0.6932 - val_loss: 1.7217 - val_acc: 0.4169\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5323 - acc: 0.7069 - val_loss: 1.6251 - val_acc: 0.4653\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5007 - acc: 0.7147 - val_loss: 1.6153 - val_acc: 0.4713\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5475 - acc: 0.7020 - val_loss: 1.6246 - val_acc: 0.4834\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5801 - acc: 0.6847 - val_loss: 1.5505 - val_acc: 0.4955\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5318 - acc: 0.6992 - val_loss: 1.5626 - val_acc: 0.5106\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5111 - acc: 0.7010 - val_loss: 1.5792 - val_acc: 0.5106\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5636 - acc: 0.6946 - val_loss: 1.5391 - val_acc: 0.5076\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5366 - acc: 0.7027 - val_loss: 1.5286 - val_acc: 0.5045\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5001 - acc: 0.7031 - val_loss: 1.5560 - val_acc: 0.5166\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5407 - acc: 0.6816 - val_loss: 1.5990 - val_acc: 0.4653\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5815 - acc: 0.6566 - val_loss: 1.5691 - val_acc: 0.4864\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5397 - acc: 0.6766 - val_loss: 1.7344 - val_acc: 0.4350\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5530 - acc: 0.6802 - val_loss: 1.7971 - val_acc: 0.3988\n",
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5970 - acc: 0.6629 - val_loss: 1.7113 - val_acc: 0.4320\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5433 - acc: 0.6777 - val_loss: 1.6405 - val_acc: 0.4683\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4943 - acc: 0.7006 - val_loss: 1.6028 - val_acc: 0.4924\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4737 - acc: 0.7150 - val_loss: 1.6888 - val_acc: 0.4441\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4947 - acc: 0.6971 - val_loss: 1.6326 - val_acc: 0.4773\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5084 - acc: 0.6890 - val_loss: 1.6237 - val_acc: 0.4683\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5298 - acc: 0.6946 - val_loss: 1.5788 - val_acc: 0.4804\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5413 - acc: 0.6728 - val_loss: 1.5200 - val_acc: 0.5136\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5444 - acc: 0.6788 - val_loss: 1.5445 - val_acc: 0.5257\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6482 - acc: 0.6745 - val_loss: 1.6037 - val_acc: 0.4924\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5524 - acc: 0.6960 - val_loss: 1.6477 - val_acc: 0.4562\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4806 - acc: 0.7281 - val_loss: 1.6579 - val_acc: 0.4804\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4654 - acc: 0.7193 - val_loss: 1.6946 - val_acc: 0.4592\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4989 - acc: 0.7080 - val_loss: 1.7204 - val_acc: 0.4562\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5302 - acc: 0.7020 - val_loss: 1.7643 - val_acc: 0.4260\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5328 - acc: 0.6964 - val_loss: 1.6665 - val_acc: 0.4532\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5207 - acc: 0.7002 - val_loss: 1.6293 - val_acc: 0.4743\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5096 - acc: 0.6911 - val_loss: 1.6164 - val_acc: 0.4834\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4958 - acc: 0.7020 - val_loss: 1.6438 - val_acc: 0.4804\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4935 - acc: 0.7112 - val_loss: 1.5712 - val_acc: 0.4864\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5709 - acc: 0.6601 - val_loss: 1.5298 - val_acc: 0.5015\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4946 - acc: 0.7154 - val_loss: 1.6271 - val_acc: 0.5136\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5246 - acc: 0.7087 - val_loss: 1.6699 - val_acc: 0.4683\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6148 - acc: 0.6925 - val_loss: 1.6608 - val_acc: 0.4743\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5172 - acc: 0.7143 - val_loss: 1.6562 - val_acc: 0.4743\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4856 - acc: 0.7260 - val_loss: 1.6733 - val_acc: 0.4834\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4618 - acc: 0.7302 - val_loss: 1.6819 - val_acc: 0.4894\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4752 - acc: 0.7157 - val_loss: 1.6528 - val_acc: 0.5015\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5161 - acc: 0.7175 - val_loss: 1.6918 - val_acc: 0.4713\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6037 - acc: 0.6897 - val_loss: 1.6974 - val_acc: 0.4622\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5368 - acc: 0.7017 - val_loss: 1.6751 - val_acc: 0.4622\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4814 - acc: 0.7217 - val_loss: 1.7467 - val_acc: 0.4441\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5049 - acc: 0.7080 - val_loss: 1.9272 - val_acc: 0.3807\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5937 - acc: 0.6685 - val_loss: 1.8046 - val_acc: 0.4079\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5331 - acc: 0.7069 - val_loss: 1.7292 - val_acc: 0.4471\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4701 - acc: 0.7309 - val_loss: 1.6619 - val_acc: 0.4924\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4603 - acc: 0.7351 - val_loss: 1.7394 - val_acc: 0.4622\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4769 - acc: 0.7284 - val_loss: 1.7191 - val_acc: 0.4743\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5393 - acc: 0.7062 - val_loss: 1.9127 - val_acc: 0.3837\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6604 - acc: 0.6150 - val_loss: 1.6627 - val_acc: 0.4562\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4892 - acc: 0.7091 - val_loss: 1.6634 - val_acc: 0.4713\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4808 - acc: 0.7179 - val_loss: 1.6484 - val_acc: 0.4985\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4717 - acc: 0.7164 - val_loss: 1.6218 - val_acc: 0.4955\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5257 - acc: 0.6893 - val_loss: 1.5759 - val_acc: 0.4985\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4990 - acc: 0.7143 - val_loss: 1.6368 - val_acc: 0.5136\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4811 - acc: 0.7172 - val_loss: 1.6674 - val_acc: 0.5045\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4769 - acc: 0.7168 - val_loss: 1.7395 - val_acc: 0.4834\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5914 - acc: 0.6985 - val_loss: 1.7352 - val_acc: 0.4471\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5125 - acc: 0.7238 - val_loss: 1.6513 - val_acc: 0.4864\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4511 - acc: 0.7397 - val_loss: 1.6732 - val_acc: 0.4683\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4541 - acc: 0.7327 - val_loss: 1.6438 - val_acc: 0.5045\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4750 - acc: 0.7214 - val_loss: 1.6165 - val_acc: 0.5076\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5423 - acc: 0.6862 - val_loss: 1.5880 - val_acc: 0.5166\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4880 - acc: 0.7182 - val_loss: 1.6363 - val_acc: 0.5015\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4782 - acc: 0.7006 - val_loss: 1.7471 - val_acc: 0.4471\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5406 - acc: 0.6826 - val_loss: 1.7926 - val_acc: 0.4260\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5357 - acc: 0.6777 - val_loss: 1.7192 - val_acc: 0.4502\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4681 - acc: 0.7189 - val_loss: 1.6972 - val_acc: 0.4804\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4546 - acc: 0.7379 - val_loss: 1.7382 - val_acc: 0.4562\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4552 - acc: 0.7274 - val_loss: 1.8542 - val_acc: 0.4199\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4945 - acc: 0.7242 - val_loss: 1.8963 - val_acc: 0.4018\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5089 - acc: 0.7129 - val_loss: 1.7367 - val_acc: 0.4592\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4849 - acc: 0.7316 - val_loss: 1.6744 - val_acc: 0.4985\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4906 - acc: 0.7305 - val_loss: 1.6553 - val_acc: 0.5015\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5353 - acc: 0.7179 - val_loss: 1.6494 - val_acc: 0.4955\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4579 - acc: 0.7443 - val_loss: 1.6896 - val_acc: 0.4894\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4527 - acc: 0.7323 - val_loss: 1.7219 - val_acc: 0.4804\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4697 - acc: 0.7150 - val_loss: 1.6860 - val_acc: 0.4955\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4707 - acc: 0.7108 - val_loss: 1.6489 - val_acc: 0.5196\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4564 - acc: 0.7309 - val_loss: 1.6451 - val_acc: 0.5136\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5126 - acc: 0.7045 - val_loss: 1.6359 - val_acc: 0.4894\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4893 - acc: 0.7242 - val_loss: 1.6705 - val_acc: 0.5015\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5949 - acc: 0.6999 - val_loss: 1.7620 - val_acc: 0.4441\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5414 - acc: 0.7115 - val_loss: 1.6970 - val_acc: 0.4804\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4469 - acc: 0.7323 - val_loss: 1.6793 - val_acc: 0.5045\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4399 - acc: 0.7559 - val_loss: 1.7404 - val_acc: 0.4834\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4113 - acc: 0.7559 - val_loss: 1.7662 - val_acc: 0.4864\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4392 - acc: 0.7443 - val_loss: 1.9648 - val_acc: 0.4079\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4959 - acc: 0.7157 - val_loss: 2.0058 - val_acc: 0.3867\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5250 - acc: 0.7024 - val_loss: 1.7960 - val_acc: 0.4471\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4645 - acc: 0.7422 - val_loss: 1.7968 - val_acc: 0.4683\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5363 - acc: 0.7083 - val_loss: 1.9251 - val_acc: 0.4048\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6166 - acc: 0.6372 - val_loss: 1.6609 - val_acc: 0.4653\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4507 - acc: 0.7200 - val_loss: 1.7010 - val_acc: 0.4955\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4273 - acc: 0.7393 - val_loss: 1.7098 - val_acc: 0.4924\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4384 - acc: 0.7467 - val_loss: 1.6774 - val_acc: 0.5227\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 0.4620 - acc: 0.7242 - val_loss: 1.6941 - val_acc: 0.4955\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4373 - acc: 0.7344 - val_loss: 1.7077 - val_acc: 0.4894\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4455 - acc: 0.7344 - val_loss: 1.7258 - val_acc: 0.4834\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4518 - acc: 0.7235 - val_loss: 1.7003 - val_acc: 0.5106\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4187 - acc: 0.7629 - val_loss: 1.7543 - val_acc: 0.4955\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4389 - acc: 0.7351 - val_loss: 1.7445 - val_acc: 0.4743\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4479 - acc: 0.7305 - val_loss: 1.7471 - val_acc: 0.4864\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4835 - acc: 0.6981 - val_loss: 1.7881 - val_acc: 0.4562\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5422 - acc: 0.6798 - val_loss: 1.9004 - val_acc: 0.4109\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5888 - acc: 0.6545 - val_loss: 1.8188 - val_acc: 0.4230\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4677 - acc: 0.7344 - val_loss: 1.6845 - val_acc: 0.4834\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4157 - acc: 0.7478 - val_loss: 1.7666 - val_acc: 0.4804\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4289 - acc: 0.7418 - val_loss: 1.7372 - val_acc: 0.5015\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4352 - acc: 0.7478 - val_loss: 1.7637 - val_acc: 0.4924\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4397 - acc: 0.7450 - val_loss: 1.7359 - val_acc: 0.4955\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4609 - acc: 0.7291 - val_loss: 1.7185 - val_acc: 0.5106\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5049 - acc: 0.7157 - val_loss: 1.7723 - val_acc: 0.5015\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4597 - acc: 0.7436 - val_loss: 1.7884 - val_acc: 0.4683\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4403 - acc: 0.7422 - val_loss: 1.8435 - val_acc: 0.4381\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4745 - acc: 0.7277 - val_loss: 1.9280 - val_acc: 0.4109\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4735 - acc: 0.7274 - val_loss: 1.8841 - val_acc: 0.4290\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4563 - acc: 0.7482 - val_loss: 1.8613 - val_acc: 0.4290\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4357 - acc: 0.7439 - val_loss: 1.8386 - val_acc: 0.4622\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4184 - acc: 0.7527 - val_loss: 1.8273 - val_acc: 0.4743\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4125 - acc: 0.7555 - val_loss: 1.8062 - val_acc: 0.4834\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4132 - acc: 0.7517 - val_loss: 1.8074 - val_acc: 0.4713\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4816 - acc: 0.7126 - val_loss: 1.8723 - val_acc: 0.4411\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5619 - acc: 0.6721 - val_loss: 1.8318 - val_acc: 0.4290\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4790 - acc: 0.7002 - val_loss: 1.8130 - val_acc: 0.4441\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4567 - acc: 0.7474 - val_loss: 1.9088 - val_acc: 0.4079\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4547 - acc: 0.7298 - val_loss: 1.8531 - val_acc: 0.4381\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4341 - acc: 0.7492 - val_loss: 1.9346 - val_acc: 0.4079\n",
      "Epoch 590/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4552 - acc: 0.7439 - val_loss: 1.8405 - val_acc: 0.4471\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4250 - acc: 0.7721 - val_loss: 1.9475 - val_acc: 0.4199\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4548 - acc: 0.7432 - val_loss: 1.8348 - val_acc: 0.4562\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4601 - acc: 0.7383 - val_loss: 1.9615 - val_acc: 0.4109\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4804 - acc: 0.7157 - val_loss: 1.8590 - val_acc: 0.4532\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4217 - acc: 0.7591 - val_loss: 1.8366 - val_acc: 0.4804\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4122 - acc: 0.7510 - val_loss: 1.8424 - val_acc: 0.4743\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4307 - acc: 0.7408 - val_loss: 1.8389 - val_acc: 0.4743\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4427 - acc: 0.7260 - val_loss: 1.7871 - val_acc: 0.4622\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4768 - acc: 0.7076 - val_loss: 1.7634 - val_acc: 0.4713\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4617 - acc: 0.7112 - val_loss: 1.7917 - val_acc: 0.4683\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4434 - acc: 0.7341 - val_loss: 1.8641 - val_acc: 0.4562\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4743 - acc: 0.7242 - val_loss: 1.9283 - val_acc: 0.4230\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5146 - acc: 0.6932 - val_loss: 1.7931 - val_acc: 0.4924\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4331 - acc: 0.7393 - val_loss: 1.9184 - val_acc: 0.4260\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4407 - acc: 0.7383 - val_loss: 1.8816 - val_acc: 0.4441\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4206 - acc: 0.7559 - val_loss: 1.8994 - val_acc: 0.4804\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3911 - acc: 0.7577 - val_loss: 1.9009 - val_acc: 0.4713\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4209 - acc: 0.7527 - val_loss: 1.8929 - val_acc: 0.4622\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4327 - acc: 0.7418 - val_loss: 1.8538 - val_acc: 0.4592\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4444 - acc: 0.7179 - val_loss: 1.8417 - val_acc: 0.4653\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4940 - acc: 0.6823 - val_loss: 1.7528 - val_acc: 0.4834\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4379 - acc: 0.7196 - val_loss: 1.7803 - val_acc: 0.5015\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4289 - acc: 0.7393 - val_loss: 1.8971 - val_acc: 0.4683\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4921 - acc: 0.7136 - val_loss: 2.0394 - val_acc: 0.4079\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5447 - acc: 0.6999 - val_loss: 1.8622 - val_acc: 0.4622\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4649 - acc: 0.7235 - val_loss: 1.8490 - val_acc: 0.4864\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4157 - acc: 0.7555 - val_loss: 1.8851 - val_acc: 0.4532\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4063 - acc: 0.7707 - val_loss: 1.9592 - val_acc: 0.4471\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4165 - acc: 0.7675 - val_loss: 1.9352 - val_acc: 0.4532\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4312 - acc: 0.7457 - val_loss: 2.0107 - val_acc: 0.4230\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4514 - acc: 0.7408 - val_loss: 1.9047 - val_acc: 0.4592\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4216 - acc: 0.7654 - val_loss: 1.8664 - val_acc: 0.4653\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4282 - acc: 0.7689 - val_loss: 1.9485 - val_acc: 0.4532\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4874 - acc: 0.7341 - val_loss: 1.8665 - val_acc: 0.4592\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4678 - acc: 0.7513 - val_loss: 1.8160 - val_acc: 0.4834\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4111 - acc: 0.7517 - val_loss: 1.8004 - val_acc: 0.4834\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3969 - acc: 0.7746 - val_loss: 1.8242 - val_acc: 0.4894\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4143 - acc: 0.7432 - val_loss: 1.7977 - val_acc: 0.5015\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4162 - acc: 0.7478 - val_loss: 1.8053 - val_acc: 0.5106\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4321 - acc: 0.7425 - val_loss: 1.8330 - val_acc: 0.4683\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4043 - acc: 0.7601 - val_loss: 1.8179 - val_acc: 0.5015\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4172 - acc: 0.7527 - val_loss: 1.8902 - val_acc: 0.4804\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4722 - acc: 0.7143 - val_loss: 1.9856 - val_acc: 0.4260\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4913 - acc: 0.7076 - val_loss: 1.9036 - val_acc: 0.4502\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4412 - acc: 0.7341 - val_loss: 1.9267 - val_acc: 0.4532\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4010 - acc: 0.7612 - val_loss: 1.9989 - val_acc: 0.4290\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4451 - acc: 0.7467 - val_loss: 2.0081 - val_acc: 0.4230\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4214 - acc: 0.7499 - val_loss: 1.9363 - val_acc: 0.4622\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3977 - acc: 0.7689 - val_loss: 2.0207 - val_acc: 0.4320\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4282 - acc: 0.7520 - val_loss: 1.9912 - val_acc: 0.4441\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4435 - acc: 0.7527 - val_loss: 1.9435 - val_acc: 0.4532\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4622 - acc: 0.7499 - val_loss: 1.8665 - val_acc: 0.4622\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4659 - acc: 0.7474 - val_loss: 1.8614 - val_acc: 0.4743\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3883 - acc: 0.7749 - val_loss: 1.9178 - val_acc: 0.4773\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3969 - acc: 0.7696 - val_loss: 1.9037 - val_acc: 0.4773\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3879 - acc: 0.7739 - val_loss: 1.9987 - val_acc: 0.4471\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3923 - acc: 0.7777 - val_loss: 2.0586 - val_acc: 0.4411\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4075 - acc: 0.7601 - val_loss: 2.1257 - val_acc: 0.4109\n",
      "Epoch 649/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4833 - acc: 0.7344 - val_loss: 2.0426 - val_acc: 0.3958\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4329 - acc: 0.7520 - val_loss: 1.9858 - val_acc: 0.4290\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4398 - acc: 0.7545 - val_loss: 1.9499 - val_acc: 0.4532\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4710 - acc: 0.7284 - val_loss: 1.9158 - val_acc: 0.4471\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4057 - acc: 0.7580 - val_loss: 1.9298 - val_acc: 0.4773\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3915 - acc: 0.7696 - val_loss: 1.9198 - val_acc: 0.4955\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3836 - acc: 0.7760 - val_loss: 1.8749 - val_acc: 0.4804\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3877 - acc: 0.7732 - val_loss: 1.8555 - val_acc: 0.4743\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3877 - acc: 0.7682 - val_loss: 1.9269 - val_acc: 0.4834\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4680 - acc: 0.7105 - val_loss: 1.9255 - val_acc: 0.4683\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4661 - acc: 0.7112 - val_loss: 1.9513 - val_acc: 0.4532\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3999 - acc: 0.7626 - val_loss: 1.9818 - val_acc: 0.4290\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4209 - acc: 0.7555 - val_loss: 1.9480 - val_acc: 0.4471\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4167 - acc: 0.7408 - val_loss: 1.9535 - val_acc: 0.4653\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3874 - acc: 0.7732 - val_loss: 1.9233 - val_acc: 0.4773\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3880 - acc: 0.7718 - val_loss: 1.9558 - val_acc: 0.4653\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3737 - acc: 0.7841 - val_loss: 2.0468 - val_acc: 0.4320\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4012 - acc: 0.7746 - val_loss: 2.2175 - val_acc: 0.3867\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5173 - acc: 0.7101 - val_loss: 2.0018 - val_acc: 0.4441\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4224 - acc: 0.7577 - val_loss: 1.9350 - val_acc: 0.4713\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3753 - acc: 0.7844 - val_loss: 1.9732 - val_acc: 0.4562\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4103 - acc: 0.7686 - val_loss: 2.0920 - val_acc: 0.4260\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 48us/step - loss: 0.4341 - acc: 0.7601 - val_loss: 1.9636 - val_acc: 0.4562\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4057 - acc: 0.7827 - val_loss: 1.9356 - val_acc: 0.4713\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3919 - acc: 0.7784 - val_loss: 1.9569 - val_acc: 0.4773\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3714 - acc: 0.7827 - val_loss: 1.9673 - val_acc: 0.4743\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3842 - acc: 0.7841 - val_loss: 2.0262 - val_acc: 0.4592\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3990 - acc: 0.7746 - val_loss: 2.1075 - val_acc: 0.4411\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4014 - acc: 0.7721 - val_loss: 2.0677 - val_acc: 0.4411\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4108 - acc: 0.7566 - val_loss: 1.9696 - val_acc: 0.4622\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4027 - acc: 0.7742 - val_loss: 2.0263 - val_acc: 0.4471\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4109 - acc: 0.7527 - val_loss: 1.9822 - val_acc: 0.4532\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5129 - acc: 0.7281 - val_loss: 1.9908 - val_acc: 0.4502\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4557 - acc: 0.7221 - val_loss: 1.8746 - val_acc: 0.4804\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3840 - acc: 0.7608 - val_loss: 1.9060 - val_acc: 0.4894\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3792 - acc: 0.7774 - val_loss: 1.9469 - val_acc: 0.4713\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4005 - acc: 0.7633 - val_loss: 1.9571 - val_acc: 0.5015\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4143 - acc: 0.7467 - val_loss: 1.9360 - val_acc: 0.4834\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3871 - acc: 0.7661 - val_loss: 1.9422 - val_acc: 0.4985\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3956 - acc: 0.7721 - val_loss: 1.9820 - val_acc: 0.4894\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3912 - acc: 0.7721 - val_loss: 1.9664 - val_acc: 0.4834\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3572 - acc: 0.7788 - val_loss: 2.0649 - val_acc: 0.4592\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3568 - acc: 0.7961 - val_loss: 2.1479 - val_acc: 0.4411\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4176 - acc: 0.7555 - val_loss: 2.1717 - val_acc: 0.4441\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5964 - acc: 0.7133 - val_loss: 1.8803 - val_acc: 0.4894\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4541 - acc: 0.7482 - val_loss: 1.8625 - val_acc: 0.5136\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3836 - acc: 0.7661 - val_loss: 1.9692 - val_acc: 0.4804\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3582 - acc: 0.7901 - val_loss: 1.9982 - val_acc: 0.4743\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3513 - acc: 0.7950 - val_loss: 2.0399 - val_acc: 0.4834\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3477 - acc: 0.8017 - val_loss: 2.0859 - val_acc: 0.4653\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3566 - acc: 0.7862 - val_loss: 2.0761 - val_acc: 0.4743\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3699 - acc: 0.7855 - val_loss: 2.1210 - val_acc: 0.4441\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3950 - acc: 0.7823 - val_loss: 2.1928 - val_acc: 0.4290\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4195 - acc: 0.7573 - val_loss: 2.1630 - val_acc: 0.4260\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3998 - acc: 0.7760 - val_loss: 2.0500 - val_acc: 0.4653\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3911 - acc: 0.7799 - val_loss: 2.0309 - val_acc: 0.4653\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4402 - acc: 0.7489 - val_loss: 2.0873 - val_acc: 0.4290\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4502 - acc: 0.7256 - val_loss: 1.9964 - val_acc: 0.4562\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4132 - acc: 0.7594 - val_loss: 2.0300 - val_acc: 0.4592\n",
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3940 - acc: 0.7622 - val_loss: 2.0015 - val_acc: 0.4773\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4033 - acc: 0.7496 - val_loss: 1.9410 - val_acc: 0.4894\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3777 - acc: 0.7686 - val_loss: 1.9849 - val_acc: 0.5076\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3654 - acc: 0.7788 - val_loss: 1.9893 - val_acc: 0.4894\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3694 - acc: 0.7872 - val_loss: 2.0011 - val_acc: 0.4804\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4229 - acc: 0.7393 - val_loss: 1.9843 - val_acc: 0.5015\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4464 - acc: 0.7175 - val_loss: 1.9368 - val_acc: 0.4955\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3671 - acc: 0.7809 - val_loss: 1.9724 - val_acc: 0.4773\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3679 - acc: 0.7936 - val_loss: 2.0257 - val_acc: 0.4653\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3924 - acc: 0.7795 - val_loss: 2.0429 - val_acc: 0.4773\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4408 - acc: 0.7605 - val_loss: 1.9925 - val_acc: 0.4471\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4013 - acc: 0.7781 - val_loss: 1.9899 - val_acc: 0.4683\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3547 - acc: 0.7925 - val_loss: 2.0392 - val_acc: 0.4773\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3487 - acc: 0.8006 - val_loss: 2.1067 - val_acc: 0.4502\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3415 - acc: 0.7911 - val_loss: 2.1413 - val_acc: 0.4502\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3814 - acc: 0.7816 - val_loss: 2.1413 - val_acc: 0.4502\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4187 - acc: 0.7728 - val_loss: 2.0901 - val_acc: 0.4411\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4085 - acc: 0.7858 - val_loss: 2.0636 - val_acc: 0.4562\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4580 - acc: 0.7608 - val_loss: 2.0050 - val_acc: 0.4864\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4621 - acc: 0.7608 - val_loss: 1.9265 - val_acc: 0.4955\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3710 - acc: 0.7816 - val_loss: 1.9933 - val_acc: 0.4924\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3548 - acc: 0.7925 - val_loss: 2.0144 - val_acc: 0.4713\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3486 - acc: 0.7841 - val_loss: 2.0399 - val_acc: 0.4713\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3505 - acc: 0.7918 - val_loss: 2.0727 - val_acc: 0.4592\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3667 - acc: 0.7865 - val_loss: 2.1200 - val_acc: 0.4441\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3811 - acc: 0.7608 - val_loss: 2.0335 - val_acc: 0.4773\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4376 - acc: 0.7379 - val_loss: 2.0013 - val_acc: 0.4864\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5160 - acc: 0.6847 - val_loss: 1.9105 - val_acc: 0.5045\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3682 - acc: 0.7749 - val_loss: 2.0396 - val_acc: 0.4653\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3496 - acc: 0.7978 - val_loss: 2.0553 - val_acc: 0.4743\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3658 - acc: 0.7883 - val_loss: 2.0295 - val_acc: 0.4894\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3628 - acc: 0.7848 - val_loss: 2.0351 - val_acc: 0.4985\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4154 - acc: 0.7725 - val_loss: 1.9988 - val_acc: 0.4955\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3782 - acc: 0.7904 - val_loss: 2.0954 - val_acc: 0.4622\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3542 - acc: 0.7915 - val_loss: 2.1073 - val_acc: 0.4471\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3706 - acc: 0.8020 - val_loss: 2.0946 - val_acc: 0.4713\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3638 - acc: 0.7932 - val_loss: 2.2331 - val_acc: 0.4260\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3863 - acc: 0.7795 - val_loss: 2.2540 - val_acc: 0.4169\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4031 - acc: 0.7675 - val_loss: 2.1073 - val_acc: 0.4532\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3669 - acc: 0.7968 - val_loss: 2.1239 - val_acc: 0.4743\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3637 - acc: 0.7939 - val_loss: 2.1871 - val_acc: 0.4441\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4149 - acc: 0.7858 - val_loss: 1.9804 - val_acc: 0.4864\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4535 - acc: 0.7552 - val_loss: 2.0201 - val_acc: 0.4894\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3788 - acc: 0.7901 - val_loss: 2.0344 - val_acc: 0.4834\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3266 - acc: 0.7989 - val_loss: 2.0886 - val_acc: 0.4653\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3272 - acc: 0.8063 - val_loss: 2.1059 - val_acc: 0.4894\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3582 - acc: 0.7855 - val_loss: 2.0657 - val_acc: 0.4834\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3927 - acc: 0.7682 - val_loss: 2.0379 - val_acc: 0.5045\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4335 - acc: 0.7584 - val_loss: 2.0826 - val_acc: 0.4894\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3683 - acc: 0.7897 - val_loss: 2.0800 - val_acc: 0.4683\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3528 - acc: 0.7999 - val_loss: 2.2085 - val_acc: 0.4622\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3613 - acc: 0.7964 - val_loss: 2.2983 - val_acc: 0.4350\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4321 - acc: 0.7570 - val_loss: 2.2344 - val_acc: 0.4320\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.7837 - val_loss: 2.0707 - val_acc: 0.4804\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3403 - acc: 0.7964 - val_loss: 2.0997 - val_acc: 0.4864\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3479 - acc: 0.7978 - val_loss: 2.1869 - val_acc: 0.4773\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3226 - acc: 0.8112 - val_loss: 2.1912 - val_acc: 0.4502\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3436 - acc: 0.7954 - val_loss: 2.3923 - val_acc: 0.4139\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4214 - acc: 0.7545 - val_loss: 2.3758 - val_acc: 0.3927\n",
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3847 - acc: 0.7806 - val_loss: 2.1828 - val_acc: 0.4562\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3420 - acc: 0.8010 - val_loss: 2.1939 - val_acc: 0.4562\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3459 - acc: 0.7957 - val_loss: 2.1677 - val_acc: 0.4562\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3670 - acc: 0.7806 - val_loss: 2.3022 - val_acc: 0.4199\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6061 - acc: 0.6974 - val_loss: 2.1141 - val_acc: 0.4411\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4148 - acc: 0.7580 - val_loss: 2.0822 - val_acc: 0.4713\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3389 - acc: 0.8066 - val_loss: 2.0839 - val_acc: 0.4743\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3311 - acc: 0.7999 - val_loss: 2.1447 - val_acc: 0.4804\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3093 - acc: 0.8278 - val_loss: 2.1779 - val_acc: 0.4622\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3318 - acc: 0.7989 - val_loss: 2.1937 - val_acc: 0.4804\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3267 - acc: 0.8126 - val_loss: 2.1156 - val_acc: 0.5015\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3457 - acc: 0.7961 - val_loss: 2.1535 - val_acc: 0.4985\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3806 - acc: 0.7830 - val_loss: 2.0864 - val_acc: 0.4894\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3645 - acc: 0.7848 - val_loss: 2.1244 - val_acc: 0.4985\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3334 - acc: 0.8031 - val_loss: 2.1459 - val_acc: 0.4894\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3325 - acc: 0.8112 - val_loss: 2.1456 - val_acc: 0.4773\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3561 - acc: 0.7865 - val_loss: 2.1875 - val_acc: 0.4804\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4127 - acc: 0.7355 - val_loss: 2.1230 - val_acc: 0.4804\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3553 - acc: 0.7760 - val_loss: 2.1372 - val_acc: 0.4773\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3210 - acc: 0.8052 - val_loss: 2.1433 - val_acc: 0.4924\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3370 - acc: 0.8190 - val_loss: 2.1822 - val_acc: 0.4864\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3190 - acc: 0.8094 - val_loss: 2.2098 - val_acc: 0.4894\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3113 - acc: 0.8292 - val_loss: 2.2551 - val_acc: 0.4622\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3458 - acc: 0.7883 - val_loss: 2.1825 - val_acc: 0.4743\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4219 - acc: 0.7376 - val_loss: 2.1880 - val_acc: 0.4834\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4730 - acc: 0.7115 - val_loss: 2.0592 - val_acc: 0.4622\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3488 - acc: 0.7844 - val_loss: 2.1804 - val_acc: 0.4894\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3354 - acc: 0.8020 - val_loss: 2.1575 - val_acc: 0.4834\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3290 - acc: 0.7968 - val_loss: 2.1821 - val_acc: 0.5136\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3396 - acc: 0.8080 - val_loss: 2.2149 - val_acc: 0.4955\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3440 - acc: 0.8056 - val_loss: 2.1371 - val_acc: 0.5045\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3752 - acc: 0.7834 - val_loss: 2.1908 - val_acc: 0.5045\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3655 - acc: 0.7922 - val_loss: 2.1992 - val_acc: 0.4955\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3501 - acc: 0.8006 - val_loss: 2.1939 - val_acc: 0.5015\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3145 - acc: 0.8137 - val_loss: 2.1857 - val_acc: 0.5015\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3231 - acc: 0.8112 - val_loss: 2.1662 - val_acc: 0.4834\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3722 - acc: 0.7732 - val_loss: 2.1717 - val_acc: 0.4834\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4036 - acc: 0.7383 - val_loss: 2.1059 - val_acc: 0.4743\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3444 - acc: 0.7894 - val_loss: 2.1430 - val_acc: 0.4592\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3310 - acc: 0.8024 - val_loss: 2.2125 - val_acc: 0.4773\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3356 - acc: 0.7964 - val_loss: 2.2456 - val_acc: 0.4441\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3343 - acc: 0.8013 - val_loss: 2.2372 - val_acc: 0.4894\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3219 - acc: 0.8101 - val_loss: 2.2703 - val_acc: 0.4411\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3636 - acc: 0.7936 - val_loss: 2.3208 - val_acc: 0.4411\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4680 - acc: 0.7485 - val_loss: 2.1666 - val_acc: 0.4441\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4030 - acc: 0.7489 - val_loss: 2.1087 - val_acc: 0.4773\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3602 - acc: 0.7760 - val_loss: 2.1326 - val_acc: 0.4955\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3159 - acc: 0.8147 - val_loss: 2.1465 - val_acc: 0.4864\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3525 - acc: 0.7946 - val_loss: 2.1775 - val_acc: 0.4985\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3272 - acc: 0.7950 - val_loss: 2.1620 - val_acc: 0.4985\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3335 - acc: 0.7971 - val_loss: 2.1769 - val_acc: 0.4683\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3119 - acc: 0.8094 - val_loss: 2.2016 - val_acc: 0.4773\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3216 - acc: 0.8020 - val_loss: 2.2155 - val_acc: 0.4653\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3582 - acc: 0.7735 - val_loss: 2.2036 - val_acc: 0.4622\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3928 - acc: 0.7615 - val_loss: 2.2180 - val_acc: 0.4532\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3886 - acc: 0.7661 - val_loss: 2.2089 - val_acc: 0.4622\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3574 - acc: 0.7872 - val_loss: 2.2100 - val_acc: 0.4743\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3338 - acc: 0.8137 - val_loss: 2.3027 - val_acc: 0.4592\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3302 - acc: 0.8112 - val_loss: 2.2752 - val_acc: 0.4532\n",
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3546 - acc: 0.7989 - val_loss: 2.3219 - val_acc: 0.4411\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3272 - acc: 0.8087 - val_loss: 2.2230 - val_acc: 0.4804\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3165 - acc: 0.8087 - val_loss: 2.2974 - val_acc: 0.4804\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3110 - acc: 0.8112 - val_loss: 2.2524 - val_acc: 0.4804\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3183 - acc: 0.8087 - val_loss: 2.3692 - val_acc: 0.4562\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3819 - acc: 0.7876 - val_loss: 2.4692 - val_acc: 0.4350\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4227 - acc: 0.7718 - val_loss: 2.3092 - val_acc: 0.4562\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3953 - acc: 0.7880 - val_loss: 2.2214 - val_acc: 0.4985\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3563 - acc: 0.8105 - val_loss: 2.1870 - val_acc: 0.4864\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3207 - acc: 0.8137 - val_loss: 2.2624 - val_acc: 0.4743\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2946 - acc: 0.8288 - val_loss: 2.2877 - val_acc: 0.4804\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2915 - acc: 0.8344 - val_loss: 2.2691 - val_acc: 0.4834\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3493 - acc: 0.7978 - val_loss: 2.2774 - val_acc: 0.4713\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3843 - acc: 0.7964 - val_loss: 2.2031 - val_acc: 0.4985\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3310 - acc: 0.8133 - val_loss: 2.2872 - val_acc: 0.4713\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3075 - acc: 0.8267 - val_loss: 2.3280 - val_acc: 0.4653\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3025 - acc: 0.8218 - val_loss: 2.4385 - val_acc: 0.4502\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3319 - acc: 0.8161 - val_loss: 2.6362 - val_acc: 0.4230\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4524 - acc: 0.7517 - val_loss: 2.4022 - val_acc: 0.4290\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3477 - acc: 0.8168 - val_loss: 2.2905 - val_acc: 0.4743\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3035 - acc: 0.8158 - val_loss: 2.2933 - val_acc: 0.4894\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3137 - acc: 0.8249 - val_loss: 2.3430 - val_acc: 0.4894\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3571 - acc: 0.8059 - val_loss: 2.3837 - val_acc: 0.4804\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3886 - acc: 0.7996 - val_loss: 2.2931 - val_acc: 0.4804\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3518 - acc: 0.8045 - val_loss: 2.3419 - val_acc: 0.4502\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3258 - acc: 0.8193 - val_loss: 2.3896 - val_acc: 0.4441\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3397 - acc: 0.8123 - val_loss: 2.4160 - val_acc: 0.4471\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3613 - acc: 0.8010 - val_loss: 2.2928 - val_acc: 0.4592\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3059 - acc: 0.8267 - val_loss: 2.3424 - val_acc: 0.4743\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2969 - acc: 0.8218 - val_loss: 2.3880 - val_acc: 0.4622\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3132 - acc: 0.8200 - val_loss: 2.4050 - val_acc: 0.4502\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3306 - acc: 0.8105 - val_loss: 2.5938 - val_acc: 0.4048\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4008 - acc: 0.7640 - val_loss: 2.3516 - val_acc: 0.4532\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3649 - acc: 0.8031 - val_loss: 2.3012 - val_acc: 0.4743\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3438 - acc: 0.8151 - val_loss: 2.3218 - val_acc: 0.4683\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3272 - acc: 0.8249 - val_loss: 2.3565 - val_acc: 0.4683\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2976 - acc: 0.8299 - val_loss: 2.3681 - val_acc: 0.4924\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3170 - acc: 0.8193 - val_loss: 2.4521 - val_acc: 0.4592\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3531 - acc: 0.8017 - val_loss: 2.4048 - val_acc: 0.4471\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3495 - acc: 0.8140 - val_loss: 2.2638 - val_acc: 0.5015\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3504 - acc: 0.8077 - val_loss: 2.2953 - val_acc: 0.4985\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3070 - acc: 0.8119 - val_loss: 2.2856 - val_acc: 0.4834\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2982 - acc: 0.8190 - val_loss: 2.3002 - val_acc: 0.4773\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3213 - acc: 0.8070 - val_loss: 2.3405 - val_acc: 0.4532\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3382 - acc: 0.7932 - val_loss: 2.2931 - val_acc: 0.4562\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3644 - acc: 0.7763 - val_loss: 2.2786 - val_acc: 0.4502\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3063 - acc: 0.8020 - val_loss: 2.3054 - val_acc: 0.4713\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3021 - acc: 0.8263 - val_loss: 2.3512 - val_acc: 0.5015\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3333 - acc: 0.8038 - val_loss: 2.3717 - val_acc: 0.5106\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4906 - acc: 0.7640 - val_loss: 2.3664 - val_acc: 0.4924\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4270 - acc: 0.7784 - val_loss: 2.2864 - val_acc: 0.4683\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3029 - acc: 0.8299 - val_loss: 2.3268 - val_acc: 0.4864\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2934 - acc: 0.8341 - val_loss: 2.3959 - val_acc: 0.4471\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3123 - acc: 0.8246 - val_loss: 2.3741 - val_acc: 0.4773\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3006 - acc: 0.8271 - val_loss: 2.4788 - val_acc: 0.4562\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3128 - acc: 0.8193 - val_loss: 2.5917 - val_acc: 0.4290\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3807 - acc: 0.8020 - val_loss: 2.5594 - val_acc: 0.4230\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3276 - acc: 0.8200 - val_loss: 2.3917 - val_acc: 0.4592\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2923 - acc: 0.8348 - val_loss: 2.3894 - val_acc: 0.4743\n",
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2755 - acc: 0.8415 - val_loss: 2.4054 - val_acc: 0.4834\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2788 - acc: 0.8341 - val_loss: 2.3996 - val_acc: 0.4683\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3649 - acc: 0.8080 - val_loss: 2.6819 - val_acc: 0.3716\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6061 - acc: 0.6897 - val_loss: 2.2154 - val_acc: 0.4773\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3243 - acc: 0.8112 - val_loss: 2.2633 - val_acc: 0.4804\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3066 - acc: 0.8179 - val_loss: 2.3237 - val_acc: 0.4773\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3012 - acc: 0.8186 - val_loss: 2.3238 - val_acc: 0.4924\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.3298 - acc: 0.8091 - val_loss: 2.2825 - val_acc: 0.4713\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.3181 - acc: 0.8052 - val_loss: 2.3023 - val_acc: 0.4804\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3037 - acc: 0.8133 - val_loss: 2.3607 - val_acc: 0.4683\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2872 - acc: 0.8337 - val_loss: 2.4450 - val_acc: 0.4411\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3008 - acc: 0.8228 - val_loss: 2.4511 - val_acc: 0.4441\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3081 - acc: 0.8182 - val_loss: 2.4560 - val_acc: 0.4683\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3026 - acc: 0.8313 - val_loss: 2.4778 - val_acc: 0.4471\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3472 - acc: 0.8024 - val_loss: 2.5409 - val_acc: 0.4350\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3327 - acc: 0.8144 - val_loss: 2.3943 - val_acc: 0.4713\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3083 - acc: 0.8218 - val_loss: 2.3586 - val_acc: 0.4804\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3292 - acc: 0.8221 - val_loss: 2.3501 - val_acc: 0.4834\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3192 - acc: 0.8204 - val_loss: 2.3761 - val_acc: 0.4804\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.2794 - acc: 0.8334 - val_loss: 2.4953 - val_acc: 0.4562\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.2900 - acc: 0.8383 - val_loss: 2.6373 - val_acc: 0.4441\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3544 - acc: 0.7999 - val_loss: 2.7351 - val_acc: 0.4109\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3645 - acc: 0.7929 - val_loss: 2.4536 - val_acc: 0.4471\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.3291 - acc: 0.8242 - val_loss: 2.4280 - val_acc: 0.4743\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.3084 - acc: 0.8239 - val_loss: 2.4314 - val_acc: 0.4562\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3350 - acc: 0.7978 - val_loss: 2.4639 - val_acc: 0.4441\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3165 - acc: 0.8130 - val_loss: 2.3986 - val_acc: 0.4683\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3144 - acc: 0.8108 - val_loss: 2.3932 - val_acc: 0.4834\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.3066 - acc: 0.8084 - val_loss: 2.4238 - val_acc: 0.4592\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3117 - acc: 0.8087 - val_loss: 2.3650 - val_acc: 0.4562\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3059 - acc: 0.8080 - val_loss: 2.3789 - val_acc: 0.4834\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.2899 - acc: 0.8299 - val_loss: 2.3800 - val_acc: 0.5015\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3872 - acc: 0.7862 - val_loss: 2.2953 - val_acc: 0.4894\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3462 - acc: 0.7957 - val_loss: 2.3434 - val_acc: 0.4804\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3222 - acc: 0.7932 - val_loss: 2.3753 - val_acc: 0.4773\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2946 - acc: 0.8267 - val_loss: 2.4246 - val_acc: 0.4713\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3234 - acc: 0.8161 - val_loss: 2.4873 - val_acc: 0.4471\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4033 - acc: 0.7834 - val_loss: 2.3787 - val_acc: 0.4441\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3643 - acc: 0.7813 - val_loss: 2.3629 - val_acc: 0.4743\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3024 - acc: 0.8256 - val_loss: 2.3699 - val_acc: 0.4864\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2737 - acc: 0.8323 - val_loss: 2.4027 - val_acc: 0.4834\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3132 - acc: 0.8084 - val_loss: 2.3819 - val_acc: 0.4955\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3454 - acc: 0.7788 - val_loss: 2.3240 - val_acc: 0.4713\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2994 - acc: 0.8077 - val_loss: 2.3899 - val_acc: 0.4532\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2980 - acc: 0.8161 - val_loss: 2.5026 - val_acc: 0.4743\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2923 - acc: 0.8235 - val_loss: 2.4762 - val_acc: 0.4743\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2943 - acc: 0.8232 - val_loss: 2.4895 - val_acc: 0.4743\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3483 - acc: 0.7989 - val_loss: 2.4772 - val_acc: 0.4350\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5171 - acc: 0.7298 - val_loss: 2.3793 - val_acc: 0.4622\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3317 - acc: 0.7982 - val_loss: 2.3224 - val_acc: 0.4804\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2901 - acc: 0.8337 - val_loss: 2.4805 - val_acc: 0.4562\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3030 - acc: 0.8207 - val_loss: 2.4678 - val_acc: 0.4622\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2703 - acc: 0.8482 - val_loss: 2.6302 - val_acc: 0.4350\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3306 - acc: 0.8204 - val_loss: 2.5744 - val_acc: 0.4471\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2975 - acc: 0.8369 - val_loss: 2.5627 - val_acc: 0.4441\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3012 - acc: 0.8267 - val_loss: 2.5639 - val_acc: 0.4532\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2919 - acc: 0.8397 - val_loss: 2.5764 - val_acc: 0.4471\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3010 - acc: 0.8239 - val_loss: 2.6463 - val_acc: 0.4381\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3448 - acc: 0.8214 - val_loss: 2.5772 - val_acc: 0.4502\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3218 - acc: 0.8147 - val_loss: 2.5092 - val_acc: 0.4622\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2848 - acc: 0.8468 - val_loss: 2.5077 - val_acc: 0.4955\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2925 - acc: 0.8327 - val_loss: 2.4711 - val_acc: 0.4713\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3000 - acc: 0.8369 - val_loss: 2.5158 - val_acc: 0.4562\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2871 - acc: 0.8394 - val_loss: 2.6064 - val_acc: 0.4502\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3129 - acc: 0.8267 - val_loss: 2.5931 - val_acc: 0.4290\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3118 - acc: 0.8344 - val_loss: 2.4536 - val_acc: 0.4683\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2772 - acc: 0.8394 - val_loss: 2.5020 - val_acc: 0.4743\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2888 - acc: 0.8330 - val_loss: 2.4824 - val_acc: 0.4622\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2699 - acc: 0.8457 - val_loss: 2.7476 - val_acc: 0.4260\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3747 - acc: 0.7872 - val_loss: 2.6651 - val_acc: 0.4230\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3890 - acc: 0.7922 - val_loss: 2.4868 - val_acc: 0.4653\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2803 - acc: 0.8457 - val_loss: 2.4951 - val_acc: 0.4834\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2781 - acc: 0.8376 - val_loss: 2.5573 - val_acc: 0.4743\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2820 - acc: 0.8422 - val_loss: 2.5781 - val_acc: 0.4502\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3228 - acc: 0.8278 - val_loss: 2.6490 - val_acc: 0.4683\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4783 - acc: 0.8080 - val_loss: 2.3933 - val_acc: 0.4834\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3107 - acc: 0.8320 - val_loss: 2.4583 - val_acc: 0.4653\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2708 - acc: 0.8376 - val_loss: 2.4442 - val_acc: 0.4894\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2580 - acc: 0.8517 - val_loss: 2.5417 - val_acc: 0.4773\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2656 - acc: 0.8404 - val_loss: 2.5291 - val_acc: 0.4743\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2638 - acc: 0.8457 - val_loss: 2.5276 - val_acc: 0.4864\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2659 - acc: 0.8503 - val_loss: 2.6086 - val_acc: 0.4592\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2893 - acc: 0.8362 - val_loss: 2.6608 - val_acc: 0.4592\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3072 - acc: 0.8218 - val_loss: 2.7651 - val_acc: 0.4290\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3585 - acc: 0.8027 - val_loss: 2.6723 - val_acc: 0.4290\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3427 - acc: 0.8080 - val_loss: 2.6778 - val_acc: 0.4199\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3274 - acc: 0.8158 - val_loss: 2.5281 - val_acc: 0.4653\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2798 - acc: 0.8447 - val_loss: 2.5270 - val_acc: 0.4683\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2772 - acc: 0.8383 - val_loss: 2.5943 - val_acc: 0.4592\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2959 - acc: 0.8168 - val_loss: 2.5157 - val_acc: 0.4743\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2947 - acc: 0.8302 - val_loss: 2.5362 - val_acc: 0.4773\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3034 - acc: 0.8186 - val_loss: 2.4794 - val_acc: 0.4622\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3331 - acc: 0.8035 - val_loss: 2.4459 - val_acc: 0.4471\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3786 - acc: 0.7700 - val_loss: 2.5032 - val_acc: 0.4350\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3813 - acc: 0.7844 - val_loss: 2.5158 - val_acc: 0.4471\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2951 - acc: 0.8281 - val_loss: 2.5009 - val_acc: 0.4834\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2483 - acc: 0.8503 - val_loss: 2.4922 - val_acc: 0.4713\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2665 - acc: 0.8482 - val_loss: 2.4937 - val_acc: 0.4773\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2747 - acc: 0.8411 - val_loss: 2.5438 - val_acc: 0.4683\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.2849 - acc: 0.8447 - val_loss: 2.5668 - val_acc: 0.4592\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2883 - acc: 0.8443 - val_loss: 2.5515 - val_acc: 0.4622\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3027 - acc: 0.8355 - val_loss: 2.6299 - val_acc: 0.4653\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3125 - acc: 0.8341 - val_loss: 2.6483 - val_acc: 0.4622\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2856 - acc: 0.8401 - val_loss: 2.5961 - val_acc: 0.4713\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2697 - acc: 0.8485 - val_loss: 2.8124 - val_acc: 0.4350\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3407 - acc: 0.8119 - val_loss: 2.9000 - val_acc: 0.4230\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3555 - acc: 0.7929 - val_loss: 2.6334 - val_acc: 0.4381\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2940 - acc: 0.8380 - val_loss: 2.5886 - val_acc: 0.4653\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2645 - acc: 0.8485 - val_loss: 2.5954 - val_acc: 0.4592\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2549 - acc: 0.8552 - val_loss: 2.6225 - val_acc: 0.4653\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2531 - acc: 0.8580 - val_loss: 2.5810 - val_acc: 0.4743\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2748 - acc: 0.8404 - val_loss: 2.5466 - val_acc: 0.4502\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2912 - acc: 0.8098 - val_loss: 2.5731 - val_acc: 0.4622\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3202 - acc: 0.7950 - val_loss: 2.5227 - val_acc: 0.4713\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 48us/step - loss: 0.3229 - acc: 0.8006 - val_loss: 2.5575 - val_acc: 0.4713\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3505 - acc: 0.8193 - val_loss: 2.6313 - val_acc: 0.4320\n"
     ]
    }
   ],
   "source": [
    "business_model = model.fit(x=X_train_business, y=y_cat_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_cat_test_business),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "0.7647058823529411\n",
      "1.0\n",
      "46\n",
      "0.9782608695652174\n",
      "1.1956521739130435\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_business)\n",
    "model_metrics(predictions, X_test_business, y_cat_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x174988ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(business_model.history['acc'])\n",
    "plt.plot(business_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 1.6095 - acc: 0.2867 - val_loss: 1.3737 - val_acc: 0.4169\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.3743 - acc: 0.3698 - val_loss: 1.4394 - val_acc: 0.3323\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.3419 - acc: 0.3670 - val_loss: 1.3779 - val_acc: 0.3384\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.3302 - acc: 0.3790 - val_loss: 1.3915 - val_acc: 0.3323\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.3208 - acc: 0.3617 - val_loss: 1.3997 - val_acc: 0.3353\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.3079 - acc: 0.3494 - val_loss: 1.3805 - val_acc: 0.3384\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2969 - acc: 0.3772 - val_loss: 1.3599 - val_acc: 0.3444\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2925 - acc: 0.3751 - val_loss: 1.3831 - val_acc: 0.3384\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2851 - acc: 0.3681 - val_loss: 1.3959 - val_acc: 0.3414\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.2805 - acc: 0.3790 - val_loss: 1.3547 - val_acc: 0.3384\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2866 - acc: 0.3934 - val_loss: 1.3579 - val_acc: 0.3384\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2837 - acc: 0.3804 - val_loss: 1.3613 - val_acc: 0.3353\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2725 - acc: 0.3878 - val_loss: 1.3911 - val_acc: 0.3293\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2571 - acc: 0.3769 - val_loss: 1.3356 - val_acc: 0.3414\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2520 - acc: 0.3980 - val_loss: 1.3574 - val_acc: 0.3293\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2453 - acc: 0.3734 - val_loss: 1.3478 - val_acc: 0.3293\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2532 - acc: 0.3755 - val_loss: 1.3461 - val_acc: 0.3293\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2543 - acc: 0.3945 - val_loss: 1.3498 - val_acc: 0.3353\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2214 - acc: 0.3924 - val_loss: 1.3841 - val_acc: 0.3263\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2463 - acc: 0.3871 - val_loss: 1.3448 - val_acc: 0.3323\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2299 - acc: 0.3920 - val_loss: 1.3280 - val_acc: 0.3263\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.2194 - acc: 0.4037 - val_loss: 1.3419 - val_acc: 0.3323\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 1.2162 - acc: 0.3942 - val_loss: 1.3105 - val_acc: 0.3323\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2054 - acc: 0.3984 - val_loss: 1.3231 - val_acc: 0.3384\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2099 - acc: 0.3998 - val_loss: 1.3149 - val_acc: 0.3323\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1944 - acc: 0.4068 - val_loss: 1.3167 - val_acc: 0.3444\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2191 - acc: 0.4156 - val_loss: 1.3620 - val_acc: 0.2961\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1953 - acc: 0.3808 - val_loss: 1.5375 - val_acc: 0.2749\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2337 - acc: 0.3635 - val_loss: 1.3162 - val_acc: 0.3293\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1830 - acc: 0.4125 - val_loss: 1.3375 - val_acc: 0.3202\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1758 - acc: 0.4047 - val_loss: 1.3557 - val_acc: 0.3202\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1782 - acc: 0.4082 - val_loss: 1.3795 - val_acc: 0.3293\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1952 - acc: 0.3924 - val_loss: 1.3232 - val_acc: 0.3323\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1543 - acc: 0.4206 - val_loss: 1.3132 - val_acc: 0.3142\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1572 - acc: 0.4181 - val_loss: 1.2933 - val_acc: 0.3202\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.1601 - acc: 0.4167 - val_loss: 1.3081 - val_acc: 0.3202\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1529 - acc: 0.4075 - val_loss: 1.2616 - val_acc: 0.3263\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1586 - acc: 0.4340 - val_loss: 1.3643 - val_acc: 0.3082\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1827 - acc: 0.4082 - val_loss: 1.3791 - val_acc: 0.3112\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1802 - acc: 0.3942 - val_loss: 1.4187 - val_acc: 0.2810\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1502 - acc: 0.3934 - val_loss: 1.3212 - val_acc: 0.3202\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1267 - acc: 0.4216 - val_loss: 1.2695 - val_acc: 0.3353\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1356 - acc: 0.4213 - val_loss: 1.2531 - val_acc: 0.3323\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1497 - acc: 0.4255 - val_loss: 1.3183 - val_acc: 0.3202\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1282 - acc: 0.4146 - val_loss: 1.4301 - val_acc: 0.2659\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1848 - acc: 0.3843 - val_loss: 1.4047 - val_acc: 0.2870\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1203 - acc: 0.3945 - val_loss: 1.3875 - val_acc: 0.3112\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1268 - acc: 0.4251 - val_loss: 1.4125 - val_acc: 0.3112\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1449 - acc: 0.4163 - val_loss: 1.3545 - val_acc: 0.3233\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1251 - acc: 0.4244 - val_loss: 1.3517 - val_acc: 0.3172\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1329 - acc: 0.4121 - val_loss: 1.3091 - val_acc: 0.3263\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1187 - acc: 0.4174 - val_loss: 1.2607 - val_acc: 0.3444\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1358 - acc: 0.4241 - val_loss: 1.2927 - val_acc: 0.3323\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1056 - acc: 0.4308 - val_loss: 1.3527 - val_acc: 0.3202\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0929 - acc: 0.4318 - val_loss: 1.5399 - val_acc: 0.3112\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1597 - acc: 0.4082 - val_loss: 1.2553 - val_acc: 0.3474\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1199 - acc: 0.4301 - val_loss: 1.2735 - val_acc: 0.3323\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0877 - acc: 0.4315 - val_loss: 1.2944 - val_acc: 0.3353\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0944 - acc: 0.4315 - val_loss: 1.3794 - val_acc: 0.3233\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1038 - acc: 0.4283 - val_loss: 1.4281 - val_acc: 0.3142\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1114 - acc: 0.4195 - val_loss: 1.3091 - val_acc: 0.3263\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0870 - acc: 0.4308 - val_loss: 1.2975 - val_acc: 0.3263\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0692 - acc: 0.4375 - val_loss: 1.2518 - val_acc: 0.3353\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.1391 - acc: 0.4153 - val_loss: 1.2227 - val_acc: 0.3565\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1107 - acc: 0.4435 - val_loss: 1.3233 - val_acc: 0.3172\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0616 - acc: 0.4336 - val_loss: 1.4124 - val_acc: 0.3202\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0679 - acc: 0.4273 - val_loss: 1.3668 - val_acc: 0.3353\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0619 - acc: 0.4192 - val_loss: 1.3883 - val_acc: 0.3565\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1332 - acc: 0.4153 - val_loss: 1.2413 - val_acc: 0.4199\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1225 - acc: 0.4607 - val_loss: 1.3799 - val_acc: 0.2870\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0708 - acc: 0.4068 - val_loss: 1.4150 - val_acc: 0.3082\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0695 - acc: 0.4139 - val_loss: 1.4373 - val_acc: 0.3233\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0663 - acc: 0.4329 - val_loss: 1.4326 - val_acc: 0.3082\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1000 - acc: 0.4192 - val_loss: 1.2943 - val_acc: 0.3172\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0589 - acc: 0.4294 - val_loss: 1.2263 - val_acc: 0.3474\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1048 - acc: 0.4241 - val_loss: 1.2536 - val_acc: 0.3535\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 1.0477 - acc: 0.4452 - val_loss: 1.2283 - val_acc: 0.3897\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.0543 - acc: 0.4480 - val_loss: 1.2002 - val_acc: 0.3927\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0957 - acc: 0.4547 - val_loss: 1.3606 - val_acc: 0.3233\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0470 - acc: 0.4318 - val_loss: 1.3414 - val_acc: 0.3293\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0219 - acc: 0.4396 - val_loss: 1.3772 - val_acc: 0.3293\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0776 - acc: 0.4389 - val_loss: 1.3502 - val_acc: 0.3172\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.0833 - acc: 0.4357 - val_loss: 1.2368 - val_acc: 0.3565\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0722 - acc: 0.4269 - val_loss: 1.2056 - val_acc: 0.3807\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0684 - acc: 0.4530 - val_loss: 1.2806 - val_acc: 0.3686\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0124 - acc: 0.4509 - val_loss: 1.2975 - val_acc: 0.3686\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0074 - acc: 0.4569 - val_loss: 1.2448 - val_acc: 0.4199\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0654 - acc: 0.4597 - val_loss: 1.2130 - val_acc: 0.4320\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0574 - acc: 0.4614 - val_loss: 1.2696 - val_acc: 0.3384\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0091 - acc: 0.4583 - val_loss: 1.2445 - val_acc: 0.3444\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1288 - acc: 0.4385 - val_loss: 1.3844 - val_acc: 0.3353\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0427 - acc: 0.4459 - val_loss: 1.4527 - val_acc: 0.3202\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0546 - acc: 0.4297 - val_loss: 1.3173 - val_acc: 0.3353\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0084 - acc: 0.4579 - val_loss: 1.2855 - val_acc: 0.3927\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0336 - acc: 0.4487 - val_loss: 1.2284 - val_acc: 0.4260\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.0289 - acc: 0.4685 - val_loss: 1.1903 - val_acc: 0.4018\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0453 - acc: 0.4614 - val_loss: 1.2295 - val_acc: 0.3716\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0188 - acc: 0.4586 - val_loss: 1.2228 - val_acc: 0.3897\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0219 - acc: 0.4614 - val_loss: 1.2334 - val_acc: 0.3837\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0252 - acc: 0.4561 - val_loss: 1.2307 - val_acc: 0.3927\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0308 - acc: 0.4586 - val_loss: 1.2232 - val_acc: 0.4230\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0079 - acc: 0.4671 - val_loss: 1.2168 - val_acc: 0.4502\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0405 - acc: 0.4646 - val_loss: 1.1998 - val_acc: 0.4502\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0888 - acc: 0.4664 - val_loss: 1.3029 - val_acc: 0.3625\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9975 - acc: 0.4530 - val_loss: 1.4343 - val_acc: 0.2961\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0639 - acc: 0.4132 - val_loss: 1.3763 - val_acc: 0.3595\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0157 - acc: 0.4463 - val_loss: 1.3530 - val_acc: 0.3595\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0026 - acc: 0.4660 - val_loss: 1.3813 - val_acc: 0.3353\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0067 - acc: 0.4495 - val_loss: 1.4093 - val_acc: 0.3202\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0238 - acc: 0.4301 - val_loss: 1.3322 - val_acc: 0.3776\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0005 - acc: 0.4487 - val_loss: 1.3665 - val_acc: 0.3625\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0541 - acc: 0.4396 - val_loss: 1.2786 - val_acc: 0.4350\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9910 - acc: 0.4709 - val_loss: 1.2556 - val_acc: 0.4320\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9892 - acc: 0.4678 - val_loss: 1.1988 - val_acc: 0.4471\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0075 - acc: 0.4794 - val_loss: 1.2469 - val_acc: 0.4048\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9790 - acc: 0.4738 - val_loss: 1.1965 - val_acc: 0.4320\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0036 - acc: 0.4850 - val_loss: 1.1871 - val_acc: 0.4411\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0218 - acc: 0.4741 - val_loss: 1.2308 - val_acc: 0.4079\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9625 - acc: 0.4706 - val_loss: 1.2775 - val_acc: 0.4018\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9520 - acc: 0.4671 - val_loss: 1.3358 - val_acc: 0.3776\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9816 - acc: 0.4621 - val_loss: 1.2700 - val_acc: 0.3686\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9936 - acc: 0.4576 - val_loss: 1.1799 - val_acc: 0.4320\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0116 - acc: 0.4688 - val_loss: 1.2116 - val_acc: 0.4320\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9595 - acc: 0.4738 - val_loss: 1.1826 - val_acc: 0.4471\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9841 - acc: 0.4812 - val_loss: 1.1571 - val_acc: 0.4924\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0446 - acc: 0.4787 - val_loss: 1.3182 - val_acc: 0.3716\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9692 - acc: 0.4621 - val_loss: 1.3741 - val_acc: 0.3927\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9760 - acc: 0.4650 - val_loss: 1.2642 - val_acc: 0.4350\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9426 - acc: 0.4886 - val_loss: 1.3073 - val_acc: 0.4048\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9362 - acc: 0.4780 - val_loss: 1.3077 - val_acc: 0.4079\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9830 - acc: 0.4716 - val_loss: 1.2539 - val_acc: 0.4411\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0349 - acc: 0.4759 - val_loss: 1.1587 - val_acc: 0.4411\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0306 - acc: 0.4695 - val_loss: 1.2620 - val_acc: 0.3837\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9356 - acc: 0.4808 - val_loss: 1.2062 - val_acc: 0.4350\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9733 - acc: 0.4769 - val_loss: 1.1886 - val_acc: 0.4350\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9382 - acc: 0.4938 - val_loss: 1.1912 - val_acc: 0.4471\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9660 - acc: 0.4886 - val_loss: 1.1901 - val_acc: 0.4622\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9719 - acc: 0.5030 - val_loss: 1.2151 - val_acc: 0.4290\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9879 - acc: 0.4924 - val_loss: 1.3089 - val_acc: 0.4230\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9576 - acc: 0.4854 - val_loss: 1.3095 - val_acc: 0.4169\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9384 - acc: 0.4861 - val_loss: 1.4244 - val_acc: 0.3444\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0025 - acc: 0.4315 - val_loss: 1.2727 - val_acc: 0.4079\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9209 - acc: 0.4938 - val_loss: 1.2722 - val_acc: 0.4079\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9365 - acc: 0.4815 - val_loss: 1.4784 - val_acc: 0.3384\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0397 - acc: 0.4709 - val_loss: 1.2682 - val_acc: 0.4018\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9118 - acc: 0.4819 - val_loss: 1.2319 - val_acc: 0.4350\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9168 - acc: 0.4843 - val_loss: 1.1684 - val_acc: 0.4683\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9519 - acc: 0.4977 - val_loss: 1.1721 - val_acc: 0.4441\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9810 - acc: 0.5012 - val_loss: 1.2468 - val_acc: 0.4290\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8962 - acc: 0.5143 - val_loss: 1.2670 - val_acc: 0.4260\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9425 - acc: 0.4790 - val_loss: 1.2392 - val_acc: 0.4169\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9478 - acc: 0.4822 - val_loss: 1.2105 - val_acc: 0.4441\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9331 - acc: 0.4945 - val_loss: 1.1774 - val_acc: 0.4955\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0065 - acc: 0.4970 - val_loss: 1.2121 - val_acc: 0.4169\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9265 - acc: 0.4889 - val_loss: 1.1988 - val_acc: 0.4230\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9741 - acc: 0.4819 - val_loss: 1.2588 - val_acc: 0.4139\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8906 - acc: 0.5051 - val_loss: 1.3578 - val_acc: 0.4018\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9169 - acc: 0.4959 - val_loss: 1.4460 - val_acc: 0.3776\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9528 - acc: 0.4720 - val_loss: 1.3184 - val_acc: 0.3867\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8929 - acc: 0.4903 - val_loss: 1.2565 - val_acc: 0.4260\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8695 - acc: 0.5185 - val_loss: 1.2653 - val_acc: 0.4230\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9558 - acc: 0.4864 - val_loss: 1.3772 - val_acc: 0.3686\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9826 - acc: 0.4864 - val_loss: 1.2725 - val_acc: 0.4199\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8785 - acc: 0.4991 - val_loss: 1.2617 - val_acc: 0.4411\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8590 - acc: 0.5185 - val_loss: 1.1951 - val_acc: 0.4592\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9064 - acc: 0.5019 - val_loss: 1.1465 - val_acc: 0.4713\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0733 - acc: 0.4829 - val_loss: 1.3012 - val_acc: 0.3988\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9189 - acc: 0.4970 - val_loss: 1.2824 - val_acc: 0.4109\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8813 - acc: 0.5065 - val_loss: 1.3817 - val_acc: 0.3867\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9460 - acc: 0.4868 - val_loss: 1.3527 - val_acc: 0.3716\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9131 - acc: 0.4783 - val_loss: 1.3804 - val_acc: 0.3927\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9181 - acc: 0.4970 - val_loss: 1.3247 - val_acc: 0.4079\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8889 - acc: 0.5055 - val_loss: 1.2660 - val_acc: 0.4230\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8551 - acc: 0.5372 - val_loss: 1.1745 - val_acc: 0.4562\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9475 - acc: 0.5069 - val_loss: 1.1486 - val_acc: 0.4622\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9759 - acc: 0.5086 - val_loss: 1.2774 - val_acc: 0.4169\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8733 - acc: 0.5164 - val_loss: 1.3964 - val_acc: 0.3867\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9553 - acc: 0.4991 - val_loss: 1.2558 - val_acc: 0.4169\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8731 - acc: 0.4998 - val_loss: 1.2019 - val_acc: 0.4411\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8718 - acc: 0.5245 - val_loss: 1.1670 - val_acc: 0.4502\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9013 - acc: 0.5150 - val_loss: 1.1683 - val_acc: 0.4411\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9031 - acc: 0.5379 - val_loss: 1.2326 - val_acc: 0.4441\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8574 - acc: 0.5301 - val_loss: 1.3001 - val_acc: 0.4139\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9622 - acc: 0.4871 - val_loss: 1.3410 - val_acc: 0.4230\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.9278 - acc: 0.5210 - val_loss: 1.2297 - val_acc: 0.4562\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8448 - acc: 0.5118 - val_loss: 1.1684 - val_acc: 0.4773\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.9303 - acc: 0.4991 - val_loss: 1.2014 - val_acc: 0.4230\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8683 - acc: 0.5210 - val_loss: 1.2434 - val_acc: 0.4592\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8430 - acc: 0.5343 - val_loss: 1.2135 - val_acc: 0.4653\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8699 - acc: 0.5227 - val_loss: 1.2046 - val_acc: 0.4683\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8712 - acc: 0.5167 - val_loss: 1.1887 - val_acc: 0.4532\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8846 - acc: 0.5280 - val_loss: 1.1813 - val_acc: 0.4683\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8919 - acc: 0.5463 - val_loss: 1.2426 - val_acc: 0.4381\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9618 - acc: 0.5079 - val_loss: 1.2734 - val_acc: 0.4471\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8473 - acc: 0.5231 - val_loss: 1.2489 - val_acc: 0.4502\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8300 - acc: 0.5269 - val_loss: 1.2351 - val_acc: 0.4683\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8502 - acc: 0.5460 - val_loss: 1.2360 - val_acc: 0.4441\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9358 - acc: 0.5238 - val_loss: 1.1585 - val_acc: 0.4713\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9816 - acc: 0.5118 - val_loss: 1.3400 - val_acc: 0.3927\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8886 - acc: 0.5178 - val_loss: 1.3352 - val_acc: 0.4260\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8607 - acc: 0.5195 - val_loss: 1.3640 - val_acc: 0.3988\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8605 - acc: 0.5150 - val_loss: 1.4231 - val_acc: 0.3807\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8853 - acc: 0.4928 - val_loss: 1.3397 - val_acc: 0.4169\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8387 - acc: 0.5379 - val_loss: 1.3841 - val_acc: 0.4079\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8545 - acc: 0.5174 - val_loss: 1.3419 - val_acc: 0.4139\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8270 - acc: 0.5284 - val_loss: 1.3508 - val_acc: 0.4230\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8640 - acc: 0.5231 - val_loss: 1.3296 - val_acc: 0.4169\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8761 - acc: 0.5139 - val_loss: 1.3190 - val_acc: 0.4381\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8294 - acc: 0.5400 - val_loss: 1.3211 - val_acc: 0.4350\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8140 - acc: 0.5354 - val_loss: 1.4188 - val_acc: 0.4199\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9092 - acc: 0.5055 - val_loss: 1.3830 - val_acc: 0.3927\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8408 - acc: 0.5146 - val_loss: 1.3687 - val_acc: 0.4199\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8771 - acc: 0.5150 - val_loss: 1.5025 - val_acc: 0.3656\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9289 - acc: 0.4790 - val_loss: 1.2067 - val_acc: 0.4683\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8166 - acc: 0.5597 - val_loss: 1.2240 - val_acc: 0.4592\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8380 - acc: 0.5491 - val_loss: 1.1977 - val_acc: 0.4562\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8585 - acc: 0.5435 - val_loss: 1.2024 - val_acc: 0.4502\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8610 - acc: 0.5544 - val_loss: 1.2744 - val_acc: 0.4592\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8281 - acc: 0.5379 - val_loss: 1.4294 - val_acc: 0.3897\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8805 - acc: 0.5210 - val_loss: 1.3154 - val_acc: 0.4109\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7928 - acc: 0.5389 - val_loss: 1.3690 - val_acc: 0.4139\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8265 - acc: 0.5241 - val_loss: 1.4220 - val_acc: 0.3988\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8616 - acc: 0.5086 - val_loss: 1.3243 - val_acc: 0.4290\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8032 - acc: 0.5453 - val_loss: 1.2494 - val_acc: 0.4743\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8482 - acc: 0.5541 - val_loss: 1.3112 - val_acc: 0.4320\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9312 - acc: 0.5185 - val_loss: 1.2523 - val_acc: 0.4713\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7844 - acc: 0.5558 - val_loss: 1.2487 - val_acc: 0.4743\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7696 - acc: 0.5763 - val_loss: 1.1965 - val_acc: 0.4924\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8521 - acc: 0.5446 - val_loss: 1.1990 - val_acc: 0.4562\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9099 - acc: 0.5410 - val_loss: 1.2576 - val_acc: 0.4502\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7846 - acc: 0.5470 - val_loss: 1.2768 - val_acc: 0.4532\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7761 - acc: 0.5523 - val_loss: 1.3063 - val_acc: 0.4502\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8138 - acc: 0.5421 - val_loss: 1.2854 - val_acc: 0.4683\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8005 - acc: 0.5421 - val_loss: 1.3578 - val_acc: 0.4381\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8585 - acc: 0.5386 - val_loss: 1.4446 - val_acc: 0.3686\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8386 - acc: 0.5129 - val_loss: 1.3886 - val_acc: 0.4018\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8092 - acc: 0.5375 - val_loss: 1.3831 - val_acc: 0.4109\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8186 - acc: 0.5604 - val_loss: 1.3686 - val_acc: 0.4169\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7975 - acc: 0.5678 - val_loss: 1.3526 - val_acc: 0.4411\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7869 - acc: 0.5622 - val_loss: 1.4301 - val_acc: 0.4139\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8158 - acc: 0.5428 - val_loss: 1.3690 - val_acc: 0.4139\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7882 - acc: 0.5551 - val_loss: 1.4523 - val_acc: 0.3927\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8643 - acc: 0.5241 - val_loss: 1.3259 - val_acc: 0.4290\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8305 - acc: 0.5301 - val_loss: 1.2236 - val_acc: 0.5015\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8184 - acc: 0.5569 - val_loss: 1.2265 - val_acc: 0.4532\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7893 - acc: 0.5636 - val_loss: 1.2427 - val_acc: 0.4924\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7453 - acc: 0.5798 - val_loss: 1.2592 - val_acc: 0.4804\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7686 - acc: 0.5720 - val_loss: 1.2409 - val_acc: 0.4804\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8376 - acc: 0.5343 - val_loss: 1.1902 - val_acc: 0.4653\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8264 - acc: 0.5745 - val_loss: 1.2876 - val_acc: 0.4471\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8495 - acc: 0.5629 - val_loss: 1.2195 - val_acc: 0.4955\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8196 - acc: 0.5822 - val_loss: 1.2841 - val_acc: 0.4622\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7349 - acc: 0.5854 - val_loss: 1.3063 - val_acc: 0.4502\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7378 - acc: 0.5865 - val_loss: 1.3384 - val_acc: 0.4350\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7875 - acc: 0.5650 - val_loss: 1.4228 - val_acc: 0.4320\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8564 - acc: 0.5347 - val_loss: 1.3784 - val_acc: 0.4048\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7944 - acc: 0.5431 - val_loss: 1.5183 - val_acc: 0.3716\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8413 - acc: 0.5136 - val_loss: 1.3223 - val_acc: 0.4471\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7404 - acc: 0.5956 - val_loss: 1.3089 - val_acc: 0.4411\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7726 - acc: 0.5801 - val_loss: 1.2344 - val_acc: 0.4743\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7951 - acc: 0.5699 - val_loss: 1.2987 - val_acc: 0.4290\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8255 - acc: 0.5597 - val_loss: 1.2314 - val_acc: 0.4532\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7855 - acc: 0.5805 - val_loss: 1.2534 - val_acc: 0.4894\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7736 - acc: 0.5611 - val_loss: 1.2933 - val_acc: 0.4773\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7871 - acc: 0.5604 - val_loss: 1.3792 - val_acc: 0.4048\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7930 - acc: 0.5414 - val_loss: 1.3993 - val_acc: 0.3867\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7835 - acc: 0.5470 - val_loss: 1.4435 - val_acc: 0.3897\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7857 - acc: 0.5565 - val_loss: 1.4061 - val_acc: 0.4048\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7708 - acc: 0.5699 - val_loss: 1.4225 - val_acc: 0.3988\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7677 - acc: 0.5646 - val_loss: 1.3852 - val_acc: 0.3988\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7185 - acc: 0.5886 - val_loss: 1.3834 - val_acc: 0.4350\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7491 - acc: 0.5837 - val_loss: 1.4758 - val_acc: 0.3716\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8393 - acc: 0.5213 - val_loss: 1.3492 - val_acc: 0.4502\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8383 - acc: 0.5431 - val_loss: 1.2663 - val_acc: 0.4894\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7418 - acc: 0.5710 - val_loss: 1.2876 - val_acc: 0.4773\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7251 - acc: 0.5928 - val_loss: 1.2838 - val_acc: 0.4743\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7889 - acc: 0.5749 - val_loss: 1.2479 - val_acc: 0.4562\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8326 - acc: 0.5819 - val_loss: 1.3016 - val_acc: 0.4532\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7041 - acc: 0.5942 - val_loss: 1.3202 - val_acc: 0.4713\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7259 - acc: 0.6048 - val_loss: 1.4442 - val_acc: 0.3988\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8456 - acc: 0.5523 - val_loss: 1.3605 - val_acc: 0.4290\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7829 - acc: 0.5833 - val_loss: 1.3792 - val_acc: 0.4411\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7162 - acc: 0.5872 - val_loss: 1.4290 - val_acc: 0.4320\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8127 - acc: 0.5572 - val_loss: 1.6758 - val_acc: 0.2961\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8639 - acc: 0.4889 - val_loss: 1.3339 - val_acc: 0.4471\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7169 - acc: 0.6055 - val_loss: 1.3250 - val_acc: 0.4592\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6994 - acc: 0.6161 - val_loss: 1.3820 - val_acc: 0.4532\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7471 - acc: 0.5872 - val_loss: 1.4079 - val_acc: 0.4109\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8224 - acc: 0.5731 - val_loss: 1.2919 - val_acc: 0.4743\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7296 - acc: 0.6013 - val_loss: 1.2770 - val_acc: 0.4864\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8039 - acc: 0.5815 - val_loss: 1.3091 - val_acc: 0.4894\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6982 - acc: 0.6044 - val_loss: 1.3342 - val_acc: 0.4592\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6802 - acc: 0.6083 - val_loss: 1.4372 - val_acc: 0.4260\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7393 - acc: 0.5854 - val_loss: 1.4926 - val_acc: 0.4018\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7831 - acc: 0.5643 - val_loss: 1.3802 - val_acc: 0.4350\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7326 - acc: 0.6073 - val_loss: 1.3806 - val_acc: 0.4350\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7193 - acc: 0.6030 - val_loss: 1.4100 - val_acc: 0.4290\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7424 - acc: 0.5861 - val_loss: 1.4761 - val_acc: 0.3807\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7741 - acc: 0.5675 - val_loss: 1.4872 - val_acc: 0.3897\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8174 - acc: 0.5463 - val_loss: 1.3854 - val_acc: 0.4260\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7524 - acc: 0.5555 - val_loss: 1.3740 - val_acc: 0.4441\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7023 - acc: 0.6087 - val_loss: 1.4722 - val_acc: 0.3927\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7851 - acc: 0.5657 - val_loss: 1.5189 - val_acc: 0.3867\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7558 - acc: 0.5604 - val_loss: 1.3175 - val_acc: 0.4713\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6928 - acc: 0.6122 - val_loss: 1.4349 - val_acc: 0.4502\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7715 - acc: 0.5752 - val_loss: 1.3719 - val_acc: 0.4441\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6881 - acc: 0.5921 - val_loss: 1.4570 - val_acc: 0.4018\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7070 - acc: 0.5953 - val_loss: 1.6045 - val_acc: 0.3535\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7704 - acc: 0.5639 - val_loss: 1.5277 - val_acc: 0.3927\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7392 - acc: 0.6002 - val_loss: 1.4181 - val_acc: 0.4290\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6667 - acc: 0.6221 - val_loss: 1.3836 - val_acc: 0.4502\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6717 - acc: 0.6242 - val_loss: 1.5767 - val_acc: 0.3746\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7447 - acc: 0.5749 - val_loss: 1.4240 - val_acc: 0.4320\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6888 - acc: 0.6136 - val_loss: 1.5038 - val_acc: 0.3958\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7633 - acc: 0.5798 - val_loss: 1.4664 - val_acc: 0.4169\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8016 - acc: 0.5611 - val_loss: 1.4139 - val_acc: 0.4109\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7116 - acc: 0.5699 - val_loss: 1.4136 - val_acc: 0.4290\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6963 - acc: 0.6016 - val_loss: 1.5038 - val_acc: 0.4048\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7082 - acc: 0.5844 - val_loss: 1.4471 - val_acc: 0.4290\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6771 - acc: 0.6161 - val_loss: 1.4725 - val_acc: 0.4169\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7077 - acc: 0.5956 - val_loss: 1.4930 - val_acc: 0.3776\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7361 - acc: 0.6069 - val_loss: 1.3563 - val_acc: 0.4955\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7013 - acc: 0.6199 - val_loss: 1.3720 - val_acc: 0.4532\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7529 - acc: 0.6115 - val_loss: 1.3295 - val_acc: 0.4713\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7721 - acc: 0.5981 - val_loss: 1.3409 - val_acc: 0.4713\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6915 - acc: 0.6083 - val_loss: 1.3782 - val_acc: 0.4683\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6693 - acc: 0.6087 - val_loss: 1.4297 - val_acc: 0.4562\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7172 - acc: 0.5801 - val_loss: 1.4107 - val_acc: 0.4381\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6988 - acc: 0.5907 - val_loss: 1.4321 - val_acc: 0.4411\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6536 - acc: 0.6196 - val_loss: 1.5081 - val_acc: 0.3958\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7163 - acc: 0.5970 - val_loss: 1.6773 - val_acc: 0.3384\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8003 - acc: 0.5463 - val_loss: 1.4202 - val_acc: 0.4622\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7033 - acc: 0.6245 - val_loss: 1.3953 - val_acc: 0.4441\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6296 - acc: 0.6604 - val_loss: 1.3892 - val_acc: 0.4743\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6186 - acc: 0.6499 - val_loss: 1.4641 - val_acc: 0.4713\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6445 - acc: 0.6418 - val_loss: 1.4830 - val_acc: 0.4290\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7777 - acc: 0.6066 - val_loss: 1.3376 - val_acc: 0.4924\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7097 - acc: 0.6333 - val_loss: 1.3545 - val_acc: 0.4804\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6988 - acc: 0.6168 - val_loss: 1.3150 - val_acc: 0.5045\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8257 - acc: 0.5784 - val_loss: 1.3805 - val_acc: 0.4441\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6512 - acc: 0.6347 - val_loss: 1.4173 - val_acc: 0.4562\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6270 - acc: 0.6404 - val_loss: 1.4408 - val_acc: 0.4532\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6185 - acc: 0.6319 - val_loss: 1.5471 - val_acc: 0.3958\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7109 - acc: 0.5939 - val_loss: 1.5976 - val_acc: 0.3867\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8148 - acc: 0.5474 - val_loss: 1.3318 - val_acc: 0.4743\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6558 - acc: 0.6270 - val_loss: 1.4365 - val_acc: 0.4924\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7053 - acc: 0.5960 - val_loss: 1.3602 - val_acc: 0.4955\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6807 - acc: 0.6069 - val_loss: 1.3788 - val_acc: 0.4683\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6202 - acc: 0.6302 - val_loss: 1.3764 - val_acc: 0.4985\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6154 - acc: 0.6414 - val_loss: 1.4132 - val_acc: 0.4985\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6310 - acc: 0.6407 - val_loss: 1.3962 - val_acc: 0.5045\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7239 - acc: 0.6157 - val_loss: 1.4017 - val_acc: 0.4592\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7621 - acc: 0.6094 - val_loss: 1.4156 - val_acc: 0.4804\n",
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6360 - acc: 0.6446 - val_loss: 1.5094 - val_acc: 0.4320\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6771 - acc: 0.6330 - val_loss: 1.5494 - val_acc: 0.4018\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7458 - acc: 0.6101 - val_loss: 1.3852 - val_acc: 0.4532\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6468 - acc: 0.6347 - val_loss: 1.3573 - val_acc: 0.4985\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6902 - acc: 0.6087 - val_loss: 1.3773 - val_acc: 0.4743\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7465 - acc: 0.6048 - val_loss: 1.3282 - val_acc: 0.4985\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6368 - acc: 0.6499 - val_loss: 1.3672 - val_acc: 0.4985\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6226 - acc: 0.6449 - val_loss: 1.4397 - val_acc: 0.4804\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6265 - acc: 0.6312 - val_loss: 1.4588 - val_acc: 0.4411\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6073 - acc: 0.6263 - val_loss: 1.5937 - val_acc: 0.4199\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8445 - acc: 0.5963 - val_loss: 1.7923 - val_acc: 0.3082\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7824 - acc: 0.5513 - val_loss: 1.4759 - val_acc: 0.4381\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6333 - acc: 0.6481 - val_loss: 1.4631 - val_acc: 0.4622\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5942 - acc: 0.6629 - val_loss: 1.4522 - val_acc: 0.4622\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6546 - acc: 0.6566 - val_loss: 1.4726 - val_acc: 0.4562\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6335 - acc: 0.6495 - val_loss: 1.5053 - val_acc: 0.4562\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6400 - acc: 0.6418 - val_loss: 1.5676 - val_acc: 0.4079\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6681 - acc: 0.6379 - val_loss: 1.5939 - val_acc: 0.4290\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6614 - acc: 0.6220 - val_loss: 1.5673 - val_acc: 0.4441\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7010 - acc: 0.6256 - val_loss: 1.6028 - val_acc: 0.3927\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7070 - acc: 0.6013 - val_loss: 1.4392 - val_acc: 0.4562\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6208 - acc: 0.6351 - val_loss: 1.4936 - val_acc: 0.4320\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6403 - acc: 0.6203 - val_loss: 1.4945 - val_acc: 0.4592\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6475 - acc: 0.6252 - val_loss: 1.4742 - val_acc: 0.4653\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6682 - acc: 0.6044 - val_loss: 1.4937 - val_acc: 0.4622\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6418 - acc: 0.6094 - val_loss: 1.4229 - val_acc: 0.5076\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6912 - acc: 0.5914 - val_loss: 1.3658 - val_acc: 0.4864\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6544 - acc: 0.6446 - val_loss: 1.3895 - val_acc: 0.4924\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5797 - acc: 0.6710 - val_loss: 1.4535 - val_acc: 0.4804\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5775 - acc: 0.6580 - val_loss: 1.4785 - val_acc: 0.4743\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6098 - acc: 0.6407 - val_loss: 1.6055 - val_acc: 0.4109\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7320 - acc: 0.5840 - val_loss: 1.5760 - val_acc: 0.3958\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6334 - acc: 0.6164 - val_loss: 1.5552 - val_acc: 0.4502\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6305 - acc: 0.6361 - val_loss: 1.6578 - val_acc: 0.3897\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6959 - acc: 0.6108 - val_loss: 1.5409 - val_acc: 0.4532\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6242 - acc: 0.6481 - val_loss: 1.5949 - val_acc: 0.4350\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6109 - acc: 0.6523 - val_loss: 1.6303 - val_acc: 0.4139\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6650 - acc: 0.6309 - val_loss: 1.6123 - val_acc: 0.4199\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6840 - acc: 0.6305 - val_loss: 1.5930 - val_acc: 0.3897\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7355 - acc: 0.5791 - val_loss: 1.4379 - val_acc: 0.4834\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6336 - acc: 0.6323 - val_loss: 1.4361 - val_acc: 0.4713\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5930 - acc: 0.6516 - val_loss: 1.5288 - val_acc: 0.4502\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6088 - acc: 0.6418 - val_loss: 1.6636 - val_acc: 0.4018\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6746 - acc: 0.6164 - val_loss: 1.6196 - val_acc: 0.4260\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6140 - acc: 0.6481 - val_loss: 1.5586 - val_acc: 0.4532\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6137 - acc: 0.6541 - val_loss: 1.5945 - val_acc: 0.4139\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6470 - acc: 0.6400 - val_loss: 1.4831 - val_acc: 0.4562\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6173 - acc: 0.6573 - val_loss: 1.4721 - val_acc: 0.4864\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6607 - acc: 0.6414 - val_loss: 1.4595 - val_acc: 0.4955\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6536 - acc: 0.6478 - val_loss: 1.4512 - val_acc: 0.5015\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5869 - acc: 0.6650 - val_loss: 1.4645 - val_acc: 0.4834\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5759 - acc: 0.6661 - val_loss: 1.5093 - val_acc: 0.4804\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6264 - acc: 0.6224 - val_loss: 1.4185 - val_acc: 0.5015\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6206 - acc: 0.6326 - val_loss: 1.4328 - val_acc: 0.5257\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6341 - acc: 0.6552 - val_loss: 1.4982 - val_acc: 0.4924\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6019 - acc: 0.6647 - val_loss: 1.5036 - val_acc: 0.4924\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5791 - acc: 0.6735 - val_loss: 1.4874 - val_acc: 0.5317\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6506 - acc: 0.6397 - val_loss: 1.4716 - val_acc: 0.5045\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6818 - acc: 0.6390 - val_loss: 1.4252 - val_acc: 0.5287\n",
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5770 - acc: 0.6791 - val_loss: 1.5197 - val_acc: 0.4713\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6094 - acc: 0.6323 - val_loss: 1.4477 - val_acc: 0.5045\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6190 - acc: 0.6354 - val_loss: 1.4223 - val_acc: 0.5076\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5746 - acc: 0.6671 - val_loss: 1.4955 - val_acc: 0.5196\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5589 - acc: 0.6710 - val_loss: 1.5380 - val_acc: 0.4924\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6468 - acc: 0.6474 - val_loss: 1.5824 - val_acc: 0.4773\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7233 - acc: 0.6323 - val_loss: 1.4651 - val_acc: 0.5015\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5655 - acc: 0.6798 - val_loss: 1.5206 - val_acc: 0.5076\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5495 - acc: 0.6914 - val_loss: 1.5066 - val_acc: 0.4894\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5774 - acc: 0.6791 - val_loss: 1.5416 - val_acc: 0.5166\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6773 - acc: 0.6344 - val_loss: 1.5005 - val_acc: 0.4441\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7485 - acc: 0.6182 - val_loss: 1.4203 - val_acc: 0.5257\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6021 - acc: 0.6611 - val_loss: 1.4872 - val_acc: 0.5015\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5999 - acc: 0.6414 - val_loss: 1.4891 - val_acc: 0.5015\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5665 - acc: 0.6626 - val_loss: 1.5090 - val_acc: 0.5136\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6113 - acc: 0.6460 - val_loss: 1.5112 - val_acc: 0.4985\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5889 - acc: 0.6460 - val_loss: 1.4845 - val_acc: 0.5257\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5280 - acc: 0.6756 - val_loss: 1.4856 - val_acc: 0.5136\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6274 - acc: 0.6418 - val_loss: 1.4889 - val_acc: 0.5045\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6769 - acc: 0.6552 - val_loss: 1.6042 - val_acc: 0.4804\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6080 - acc: 0.6668 - val_loss: 1.6052 - val_acc: 0.4381\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6598 - acc: 0.6464 - val_loss: 1.5922 - val_acc: 0.4502\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5405 - acc: 0.6840 - val_loss: 1.5315 - val_acc: 0.4894\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5809 - acc: 0.6724 - val_loss: 1.7659 - val_acc: 0.3927\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6734 - acc: 0.6231 - val_loss: 1.5584 - val_acc: 0.4743\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5459 - acc: 0.6862 - val_loss: 1.5525 - val_acc: 0.4592\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5517 - acc: 0.6847 - val_loss: 1.5786 - val_acc: 0.4562\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5772 - acc: 0.6432 - val_loss: 1.5660 - val_acc: 0.4713\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5634 - acc: 0.6541 - val_loss: 1.4923 - val_acc: 0.4985\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6257 - acc: 0.6404 - val_loss: 1.5293 - val_acc: 0.4894\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6475 - acc: 0.6168 - val_loss: 1.4592 - val_acc: 0.5287\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5617 - acc: 0.6717 - val_loss: 1.5626 - val_acc: 0.5015\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5632 - acc: 0.6816 - val_loss: 1.5849 - val_acc: 0.5196\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6667 - acc: 0.6506 - val_loss: 1.5243 - val_acc: 0.4985\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6684 - acc: 0.6661 - val_loss: 1.5572 - val_acc: 0.4743\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5184 - acc: 0.7013 - val_loss: 1.5823 - val_acc: 0.5076\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5312 - acc: 0.7059 - val_loss: 1.7102 - val_acc: 0.4290\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6029 - acc: 0.6647 - val_loss: 1.7693 - val_acc: 0.4290\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6212 - acc: 0.6541 - val_loss: 1.6774 - val_acc: 0.4411\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5770 - acc: 0.6640 - val_loss: 1.6109 - val_acc: 0.4683\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5203 - acc: 0.7006 - val_loss: 1.6401 - val_acc: 0.4653\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5403 - acc: 0.6682 - val_loss: 1.7042 - val_acc: 0.4139\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6231 - acc: 0.6372 - val_loss: 1.6426 - val_acc: 0.4441\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6972 - acc: 0.6044 - val_loss: 1.6589 - val_acc: 0.3897\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5694 - acc: 0.6664 - val_loss: 1.6457 - val_acc: 0.4834\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5396 - acc: 0.6918 - val_loss: 1.7028 - val_acc: 0.4381\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5710 - acc: 0.6858 - val_loss: 1.6036 - val_acc: 0.4773\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5657 - acc: 0.6795 - val_loss: 1.6634 - val_acc: 0.4502\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5562 - acc: 0.6943 - val_loss: 1.7564 - val_acc: 0.4139\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5900 - acc: 0.6689 - val_loss: 1.7019 - val_acc: 0.4290\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5639 - acc: 0.6886 - val_loss: 1.6005 - val_acc: 0.4773\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5262 - acc: 0.6939 - val_loss: 1.7409 - val_acc: 0.4109\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5662 - acc: 0.6488 - val_loss: 1.6584 - val_acc: 0.4350\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6070 - acc: 0.6242 - val_loss: 1.6582 - val_acc: 0.4532\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6182 - acc: 0.6404 - val_loss: 1.7290 - val_acc: 0.4048\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6988 - acc: 0.6175 - val_loss: 1.6011 - val_acc: 0.4350\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5507 - acc: 0.6671 - val_loss: 1.5693 - val_acc: 0.4864\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5146 - acc: 0.6869 - val_loss: 1.6092 - val_acc: 0.4653\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4951 - acc: 0.6964 - val_loss: 1.5905 - val_acc: 0.5045\n",
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5189 - acc: 0.6812 - val_loss: 1.6132 - val_acc: 0.4985\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6496 - acc: 0.6273 - val_loss: 1.5808 - val_acc: 0.5106\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5677 - acc: 0.6661 - val_loss: 1.5585 - val_acc: 0.5196\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5650 - acc: 0.6830 - val_loss: 1.5509 - val_acc: 0.5287\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6228 - acc: 0.6777 - val_loss: 1.5408 - val_acc: 0.5076\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5594 - acc: 0.6872 - val_loss: 1.5671 - val_acc: 0.4894\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4906 - acc: 0.7076 - val_loss: 1.6260 - val_acc: 0.4592\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5067 - acc: 0.6872 - val_loss: 1.6250 - val_acc: 0.4894\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5360 - acc: 0.6759 - val_loss: 1.6236 - val_acc: 0.4773\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5829 - acc: 0.6372 - val_loss: 1.5392 - val_acc: 0.5076\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5241 - acc: 0.6865 - val_loss: 1.5864 - val_acc: 0.5136\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5513 - acc: 0.6830 - val_loss: 1.6460 - val_acc: 0.5196\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7009 - acc: 0.6530 - val_loss: 1.5663 - val_acc: 0.4683\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5242 - acc: 0.6823 - val_loss: 1.5704 - val_acc: 0.4864\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4967 - acc: 0.7066 - val_loss: 1.6171 - val_acc: 0.4622\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5261 - acc: 0.6629 - val_loss: 1.6267 - val_acc: 0.4834\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5493 - acc: 0.6597 - val_loss: 1.6137 - val_acc: 0.5045\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5347 - acc: 0.6805 - val_loss: 1.5831 - val_acc: 0.5317\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5153 - acc: 0.6921 - val_loss: 1.6246 - val_acc: 0.4985\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5509 - acc: 0.6766 - val_loss: 1.8761 - val_acc: 0.3444\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5865 - acc: 0.6221 - val_loss: 1.6338 - val_acc: 0.5136\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5161 - acc: 0.7112 - val_loss: 1.7770 - val_acc: 0.4592\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6234 - acc: 0.6643 - val_loss: 1.8747 - val_acc: 0.4048\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6251 - acc: 0.6358 - val_loss: 1.5980 - val_acc: 0.5076\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5286 - acc: 0.6823 - val_loss: 1.5959 - val_acc: 0.4955\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5236 - acc: 0.6858 - val_loss: 1.6260 - val_acc: 0.4622\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5085 - acc: 0.6721 - val_loss: 1.6170 - val_acc: 0.5015\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4722 - acc: 0.7091 - val_loss: 1.6290 - val_acc: 0.4985\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4758 - acc: 0.7108 - val_loss: 1.7041 - val_acc: 0.4743\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5448 - acc: 0.6805 - val_loss: 1.7652 - val_acc: 0.4713\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6457 - acc: 0.6270 - val_loss: 1.5473 - val_acc: 0.5257\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5608 - acc: 0.6805 - val_loss: 1.6800 - val_acc: 0.5076\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6721 - acc: 0.6541 - val_loss: 1.6212 - val_acc: 0.5136\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5803 - acc: 0.6833 - val_loss: 1.6661 - val_acc: 0.5227\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4752 - acc: 0.7263 - val_loss: 1.6381 - val_acc: 0.5378\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4725 - acc: 0.7298 - val_loss: 1.6942 - val_acc: 0.5227\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4801 - acc: 0.7186 - val_loss: 1.7276 - val_acc: 0.5196\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4841 - acc: 0.7207 - val_loss: 1.7638 - val_acc: 0.4743\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5345 - acc: 0.7098 - val_loss: 1.7346 - val_acc: 0.4592\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5594 - acc: 0.7066 - val_loss: 1.6668 - val_acc: 0.4985\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4833 - acc: 0.7231 - val_loss: 1.7211 - val_acc: 0.5076\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4706 - acc: 0.7344 - val_loss: 1.7301 - val_acc: 0.5287\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4818 - acc: 0.7274 - val_loss: 1.8303 - val_acc: 0.4290\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6368 - acc: 0.6788 - val_loss: 2.3667 - val_acc: 0.2749\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7526 - acc: 0.5879 - val_loss: 1.6152 - val_acc: 0.4713\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5172 - acc: 0.7038 - val_loss: 1.6551 - val_acc: 0.4804\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4681 - acc: 0.7172 - val_loss: 1.6821 - val_acc: 0.5045\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4514 - acc: 0.7231 - val_loss: 1.7276 - val_acc: 0.5317\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4388 - acc: 0.7415 - val_loss: 1.7537 - val_acc: 0.5076\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4538 - acc: 0.7295 - val_loss: 1.7637 - val_acc: 0.5015\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.6099 - acc: 0.6865 - val_loss: 1.9580 - val_acc: 0.3505\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.7531 - acc: 0.5794 - val_loss: 1.6232 - val_acc: 0.4985\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5135 - acc: 0.7031 - val_loss: 1.6938 - val_acc: 0.5136\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4555 - acc: 0.7323 - val_loss: 1.7415 - val_acc: 0.4985\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4517 - acc: 0.7249 - val_loss: 1.7853 - val_acc: 0.4773\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4960 - acc: 0.6879 - val_loss: 1.7225 - val_acc: 0.4834\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5394 - acc: 0.6640 - val_loss: 1.6611 - val_acc: 0.5166\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5046 - acc: 0.7002 - val_loss: 1.6802 - val_acc: 0.5196\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4809 - acc: 0.7210 - val_loss: 1.7295 - val_acc: 0.4985\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4717 - acc: 0.7066 - val_loss: 1.7727 - val_acc: 0.4653\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5021 - acc: 0.6844 - val_loss: 1.8103 - val_acc: 0.4471\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5111 - acc: 0.6749 - val_loss: 1.7723 - val_acc: 0.4320\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5906 - acc: 0.6671 - val_loss: 2.0278 - val_acc: 0.3656\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6243 - acc: 0.6478 - val_loss: 1.7971 - val_acc: 0.4350\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5288 - acc: 0.6978 - val_loss: 1.7390 - val_acc: 0.4834\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4806 - acc: 0.7295 - val_loss: 1.7648 - val_acc: 0.4924\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4946 - acc: 0.7203 - val_loss: 1.7461 - val_acc: 0.5136\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4625 - acc: 0.7457 - val_loss: 1.7584 - val_acc: 0.5257\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4452 - acc: 0.7383 - val_loss: 1.8073 - val_acc: 0.5015\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5019 - acc: 0.7164 - val_loss: 1.7061 - val_acc: 0.5347\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5399 - acc: 0.7115 - val_loss: 1.7203 - val_acc: 0.5136\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4875 - acc: 0.7253 - val_loss: 1.7158 - val_acc: 0.5106\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5218 - acc: 0.7038 - val_loss: 1.6715 - val_acc: 0.5227\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5062 - acc: 0.7020 - val_loss: 1.7418 - val_acc: 0.4955\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4924 - acc: 0.7013 - val_loss: 1.7735 - val_acc: 0.4834\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4841 - acc: 0.6953 - val_loss: 1.8603 - val_acc: 0.4350\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5302 - acc: 0.6742 - val_loss: 1.8527 - val_acc: 0.4622\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5493 - acc: 0.6967 - val_loss: 2.0415 - val_acc: 0.3927\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5647 - acc: 0.6897 - val_loss: 1.7534 - val_acc: 0.4743\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4945 - acc: 0.7235 - val_loss: 1.7790 - val_acc: 0.5106\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4544 - acc: 0.7411 - val_loss: 1.8250 - val_acc: 0.4985\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4370 - acc: 0.7341 - val_loss: 1.8329 - val_acc: 0.4834\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4533 - acc: 0.7453 - val_loss: 1.9069 - val_acc: 0.4532\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5058 - acc: 0.7238 - val_loss: 1.9414 - val_acc: 0.4562\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5082 - acc: 0.7150 - val_loss: 1.8387 - val_acc: 0.4955\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5055 - acc: 0.7207 - val_loss: 1.9342 - val_acc: 0.4350\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5976 - acc: 0.6766 - val_loss: 1.8900 - val_acc: 0.4018\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6378 - acc: 0.6481 - val_loss: 1.7074 - val_acc: 0.4924\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5252 - acc: 0.6921 - val_loss: 1.7255 - val_acc: 0.4834\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4489 - acc: 0.7094 - val_loss: 1.8116 - val_acc: 0.4713\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4305 - acc: 0.7369 - val_loss: 1.8218 - val_acc: 0.4894\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4341 - acc: 0.7288 - val_loss: 1.8279 - val_acc: 0.5166\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4482 - acc: 0.7242 - val_loss: 1.7172 - val_acc: 0.5106\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4515 - acc: 0.7358 - val_loss: 1.8067 - val_acc: 0.5257\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5579 - acc: 0.6826 - val_loss: 1.7362 - val_acc: 0.4834\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5035 - acc: 0.6752 - val_loss: 1.7623 - val_acc: 0.5378\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6179 - acc: 0.6826 - val_loss: 1.7515 - val_acc: 0.5015\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6127 - acc: 0.6890 - val_loss: 1.7185 - val_acc: 0.5045\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4110 - acc: 0.7492 - val_loss: 1.8728 - val_acc: 0.5076\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4282 - acc: 0.7376 - val_loss: 1.8604 - val_acc: 0.4804\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4488 - acc: 0.7203 - val_loss: 1.7704 - val_acc: 0.4985\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4476 - acc: 0.7055 - val_loss: 1.7721 - val_acc: 0.5196\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4591 - acc: 0.7309 - val_loss: 1.8156 - val_acc: 0.5136\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6053 - acc: 0.6562 - val_loss: 1.6772 - val_acc: 0.5498\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5008 - acc: 0.7172 - val_loss: 1.7815 - val_acc: 0.4985\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4835 - acc: 0.7372 - val_loss: 1.7886 - val_acc: 0.4955\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.7471 - val_loss: 1.7889 - val_acc: 0.5196\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4205 - acc: 0.7513 - val_loss: 1.8259 - val_acc: 0.5317\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4172 - acc: 0.7489 - val_loss: 1.8474 - val_acc: 0.5196\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4040 - acc: 0.7647 - val_loss: 1.9057 - val_acc: 0.5045\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5108 - acc: 0.7143 - val_loss: 1.9382 - val_acc: 0.4562\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5699 - acc: 0.7087 - val_loss: 1.8351 - val_acc: 0.5076\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6925 - acc: 0.6756 - val_loss: 1.7138 - val_acc: 0.5045\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5309 - acc: 0.6928 - val_loss: 1.7361 - val_acc: 0.5166\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4343 - acc: 0.7309 - val_loss: 1.7976 - val_acc: 0.4864\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4064 - acc: 0.7584 - val_loss: 1.8292 - val_acc: 0.4894\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4043 - acc: 0.7679 - val_loss: 1.8886 - val_acc: 0.4924\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4359 - acc: 0.7429 - val_loss: 2.0061 - val_acc: 0.4441\n",
      "Epoch 590/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5112 - acc: 0.7200 - val_loss: 2.0845 - val_acc: 0.4230\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5366 - acc: 0.6999 - val_loss: 1.8248 - val_acc: 0.5136\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4166 - acc: 0.7520 - val_loss: 1.8896 - val_acc: 0.5196\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4053 - acc: 0.7524 - val_loss: 1.9565 - val_acc: 0.4773\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3999 - acc: 0.7471 - val_loss: 1.9190 - val_acc: 0.4773\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5125 - acc: 0.6960 - val_loss: 1.8861 - val_acc: 0.4471\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6735 - acc: 0.6252 - val_loss: 1.7973 - val_acc: 0.4804\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5067 - acc: 0.7147 - val_loss: 1.8899 - val_acc: 0.4743\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4699 - acc: 0.7379 - val_loss: 1.7860 - val_acc: 0.5257\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4127 - acc: 0.7679 - val_loss: 1.8023 - val_acc: 0.5257\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4002 - acc: 0.7682 - val_loss: 1.8247 - val_acc: 0.5408\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5325 - acc: 0.7115 - val_loss: 1.8396 - val_acc: 0.5045\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6213 - acc: 0.6914 - val_loss: 1.7252 - val_acc: 0.5287\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4484 - acc: 0.7485 - val_loss: 1.7928 - val_acc: 0.5015\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4145 - acc: 0.7496 - val_loss: 1.8560 - val_acc: 0.4864\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4266 - acc: 0.7319 - val_loss: 1.8446 - val_acc: 0.5045\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4372 - acc: 0.7362 - val_loss: 1.8168 - val_acc: 0.5257\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4056 - acc: 0.7489 - val_loss: 1.8542 - val_acc: 0.4924\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4358 - acc: 0.7312 - val_loss: 1.8403 - val_acc: 0.5015\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4526 - acc: 0.7348 - val_loss: 1.9558 - val_acc: 0.4653\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4752 - acc: 0.6981 - val_loss: 1.8788 - val_acc: 0.5045\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4294 - acc: 0.7450 - val_loss: 1.9333 - val_acc: 0.4804\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4493 - acc: 0.7379 - val_loss: 2.3600 - val_acc: 0.3444\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6191 - acc: 0.6347 - val_loss: 2.0703 - val_acc: 0.3958\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5985 - acc: 0.6855 - val_loss: 1.8152 - val_acc: 0.4804\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4447 - acc: 0.7348 - val_loss: 1.7879 - val_acc: 0.5257\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4301 - acc: 0.7457 - val_loss: 1.9074 - val_acc: 0.4622\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4546 - acc: 0.7087 - val_loss: 1.8196 - val_acc: 0.5106\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4411 - acc: 0.7298 - val_loss: 1.8513 - val_acc: 0.5317\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4579 - acc: 0.7334 - val_loss: 1.7815 - val_acc: 0.5045\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4517 - acc: 0.7256 - val_loss: 1.8056 - val_acc: 0.5015\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4246 - acc: 0.7478 - val_loss: 1.8533 - val_acc: 0.5257\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4193 - acc: 0.7520 - val_loss: 1.9086 - val_acc: 0.5166\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4975 - acc: 0.7341 - val_loss: 1.9014 - val_acc: 0.5106\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5338 - acc: 0.7372 - val_loss: 1.8774 - val_acc: 0.5106\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4267 - acc: 0.7587 - val_loss: 1.9241 - val_acc: 0.5196\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4033 - acc: 0.7728 - val_loss: 1.9658 - val_acc: 0.5076\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3852 - acc: 0.7707 - val_loss: 1.9867 - val_acc: 0.4985\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4233 - acc: 0.7573 - val_loss: 1.9045 - val_acc: 0.5227\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4008 - acc: 0.7601 - val_loss: 1.9247 - val_acc: 0.5287\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4096 - acc: 0.7608 - val_loss: 1.9091 - val_acc: 0.5166\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4561 - acc: 0.7439 - val_loss: 2.0087 - val_acc: 0.5196\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8167 - acc: 0.6626 - val_loss: 1.8884 - val_acc: 0.4713\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5848 - acc: 0.7136 - val_loss: 1.8371 - val_acc: 0.4985\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3969 - acc: 0.7644 - val_loss: 1.9318 - val_acc: 0.5106\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4026 - acc: 0.7612 - val_loss: 1.8984 - val_acc: 0.4924\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4582 - acc: 0.7256 - val_loss: 1.9609 - val_acc: 0.4683\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5991 - acc: 0.6552 - val_loss: 1.8509 - val_acc: 0.4924\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4091 - acc: 0.7436 - val_loss: 1.9140 - val_acc: 0.5287\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3773 - acc: 0.7865 - val_loss: 1.9600 - val_acc: 0.5196\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3733 - acc: 0.7749 - val_loss: 1.9515 - val_acc: 0.5227\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3920 - acc: 0.7703 - val_loss: 1.9926 - val_acc: 0.5287\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4181 - acc: 0.7686 - val_loss: 1.8899 - val_acc: 0.5347\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5733 - acc: 0.7140 - val_loss: 2.0269 - val_acc: 0.4653\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6816 - acc: 0.6900 - val_loss: 1.9542 - val_acc: 0.4713\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4456 - acc: 0.7633 - val_loss: 1.9614 - val_acc: 0.4713\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4039 - acc: 0.7718 - val_loss: 1.9434 - val_acc: 0.5166\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3765 - acc: 0.805 - 0s 70us/step - loss: 0.3743 - acc: 0.7904 - val_loss: 1.9891 - val_acc: 0.4804\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3881 - acc: 0.7707 - val_loss: 2.0227 - val_acc: 0.4773\n",
      "Epoch 649/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3733 - acc: 0.7816 - val_loss: 2.1659 - val_acc: 0.4713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4425 - acc: 0.7510 - val_loss: 2.0066 - val_acc: 0.4622\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4856 - acc: 0.7281 - val_loss: 1.9491 - val_acc: 0.5015\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4142 - acc: 0.7654 - val_loss: 2.2176 - val_acc: 0.4169\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4718 - acc: 0.7319 - val_loss: 2.0591 - val_acc: 0.4169\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4257 - acc: 0.7355 - val_loss: 1.9677 - val_acc: 0.5166\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3972 - acc: 0.7654 - val_loss: 1.9789 - val_acc: 0.4955\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4612 - acc: 0.7425 - val_loss: 2.1144 - val_acc: 0.4260\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5695 - acc: 0.6766 - val_loss: 1.7950 - val_acc: 0.5136\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4517 - acc: 0.7249 - val_loss: 1.8925 - val_acc: 0.4985\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4017 - acc: 0.7467 - val_loss: 1.9628 - val_acc: 0.5015\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3797 - acc: 0.7749 - val_loss: 1.9743 - val_acc: 0.5045\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4176 - acc: 0.7344 - val_loss: 1.9675 - val_acc: 0.5045\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4885 - acc: 0.6957 - val_loss: 1.8318 - val_acc: 0.4985\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3999 - acc: 0.7503 - val_loss: 1.9676 - val_acc: 0.5166\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3550 - acc: 0.7799 - val_loss: 2.0256 - val_acc: 0.5045\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3817 - acc: 0.7675 - val_loss: 2.0413 - val_acc: 0.4924\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4709 - acc: 0.7411 - val_loss: 2.1466 - val_acc: 0.4532\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5151 - acc: 0.7200 - val_loss: 2.2146 - val_acc: 0.4048\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5074 - acc: 0.7295 - val_loss: 2.0639 - val_acc: 0.4562\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4546 - acc: 0.7351 - val_loss: 2.0123 - val_acc: 0.4985\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4218 - acc: 0.7816 - val_loss: 1.9904 - val_acc: 0.5257\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3641 - acc: 0.8020 - val_loss: 2.0250 - val_acc: 0.5106\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.3536 - acc: 0.7957 - val_loss: 2.1134 - val_acc: 0.4804\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4477 - acc: 0.7291 - val_loss: 1.9282 - val_acc: 0.5015\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4201 - acc: 0.7362 - val_loss: 1.9196 - val_acc: 0.5317\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4028 - acc: 0.7612 - val_loss: 1.9434 - val_acc: 0.4894\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4424 - acc: 0.7196 - val_loss: 1.9047 - val_acc: 0.5166\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4198 - acc: 0.7348 - val_loss: 1.9617 - val_acc: 0.4894\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3888 - acc: 0.7527 - val_loss: 1.9723 - val_acc: 0.5136\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3811 - acc: 0.7763 - val_loss: 1.9894 - val_acc: 0.5227\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4288 - acc: 0.7510 - val_loss: 1.9995 - val_acc: 0.5317\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7260 - acc: 0.6597 - val_loss: 2.1679 - val_acc: 0.4502\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7691 - acc: 0.6418 - val_loss: 1.8691 - val_acc: 0.4985\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4483 - acc: 0.7612 - val_loss: 1.8388 - val_acc: 0.5227\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3601 - acc: 0.7834 - val_loss: 1.9103 - val_acc: 0.5317\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3497 - acc: 0.8042 - val_loss: 2.0131 - val_acc: 0.5196\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3538 - acc: 0.7904 - val_loss: 2.0896 - val_acc: 0.5196\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3538 - acc: 0.7865 - val_loss: 2.0404 - val_acc: 0.4955\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3533 - acc: 0.7932 - val_loss: 2.1114 - val_acc: 0.4804\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3545 - acc: 0.8020 - val_loss: 2.1648 - val_acc: 0.4894\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3662 - acc: 0.7735 - val_loss: 2.1188 - val_acc: 0.4743\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4002 - acc: 0.7408 - val_loss: 2.0957 - val_acc: 0.4653\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4203 - acc: 0.7267 - val_loss: 1.9969 - val_acc: 0.5015\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4575 - acc: 0.7316 - val_loss: 1.9761 - val_acc: 0.4955\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4934 - acc: 0.6950 - val_loss: 1.9192 - val_acc: 0.5257\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4588 - acc: 0.7376 - val_loss: 2.0021 - val_acc: 0.5287\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3629 - acc: 0.7887 - val_loss: 2.0647 - val_acc: 0.5196\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3422 - acc: 0.7911 - val_loss: 2.0742 - val_acc: 0.4864\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3545 - acc: 0.7897 - val_loss: 2.1476 - val_acc: 0.4864\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4473 - acc: 0.7615 - val_loss: 2.0772 - val_acc: 0.5166\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7397 - acc: 0.6869 - val_loss: 1.8360 - val_acc: 0.4834\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5149 - acc: 0.7059 - val_loss: 1.9712 - val_acc: 0.4350\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3924 - acc: 0.7274 - val_loss: 1.9105 - val_acc: 0.5257\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3429 - acc: 0.7876 - val_loss: 1.9895 - val_acc: 0.5317\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3409 - acc: 0.7915 - val_loss: 2.0559 - val_acc: 0.5166\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3478 - acc: 0.7939 - val_loss: 2.0132 - val_acc: 0.5015\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3871 - acc: 0.7707 - val_loss: 2.0260 - val_acc: 0.5076\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4395 - acc: 0.7270 - val_loss: 1.9619 - val_acc: 0.5227\n",
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4660 - acc: 0.7217 - val_loss: 1.9435 - val_acc: 0.5045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3826 - acc: 0.7689 - val_loss: 2.0659 - val_acc: 0.5166\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3409 - acc: 0.7964 - val_loss: 2.1115 - val_acc: 0.5196\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3459 - acc: 0.7957 - val_loss: 2.1052 - val_acc: 0.5529\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3985 - acc: 0.7760 - val_loss: 2.0719 - val_acc: 0.5408\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4412 - acc: 0.7633 - val_loss: 2.2358 - val_acc: 0.4894\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6904 - acc: 0.7098 - val_loss: 2.0404 - val_acc: 0.4834\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4437 - acc: 0.7651 - val_loss: 1.9577 - val_acc: 0.5166\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3361 - acc: 0.7915 - val_loss: 2.0796 - val_acc: 0.4773\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3536 - acc: 0.7876 - val_loss: 2.0647 - val_acc: 0.4955\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3699 - acc: 0.7555 - val_loss: 2.0423 - val_acc: 0.4985\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4450 - acc: 0.7179 - val_loss: 1.9221 - val_acc: 0.5438\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3796 - acc: 0.7746 - val_loss: 2.0350 - val_acc: 0.5408\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3871 - acc: 0.7841 - val_loss: 2.0825 - val_acc: 0.5196\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3614 - acc: 0.7911 - val_loss: 2.1652 - val_acc: 0.4864\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3586 - acc: 0.7908 - val_loss: 2.1816 - val_acc: 0.4924\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3737 - acc: 0.7883 - val_loss: 2.1924 - val_acc: 0.4834\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4105 - acc: 0.7693 - val_loss: 2.1708 - val_acc: 0.4562\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3874 - acc: 0.7890 - val_loss: 2.2065 - val_acc: 0.4713\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4215 - acc: 0.7739 - val_loss: 2.2936 - val_acc: 0.4502\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3878 - acc: 0.7781 - val_loss: 2.0889 - val_acc: 0.4985\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3889 - acc: 0.7763 - val_loss: 2.0796 - val_acc: 0.5317\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3883 - acc: 0.7939 - val_loss: 2.1901 - val_acc: 0.4773\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6385 - acc: 0.7066 - val_loss: 2.5046 - val_acc: 0.3414\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4912 - acc: 0.6879 - val_loss: 2.0622 - val_acc: 0.4773\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3533 - acc: 0.7894 - val_loss: 2.0496 - val_acc: 0.5378\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3280 - acc: 0.8087 - val_loss: 2.1997 - val_acc: 0.4924\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3367 - acc: 0.8038 - val_loss: 2.2569 - val_acc: 0.4955\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3427 - acc: 0.7999 - val_loss: 2.2167 - val_acc: 0.4894\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3547 - acc: 0.8031 - val_loss: 2.3637 - val_acc: 0.4350\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4244 - acc: 0.7622 - val_loss: 2.4113 - val_acc: 0.4230\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5138 - acc: 0.7253 - val_loss: 2.3293 - val_acc: 0.4290\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4486 - acc: 0.7545 - val_loss: 2.1024 - val_acc: 0.5076\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3563 - acc: 0.8006 - val_loss: 2.1682 - val_acc: 0.5347\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3239 - acc: 0.8154 - val_loss: 2.1780 - val_acc: 0.5196\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3215 - acc: 0.8204 - val_loss: 2.1453 - val_acc: 0.5347\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3237 - acc: 0.8087 - val_loss: 2.2092 - val_acc: 0.4864\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3819 - acc: 0.7932 - val_loss: 2.3608 - val_acc: 0.4773\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5701 - acc: 0.7305 - val_loss: 2.1166 - val_acc: 0.5076\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5227 - acc: 0.7464 - val_loss: 1.9831 - val_acc: 0.5076\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3899 - acc: 0.7633 - val_loss: 2.0638 - val_acc: 0.5076\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3553 - acc: 0.7844 - val_loss: 2.1088 - val_acc: 0.5317\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3314 - acc: 0.7982 - val_loss: 2.2135 - val_acc: 0.4924\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3579 - acc: 0.7651 - val_loss: 2.1800 - val_acc: 0.4924\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3541 - acc: 0.7686 - val_loss: 2.1830 - val_acc: 0.4985\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3317 - acc: 0.7802 - val_loss: 2.1187 - val_acc: 0.5136\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3944 - acc: 0.7594 - val_loss: 2.1771 - val_acc: 0.4773\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5001 - acc: 0.6950 - val_loss: 2.0290 - val_acc: 0.4773\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3878 - acc: 0.7418 - val_loss: 2.0784 - val_acc: 0.4924\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3607 - acc: 0.7605 - val_loss: 2.1105 - val_acc: 0.5227\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3476 - acc: 0.7763 - val_loss: 2.1725 - val_acc: 0.5317\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4418 - acc: 0.7612 - val_loss: 2.2733 - val_acc: 0.5166\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8157 - acc: 0.6925 - val_loss: 1.9834 - val_acc: 0.4773\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4027 - acc: 0.7732 - val_loss: 1.9822 - val_acc: 0.5317\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3560 - acc: 0.7961 - val_loss: 2.0981 - val_acc: 0.4894\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3569 - acc: 0.7640 - val_loss: 2.1244 - val_acc: 0.5166\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2985 - acc: 0.8186 - val_loss: 2.1372 - val_acc: 0.5347\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3893 - acc: 0.7837 - val_loss: 2.1168 - val_acc: 0.5166\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4538 - acc: 0.7316 - val_loss: 2.0753 - val_acc: 0.4894\n",
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3776 - acc: 0.7443 - val_loss: 2.1587 - val_acc: 0.4834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3204 - acc: 0.7925 - val_loss: 2.1482 - val_acc: 0.5347\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2903 - acc: 0.8175 - val_loss: 2.2007 - val_acc: 0.5106\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3278 - acc: 0.7985 - val_loss: 2.1130 - val_acc: 0.5106\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3973 - acc: 0.7605 - val_loss: 2.2324 - val_acc: 0.4320\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4435 - acc: 0.7210 - val_loss: 2.0426 - val_acc: 0.5438\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3333 - acc: 0.7957 - val_loss: 2.2279 - val_acc: 0.5106\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3227 - acc: 0.8098 - val_loss: 2.1642 - val_acc: 0.5347\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3193 - acc: 0.8140 - val_loss: 2.2131 - val_acc: 0.5347\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3627 - acc: 0.8003 - val_loss: 2.2203 - val_acc: 0.5196\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5669 - acc: 0.7281 - val_loss: 2.0458 - val_acc: 0.5196\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5885 - acc: 0.7168 - val_loss: 2.2068 - val_acc: 0.4743\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3987 - acc: 0.7827 - val_loss: 2.1422 - val_acc: 0.5076\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3226 - acc: 0.8186 - val_loss: 2.1130 - val_acc: 0.5438\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3054 - acc: 0.8080 - val_loss: 2.2263 - val_acc: 0.4985\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2991 - acc: 0.8179 - val_loss: 2.3286 - val_acc: 0.5045\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3097 - acc: 0.8161 - val_loss: 2.3235 - val_acc: 0.4894\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3328 - acc: 0.8116 - val_loss: 2.3383 - val_acc: 0.4562\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3257 - acc: 0.8098 - val_loss: 2.3866 - val_acc: 0.4350\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3566 - acc: 0.7795 - val_loss: 2.3446 - val_acc: 0.4471\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4935 - acc: 0.7228 - val_loss: 2.1586 - val_acc: 0.4411\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4680 - acc: 0.7157 - val_loss: 2.1182 - val_acc: 0.5045\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3491 - acc: 0.7707 - val_loss: 2.1495 - val_acc: 0.5136\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3089 - acc: 0.8038 - val_loss: 2.2677 - val_acc: 0.5045\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3302 - acc: 0.8066 - val_loss: 2.2942 - val_acc: 0.4864\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4126 - acc: 0.7496 - val_loss: 2.1361 - val_acc: 0.4713\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3741 - acc: 0.7453 - val_loss: 2.1693 - val_acc: 0.5317\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2923 - acc: 0.8137 - val_loss: 2.2894 - val_acc: 0.5257\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3061 - acc: 0.8253 - val_loss: 2.2745 - val_acc: 0.5227\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3023 - acc: 0.8151 - val_loss: 2.4879 - val_acc: 0.4834\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3246 - acc: 0.8013 - val_loss: 2.3694 - val_acc: 0.4592\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4594 - acc: 0.7777 - val_loss: 2.7802 - val_acc: 0.3202\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8248 - acc: 0.5956 - val_loss: 2.2141 - val_acc: 0.4230\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4424 - acc: 0.7570 - val_loss: 2.1463 - val_acc: 0.4773\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3375 - acc: 0.8140 - val_loss: 2.2079 - val_acc: 0.5136\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3139 - acc: 0.8267 - val_loss: 2.2813 - val_acc: 0.5076\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2936 - acc: 0.8271 - val_loss: 2.4687 - val_acc: 0.4713\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3608 - acc: 0.7961 - val_loss: 2.3615 - val_acc: 0.4653\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3467 - acc: 0.8091 - val_loss: 2.2897 - val_acc: 0.4834\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2945 - acc: 0.8299 - val_loss: 2.3778 - val_acc: 0.4924\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2831 - acc: 0.8344 - val_loss: 2.3507 - val_acc: 0.5015\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3090 - acc: 0.8154 - val_loss: 2.4545 - val_acc: 0.4592\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4112 - acc: 0.7735 - val_loss: 2.6603 - val_acc: 0.4290\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5841 - acc: 0.7140 - val_loss: 2.0981 - val_acc: 0.4894\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3776 - acc: 0.7989 - val_loss: 2.1680 - val_acc: 0.5257\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2920 - acc: 0.8313 - val_loss: 2.3070 - val_acc: 0.4864\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3001 - acc: 0.8285 - val_loss: 2.2331 - val_acc: 0.5287\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2882 - acc: 0.8355 - val_loss: 2.2946 - val_acc: 0.5257\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3941 - acc: 0.7901 - val_loss: 2.3280 - val_acc: 0.5227\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5541 - acc: 0.7555 - val_loss: 2.2145 - val_acc: 0.5136\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4061 - acc: 0.7999 - val_loss: 2.1816 - val_acc: 0.5287\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2999 - acc: 0.8168 - val_loss: 2.1877 - val_acc: 0.5015\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2887 - acc: 0.8105 - val_loss: 2.2251 - val_acc: 0.5166\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3067 - acc: 0.8052 - val_loss: 2.1702 - val_acc: 0.4955\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3704 - acc: 0.7710 - val_loss: 2.2365 - val_acc: 0.4955\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3885 - acc: 0.7439 - val_loss: 2.2182 - val_acc: 0.5045\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3181 - acc: 0.7939 - val_loss: 2.2537 - val_acc: 0.5257\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3167 - acc: 0.8197 - val_loss: 2.3123 - val_acc: 0.5317\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3037 - acc: 0.8295 - val_loss: 2.2830 - val_acc: 0.5015\n",
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3399 - acc: 0.7996 - val_loss: 2.3084 - val_acc: 0.4562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5324 - acc: 0.6907 - val_loss: 2.3332 - val_acc: 0.4169\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5169 - acc: 0.7182 - val_loss: 2.2987 - val_acc: 0.4411\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3652 - acc: 0.8003 - val_loss: 2.2277 - val_acc: 0.4834\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.3115 - acc: 0.8242 - val_loss: 2.2814 - val_acc: 0.4955\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3128 - acc: 0.8204 - val_loss: 2.3562 - val_acc: 0.4773\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3016 - acc: 0.8288 - val_loss: 2.3784 - val_acc: 0.4713\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2971 - acc: 0.8359 - val_loss: 2.4154 - val_acc: 0.4894\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2991 - acc: 0.8295 - val_loss: 2.5075 - val_acc: 0.4592\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3324 - acc: 0.8147 - val_loss: 2.5891 - val_acc: 0.4471\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3921 - acc: 0.7929 - val_loss: 2.8079 - val_acc: 0.4169\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5385 - acc: 0.7249 - val_loss: 2.2022 - val_acc: 0.4441\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3729 - acc: 0.8077 - val_loss: 2.2639 - val_acc: 0.5136\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2925 - acc: 0.8278 - val_loss: 2.3462 - val_acc: 0.5136\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3092 - acc: 0.8267 - val_loss: 2.3903 - val_acc: 0.4864\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3089 - acc: 0.8320 - val_loss: 2.4334 - val_acc: 0.4924\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3139 - acc: 0.8274 - val_loss: 2.5611 - val_acc: 0.4622\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4096 - acc: 0.7865 - val_loss: 2.3874 - val_acc: 0.4804\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4901 - acc: 0.7728 - val_loss: 2.2208 - val_acc: 0.5166\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4375 - acc: 0.7813 - val_loss: 2.1400 - val_acc: 0.5015\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3160 - acc: 0.7978 - val_loss: 2.2260 - val_acc: 0.5317\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3025 - acc: 0.8056 - val_loss: 2.2182 - val_acc: 0.5287\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2834 - acc: 0.8267 - val_loss: 2.3007 - val_acc: 0.5106\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2831 - acc: 0.8359 - val_loss: 2.3285 - val_acc: 0.5106\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2783 - acc: 0.8278 - val_loss: 2.3517 - val_acc: 0.5076\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3508 - acc: 0.7696 - val_loss: 2.2499 - val_acc: 0.4894\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4863 - acc: 0.7094 - val_loss: 2.2166 - val_acc: 0.5227\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4336 - acc: 0.7555 - val_loss: 2.2356 - val_acc: 0.5045\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3557 - acc: 0.8112 - val_loss: 2.3423 - val_acc: 0.4864\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4287 - acc: 0.7954 - val_loss: 2.3508 - val_acc: 0.5106\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4747 - acc: 0.7756 - val_loss: 2.2148 - val_acc: 0.5106\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3171 - acc: 0.8179 - val_loss: 2.2458 - val_acc: 0.5136\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2670 - acc: 0.8401 - val_loss: 2.2934 - val_acc: 0.5076\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2884 - acc: 0.8242 - val_loss: 2.2864 - val_acc: 0.4804\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3430 - acc: 0.7710 - val_loss: 2.2137 - val_acc: 0.5045\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3071 - acc: 0.8042 - val_loss: 2.3028 - val_acc: 0.5106\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2863 - acc: 0.8168 - val_loss: 2.2564 - val_acc: 0.5106\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3270 - acc: 0.7954 - val_loss: 2.2804 - val_acc: 0.4924\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3911 - acc: 0.7615 - val_loss: 2.2369 - val_acc: 0.4713\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4063 - acc: 0.7467 - val_loss: 2.4701 - val_acc: 0.4562\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3960 - acc: 0.7777 - val_loss: 2.3715 - val_acc: 0.4713\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4090 - acc: 0.7872 - val_loss: 2.4375 - val_acc: 0.4532\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3414 - acc: 0.8035 - val_loss: 2.4297 - val_acc: 0.4592\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3091 - acc: 0.8274 - val_loss: 2.4183 - val_acc: 0.4743\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2899 - acc: 0.8478 - val_loss: 2.4695 - val_acc: 0.4924\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2971 - acc: 0.8292 - val_loss: 2.5030 - val_acc: 0.4683\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3371 - acc: 0.8168 - val_loss: 2.3369 - val_acc: 0.5106\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3144 - acc: 0.8344 - val_loss: 2.3478 - val_acc: 0.5227\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2978 - acc: 0.8309 - val_loss: 2.2658 - val_acc: 0.5076\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2968 - acc: 0.8418 - val_loss: 2.3974 - val_acc: 0.4653\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4020 - acc: 0.7865 - val_loss: 2.4800 - val_acc: 0.4441\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5495 - acc: 0.6939 - val_loss: 2.3839 - val_acc: 0.4502\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3261 - acc: 0.8063 - val_loss: 2.3600 - val_acc: 0.5045\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2624 - acc: 0.8471 - val_loss: 2.4434 - val_acc: 0.4683\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2760 - acc: 0.8485 - val_loss: 2.5734 - val_acc: 0.4713\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3217 - acc: 0.8218 - val_loss: 2.6777 - val_acc: 0.4411\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4274 - acc: 0.7584 - val_loss: 2.3303 - val_acc: 0.4532\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3864 - acc: 0.8045 - val_loss: 2.4110 - val_acc: 0.4532\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3515 - acc: 0.8059 - val_loss: 2.3375 - val_acc: 0.5136\n",
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2848 - acc: 0.8271 - val_loss: 2.4714 - val_acc: 0.4653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2739 - acc: 0.8316 - val_loss: 2.4017 - val_acc: 0.5227\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2685 - acc: 0.8454 - val_loss: 2.3868 - val_acc: 0.5378\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2866 - acc: 0.8380 - val_loss: 2.3762 - val_acc: 0.5166\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3931 - acc: 0.7661 - val_loss: 2.4300 - val_acc: 0.4804\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4850 - acc: 0.7105 - val_loss: 2.2035 - val_acc: 0.5136\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3701 - acc: 0.7872 - val_loss: 2.3249 - val_acc: 0.5136\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.2725 - acc: 0.8457 - val_loss: 2.4792 - val_acc: 0.4985\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3047 - acc: 0.8330 - val_loss: 2.5190 - val_acc: 0.4894\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4616 - acc: 0.7876 - val_loss: 2.4828 - val_acc: 0.5317\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5841 - acc: 0.7591 - val_loss: 2.0997 - val_acc: 0.4955\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3271 - acc: 0.7925 - val_loss: 2.3761 - val_acc: 0.4864\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2803 - acc: 0.8404 - val_loss: 2.3637 - val_acc: 0.5015\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2581 - acc: 0.8482 - val_loss: 2.4659 - val_acc: 0.4955\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2495 - acc: 0.8464 - val_loss: 2.5522 - val_acc: 0.4894\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2668 - acc: 0.8390 - val_loss: 2.7178 - val_acc: 0.4622\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3351 - acc: 0.8091 - val_loss: 2.6853 - val_acc: 0.4532\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3955 - acc: 0.7788 - val_loss: 2.5720 - val_acc: 0.4411\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3315 - acc: 0.8193 - val_loss: 2.5842 - val_acc: 0.4411\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3222 - acc: 0.8221 - val_loss: 2.5152 - val_acc: 0.4532\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2968 - acc: 0.8249 - val_loss: 2.4089 - val_acc: 0.5076\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2880 - acc: 0.8221 - val_loss: 2.3534 - val_acc: 0.5045\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3569 - acc: 0.7774 - val_loss: 2.3392 - val_acc: 0.4894\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3439 - acc: 0.7739 - val_loss: 2.3854 - val_acc: 0.4834\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3119 - acc: 0.8094 - val_loss: 2.4013 - val_acc: 0.4985\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3206 - acc: 0.8080 - val_loss: 2.4950 - val_acc: 0.4804\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3007 - acc: 0.8101 - val_loss: 2.4955 - val_acc: 0.4713\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3080 - acc: 0.8045 - val_loss: 2.4376 - val_acc: 0.5287\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2463 - acc: 0.8401 - val_loss: 2.5347 - val_acc: 0.5136\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2476 - acc: 0.8531 - val_loss: 2.6839 - val_acc: 0.4864\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3242 - acc: 0.8334 - val_loss: 2.6756 - val_acc: 0.4411\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4491 - acc: 0.7598 - val_loss: 2.6863 - val_acc: 0.4411\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3874 - acc: 0.7883 - val_loss: 2.5203 - val_acc: 0.4441\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3331 - acc: 0.8070 - val_loss: 2.4646 - val_acc: 0.4773\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2987 - acc: 0.8376 - val_loss: 2.4784 - val_acc: 0.5106\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2694 - acc: 0.8507 - val_loss: 2.5439 - val_acc: 0.5106\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4826 - acc: 0.7841 - val_loss: 3.1389 - val_acc: 0.3293\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7880 - acc: 0.6594 - val_loss: 2.2189 - val_acc: 0.4834\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3371 - acc: 0.8024 - val_loss: 2.2751 - val_acc: 0.5287\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2640 - acc: 0.8394 - val_loss: 2.4448 - val_acc: 0.5196\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2563 - acc: 0.8503 - val_loss: 2.6315 - val_acc: 0.4955\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2646 - acc: 0.8556 - val_loss: 2.6965 - val_acc: 0.4773\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2890 - acc: 0.8422 - val_loss: 2.6700 - val_acc: 0.4713\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2927 - acc: 0.8337 - val_loss: 2.5774 - val_acc: 0.4834\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2644 - acc: 0.8447 - val_loss: 2.6664 - val_acc: 0.4653\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3085 - acc: 0.8161 - val_loss: 2.7873 - val_acc: 0.4532\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3814 - acc: 0.8035 - val_loss: 2.4257 - val_acc: 0.4924\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2889 - acc: 0.8461 - val_loss: 2.5310 - val_acc: 0.4955\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2502 - acc: 0.8538 - val_loss: 2.6366 - val_acc: 0.5015\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2832 - acc: 0.8478 - val_loss: 2.6895 - val_acc: 0.5196\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3244 - acc: 0.8228 - val_loss: 2.7001 - val_acc: 0.4834\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4401 - acc: 0.7950 - val_loss: 2.6040 - val_acc: 0.5015\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4132 - acc: 0.8098 - val_loss: 2.3816 - val_acc: 0.5287\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2870 - acc: 0.8436 - val_loss: 2.4926 - val_acc: 0.4894\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2729 - acc: 0.8359 - val_loss: 2.5355 - val_acc: 0.4713\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3015 - acc: 0.8035 - val_loss: 2.4862 - val_acc: 0.5106\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2688 - acc: 0.8278 - val_loss: 2.4589 - val_acc: 0.5227\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2618 - acc: 0.8415 - val_loss: 2.5560 - val_acc: 0.5227\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2689 - acc: 0.8411 - val_loss: 2.5448 - val_acc: 0.5287\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3380 - acc: 0.8094 - val_loss: 2.4956 - val_acc: 0.4924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4484 - acc: 0.7242 - val_loss: 2.3782 - val_acc: 0.5045\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2820 - acc: 0.8348 - val_loss: 2.4666 - val_acc: 0.5015\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2865 - acc: 0.8390 - val_loss: 2.5303 - val_acc: 0.4985\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2745 - acc: 0.8559 - val_loss: 2.6282 - val_acc: 0.4653\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3151 - acc: 0.8362 - val_loss: 2.9489 - val_acc: 0.4018\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4467 - acc: 0.7700 - val_loss: 2.8006 - val_acc: 0.3837\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4232 - acc: 0.7728 - val_loss: 2.4606 - val_acc: 0.4773\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2897 - acc: 0.8383 - val_loss: 2.5327 - val_acc: 0.4924\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2782 - acc: 0.8306 - val_loss: 2.4770 - val_acc: 0.4743\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2964 - acc: 0.8274 - val_loss: 2.5291 - val_acc: 0.4804\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2981 - acc: 0.8066 - val_loss: 2.4657 - val_acc: 0.5166\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3191 - acc: 0.8077 - val_loss: 2.4285 - val_acc: 0.4894\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3245 - acc: 0.7992 - val_loss: 2.3837 - val_acc: 0.5136\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2503 - acc: 0.8447 - val_loss: 2.6446 - val_acc: 0.4773\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2510 - acc: 0.8514 - val_loss: 2.7673 - val_acc: 0.4622\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2559 - acc: 0.8443 - val_loss: 2.7041 - val_acc: 0.4683\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2773 - acc: 0.8344 - val_loss: 2.5688 - val_acc: 0.4955\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3002 - acc: 0.8151 - val_loss: 2.5343 - val_acc: 0.4562\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4107 - acc: 0.7636 - val_loss: 2.4175 - val_acc: 0.4532\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5961 - acc: 0.6992 - val_loss: 2.6813 - val_acc: 0.3927\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4534 - acc: 0.7577 - val_loss: 2.5156 - val_acc: 0.4804\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3392 - acc: 0.8285 - val_loss: 2.4577 - val_acc: 0.4985\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2639 - acc: 0.8538 - val_loss: 2.4473 - val_acc: 0.5166\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2367 - acc: 0.8679 - val_loss: 2.5819 - val_acc: 0.5136\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2304 - acc: 0.8686 - val_loss: 2.5581 - val_acc: 0.5076\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2321 - acc: 0.8662 - val_loss: 2.6363 - val_acc: 0.4985\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2408 - acc: 0.8595 - val_loss: 2.7660 - val_acc: 0.4924\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3081 - acc: 0.8320 - val_loss: 2.5674 - val_acc: 0.5045\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3358 - acc: 0.8246 - val_loss: 2.4618 - val_acc: 0.5106\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2802 - acc: 0.8475 - val_loss: 2.6714 - val_acc: 0.4834\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2597 - acc: 0.8616 - val_loss: 2.8898 - val_acc: 0.4562\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4146 - acc: 0.7901 - val_loss: 2.7690 - val_acc: 0.4109\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4269 - acc: 0.7665 - val_loss: 2.5354 - val_acc: 0.4773\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.2997 - acc: 0.828 - 0s 70us/step - loss: 0.2850 - acc: 0.8383 - val_loss: 2.4736 - val_acc: 0.5015\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2442 - acc: 0.8647 - val_loss: 2.5590 - val_acc: 0.5076\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2497 - acc: 0.8602 - val_loss: 2.6264 - val_acc: 0.4985\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2860 - acc: 0.8429 - val_loss: 2.7713 - val_acc: 0.4804\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3116 - acc: 0.8373 - val_loss: 2.6572 - val_acc: 0.4592\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3025 - acc: 0.8362 - val_loss: 2.7125 - val_acc: 0.4592\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2779 - acc: 0.8376 - val_loss: 2.6738 - val_acc: 0.4985\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2809 - acc: 0.8401 - val_loss: 2.7597 - val_acc: 0.4622\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3322 - acc: 0.8179 - val_loss: 2.6991 - val_acc: 0.4502\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3157 - acc: 0.8288 - val_loss: 2.5643 - val_acc: 0.4864\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2612 - acc: 0.8566 - val_loss: 2.5998 - val_acc: 0.4955\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.2690 - acc: 0.8570 - val_loss: 2.8893 - val_acc: 0.4743\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3192 - acc: 0.8253 - val_loss: 2.5775 - val_acc: 0.4653\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2838 - acc: 0.8464 - val_loss: 2.6823 - val_acc: 0.4985\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2283 - acc: 0.8690 - val_loss: 2.8236 - val_acc: 0.4743\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3116 - acc: 0.8281 - val_loss: 2.8177 - val_acc: 0.4834\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5689 - acc: 0.7622 - val_loss: 2.7193 - val_acc: 0.4834\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7029 - acc: 0.7348 - val_loss: 2.1969 - val_acc: 0.5287\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3306 - acc: 0.8070 - val_loss: 2.3536 - val_acc: 0.5015\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2517 - acc: 0.8397 - val_loss: 2.5093 - val_acc: 0.5136\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2220 - acc: 0.8743 - val_loss: 2.6510 - val_acc: 0.5045\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2255 - acc: 0.8700 - val_loss: 2.7415 - val_acc: 0.5076\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2130 - acc: 0.8806 - val_loss: 2.6946 - val_acc: 0.5076\n"
     ]
    }
   ],
   "source": [
    "w2v_model = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "0.9180327868852459\n",
      "1.0819672131147542\n",
      "18\n",
      "1.5\n",
      "1.7777777777777777\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_w2v)\n",
    "model_metrics(predictions, X_test_w2v, y_cat_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXeYVNXdgN8zZSsLLL2pIB1FpQh2QSyAvcTEEqN+UdHY\nYjRBjS0xkUQldrHEEguKvYEFBUVBAWnSe1nq0nZZtu+e7497z8y9d+6dubO7syzLeZ9nn5259Uw7\nv/PrQkqJRqPRaDQAgX09AI1Go9E0HLRQ0Gg0Gk0ELRQ0Go1GE0ELBY1Go9FE0EJBo9FoNBG0UNBo\nNBpNBC0UNAcUQohXhBAP+jx2rRDi1FSPSaNpSGihoNFoNJoIWihoNPshQojQvh6DpnGihYKmwWGa\nbe4QQiwQQuwVQvxXCNFWCDFJCLFHCDFZCJFrOf4cIcQiIcRuIcRUIURvy75+Qog55nlvAxmOe50l\nhJhnnjtdCHGEzzGeKYSYK4QoFEJsEELc79h/gnm93eb+K83tmUKIR4UQ64QQBUKI781tQ4QQeS7v\nw6nm4/uFEO8KIV4XQhQCVwohBgkhZpj32CyEeEoIkWY5/zAhxFdCiJ1CiK1CiLuEEO2EEMVCiJaW\n4/oLIfKFEGE/r13TuNFCQdNQuRA4DegBnA1MAu4CWmN8b28GEEL0AMYDt5r7JgKfCCHSzAnyQ+A1\noAXwjnldzHP7AS8B1wEtgeeAj4UQ6T7Gtxe4AmgOnAlcL4Q4z7zuIeZ4nzTHdBQwzzzvEWAAcJw5\npj8D1T7fk3OBd817vgFUAX8EWgHHAsOAG8wx5ACTgc+BDkA34Gsp5RZgKnCx5bq/Bd6SUlb4HIem\nEaOFgqah8qSUcquUciMwDfhJSjlXSlkKfAD0M4/7NfCZlPIrc1J7BMjEmHSPAcLAY1LKCinlu8As\nyz2uBZ6TUv4kpaySUr4KlJnnxUVKOVVK+YuUslpKuQBDMJ1s7r4UmCylHG/ed4eUcp4QIgBcDdwi\npdxo3nO6lLLM53syQ0r5oXnPEinlz1LKH6WUlVLKtRhCTY3hLGCLlPJRKWWplHKPlPInc9+rwOUA\nQoggcAmG4NRotFDQNFi2Wh6XuDxvYj7uAKxTO6SU1cAGoKO5b6O0V31cZ3l8CPAn0/yyWwixGzjI\nPC8uQojBQogpptmlABiFsWLHvMYql9NaYZiv3Pb5YYNjDD2EEJ8KIbaYJqV/+hgDwEdAHyFEFwxt\nrEBKObOGY9I0MrRQ0OzvbMKY3AEQQgiMCXEjsBnoaG5THGx5vAH4h5SyueUvS0o53sd93wQ+Bg6S\nUjYDxgHqPhuAri7nbAdKPfbtBbIsryOIYXqy4ixp/CywFOgupWyKYV6zjuFQt4Gb2tYEDG3ht2gt\nQWNBCwXN/s4E4EwhxDDTUfonDBPQdGAGUAncLIQICyEuAAZZzn0BGGWu+oUQItt0IOf4uG8OsFNK\nWSqEGIRhMlK8AZwqhLhYCBESQrQUQhxlajEvAWOFEB2EEEEhxLGmD2M5kGHePwz8FUjk28gBCoEi\nIUQv4HrLvk+B9kKIW4UQ6UKIHCHEYMv+/wFXAueghYLGghYKmv0aKeUyjBXvkxgr8bOBs6WU5VLK\ncuACjMlvJ4b/4X3LubOBa4CngF3ASvNYP9wA/E0IsQe4F0M4qeuuB0ZiCKidGE7mI83dtwO/YPg2\ndgL/AgJSygLzmi9iaDl7AVs0kgu3YwijPRgC7m3LGPZgmIbOBrYAK4Chlv0/YDi450gprSY1zQGO\n0E12NJoDEyHEN8CbUsoX9/VYNA0HLRQ0mgMQIcTRwFcYPpE9+3o8moaDNh9pNAcYQohXMXIYbtUC\nQeNEawoajUajiaA1BY1Go9FE2O+KarVq1Up27tx5Xw9Do9Fo9it+/vnn7VJKZ+5LDCkVCkKI4cDj\nQBB4UUo5xrE/FyNuuytGUs/VUsqF8a7ZuXNnZs+enaIRazQaTeNECOEr9Dhl5iMzI/NpYATQB7hE\nCNHHcdhdwDwp5REYxcUeT9V4NBqNRpOYVPoUBgErpZSrzSSitzCqPFrpA3wDIKVcCnQWQrRN4Zg0\nGo1GE4dUCoWO2At45ZnbrMzHyDjFLBVwCNDJeSEhxLVCiNlCiNn5+fkpGq5Go9Fo9rWjeQzwuBBi\nHkbq/1yMGvE2pJTPA88DDBw4MCaGtqKigry8PEpLS1M83H1PRkYGnTp1IhzW/VA0Gk3dk0qhsBGj\nWqWik7ktgpSyELgKItUt1wCrk71RXl4eOTk5dO7cGXtBzMaFlJIdO3aQl5dHly5d9vVwNBpNIySV\n5qNZQHchRBezA9ZvMEoNRxBCNLe0D/w98J0pKJKitLSUli1bNmqBACCEoGXLlgeERqTRaPYNKdMU\npJSVQogbgS8wQlJfklIuEkKMMvePA3oDrwohJLAI+L+a3q+xCwTFgfI6NRrNviGlPgUp5USMnrnW\nbeMsj2dg9ODVaDQaTRwem7ycAYfkcmL3hPlntUKXuagDdu/ezTPPPJP0eSNHjmT37t0pGJFGo2lM\nVFVLnvh6BTPX7Ez5vbRQqAO8hEJlZWXc8yZOnEjz5s1TNSyNRtNIWLSpgGoJrZokasZXe/Z1SGqj\nYPTo0axatYqjjjqKcDhMRkYGubm5LF26lOXLl3PeeeexYcMGSktLueWWW7j22muBaMmOoqIiRowY\nwQknnMD06dPp2LEjH330EZmZmfv4lWk0mobAOU/9AECzzNSHojc6ofDAJ4tYvCnpAKa49OnQlPvO\nPsxz/5gxY1i4cCHz5s1j6tSpnHnmmSxcuDASNvrSSy/RokULSkpKOProo7nwwgtp2bKl7RorVqxg\n/PjxvPDCC1x88cW89957XH755XX6OjQaTcPjl7wCvlq8hZuHdScUtBtvVm4r4sVp0Sj9nIzUT9mN\nTig0BAYNGmTLI3jiiSf44IMPANiwYQMrVqyIEQpdunThqKOOAmDAgAGsXbu23sar0Wj2HTe/NZc1\n2/fS75Bcjj20JbPW7ow4k29442eWby2iR9smLN9axCm92qR8PI1OKMRb0dcX2dnZkcdTp05l8uTJ\nzJgxg6ysLIYMGeKaZ5CeHrUVBoNBSkpK6mWsGo1m3xIwo8y/XZbPGz+uY/KSbYy/5hiO7dqSiqpo\nAYfubZrUS0h6oxMK+4KcnBz27HHvalhQUEBubi5ZWVksXbqUH3/8sZ5Hp9FoGjJlldUAvDJ9bWTb\nnPW7TKFg7CuvrCY7vX6may0U6oCWLVty/PHHc/jhh5OZmUnbttFCr8OHD2fcuHH07t2bnj17cswx\nx+zDkWo0mlSybU8pSzfv4aQesbkEU5dto2lmmP4H59q2F5RUxBy7p7SSCbM2kLfLsBjsLa+iRXZa\nzHGpQAuFOuLNN9903Z6ens6kSZNc9ym/QatWrVi4MNpb6Pbbb6/z8Wk0mrqnoqqaR75YxqiTu5Kb\nncb5T09n4+4S3rv+OO75cCETRh1LE3OFf+XLswBYO+ZMpJRUVUuEEOwpjQ1dr6yq5oFPFkWe7y2r\nJC1UPxkEOk9Bo9FoHFRVS3YUlcVsrzTNOYovFm3hue9Wc8VLMxn26FQ27jZW9ne+v4DFmwuZs26X\n6/WfmbqKbndPotBFSwAorayi2lIPuri8irRQsIavJjm0UNBoNBrg8ckrOOFf3wBw/jM/MODByUgp\n2V1czqbdJeTvKaPHXyfx78+XRs4pLjMq/f+ysYBV+Xsj20sqjO1bCtyLVz47dRUAa3bsdd1f5KI9\npAXrZ7rW5iONRqMB/jN5eeTxgrwCAJ7/bjUPTVpqO+6Zqav48/BeAJQ7NAfFhp2GxvDmzPV0bdOE\nfge5Vy5Yne8hFMoqkdhbx6TXk/lICwWNRnNAUl0t+Wj+Rs4+ooMtaazz6M8ijz/7ZXPca5RXugsF\nxbwNu7nw2el0bpll256TEaKorJK8XcWu5y3cWEhphf3a9SUUtPlIo9E0Wiqqqqmqtq+4yyurqa6W\nvDcnjz++PZ+Xf1jreX7Yw2RTVGaYd4rL49c3U6zdEZ38f/3cjEi5is27DfNSKGDPP9hSGGt20o5m\njUajScAn8zfx5aIt3P7OfE4b+23M/t73fM7lL/4UeS6lpMdfJ3Hfx4vYXWw4eTcVeCeKllXGdAcG\nosKgLIGm4MZPa3ZG8g/UvUPBxElpWijsR9S0dDbAY489RnGxuwqp0Wjic9P4uVz72s+8+3MeK7YV\n2fZJKamslsxYvYM563dx+Ys/sW2PEVH02o/rCJqrc6cmYWX7nnLX7WWmacfLp5AIFaWUb44nYMlU\n7to6m8sGHxxzTn05mrVQqAO0UNBo6p9Za917C0xbkU/n0Z8xY9WOyLYLnpnO9yu3M8niIwibq/PK\nOELBzYwDUQ3BzadwzKEtEo5d+QtU4pqz+mnv9k1jzkkPa0fzfoO1dPZpp51GmzZtmDBhAmVlZZx/\n/vk88MAD7N27l4svvpi8vDyqqqq455572Lp1K5s2bWLo0KG0atWKKVOm7OuXotE0aFblF/HGj+s5\nrU9bLnnBvWTMB3M2AvDst6ti9s2y5A0oUVBV5S0UvPjfjLVc0L+Tq1DIyfBf3loJhbZNM9hsCV/N\nDMfmJKQF6ydPofEJhUmjYcsvdXvNdn1hxBjP3dbS2V9++SXvvvsuM2fORErJOeecw3fffUd+fj4d\nOnTgs8+MyIaCggKaNWvG2LFjmTJlCq1atarbMWs0DZSS8ioy02o2wf3hjTks3bKH7HTv89VEO23F\n9ph9O4ui5qCScsNfUCVrIhTW8b8Z6/jVgE4x+5Ipb11sjuGsI9ozb0O0C6ObWUr7FPZTvvzyS778\n8kv69etH//79Wbp0KStWrKBv37589dVX/OUvf2HatGk0a9ZsXw9Vo6l3pizdRu97P2dBXmwb2q8W\nb2XRpgI27Y46fsfPXM8n8zdFnqtJdOMub+dwYal7ljDAbksGsbpW2IeT1wu3ybtpEpqColubJvz9\n3GiFZzW2847qENlWX0Kh8WkKcVb09YGUkjvvvJPrrrsuZt+cOXOYOHEif/3rXxk2bBj33nvvPhih\nRrPveOfnDQCs2FrEEZ3sCV3X/G925PEXt55E19bZ3Pm+ofVnpwc5pVfbSELXqny7U1nRefRnHNo6\n23UfECkrkRYMUGpmHY+fuYEebXOSfi3Ns8KRKCIrNWmEEw4GCFjCUo86yFg0ntanHR/OM4Si1hT2\nI6yls8844wxeeuklioqML+3GjRvZtm0bmzZtIisri8svv5w77riDOXPmxJyr0TR2lGknUVuAK1+e\nSbe7o4Ukv1+xw7Z/9Xb3TGCwZwk7k8bU/UNBEYn8Afjbp4sBGNwlsZNYUVklXX0KuVnJVzMNBYQt\nV2HAIS1Y+MAZDO0VrbaqM5r3I6yls0eMGMGll17KscceC0CTJk14/fXXWblyJXfccQeBQIBwOMyz\nzz4LwLXXXsvw4cPp0KGDdjRrGi2z1+6kR7scBMbEp3IEvNjsqBk0dfk27pG9yU4zpiy3yqJutGyS\nbksciyadVfH+3I2R7cqtMOLwdsxau5M4AUm2a01esi1me9umGb7GZiUUFLawVIAm6SFbnkSjEApC\niOHA40AQeFFKOcaxvxnwOnCwOZZHpJQvp3JMqcJZOvuWW26xPe/atStnnHFGzHk33XQTN910U0rH\nptHsSyqqqrlo3Az6tG9KbrZhb9/tUR3Ui9X5e/l4/iaWbklOq062B0FWWojk3c522jRNT3yQg1Ag\nEMmbcG5X7Pd5CkKIIPA0MALoA1wihOjjOOwPwGIp5ZHAEOBRIUT9dJLQaDRxWb/Dnj9z7lPf8/jk\nFewudk/o8mKvuTpfvLmQtduNaxYkcQ1lo7/lrXlJ3RegZZJCoaZRUVba5tRMU3ATCtZNof1dKACD\ngJVSytVSynLgLeBcxzESyBFG49EmwE7An16o0WhSxpz1uzjp4Sm8NXN9ZNv8vAL+M3k5R/3tq6Su\ntbc8agJRmbzJaAq92iXvBFa0bJKcUMhOD8aYceL5P9JDgRgHcE5GiEsGRTOSOzbPTHhfL03B2pO5\nnmRCSoVCR2CD5Xmeuc3KU0BvYBPwC3CLlDLGcyOEuFYIMVsIMTs/P9/1ZrIGscb7IwfK69TsW7aZ\nmbxfLt4KxDaXcVJSXsXH8ze51gpSmoKVVflFdB79GVOWbouc70UyyWBOnJnCicjJCOMyN3vSt2Mz\nurS0RzsFhOChC/rSOscwI00Ydaxtf4aZmWyNUgoFBcEE3vdgYP/XFPxwBjAP6AAcBTwlhIjJ75ZS\nPi+lHCilHNi6dWzv04yMDHbs2NHoJ0wpJTt27CAjI3n1VKNJBmXLVt3Hiiu8J+13f87j318s5ebx\nc3l88grbvtKKKltbScXCjYUAvDpjLQA3vPGz5/Wb1KJhfYZLZnA8mmaEbatzgHhTtRDEhKUKc1bt\nYGoIzvG3yEpj0QNncNMp3SLbwh6agpVEQqOuSKWjeSNwkOV5J3OblauAMdKYzVcKIdYAvYCZydyo\nU6dO5OXl4aVFNCYyMjLo1Ck2i1KjSZbNBSUs3FjIaX3axuzba1YBVXZs1WFMsaWglDGTlnDbaT25\n/Z35ke2v/7iOFduKOL9fR2au2UnrnHR+WGkPJ7WinKdTlnn/dr3i/nu1y+EPQ7tx0/i5nudaTUFp\nwUDCAnY5GaGkJl+BiLmmuucLVwxg1ppdrtpKdnrI5kQOevgUrCTaX1ekUijMAroLIbpgCIPfAJc6\njlkPDAOmCSHaAj2B1cneKBwO06VLl1oOV6M5MNhcUELzzDQufGY6mwpKWf3PkbbEKYiac1QYpLNv\nwP9mrOXDeZtYvLnQtr2wtJKvFm9l8pKt+FHc/SRkeZmPstNDCRPFrBOpSnxrmhGi0COkNScjlJT5\nCBFbFE+d3iYngzOPaO95qjWTOhwQEQHs9b7t90JBSlkphLgR+AIjJPUlKeUiIcQoc/844O/AK0KI\nXzDey79IKWMLlmg0mjrj2Ie+4ejOuWwycwFKKqrIdpg49sYIBbumsHOvET20fKt7ZrFfS64/oeA+\nTQUDImGYpnXVr6qh5manuQqFYECQnRaKcTTHI+BiPvJ7vtVHEAoGIkXwvLSZ+nI0pzRPQUo5EZjo\n2DbO8ngTcHoqx6DRaGKZtTZaLfS75fmM6Btd0VZWVVNsOofTHEKhXdMMthSWJmxD6RclXOLhJRRC\nAUE4gVCxakDhgGE+ap4ZZp3Lsa2bpBvHJ7EgDwhBpaPKql+ZYs1gDgVFVCh4vLcHiqNZo9HUI27B\nGNe/MSfy+LMFm+l29ySWbDHMQmrVq8xHR5o1efa4RBTVhKnL8vl8Yfw+yCqL2UkwIDzbZUaPid3W\nsol7cplX0pnT8WzfB2VOR7NPoWA1B4UCgsw0Y7CemkIjcDRrNJoGRkWc3gHrdxQz+r0FAMxcY2gS\nVdWS3700k2+XG47gFtnGxLknTiXSZBn1+py4+70iiMLBQExvYydWU46abA/Kdc8b8Jv9/I/zD2fp\n5j289uM6isqqamw+srbgDAUCZJrCz0tTqCdFQWsKGk1j564PfuHdn/MAqKz2NvucOvbbiAagyk9X\nVcuIQABoYZapKKojTcEPXjV/ggGR0CdhXY2r0NBOuVmuxyrzTaIp/bLBh3D7GT0Bo3WmU/lKJBTU\n4dboo1AgsfkopM1HGo3GjbLKqkhmMMDP63axOU7z+Td/Wh8JG62o9NYUrGYLNTE5W1VGNYWaC4VE\nq3snXm0onZVF3bCaXN68ZjB3j+xNsyxDsDXLDNPTUjI7meieZplhvv7TyTx43uEx+xJdpd/BzWPu\nF7AIBa/2oI0ho1mj0dQhxeWV7Cgq4+bxczl+zDdUVUs27S7hwmenM/o9926D1qb0Ukr2lLmbfazl\nLKxUO5bBqpZQoY8yFZcNPpjrTjo0ZnuyCWXpIffjgwGRcPVsdTT3bJfDNScdahMkH914PKNO7gpE\nfQfxfAhWurZuQpaLvyPe6X89szcPX3QkECscVaaz1/nJREXVBu1T0Gj2E0Y+Ps1WBrqkoirSH8Bq\n4rGy15Jf8OQ3Kxn71XLX40a/7y5UyhymjFxTKPgxH/3uuM5khII895099SgjHEzK/JThoSkEA4Jg\ngq5pVk1BTarWFXpGOBgpR6G2OufeZKfieELl9ydGhaRz7EIIRo/oxQnd3FvzavORRqOxsdZRtbS4\nvJISs/yEl+XDWnfISyDEY+aanZHH6aEA2WYV0XgOa0UwIFydo2qSH9ylha9WmF5+g4DwYT6y7FcC\nQkUsqblbjae+i+S4jX3UyV05vKN7q17taNZoNHEpLa+OtJT0KqtcVAvbv5NwMJCU6ScUcC/doK6R\nm5UWsaPHw8t8FBCJS0MEHHZ7iAoKtUdlTFe4OHi7tWli0xyuPK5zzDFPXdqPs4/sELM9EclmKNdX\nRrMWChrNfsr8vN2RDmZhjwljk6ODWW0QJOcPCAUDDvON8V+tzLPSgpRWJE6C84o+EiKx09ottl+d\no8w8SvspdVR4feKSfnxww3GR5+9dfxz3n3NYzPXOOqIDT17SL+443EiUY+FECwWNRsPmghJKK6rI\n21Ucs++m8XMjFUj3llcxf8NuWzjjym17+N1LRm3Jow5qXuuxVEnpad93IxQQtpW6moSzwoYrMys9\nmLBAHcQRCtgnyrn3nMbdI3vbjnEzuTgnV6WJlJkCSu09KDfTVncp2aipRCStKWhHs0bTeJFSUl5V\n7WkaURz70Dec0K0VJ3Z3dz5uLYw2nz/36R9ICwZY/o8RlFdWM2Vp1PncvlkG8zbEnh8MCFuEUjyq\nqqUvc4/12taJTD1Kj2gK/qaf9Dj3tDpfc7PTYnwU7ppCwDYeJeiUpqCElzPap65X6skKmfpyNGuh\noNHsA17+YS1/+3Qxc+45LZJJe/LDUxjcpQX/NkMWVUmK71du59DW2Z7XslJeVc3Ix6fFVC9t18y9\nB0c46F8oSJJrVxkKCARWTcG8jnk7v6YoL2e0ELETtfO5s/qr9Rg1nm5tmgDwu2M7289NsVBI9nra\n0azRNAL2llVyy1tzyd9TZtv+2S9GvZ8VW41G9Gu272XdjmImzM6LHGOdq53nx8MpEMAo4+xGUnZt\nCRkJNBsroWDAdSJTuQ9ZPgWMdbX/z/P7cq0l98G52h7Wu61tm1tsf7S8hPG/eVYaa8ecyXn97I0h\n1alKsNW1+SjZlb/2KWg0jYAP523ko3mbeGyyPRy0ldk7ON/sbDbqtWjnsYqqalZuK7KVpEhGKLjR\nNNPdKJCo9LSTgI/SEgqv6KOkhYLlGiMObxd579R4rHRonsnKf450PTfetkT3dbtXbQn5CMe1st/3\nU9BoDmRKyqv47JfNkdWlMwmsSbrhwFTRQzssJaT//flSXpi2xnb8Dh8lpuPhtcJPRlNQTWoyw0Ff\npbODAQEuhylZ59c/YWteHxRJZfbGjz7yuJ/533mfutcUGqajWWsKGk0K+M/k5dz+znymrzJaUb77\ncx5jv1wW2a9+36rDWc92TSL7FuQVxFxvzfa9NR7LEZ2aea4ywyH/E43yBRT4KHEBsZqCMsNURTSF\n5Nek4SRNLn6ij5yoz8Z52L7yKTxzWX+OjPMZ1jVaKGg0dcia7XvpPPozJi/eCsCq/Ghnsie+WQkY\nUTyqaqlqXtPKrPF/SMssWjZxL+HsJ/vXjQ9uON7T9JFsrHwyCOFY1ZsPj+vaEog6eBW5WWHa5Lj3\nNFAEAyJao8hHAQq3iTSS0ZzgXGe5irqPPvL33o/s256PbjzBd02m2qKFgkZTh3wwx5jsV5sr+y2O\n5LHSiipbv+Onp66ktKIqknlcXF7l6RR2awBv5ZZh3V23O0NDrVzYvxPgbkr5vxO6xL2fIp5fwjaP\nmprGDUO68f1fhtKzXY7t2E65Wcy8+1TaejS7ATP3IYm50e11J57cVUiq7ek+jz6qL7RQ0GjqEGd0\np/IZKJZv3WOzx5dXVvPMlJWRPgZFpZWeNvOmCYSCW7jojUO7Ad5ll4/v1oq1Y87kIJceA2cc1s72\nXL20EYfbt/fu0NRzTNbV7T/OP5xWTdJJDwU8expAfNt5IOBHP7AfP+LwdjbBldCnEDEfJc55qA01\n1fxSjXY0azR1iHPecNbGP+epH7j5lG62bXvKKikzaxiVVFTx0g92J7Mikabglvl7s6k9eAkaNdFJ\nl3JwXvcbcEgukxZuiTw/pEUW8zfsZsAhufy8bpfrOQC/GngQvxp4kOd+NYbju7XinZ/zPI9LxowS\nFIJnLx9g3xapfZSgblKMo7nma+i595wW8aU4x9HQ0JqCRlOH+CnbMNEyoYJhfnFGJ7nRNCO+UHCL\nZlHho14TkJrnnN3D7jijJz3aNuGZy/pHmsK49XcGI4pozUMjueesPnHH55d/nN+Xr/90suf+pMxH\nLgdH+ybEP9cpA2qTPJabnRbxGynqK0M5WbSmoNHUIZU+SkoXO3oJhIMByiuryc0Ks6vYO7JHtZP0\nIhhnkvFyNKuJyTnf/8E0O43s257Kasnc9XMjuoRzBZ0RDiBEdN3duWUWr149KO5Y3VBjSAsF6Nq6\nCe9dfywrtxmO+huGdI1qD0loCl5d2yCxo7mhZTTXFw1TVGk0+wlv/rSezqM/47vl+Yx4fBpbCxNX\nJXU2mAkFBWWV1Qzt1SZu7PohLb3t8BA/7t3LHh6MaArewsx5rvM2znIVTTPDHNLSX1mOeAw4pAW/\nPvpgAP48vBez7j4ViG2G8/KVR/PpTSe4XsOtlEa81+p2fWWWS86bkZi6znuoK1IqFIQQw4UQy4QQ\nK4UQo1323yGEmGf+LRRCVAkhWqRyTBqNFxt2FrO9yDtzWErJOU99z2cLNrM6v4jPF25h3LerALji\npZks2VzIsi17Et5nrxmG+uxl/QEorag2i+MF4k78zmidGOLMMZ7mo4hPwRt1qppLnTZ9VbCuW5sm\nNMsM86fTe8YfpwcJ5mrLeOz3H9qrjWdjGrekvZZmn+lRQ7q6nuMsb/HuqOO49dTuSdV98kNdZ0jX\nFSkzHwkhgsDTwGlAHjBLCPGxlHKxOkZK+TDwsHn82cAfpZQ73a6n0aSaE/89hbZN0/nprlNd95dW\nVLMgr4CO3IWaAAAgAElEQVQbx8+JTGCdHZN4SUUVHZpl0CwrjSUuNYgg2je5ZZN0mmeFKSqroLyy\nmrRgIG7eQCLzkTPLeMrtQyKPPR3N5sTk7MVsxTl5xWoKxpiz00PMv+/0uGOsC5IJAnKL8MlMC7J2\nzJkJz1WO757tchIL5EZEKjWFQcBKKeVqKWU58BZwbpzjLwHGp3A8Go0nO80yElsLy/ho3kbXY1S/\nY+s045xsi8oqSQsFmHTLiQnvmRYK0KNNDp/M30xBSQVpoUDEVOEW++/VXU3hdFa3axrNd/DSFNT2\neKv0GNOTU1NIokhePPy2w/SrUUBykUqRc+rYTLS/kUqh0BGwVnDPM7fFIITIAoYD73nsv1YIMVsI\nMTs/371BuUZTG3ZYzEa3vDUvZv+a7Xtt/Y4VzlV0UWllwslbkR4K8IdTukXKRqSFApFooeZZsZFG\nVht0n/axuQFljs5h1oJrXkOKCIU443T6r51TZjKNdzSx9GjbJPFB9UhD+TTPBn7wMh1JKZ+XUg6U\nUg5s3bp1PQ9NcyDgXGVXVUuenrKSN35ax9IthQx9ZCr/cWl875wgK6tlxASUyGQcDgYYcEhu5Pmy\nLUWRc92EgnW1/9xvBzD24iNt+8srqxlzQd/I83glpNXTSJ6CZfndMtteZsN5rlOLSaacdjwSOYDr\nm/oYzpTbh/Du9cclPrAeSaVQ2AhYM1U6mdvc+A3adKRJIVsLS3lo4hLPhjLO/ILud0/k4S+WcfcH\nCxk31XAmf79ye8x5K7YVxWxTduxEIYfhoLD5CfJ2FUfOaZ4ZW//IOsmnhwIx1y+rrOYsSwN5W3VR\nx7FqIlfJdWoC/PdFRzDRYfpynntev4783wldOL6bUcMomb7NTt6+9hiuM/sjHNwifnSVk1SVAvqD\nmVzYItu9BlVd0qVVdsL8k/omlUJhFtBdCNFFCJGGMfF/7DxICNEMOBn4KIVj0Rzg3Pn+Lzz33Wpm\nr3WPY3A6aa2yQz3226Esqik4aug4cJqZerSNOjObZMQ6la2Tc3Z6KPK8VZN0ju/WkquO6+x5L+dq\n/7Q+bYFo+Wr1yo7v1oq2Te21l2I0hVCAe87qE/El1MZ8NPjQltw5sjfP/XYAjzg0n9pwSq82Np9K\nMvz2mENYO+bMWgm7/ZmUCQUpZSVwI/AFsASYIKVcJIQYJYQYZTn0fOBLKWXNawNrNAlQuQHWiX36\nqu30//tXfL5wc9z+AMrmX2EmpiWSDU5NwSuiKOyYwR+ymH7ceg1YM2Cz0oIR009uVpg3fn8MbZpm\nJIwyUvz9vMOZ9ueh5JqrYRV95BwTeEcuHdnJyHROtMK/YUhX+ptZ0V6ccVi7Ol0xv3Tl0fx417A6\nu96BREozmqWUE4GJjm3jHM9fAV5J5Tg0GmWvLjSrkW7cXcKlL/wEwF8/XMiJ3b19VbuLjcgkZ9KZ\nF0oIqEnby4zk1BSy00ORCdi6Sm2dk07+njJ7bwIhXJ3EfoVCeijAQZbJXJmP3JzkXtrHjad048wj\n2seUwHby5+G94u5PFrc6TZq6Q5e50DRqJszaQPOscGTSU6GnJZby1duLyvlgrpe7C3b7bCqjUPdQ\nkUleE7VbO0Z1aLtm0To5Srg4j4+Gk0YnSb/mI+dzdQ238+OFsyYSCJr9Dy0UNI2aP7+3AIBBXYxE\n+eLyShZuLODb5f5Dm/12GlNsM/spq7nU06fgVqzN/O9WytpPz2DvzOX4z1vlpFNYWul6fkPNvNWk\nBi0UNPstlVXVcXMC7v94UeRxtekIqKiSnPXk90ndx9oToW3TdLYWepfCAGu9flNTSFCMzoqwmI/a\nN8vg9D5t+XzRlsh1f39Cl0i/5pCL+cgrWctpcHFO/q//32C+X7mdHBe7fjI9keuXhjqu/RstFDT7\nJbPW7uRX42bwzqhjObqze7msV6avjTyebdb5r/RR2joe3do0SSgUYlb0HpOqckj/eOcwSs1+CurU\ncDDAjDsNR6nqXRAMCP5qKU+dTNMXZw6AU3h0aJ7JxR69DuqrYbymYdBQktc0mqSYsWoHAN8uizUD\nFZVV8opHo5qKWgqF3KzEsesRTcF87mV9URNzu2YZdG6lqorGOqfVdO4UNpHnPvyutUnEaqBl/zUp\nQn/cmv2Cn1bvsBWYUxE+bk1t7nhnPvd/sjhmO0Tt/X744taTYra5ZRo7iS0g53+lHe9Qr/r+fuZ7\nnykWvu67r2lgic+NDi0UNPuUl39Yw3c+nL6/fv5HRjw+LfJc1Qhyyy9YlR+bZax4a9YGz31O3HIF\nshNUKoVYB7KaVE/q0ZqXrzo67rmx+oGlZLXjWLfoIy/aNk1PeIwXDbUZjCY1aKGg2ac88Mlirnhp\nZtLnpZn2eGfNohVb97B8q7dQSAa3TN0maYmFgqqyGW0Ab/wfflg7hvZsE/9c81j7yt5dKiSjKTTP\nSmPNQyN9HBlLvHLemijtmmaQ45KJvr+hP21Ng8e6ElYOWZVdXFFVTWVVNVJKqqslp/3nuzq7b4ZL\nUxWrpnCOpc6QO44oJB8LbiVQrIt/5QDOSbebrpI16wghXLWfRGSnN8xyDw3MqsUPo09h3r2p7yeR\navZ/saZp1KzKL6JZZnQyXLN9L73bN6XULBNdXllNn3u/oG2zdDbsLKn1/To2z2TjbuM6bj0NsiyC\n4pRebfh4/qaYYx7+1RG252pF72cSV05da9buHWf05OZh3WNq8ahktmRs7JP/dDLrtidXUSZRcx+N\nQWMxs2lNQdMg8LKLD3v0W4Y9+m3k+RpzQiutMMxGu4rLKa+qrhOBMOLwdrzx+8GR56GAiBEMqiVj\nl1bZnNfPtT0IR5g1gZzmIz9h9UqrsL4dQgjX4mw1CRXt2DyT47q1SuqcmmgXmv0XvQTQ7DOsgmBX\ncYWtVPHXS7ZGJkJrRvFq04lcZpqRVufXXR3FZy7rz5bC0sjzYECQHgrYIpxUZ7QsH/16oyGp9sn7\nvrP7sHSzey/n+87qQ3ZakNMPa5vw+lGfQmrDcWrSvSyV6OCj1KKFgmafYZ1sN+4qYW9ZJQe1yOLt\nWev5y3u/uJ6jhIByMG8v8h9imggh7JqBEIL0cABrFKuKekrGZOMMUb3q+C6ex7ZpmsG/L/JXQtpP\nK02NJlm0UNDsM6zhpLdNmMeKbUX8dNcwT4EAsMo0H1VWG+c6o4/8cGSnZhzUIotPF2yO2ZfuMJVs\nLyq3PU8L2vsPxMPZ3ayuCbiYmlLFbaf10MXvDhC0T0Gzz1ARRBDtYLZwY4Hn8TkZIRZvKuC1H9dR\nWeU9E35+64me+wD+ddERPHVpf9d9bs5lK+2bG41bTuye2C7vDE3dn+0eNw/rzsi+7ff1MGw0LKNW\n48GXUBBCvC+EOFMIoYWIps5wSzxbuLHQ5UiD3Kw0Kqok93y4kJ/NWkZudImUjMB1detWiE4Rdiln\nbeWg3Cym/Xkofz6jp237f3830POcVGUEe102LRTgzCMa1gSu2X/waz56BrgKeEII8Q7wspRyWeqG\npTkQcBMKK7a5O2DBKDGx3uymqXoWuBG2TPr3n30Yr/+4jsrqaiYv2QbE1wYSOVXDQWFrTqMY1jvW\nMRyJPkrxUsoZubX8wRGpvaGmUeNLKEgpJwOTzX7Kl5iPNwAvAK9LKZMrOK85oFCTlnPCLa+qijnW\nzc6vsOYr7IgjFKyO3RO6t+IE09TTefRnAIRDNV+51yQSJ1U+hYYWFVRvaM96SvHtaBZCtAQuB34L\nzAXeAE4AfgcMScXgNI2DP749jwV5BXxz+xDb9vLK5H7cta1wqohnPvKiWWY4rokI4JMbT3Bt2RnJ\nPahjp0JzU0heMujgOr2u5sDGr0/hA2AakAWcLaU8R0r5tpTyJkCHJGji8uG8Taw2o4aKyyu5/+NF\nFJZW8Mp09/LWXvTt2Mz3sVlpQa476VDbNlXLSPkNJlx3LJcMcu8hoPjf1YMAaJoZYqBL34ZWTdIj\nGkzfTs04tmvLyL5EpbNrS3Z6iFX/HMmNp3RLzQ00ByR+NYUnpJRT3HZIKeMvnzSNHiklXyzayqm9\n28TthAYw6vU5fLc8n7xdxREbv19O6N6aF6b5EySL/zY8Ztsxh7Zk6rL8yBgHdWnBoC4tGD/Tu3Jq\nz3Y5QGzdIcVPdw3zzMaO1jxKnZmnsZRWqAkHqvUs1fgVCn2EEHOllLsBhBC5wCVSymdSNzTN/sKk\nhVu44Y05jB7Ri1End41sLymvotoyYb49a32kTHY8n4AXfua/oT1be+57+tL+rNhWFFPL5+/nHkbe\nbvcyGW2bZvC3cw/jVBdHMqhJOf7AdI9jzf6EX6FwjZTyafVESrlLCHENRlSS5gBH1SPa5ZjoB/9z\nMoWlURu7NSlN1S5KBj8O25evGuS5Lzs9xFEHNY/Z/ttjO8e95hUJ9iciWI9JZhpNbfHrcQsKS6iD\nECIIJOxLKIQYLoRYJoRYKYQY7XHMECHEPCHEIiHEt27HaBo2yrk6Z/0uOo/+jCe+XsGo1362CQQn\n1i5qftnfVtzqF6PNHHWLlq2pxa9Q+Bx4WwgxTAgxDBhvbvPEFBxPAyOAPsAlQog+jmOaY2gb50gp\nDwN+leT4NfuQNdv38tv//sR2szjQrLVGQtnYr5bz+aIttbr27L+eyoX9O9m2ednm73Akkmk0mprj\n13z0F+A64Hrz+VfAiwnOGQSslFKuBhBCvAWcC1ib514KvC+lXA8gpUzO86jZp/z908VMW7Gdjs0z\na3Wd207rwdivltu2tWqSzr1n96FpZoiXf1gLgJcPW1UurSseuqAvRXG0HL9oDUGzP+Lr1ySlrJZS\nPiulvMj8e05KGZt5ZKcjYA3ryDO3WekB5AohpgohfhZCXOF2ISHEtUKI2UKI2fn5ifv5auoHVdK6\nVU7N+/+CdxnqZplh7jv7sMhzIQQPnnc4Nw/rbjuuroXCJYMO5hpHOGtNEA4HtDZ71C3O91dTN/jS\nFIQQ3YGHMMxAGWq7lLK2v5wQMAAYBmQCM4QQP0opbctGKeXzwPMAAwcO1L+tembsl8soLK3k/nMO\ns20vNIVCpksv42TI9NGbAAyH7eXHHALAE1+viGx3VjbVNG7UIsDv90aTHH5/zS8DzwKVwFDgf8Dr\nCc7ZCFgzgzqZ26zkAV9IKfdKKbcD3wH+islr6o0nvlnJK9PX2raN+3ZVpLJpRZyKpW48fJG9XWVG\nyP7jfvmqo13P8/IpJKpsuq9RUUc6+qhuuKB/J249tTu3nto98cGapPH7a8qUUn4NCCnlOinl/cCZ\nCc6ZBXQXQnQRQqQBvwE+dhzzEXCCECIkhMgCBgNL/A9fU99IKXnhu9WMmbQ0ss0ZipqIExxlp52t\nJg+1VDm1Yq1OYa1+2lCjkpwyLNUd0g4UwsEAt57ag6w03Q4mFfgVCmVm2ewVQogbhRDnk6C8hZSy\nErgR+AJjop8gpVwkhBglhBhlHrMEI4ppATATeFFKubCGr0VTx0xfuZ1Tx0ajhKWU5BeV8Y+Jdrm9\nOslG8GHHyt7pE/DSCKzbJ992MiMObwekruBcbfn10Yai3LJJwuhtjabB4Fco3IJR9+hmDB/A5RiF\n8OIipZwopewhpewqpfyHuW2clHKc5ZiHpZR9pJSHSykfS/4laFLFjePnstI0EYGRcFZWg6QzJ07N\nIOToYeAs3RDpYObY3qOtUYKiXbMMGiLXn9yVVf8cSU6Ge4kMjaYhklAomPkGv5ZSFkkp86SUV0kp\nL5RS/lgP49PsA1bnF3HbhHkxPQt63/s5xeWJgs7ic+YR7WPKTDg1B+fkH4zUELJf66ZTuvHuqGMZ\ncEhurcaUKoQQB3RtIs3+SUKhYIaenlAPY9HUM5VV1Tz65TIKiu3tMO77eBHvz3HGBBioMNSa0rml\n0aBm/DXHRLblZtnNK07zkfIZOLeHgoFI5dJe7XK4ZVjDdDzeMKQrRx3UnDMbWDtLjcYNv56auUKI\nj4F3gIgBWUr5fkpGpakXvli0lSe/Wcn2ojIeuiAaEeSVNwCwo6isVvdUje+tJaZzMkL8cv/p9L3/\nSyCepuC96v781pNqNa5UclCLLD78w/H7ehgajS/8+hQygB3AKcDZ5t9ZqRqUpn4oLjeydsscbTGz\n073XChMXepevGNm3nee+7ma0ULpLTkMwIGx2d6fjOODhU9BoNHWP33acV6V6IJr6p6raCJEMmZPt\nbRPm0aFZJpVx8g4+mb8p8njgIbnMXrcr8vyZywZEWl466duxGSu2FblqIaGA01yE47mxv4EGGWk0\njQq/Gc0v45KlL6W8us5HpKk3Kk2hEDRnYeVHOOMw994BTppk+I8TV9pIjss5zjyDGPOR+VxrChpN\n6vFrPvoU+Mz8+xpoChTFPUPTIFm4sSCiIVg1hb2W3sK7i/05k91CLZ+4pF/EVKQ4+8gOkcStpi7n\nxJqLkvcpaDSausGv+eg963MhxHjg+5SMSJMyVuUXcdaT33PdSYdy58jeVFQZq/dgQJC/p8x2nKJt\n03S2Fro7l52hpQDnHNmBLQUl/HOikfH85CX9OPvIDmzaXUKL7DRO7B7bGS2RptBQM5Y1msZITYvG\ndAfa1OVANKmntMLIMXjuu9UUl1fy7s95gKEplFRE8w+2F0XzE9LNukQj+7aLKZHdNNN9TaEc1SMO\nb8fZR3YAoEPzTB48ry9pLhVNvaKNnM+rdfGghk1VhS7w1Ajw61PYg92nsAWjx4JmP8JaTuJPE+az\ndMseAF78fo1n/oE6JzstFDMpN/GoPaMEiTMpzYsY85GH5qDMXQcc1dVQWQppWft6JN5UV8HfW8Gx\nN8IZ/9jXo9HUAr/9FHKklE0tfz2cJiVNw6fKEnm6fmexbd87ptbgRIWQBgMi0nZTkZudxl/P7B1z\nTokZ6hovtBWioabOaCMnD553OF1aZdMmp2GWs0g5X98P/2wP5cUJD91nVJYa/2c8tW/Hoak1voSC\nEOJ8IUQzy/PmQojzUjcsTW04+eEpdB79GVe/Msu23brS3lvmr7OYKmsdCAj2mN3IVARRZjjIrwYc\nFHOOql7ZpVX8la2qdKo0hQv6O3swGQzt1YYptw9xNT0dEMw1q9RXNGShUGZ/XLyz5teqroIis5lW\n8U7DLKWpN/z+yu6TUhaoJ1LK3cB9qRmSpras22FMHt8stXc3tZp/Sn0WtlN5CDstfoaDWxiTfWZa\n0HWVf36/joy9+EiuPr5L3Gu/ec0xvHzl0YRMM9MjFx3JsgeH+xrXAYVM8FkV74SyfRwMaBUKH14P\n/+5S88l88n3wSDfjdf27i3E9Tb3hVyi4HaeLmTcglmwuRLo4+UorqlizfS9DHp7Ck99Eu5VtKSxN\n6vortu3hssEHA5bOV+EgIRepEAgILujfKTLZe9GqSTpDe0XjFQIBEfFH7LdUlsGudXVzrT1boGxP\nVCh4TbL/7gJPD6qbe9aUSsv3aeVk4/+WX4z/UsKOVf6vtdRMgNyz2fj/yzu1H19Nqa6CnWv23f33\nAX6FwmwhxFghRFfzbyzwcyoHpknMda/NpvPoz5izfhcjHp/Gf79fw55S+8Rx8/i5DH1kKmt3FPPF\noq2u1/nprmEJ75WTEeYf5/dl7ZgzI53WMsJBnVDm5KMb4fEjoMKH0C3cHN/M8mhPeO7kaERPdRyT\nX6F7AUNPtq/0N0a/VFkq6maZda1KTePCrBfhyf6wYRYU5MG6Ge7XKMiDXWth73bjeZ4yf+7D79jX\nf4MnjoLdGxIf20jwKxRuAsqBt4G3gFLgD6kalMYfapJXpp3PF26JFJVTTF7iLgistMlJT3iM1R+h\n8huy0hq4UNizBQqSnCyTYe+OWK1g6afG/7JC838RbF+BK2N7Gav8eOxcFdUU8mb6D/msroLN873H\n/dQA+DxBAKGUsGkuVJTA1sWwcU7s/StKYesiu/koaFa9Ld9raDrz3zKe71gJ/zkMXh4OSz4xrglQ\ntA02zDT2PX5k9L375BbjvzU6beuixMKsZJe3ZrJjVXL+jpVfm9fcabwXBwB+o4/2SilHSykHSimP\nllLeJaVMrt2WJmWETXOONelM4SeKU1h+dKrf8TOX9WfmXcN48/eDgaggACg3S1ZkpgVjehw0KB7t\nCf/pA5UJ2oXu2Qo7Vye+3ral9gllbG9DK3CjeKexMh7/G3hqYO3i95VQePdqWPC2fZ91grTe49t/\nwXMnweYFxvPNC6C00DhmzivGtq2L4t939kvw/BAYczA8eyy8MBQWmYWR85cZK/r3fw/PHmdMmoqg\nmbVeUQz/Oxc2zra/DoC3LzeuWbwTHukO/z3NexwiEH2tzx5nnOtky0JDyOxaB88ca2gmbjzZ3/jc\n/FJtat7z3zLei8Uf2ffvWhddeFSUxAqODbMMs9/6n/zf00nZnqgprh7wm6fwFfAr08GMECIXeEtK\neUYqB6fxR4nZ+GaXz/IU8Sg3J/++HZvRpmkG+WapbJtQMB+nhwI2gdKgKNwcffzVvTBijLFqz19q\nrGSbdoRs08zxaA/j//0Fsdex8sxgaNkdbjInuSpHpndBXjRC6PPRsHpKdF9VOYQsGllFSfx7lVrG\nYp1M85faj7OajT79I5z2AKQ3hWljjW1LPoGW3eC5E6H7GXDExYZJBKDFod73L9kNc1+Ljl2xY5Uh\nZJ8eBO36RierIktQQ0RTKIKNViuzi2Cs9FOKXdjHsfIr++7inTAuidLklUmYzZTJbuMc479T61OL\ngvsLYNJfYM6r8MfF0Kyjof1Yhd1130H7I/3fW/HWZbDmW7hnBwRT78r1e4dWSiAASCl3CSF0RnMD\nYdTrde/eUdnLyvFbaVE5lKbQoENEx/aKPt5qtv1+7/ewfJLxuGlHuG2x/+uVm4rxDg9TEBjmD4VV\nIIAhLKxC4SOL9bVwMzR1NOB57YLoY6tQEA5HvDJXAfz8smGiOfzC6Ar3u39Dp4HG47xZcOiQ6PHN\nOnm/ljcvdjeXBNNgm/m+WVevKmwWIGi+TmdehVsUVaLIKohqCl4+lRcT+8RiWPu9MUGn59i3715v\nrMzbmp+lcu4rYR9P41MCe/d6QygUOPwQVf7CwGNYb/pgKksh2CT+sXWA3191tRDiYPVECNEZV7Gv\n2d/5+MbjGXvxkZGsYhVpZC2n3d7siZyxv0QKbV5grOK3LIhuc3PMlsbRFPZY+kgU74TVU5MbQ0WJ\nYetWkTnrLd1snxkce7wyuYB9pa40s+oqWPxx7ESZN9vwQ1j5/E7jf8lOyGph2RFHy9sw0337+h/d\ntZw130Yfq9VsucPCXOVixvOzare+ZoXVjOdl+quOI3BeOdNYJDh5rK9holIoIeAnRySrlfF/r5lj\nsWKyfb8fAeiGWggko+HUAr+awt3A90KIbzG+SScC16ZsVBpX/jRhPu/NMTKP/UQMeXHf2X144BP3\nVfIRnZpzRKfmkeeqVIXVfPTi747mpzU7yM1Oizm/QVJWAE8dnfiH/d41cNkE930qPDKYZkwo25LQ\nMsCYSF8921jJ373FPpZ4wshJ0TZY8ilsWwJTHoT2R9n3B8Oxq1mrkFCRPWAInu0rIKe9IeR6n2U6\nYncYWo3bJLR5XuLJadsS43+FQyi4CZOyPfGvBe6agh+zU1UZBCz1uqwmRXCYtjxQ/pGI1hNnLZxp\n9gov2WVEK81/M3Y8YLznZYXQcYDxfNkk6DQoas50EjCFQiKTYx3h19H8OTAQWAaMB/4E1M8ID3DG\nfbuK2WuNVZESCADLt/r4MXlgbXT/zZ9OjntsKGis0qzmo9Y56Zx1RIca33+f4Gell7/Ee5+ymac1\niRUIfqJSFr1vCAQwfBvxfuDx4uLnvApvXwbzxxvPratngEAovonDOgmvnmo4wSf92bjmlIcMR+x/\nT4uagJxUliWekNVK2engdyvTMfP5+NcCQyhUVcKc/0W35S9NrK0p4VW2B6Y/BU8OiB3nsknu50pp\nvE4lUPdsim73Ol6ZB5VW6ERpSk8NhBdOMbSdihIjGOH5OL9DJRQSBQbUEX7LXPweo4/Cn4DbgdeA\n+1M3LA2AlJIxk5Zy0bjYuO7aBLNY+xIc2jq+jbJZprFSumVY95rfsDGgJrp0l/fr+SGJz//mwejj\nir2xq+0NMyHPXLn6yQRWQirgMOEFw/HNFPPeiN2mTGnfjoluC3logZVl/s0YTke8m2B2G08MwoiE\nmvrP6KbXzjMim+L9EJTwWvUNfHl3rOYCxoQ85Z+xeQgVJUYEVwwe98ubBbP/azwuL/IwlTm2vff7\nqJAu2ACzX3YPt1Xmo/G/dr93HePXp3ALcDSwTko5FOgH7I5/CgghhgshlgkhVgohRrvsHyKEKBBC\nzDP/7k1q9I2c4vIqz32bdidW1O4/u0/k8cUDo05Ft9yCBfefzvx7T4/ZHg4GWDvmTH53XOeE96s3\npISZL8TarJPF+QNUTkY3IpOwh8U1mRh257izWxur8xdPMZ5X+lDCpfndcE60gTBxTRxO5ydAKDN2\nm1MDUVSW+BcKzkmwprWbRCBqvnPitR2i40wkZL/9V2whv9ICux9JoYTQ4o+jeRYA4y+JPq4odtcE\nY6LVNti/b5/eClMfMr7bVmFnFfzLv4j/WuoAv0KhVEpZCiCESJdSLgV6xjtBCBEEngZGAH2AS4QQ\nfVwOnSalPMr8+1sSY2+0qHIVu4qjP6pXfrCbFEa/7x23/PKVR3PeUR1sE7mwOBWDAcGE647lpSsH\nRrY1zQjTLCu2K1q9UFoAM56O/hDW/xjrpLOycjJMvB2+uLt29927LXbbJJeELilh2iPG4wL3arI2\nbaFlAq3KaUZpfoj9uZ9MY7USdU4+hXmwbnri84MWTSDsUn22xCPBS1b78wNArPCoqaO0rABPQVe4\nyX07RN9HLwFnRUr7RPzdw/F9PRN+a+RZKIotvpryYkNbcLJ0ov25CMa+lz88Zny3rf4O6/dlzXfe\nY6oj/AqFPCFEc+BD4CshxEdAogIvg4CVUsrVUspyjEzoc2s+1AOD2ybMo8udxpdHtcVMCwW438Mx\n7ElVqNoAACAASURBVMbQXm147Df9bDkEo0dEQzQDQjCoSwtO6eXSi7l8r/GDqGn4XE349Db44i5Y\n94Px/KUz4I0LvY9XZgG3lRzAog/83dfN7lviogBbM4PdzAJWep0F2a3iH+OcMGImTx+agnK6umlL\n1igrL8IW7cDv+6XwMvlkORylzpWxn8nZC5Un4MQakutEva/Sx30riu2O7Nn/db/2tEcSv47yIvcC\nhQvesp8bCLoLD7ALJKvZ6/QHY4+tY/w6ms+XUu6WUt4P3AP8F0hUOrsjYNVV88xtTo4TQiwQQkwS\nQhzmsv+A4v05hn23sqqa1duNL0NOnL4EHZr56zGQm51GyDQbxS1NMfUhw/7tzJxNJUVmKQ5ZbZRg\nUMx8AcadCJvm2Y9Xq1yvCfqdK/3dt6I09sfrtNFDNALFD4Fg4uMriiFkfm7NDopd7SdTk6iiBLLj\npAwNudN9u5vJyC9uprJh98ExN9i3Oc1HvhLVPPAyFX7/n+jjQxwJbOp+zrBdNxOglx/ASXUlLJsY\n/5iKYijyWLDkWcrZC+Fd3XbG04bGt+qb6LbrZ9hLfqSIpLOPpJTfSik/Nlf/tWUOcLCU8gjgSQxN\nJAYhxLVCiNlCiNn5+fl1cNuGz4ZdJczfYKxaf1X6LocKdzX55mHduX5I18jzR3/lnTGphIGz05kN\n9eMrL4Kv7qtdXXw3Ni+AH8fZtymbbzDNUMsVE283Vr2T77cfryZdtx9xMmF7FcXw47Pu13Ybnx8C\nYdOuH+++5hiPuxm6nGzXFCbe4W26caOyJL4QGjIaznoMmh9s356MoEvE4RfCibfFXtOpKSx8t+b3\nKN6R+JjOJ9qfL3rfqLhqXZ236gFtD489t2yP/8/Zy4SoKN8L25e777NmpG/5xVvArPoaXh4Br51v\nPG9/FLR1s77XPalMSd0IWDuwdDK3RZBSFkopi8zHE4GwECJG95ZSPm/WXRrYunVs4/f9mryfjXA5\nYNmWqH1x6CNT+e/3a8imhNHht3grzV1t7N42h78Mj5qGLhzgnaWqNIVItevKcpg02h67rmLCJ/3Z\nsG+62dhrw3MnxhZi22AmcpXsipqQrDgnSSXU1k6LPdZPNctrzUSripJYzcBtFakmi0NOSHztQMhu\nr3ejwnTWpmUbGbWlhdF9M5937x8w8Or494zHwKvgfEfop5tGBHBHEiWuFWol7sy2TjbBLx5+BeWJ\ntxuOe4CfxsFbl9o1hUDYnlmuKCty/z65Ec+5DYZQWOvyPYbY92TOq/7umeg7VYekUijMAroLIboI\nIdKA3wAfWw8QQrQTpuFbCDHIHI+PJUEj4sVT4Mu7+XLRFtZsj1WRgxjhhRm4q95NErS8fOzXR/H8\nb4347KDTfLTkY/jpWUMjUAjHV0JFjGycA9+YvXcryw0/gM2mL2HyA0YBMD+4hRJ6ra6cmalWf4fz\nOrvXJ7532OwI98nN0YqcClehYGokmc1j9zkJhGLfQyfqfctobtjhy304bs8cC4dd4L7Pz6rfeYxz\nAlekN018LYCMZtHHaiWebMbuwcclPkbhN8Fv2D1wicP0ufzz6OOire4TbHmRe6E9N7yq3lqv5cwq\nP8jMWvfy35z05/jXrEvNLgEpEwpSykrgRuALYAkwQUq5SAgxSggxyjzsImChEGI+8ATwG+nWKaYR\nsjq/iOLy6OR27Ws/M33V9pjjAqgfmrvJJzvd+HF7WYTO69eR0w9rB7iYj1zttI4LqR/6yyONOjoV\npUYExOz/wie3AjCkZ2tuPbIavh9rr+kTD7c6Nm6OX7djrWYj56S+2xL/cMEL7tdTTta9+XabNLiv\noNVqzjoReiJJWAFm11rjf9P2jrITcYhn8kukKfg9BuJPPlY/hFV4KE0qLdvfPRRXxnES1wZn0biV\nlki2YBjOeTL2HOf3KB6Jele4BStc/L/YbREEDL0L0nK8D/H7+dUBKa1oJqWcKKXsIaXsKqX8h7lt\nnJRynPn4KSnlYVLKI6WUx0gpfcTS7f9UVUtOefRbRr1uj6hYujl2xRgyhUK1h1BQmsLU24fw6tXx\nu28FnV3S1ORqnQicq1wlFNRkWbwjOqmak/grVw3i1iPM4xJF3kTubU4kVi3A+mOyrmSd0SPVFtuv\n8nlMecjITrWaGcIeztRwnN7RgZBRIvu9a6IaiXK6Z/jQFPzYpZVQyOkQG7FTEwJhuPQd6Bqn9Ilz\nsvda1QsROwFdanY+y4xmwkdWvhD9PHI7R7cN9tFC0ymAW3ZLfE48jjUd3fFMLbIaWnSB66fbx+in\nnemv3/B37C6XjPR4AjM9x3jf3UKDFY1BU9B4M2+DMZl+t9zuNJ9plrPolBudzEIYE5MSCucc2YE/\nDI06lrNNoXBIy2xO7hHf36J8ClVKGVNCwWpjdQoFZRpIMzN5i3dY6sFYfhzKEZjms4qjurd1wrdq\nCtbtMZqCVSiY9/12jJGdao148XI6ewkLMCbE96+BXybAVkcuiB/zUVV54nRzFdOe0Sz+++X0Iyht\nodPR9u1bf4Eep8NJd3hfy+n8jmfqcR6rFhPW19/8oKifQn1HulhKNRzriETyQzgThtYw96T/FVFN\nLq5QMD+btocZ5dQVXqGhVnqfZZjw/BwL0MHS0yGY7l06RH0H4kWE5bT33lfHaKGwD7jwWY92hCZW\nP0G7JsZqKjPN2BYMCO44oxe92xvqe9jaB3nCFdH+ti6oHss5GeaPXoXsWX9ETjOFmjxUieHi7dFJ\n2WrnVSv2tDircCsRTcEy4Zd6JMk7JzCrUFCr7sg+8zUNuhZ6jnC/npujUf0gA6HoCvb5IfD+ddFj\n/GgK8VpmKpTZLhiKXx//rP/AZe/Cuc/Yt3tFN8WbDJ2r8niCS10nmAZXToxqbVbzWcAydvX5BENR\nzSe7BgEhoUw42cW2HvIRdm3VbuKZWpyLnuFjjD4TicJRfzM+OhaVcNbOo8GSor8lki4Y9n4d6vvo\n9r1U9EmUAVB31J+hSuOb9HD0Bzz2osPhLRDml1n5Bd6+7hi2FDi6bi3+yPjzaBZz4ynduGFoN+Ma\nG2bC1w8YOxIJhTXTon0EKkqJ+B2sJRPUij2RszEQMiZO9SP87PboPi+fgjORzmo+cjr9qioM2+zI\nh+3bj7sZpj9hjsExQYYyIKetIWBktd10teCt6GM/PoXKUu9Jqc+5RpkCJRQCocThq91dOpJ5CRKn\nedCKM+Eq3uekrj94FHQ+PppFK4Iw7F6jSU9lWXTs1mtdORFWfGms+oNp7pPtaX+HJmZuxekPGu9D\naQH083D0hjISZ0Nb3/N4wtG575jrDUGxIk75CBGEXiONx+GMaPBFTvv4iYJWzUAIo56UW7yIElTx\nzEd+fU91gNYU6pmisvgryZN6tLZ5D1RumjAnsp6t0uCpQTTN+44ebS2OKeePb8tCeLS3LdxUCBGN\nPPrcUorKNok5hUKVEaVjfW5dqb9troZUFm4kYagaxp0QG22h7vX2Zcb/eZbmLG5VNCE23t16f6eD\nsLLMvZjb6X93vzYYE+ZvzXFmtvAO1/RjPqoo8RYKp9xrTJZqUgmEamYrdl7/MDOWPV5/BKewL4wT\nax/RFNSkL6PXUIKxtMCy3yIU2vSC483vi9fqu+spcORvjMfH3WRMzENGxzb9ueYbOP+5+OY+hW+h\n4PLZ+DV5gt3E48z9iLmXYxxWIdGub/Sx+r7F04g69PM3vjpAC4UUMmXpNjqP/ow563fx9JSV5O8p\nY9pyr+Q744c3rFc0O/Xt7EdpMd0IA00Ph3jzmsH8X68q2L4s2jhFYbWf39/MaE+4Z1O08TjA8i8N\nQeHMmP12DLxxsfE4xtEs7T/66kr7JL3k4+h26ziqK4zknHf/z3499ePdNDfa21bhNYk4t1uFQoy/\nocz+47vkbbjKozyyQlZDbhfj8dR/wgaPfrrOLl1OAmE4+wlvR7YQxtjUqjcQ8hYg5z7tdoHofaz0\nOiv+uMBw4p7xUOLjIKopqUlNff4iEDUPFe9w1xT84CV0nXQcYAgPZVZp3dvInA67OG2t39t4gtZN\nM3OrfGvDYmqzruY79IMhdzkHYh/HDT/CeWaypnodg661R285328nzQ+ul0xmhTYfpZCXzCJ2Fzxj\nBFU9/MWyyL4rj+vMK9PXRp4LJPPuPYOmmSE+nGdMloOrfobl0SOO69oK1pkbnKtWL/Xa+gOZfL8h\nKLYvI2ZVqdRnt+gjq/25usp9ElDmiYimoGLXnWYLy7Ws4aPgLhSC6bERPSr5LZju7oS2vuaew2Ov\n6YYQxmuPN8GpCBJlAnNy9O+hVTfvla0QdrtxPE2hR5xxO8+J2KTjrDSFMJy/uZ2NVpHPnRT/WDU+\nsAuFpuZqPpwZXXUnW9PIK0fCC7U6z8w1Mqd/fDa2DLb1e2V9fzJz7WZJt/fbKuzD2bHXbmrRYKya\nQjBsaEXWkt7BNKP96bofjMdteht/EP2cRMCesKiEpNd3wVcodN2hNYVaUFZZxftz8nCmVsxcs5OH\nJi2hZZzOZOf1s5eBCiBplhVGPNGPy4peiT1BTdYqbDOjudFn9v5msGerd6SNdfWRYxbAK3KpDhq5\nj0NYOIWArHYPu1STZKIiZNZib9857P6VZcYP4GBL9cm0LMPc8kgP+PIe+/HhzNgJqXxvfIddPLwm\nq0DI2GcNuXRbcapVtKemELCbKgJBb59CvAQ4p3ahhEGbXtDa0pvabTLpNdLoTXz1l4b93/3mxr8Y\n81HAmPDOfhxG/Dv1moJCrc7VeUroHnQMdDvVHIPle2D9zju1O+tnqLDmB7iZGa+2aJpWge/mExIi\neoxXtrwI2n0EwkMDBDh0KFzyVuz2FKKFQi14fPIKbpswny8Xb7Vtv/i5GTz37Wo+nOdd1jfd0fT+\ni1vMEgq71nBRsUtLSDVJqIifjGZGbD4Yjek9NQXLD6SJKRTeuMhe+dPtPoqKYhfzkWNF/9Pz8IsZ\nyx4RCh4ThXW7tdgXGNcVQWhq6eqmTAVFWw1HsYr8aHu4McE6hULJLu/QPy9kgozczFwjkkRN9i27\nwY0z7XHuIgDH32I89rI1iwBkWMwG8TQFN6HgXMFHrmOZfPpfEX086nv3awMcPNhwIsebcJyTvggY\nYxhwpTGpufkU/JAo49uJNTIMLELhaItQsIzB+n4oM016U8M/4WaWs34GbnkjVl+HNVfDGqlmRY3P\nWQBQjT8QMBIr1b2EU1OwLMyOuDjW15JitFCoBVsKjQmwsKSCFVv38OmCTWzY6a+RSFoowH2WJjjd\nWmXFVpW0or4nSrVNy46WdEjPiaMpWL7wLQ6NPq72SLJy/mDLi2LNR06h8JWlN5ISCjUpk1xeZPzI\nznosus0Z4vqQ+QMZdI1xrNOMU7wzeedtM7NEl6d2Y0baBMOGj+KKj433soelKVG/30Yd3IOvc7E1\nAwj7yjWeT8FtslGTgxLuCuvnoz6/7NaJHaFgFIjzwjnpO78bEfNSkp91jTUFNama4wqmRSdUr++b\nSqaU1YZ/wi1YwJpYlug9a2KpSBsMu9v61eLB+ZuMaAoBQ2s/8hL7fvV+n3hbdFttG0nVAC0U6gAh\nBKf95ztufHMuv34uNgdh7K+OYER3u3MsPRTgquO7RDfIau84feMuxj8VoRPOjE7AlWXeQsH2A0zg\nrHKLXS8rcpiPqmKFl1UVVqsj2znW6yYYQ1W5fTXtZYoJZRo/sgVvGSY0Rf6S5EoWAPzuk/j7ywqj\nP9iew6NmOOsk6Vyp9rss9joiYHcwKkHjhttqeshd8KtXXfwkLkIh0ftsHasXvoWCR86Dq2Ck5j6F\nGA0pHA3D9dJWVNJXvISzVpamSImyqq0Z+14CXQnaDEcdKfVeq9evIoq2LjS3B6JjVlpnst/lOkAL\nhdrg8lvYVBBrxrlg9ys8u+FcugrDgRyikvSgSz6AxSEWxLHyUV8Y9eW22s1fPQteGek+RusKKpGa\nX1XuYqMvspumrOaj1r2j2xRumsIDzWH8pcZjFT7plQjmFDhe5QHCGd6JYolKGztp0SXxMa6Tp+Uz\ndE6MruafgEVTEMaEZrUj28xRLvcLpcFh5yXIbTDH5Ddaxe0+6lR1H2XmaO3QKtR74vW9UqYdJ8nW\n8XH6FJRmErQUH/QUCu383ePPa+B3n8ZO5E0c51t7V3h9h0/4I/zmzdhgAaumAFHNL1JlNhA9TvmG\napIEWEu0UKgFahqoqIp+Ibu2zqZH26gzsUV2GiwxVqJthKEJrMy4guafOkI1ZZVNKKTjMO9EhIKp\nTspqXKWSk0RCITM3qjJXlhrjCITh0CHmiyu2azDV1dEv8aFDzAxPyypMhbs6IziWqUxraaykPCMq\nHK/JSyiEMr39KH7i2pPFbSK2aQpOIe422YropKMmCGvc/MGWekJ+VvCKLMvqNSIMaqMpOBzNBw82\n8jhOcTj6E5luOg2A4f/yec84qKqyqhOa+v5ZzUdeJiznpO5FVgvocmLs9s7/3955h8tVVQv8t+7M\nLcm9IZ0QkhDSIISSQoihiHSBgEFFA1JEQZ7SBEQJgvIsnwUL2BB5iqKgWKgfscJTRH0gIL2HICQQ\nILRAgrk3d2a/P06ZPWdOm7kzd+bOrN/3zTdzyuzZ+8w5e+219tprBcKl25106IIycdo3e0mpYPY7\nfbfOQeFoH597NBxzLcxLGbm1iqhQqJCTrryb6+91Rv5PvVToFF9/azMzxheEwmcPm+Pb7zMUOuX2\nJ1YUr9Tt2wgvOSk3+2ino0QoeOYj97eiXEOD2A9L2IPTM6Ggqr71amHx1bKrYId3hZfn/W62w+mY\nbY+i/k3OqPnbEYttTD4wYg45bhNlPmrvih5xxgW8q5QwM0+U+Sh4zN7nmY/8QINWuXZ74iZj7bp8\n6Hew9bzS7w1EUwirz4z9QsJvJ4zSAWbsG/KbZXY7waiknhBqay90sMHw6h4DdecMDkrshZHlBjMM\nmo9KhKMUjovArAPiV6nXCF2nUCG3PFrwONrYV+hsX9nYx/COwmXtam/zXTgz5Is7+xXWhNJV7/WF\nQq900UHANOJ5EfVaQiEN3nlvvhD98Houjd92O5eOHqfTnrl/YXGaX15/8UMJgXJNfBwZTyh4dtSw\n4zZRq02zXdGdS5SwOPOh8jskv8wwoRBjPooagftCwTOB2BFqre/E1dMWelMDOQmqMacgAU0hCl8o\nxNyLYe0oV1MI4msK7cmaQtKCwzDOetgJ1XHzWc4CupIyt3Bs/Z7A6dkqOv1mEV6nb5mJig6XKdBr\nhAqFCrj6zuJFV5s2F9+Q7dZ8gTH4QqGNPGOxJo7utUI8uAIBoFc66ZRAx+pHJvXMR7nkaJzeeU/f\n7sw7jJkRcoKUunD6AdBCbKb5XCFEQlSnEZVkHZw6h3UUE+fB2vtK2xS08RYqGd3+qIdq1JTw/WkI\n7TzjzEchdQi6pEJAU7CFQkzHEBeGuWxNIW49RIJQSJrkjSq/3Ilmz7nCc7HNWwI1SVuxXUjTMnKy\nE6F26/nOfRnk5L84Grt3jU+42YkPteLs+OvuC4MEoVDnlDJqPgphcy7PwZf8ldsCISle3djH+v9s\n5vzri0e5nhnJ442Xn2fpbOfB7cvli8xHF7X/oHBixOimX9qjNQXffNRP5JzC2Y8VFiblc4X0gcFs\nUH7ZEX7vYZNcG9cVhFnUw/3jmNW4+Zzz4BwUSC/qd4hBoRAVbyhFMps4PrmqvPNDBaCtKQTNRxEj\n8ODI1TYPpNVi4sxjEhiNJpHWTBWG99/M2C+5PjblagpeUEBvUGPCzEcRmkIlQsFj6/nh9R87w1kA\n6DFuVvF2FMH/pkQouMfLXfdRZVRTCOHFNzbx2Atv8unrHuTvy50b/tWNfSz4wp9Sff/StcvYkBnJ\njXyfvv58kflogkREArXoasuXTjSXCIUYTWGLiYVFbkkaxXYHlXZg3oMWpjpvsBbqlWvv/Md34cWH\nYfjo0gnAqFFSlE14xFYDG1F1l2kPDgshUfacQohQACfZzpvPp+/I02gK1XRJjWL4GPj4A8WLDUsr\nFLKrTKFw2MWwz3mFNSu+ptCRbMJKE8SwKpRh8omaU2gQoaCaQgheX2OMYf1bTuf8wJq4NQQOX35P\nIfJhT249Y1nP2yf0FpmP/pwPUUcDjMxs4stLty/e2ZaBV54quFvmc8SOlL0b7vXVpZ5AHt1bOgHG\nSkYsXjiBkI7Qni8o9+b94/mw/lkn7ktQO/EFUKBNUQ917CKjCm2yYSEQPMJCZ1Qy0RxmkhnphjxJ\nO4KO66x981G6osI76JiwC0FGT01XH5skl9Tlzzovj2xnsenPn1OwXDftBD825aYIrZQ01zut99FA\nNOAqoJpCCL39zgP+/PpNzP38H1N/b8kuE/nNXc+Aa3W6p+tj8CP8Pz9LjgNnj4OV8eXIpvXM3SLQ\nka+5B75jZXIyufh7x7vBbrkQFnww/Jwx09z4O8H8AiExm/a/0Imjb8c9SpN6MoxNrxc/EOc86cxD\n3HlZ6blhmoI/B1Llh+cjf4YbT7PcZy1CJ5qtz2nXKcS5gJY7gg6j3In0opAQgWtdjRSQoUIhoY5J\nHkO2o8OEOXDOyug0sGkS9FSDVNc9wXyEagoNyX/6clx8yxPJJwLjWM8sKSyUGtGZ5doP71R6ojuy\naSNPW9o//IWAd05wtJ/PxXt92A+7l3g+iDf6DXZURclB3GMjtnJuYltTqFgovFHcyfZsGZ04JnRO\nIUEYVOq9MXxMdOeSONEc1BTC6iDx2kC5tvZtQ/zqfUlVgUvqOe59HxVjqRLsa9Q5shCifCAEPbd6\nxkf/53G5FapKiuvta3EJmoLOKQwSr65yArDt+J7YLEa/f3gtKx5Ym6rIv3WeQZdsZttNP+f9Cycj\nIsXJ5wNkyCPBlcpBusc7k7lRLpseub7wpfsXuBFQ04w6vVFU8Fz7Qcq0Q3+uEPzLDvKVJvVkGCYX\nMrkdcSuG2eAL9r2IHxiAS1/UhGXoSDBuojlKUwhpZ7mTwwDnvxhRVlvxexK2IAqaC6vRodr1+OST\nDOi/KSk7xT0+WO6daRYN+v9zhNBV76NBZu39sOIThdWRAW687zm2Xb6CXAoh/fmlOwLQJZutfa6G\nENNRZiSPJAUPGznZuTm8NJMjIibxouIk+aP/FPLee+hjR6/W0vy2bHGMpUqFApSaY6LqG6r+m8B7\nFYn6f8rWFCKEQlxHVk5n0N4Vrl0FO54kRJzQ0VMWlx6rivnIqke2M9w0WS52Jrgopiwu1njnfmDg\nvxtHOQK9LWqiuTGEQutoCv4il/Be/4srHgXgnF9HhJS2OOZtU3lzUz/cVtjX5eVVjjGptGHoaU94\nWMWNse+lbDzBXdpvzycArPpL6Xf9tIykM0V44bODHfJLD1vleJEpM07dqiYUUmoKYZ1Ikqaw+GPh\n+9Ow05Fw/y9K90e5mHqUaBhhXjcS0c5qjp7L9D4CZwQfmpK1CvWqdLFgLO7/HnePn2jlXI7IWV5d\n0piPhoZLautoCgmuay9vCMuoXcCOZ5RpE07dNyKaYlRIauDs/WcwZlhCZy3ipJT0lvZnOorD9Uax\nfDW87ydWOYHfCVu45ke/TOGWKBlngnCzFRo8KACnvI3UBEehUUIhLjdCVKew6CPp6xFklhXE7SQr\n30M15hSizEeFQlJVMZZKVsW2D4vQCqpYn1pQy7LLJZWGFnAoCN4LO73XeZ++TxUrVj41vaoicrCI\nPC4iK0Vkecx5u4lIv4gcWbPKxCxy2bQ5l6ixnXPQ9nz5PTuz3+zSDnrRttYcRS569DyhJ1t+noFs\nV7rE4sEgcEEPj9FTS7/jzQ/EdVSemact45z32tOFY7YAnLonHPH95Hr65SZoCt4DH5pFzf2zahHj\nyGbyrjDTXTgVqilUMtEcsX6hWpQbEC+2jCpQi47bzgTXKKSpS5JL6jaLHa1my9nUk5pdVRHJAN8D\nDgHmAEeLyJyI874KpPf9rKhC0eaj2Z/5fcm+RdOKJ6M72zMcvWgbrjhht5Jzf/Jha1+cSSXJYyiM\nbIfzkCa56ZUEK7M6se0PDe/UfKEQt6rVMx9lS8sICriy7KpJQsHLRmWZj879t/PudQqD4YO++ynO\ne9hCPrvj3eP05LKSNIVq2JKrET9nn/Oc99hFafXEEwpVcOGtGhWYjxpJqFnUslaLgJXGmFXGmD7g\nGmBpyHmnA9cCMYmDq4DX8Vkd2aNr32Bjb3gnPnp4cScbTJ9pYwfAizMfYXKO0Bi3HSy9NOKkwM3l\ndYodZQb2ss0dUfMcXujpWE3ByisbFKjBckdMTF/PJPPR4ZfAsDHFE83+5LQnFEI0qCXfSPf7aZmx\nnzN66wkJ+eE91D0TCqEY4hCJ6Mhs4XIGTC4deKSmkjmFIDsf6bS5GkK31cxHcQSTEtU58F0UtZxo\nngSstrbXAEVGZxGZBLwb2BeIfBJE5GTgZIBttkmRYjC0kOJoii9v6OWQb93ODhPDA651dxRfmjih\nUESc734+58b+yZSmmYwiLO5+GuzOJ98f3vF7+Wpjwyd75qO2UqGw+6nw0G8K2+1d8Ok1xZnQksr1\ntwP1m3+s84o7J3gN9zwTdjsp+berRbkPdeREs4cJTxxf1m80RqRNn5YzH8Vcdz93c0SWxAah3lf1\nEuBcY+Kn240xlxtjFhpjFo4fX2EmImtOYfWrb7Hv1/4CONpCGKO7i71eOrMJquq9V8Gzd8TPGXi5\nCNqyIfbwiJspbFJqu0Pi6wLFmkKUyWrustKyg9gTzcG/adKCwuR2GtPH4d+yyg128ClGpUHtYr8L\nircH4g1VCZV0SnHrFKpBo5kmalmPOuQaiCbFf9ju3uNRqXMbhFpe1ecAO1bxZHefzULgGhH5N3Ak\ncKmIHFGT2lhzCv9z+yreDJiN3rNgkv95yphhnL7fTE7ee7q/b1xPjH/1pvVw46nwkyXx5qO8az5q\nayudGPY738DNFRZmN42WYZ+f64cDLow51xIgO74b3vWd0nLaMuHCpZyHfv7x4fWDdGkH2zLOqRn5\nxgAAEbJJREFUKt73/8zZ3jqQyKfcFda7fQT2Pb+87wyUsI7soC/AljuWtqciqhgyoxrU0iW1UQQf\npBPs3sCnz/Lg2+4QOCIkvEsdqaX56C5glohMwxEGRwFFK0iMMf6adxH5CXCzMeaGmtQmwSX16EXb\ncN2/HJl1+6ecyKifPnQHLv+rE2J5THeMUHjt3857Wza+YzL5gvkoqClkh7khJCJuLrsTTZNuUgQ+\n9HsnjHW+H7YqBOtj/nEwbW+rbKsDsd1a7d+VTCHyavEPJdfFL8t6iIPmo7TmMW/dhsf+n4U31jq5\nGPY4LX1dAJZ8PXz/gZ+PXZnuUy1NYdKucMo/yi8rjGDM/npTCzOWacCJ5lRCwX3m7ZA1H7imNvUZ\nADUTCsaYfhE5DfgDkAGuMMY8LCIfdY8Prni00vYFLR1Ldp7I2LhOH8hmYh4yTxC0tSdoCv1uDuRs\nacfe3gW966NvLju8hD3BuuSbEZ011sRWQBAu/W7xdpp1CiYPy66GZ/4Od1iT5HEd43YHwxOlnl1F\n5dq841wYG7H+I4q3f6K889PgpSdNopIVqLXuyKQVNIVBKLtsyjAf2ZpCA1LTFc3GmN8Cvw3sCxUG\nxpgTalkX7yF5/a3/YAKLcs4+aDs6IiaSbz59L9a8lvAneh22tMGKc6IqYJmPMqVCYdrezjnvOBe+\nG+L+aIe1sN1Tdzsxul5tBZNZLLY2EHUsvxl2OMx5pRUKR18Dn4sIfR22GGzfT8fXs9GoZBRcjSBz\ncQR94etNq5mP4u6J+cfA6jth76g+ojFonTAXrjp9zi/v5ZZ88c3U05mlPUIT2GnSSHaalOBNk3OF\nQm/EiH3UNo6JI9frpO0bsXWp+ahzhJNMJAp7ErUzKkVlgIlzYeGJsPiU+POiFtNAYUQftSgvLAb8\nwV9xYzjFPCBpYvU3OtUyH1WTVtAUTIowF4NNmnZ2joD3/bj2dRkgrSMU3IckQ+mouaczSzYzANtn\nf0yieihEGF1zt7P95vOlIaGTVucedwNc7iYSKScC5mHfTHFetvi96JjbeUd59oR1/HGxhw67GLaY\nVJ1ga3WnEk2h1qNbLwJng3SYaj4acjTSVa0t7kPSZgmFvWaOY9KoYXR3ZpNdTuPIJQiFrlGOULJD\nNgTDFCeN/reeB2/7aGX1SyIufn6nN38RYTdP+2AecpHzvvDDsN07az9iHgwaqlPyaDDTSk3WSzRY\nG6E64UUahCZ4MtOx2QjtOJFKPX524iJy+SqEFogTCiO3gfdfCd/fk8gbZo8z0oVJ8OYhsh2OG1u1\nwhB46nhY6stDv+6Yv2YdVNi37KqCBpH2oX/bfxVvN8riqoHQiG3w5o8aRVOoJQ0lFBqoLgOkZYRC\nfx7aKZiPLj9uV0RkYGYjj7jFKPud73SqwQQ1AEf9wungZx4Q/t0ge3/SGWHPP746cek9ho+Bd34J\nZi8JP3bAfxfv2+HwwucmehiagrwX+baJ/5dGXNHcBBqCR8sIhZxrKfPMRwftuFXoeVFeSLF4MYQ8\nxs6CV9wkObZnT/C82YeW9zsd3aWreMvhuBuINAPtfmplZTZIYpD64HUEZbb9iMscc2At8NyPm8E8\nF0kDCoVG1BorpJnvnCLyRE80e9xzwQHx6xGiCHb2ndY6Ak+Nf+tl5wWFKJSDzYx9a1Bo8zwMg8a8\no2tXtucQ0CjeR7WkkUxkfniR+lajGrSQUHA1BYkWCmN7YhK62Gx8Gb5mJa0JCoV2K45P2IitnGQ0\njU6jBWBrdUwLmI88GqqNzXP/N9JVrSme+ShOU0iN51rqEZxTsGMThfnjN5Nq39LmowbEC8jYKGEu\nakkjCYUmGhQ1Ue8UT76aQiEYyuLVp4u3i3IAhPn+N9FlT3oYTro1XawmpTp4cwqtYD5qpDY2koAa\nIE3UO8WTdzuv8d1Zvn7QzqUnGBPfwRkDN58F9/wYjryi+Jg3qexRJBRCbtymWLjlkTDZOnnhoNWk\nYTnzQXjj+cH5rXwruaQ2z+i8kWgZoZAzzg10Sv7ndNx8Ocxb5xzwXDsv3d2JL/SJx8IL+Mb2sOFF\nt7DA6t5gQLqXHy98DtUUWuCBbQW8xYhbhQwybEZt47wGAy9D3NhZg/N79aQhn6OhL6haSCg4N1BH\n/wZnxxfdh+esR2DkJFj3aHwBnkAA6A0k5tkcmGhee3/hc5hWkGQ++vgD8K1d4s9pOIb+w1A2w0Y5\n4ckn7FjvmhSYvg8cey1M26fOFQkwYmL1y2wik00j0TpCIeoGeu5uWH1H+LHeDW6Y60BIijdfKN4O\nTjRPWVwos5I5hdFT4483JC060Tx193rXoJS0iyEHi4/+HUaErwsaECoUakLrCAVj3UDjdyhoBr86\nvvjE/l7o2+is5L1ouhPt84x/FZ9zeyA5y2YrtLa0wTG/gq+45oIwFTdNhNAzHxoaN/1A7LoffwAy\nVVyZrTQmW+1Um3IbaaLZownmOYZAr1MdcmLJv2VXRZ942V5wkZsQLtcLrz5VmLyLwk5iY/LF+Q7C\nAt2lsYWOmuKYtRodzxW1EpfU0VNhixqYFZTWYCgMmoYgLXNVc5LlwN6L+Nv+18O4mOxeLz/hvL/y\nVGGftxK5EoIhsqG5XFIVpV40klDwPA7twJFDlJbpnXJ5w5NmMhvHzHF2nPuMMyH803c528PHFXf+\n31lQ+Lzmrsp/uCtMU2iiy54m45Si1IJG8j7qGO6YfHsm1LsmA6aBRG1tybvmjYzXeQ0bBdPfAZ9c\nBR/7P5izNPrL13yg8h9uqjUJMeiKZmWwabSByKgp1Y1eXCdaRih4eRMybYEbqXssTJgz8M77gM8V\nb0/dM/rcjoQsa0OKBnswleZnl2X1rkFT00R2jHg8TaEtKBQ8BmrSGTbKWcT0woPO9nE3hCffOfeZ\n4onoIY9qCMogs/RSWPKNeteiaWkZTcFLsBYlE3xNYfS24ccXBFxXT7sHDv9WYbtnAnzkz3DBS852\ntqM4hLZHWHYzRVHSk8lC54h616JpaRmh4JuPouyQ3tqB6fvAGfeVHh/prjuYfZjT8Y+bWRzjqHML\nR7BkU4bfbhrUfKQozURNhYKIHCwij4vIShFZHnJ8qYg8ICL3icjdIrJXreqSzyeYj/w5BQlfkr/z\ne+HC1+Goq62O3ypr/PZVq+vQpIZmpC13hDEzks9TFGXA1GxOQUQywPeAA4E1wF0icpMx5hHrtFuB\nm4wxRkR2AX4FzK5FfXImYqLZw59TME5Yi+ww6LfCV7R3l3o7eFmu5h4N3eOqW+GhwmB4gJzyj9r/\nhqIoQG01hUXASmPMKmNMH3ANUOT3aYzZYIzvy9hNDYebnvmoLaoTC3ofBX2gwzyGvPAW7c3kTVQm\n6oqqKE1FLYXCJGC1tb3G3VeEiLxbRB4DVgAfDitIRE52zUt3r1u3rqLK5BM1BVcomIik4GEdf99G\n572pXEwVRWll6j7RbIy53hgzGzgC+ELEOZcbYxYaYxaOHz++ot/JueGLIieavUUnfhyjwHlhqyc9\nTaEjxMsoyOJTYfKi5POGGlvu4AjQvT9V75ooilIFarlO4TlgirU92d0XijHmryIyXUTGGWMGEGwo\nHN98FCUGs27KyJybajONrdzXFLqTzz34S8nnDEW6toALX6t3LRRFqRK11BTuAmaJyDQR6QCOAm6y\nTxCRmSJO7ysiC4BO4JVaVCbRfORpCv29buVSXJo+N2FPK88pKIrSVNRMUzDG9IvIacAfgAxwhTHm\nYRH5qHv8MuC9wPEishn4D7DMmniuKm0CXe1tZCNdUl03U28VchqhsPvp8OydMOeI6lRSURSlztQ0\nzIUx5rfAbwP7LrM+fxX4ai3r4HHwThN5bKeY2P3e2oNyNIVxM+HUiKxtiqIoQ5C6TzQ3DF4GME9T\nOOrnqgEoitJyqFDw8DQFb6J5ym7w/ivrVx9FUZQ60DJRUhOZtBB2/RDscXq9a6I0C+++PDxSrqI0\nMCoUPDJZOPySetdCaSbmatx/Zeih5iNFURTFRzWFJJZ8AybOr3ctFEVRBgUVCknsdlK9a6AoijJo\nqPlIURRF8VGhoCiKovioUFAURVF8VCgoiqIoPioUFEVRFB8VCoqiKIqPCgVFURTFR4WCoiiK4iM1\nymlTM0RkHfBMhV8fB1Q91WeDo21uDbTNrcFA2jzVGJOY5H7ICYWBICJ3G2MW1rseg4m2uTXQNrcG\ng9FmNR8piqIoPioUFEVRFJ9WEwqX17sCdUDb3Bpom1uDmre5peYUFEVRlHhaTVNQFEVRYlChoCiK\novi0jFAQkYNF5HERWSkiy+tdn2ohIlNE5M8i8oiIPCwiH3f3jxGRP4nIk+77aOs757nX4XEReWf9\nal85IpIRkXtF5GZ3u9nbO0pEfiMij4nIoyKyewu0+Sz3nn5IRH4hIl3N1mYRuUJEXhKRh6x9ZbdR\nRHYVkQfdY98WEam4UsaYpn8BGeApYDrQAdwPzKl3varUtonAAvfzCOAJYA5wEbDc3b8c+Kr7eY7b\n/k5gmntdMvVuRwXtPhv4OXCzu93s7b0SOMn93AGMauY2A5OAp4Fh7vavgBOarc3A3sAC4CFrX9lt\nBP4JLAYE+B1wSKV1ahVNYRGw0hizyhjTB1wDLK1znaqCMWatMeZf7uc3gUdxHqilOB0J7vsR7uel\nwDXGmF5jzNPASpzrM2QQkcnAEuCH1u5mbu9InM7jRwDGmD5jzOs0cZtdssAwEckCw4HnabI2G2P+\nCrwa2F1WG0VkIrCFMeYO40iIn1rfKZtWEQqTgNXW9hp3X1MhItsC84E7gQnGmLXuoReACe7nZrgW\nlwCfAvLWvmZu7zRgHfBj12T2QxHpponbbIx5Dvg68CywFlhvjPkjTdxmi3LbOMn9HNxfEa0iFJoe\nEekBrgXONMa8YR9zRw9N4XssIocBLxlj7ok6p5na65LFMTF83xgzH9iIY1bwabY2u3b0pTgCcWug\nW0SOtc9ptjaHUY82topQeA6YYm1Pdvc1BSLSjiMQrjbGXOfuftFVK3HfX3L3D/VrsSfwLhH5N44Z\ncD8RuYrmbS84I781xpg73e3f4AiJZm7zAcDTxph1xpjNwHXAHjR3mz3KbeNz7ufg/opoFaFwFzBL\nRKaJSAdwFHBTnetUFVwvgx8Bjxpjvmkdugn4oPv5g8CN1v6jRKRTRKYBs3AmqYYExpjzjDGTjTHb\n4vyP/2uMOZYmbS+AMeYFYLWIbO/u2h94hCZuM47ZaLGIDHfv8f1x5suauc0eZbXRNTW9ISKL3Wt1\nvPWd8qn37PtgvYBDcTxzngLOr3d9qtiuvXDUyweA+9zXocBY4FbgSeAWYIz1nfPd6/A4A/BSqPcL\n2IeC91FTtxeYB9zt/s83AKNboM2fAx4DHgJ+huN101RtBn6BM2eyGUcjPLGSNgIL3ev0FPBd3GgV\nlbw0zIWiKIri0yrmI0VRFCUFKhQURVEUHxUKiqIoio8KBUVRFMVHhYKiKIrio0JBUQYREdnHi+yq\nKI2ICgVFURTFR4WCooQgIseKyD9F5D4R+YGbv2GDiFzsxvi/VUTGu+fOE5E7ROQBEbnei38vIjNF\n5BYRuV9E/iUiM9zie6zcCFcPKPa9olQZFQqKEkBEdgCWAXsaY+YBOeAYoBu42xizI3AbcKH7lZ8C\n5xpjdgEetPZfDXzPGDMXJ26PF/lyPnAmTnz86TjxnBSlIcjWuwKK0oDsD+wK3OUO4ofhBCXLA790\nz7kKuM7NdTDKGHObu/9K4NciMgKYZIy5HsAYswnALe+fxpg17vZ9wLbA32rfLEVJRoWCopQiwJXG\nmPOKdop8JnBepTFieq3POfQ5VBoINR8pSim3AkeKyJbg58ydivO8HOme8wHgb8aY9cBrIvJ2d/9x\nwG3GyYK3RkSOcMvoFJHhg9oKRakAHaEoSgBjzCMicgHwRxFpw4lgeSpOcptF7rGXcOYdwAlvfJnb\n6a8CPuTuPw74gYh83i3jfYPYDEWpCI2SqigpEZENxpieetdDUWqJmo8URVEUH9UUFEVRFB/VFBRF\nURQfFQqKoiiKjwoFRVEUxUeFgqIoiuKjQkFRFEXx+X9iAEVHmBVs7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177126710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model.history['acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18d614978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model.history['val_acc'])\n",
    "plt.plot(business_model.history['val_acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['zillow', 'business', 'w2v'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.002)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 2s 862us/step - loss: 1.1259 - acc: 0.1254 - val_loss: 1.9368 - val_acc: 0.1601\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1175 - acc: 0.1909 - val_loss: 1.9460 - val_acc: 0.1601\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0942 - acc: 0.1997 - val_loss: 1.8857 - val_acc: 0.1601\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0813 - acc: 0.2149 - val_loss: 1.7835 - val_acc: 0.1601\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0766 - acc: 0.2233 - val_loss: 1.7950 - val_acc: 0.1601\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0503 - acc: 0.2261 - val_loss: 1.7223 - val_acc: 0.1601\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0509 - acc: 0.2279 - val_loss: 1.6586 - val_acc: 0.1601\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0278 - acc: 0.2420 - val_loss: 1.6721 - val_acc: 0.1722\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0292 - acc: 0.2437 - val_loss: 1.7730 - val_acc: 0.1631\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0327 - acc: 0.2251 - val_loss: 1.6964 - val_acc: 0.1662\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0125 - acc: 0.2497 - val_loss: 1.6117 - val_acc: 0.1601\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0133 - acc: 0.2557 - val_loss: 1.6578 - val_acc: 0.1601\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0113 - acc: 0.2416 - val_loss: 1.6748 - val_acc: 0.1541\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0103 - acc: 0.2490 - val_loss: 1.6503 - val_acc: 0.1752\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0070 - acc: 0.2515 - val_loss: 1.6100 - val_acc: 0.1601\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9940 - acc: 0.2430 - val_loss: 1.5729 - val_acc: 0.1601\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9904 - acc: 0.2529 - val_loss: 1.5854 - val_acc: 0.1601\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9849 - acc: 0.2603 - val_loss: 1.6387 - val_acc: 0.1601\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9971 - acc: 0.2600 - val_loss: 1.6193 - val_acc: 0.1601\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9931 - acc: 0.2462 - val_loss: 1.6175 - val_acc: 0.1601\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9922 - acc: 0.2381 - val_loss: 1.5752 - val_acc: 0.1601\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9872 - acc: 0.2473 - val_loss: 1.5924 - val_acc: 0.1601\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9783 - acc: 0.2543 - val_loss: 1.5362 - val_acc: 0.1601\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9744 - acc: 0.2459 - val_loss: 1.4994 - val_acc: 0.1601\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9659 - acc: 0.2642 - val_loss: 1.5888 - val_acc: 0.1601\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9917 - acc: 0.2371 - val_loss: 1.7075 - val_acc: 0.1601\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.0094 - acc: 0.2279 - val_loss: 1.5381 - val_acc: 0.1601\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9706 - acc: 0.2483 - val_loss: 1.4793 - val_acc: 0.1601\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9717 - acc: 0.2423 - val_loss: 1.4830 - val_acc: 0.1601\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9665 - acc: 0.2536 - val_loss: 1.5308 - val_acc: 0.1601\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9596 - acc: 0.2719 - val_loss: 1.6196 - val_acc: 0.1631\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9717 - acc: 0.2328 - val_loss: 1.5156 - val_acc: 0.1601\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9572 - acc: 0.2543 - val_loss: 1.5284 - val_acc: 0.1601\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.9541 - acc: 0.2529 - val_loss: 1.5788 - val_acc: 0.1631\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.9730 - acc: 0.2473 - val_loss: 1.6203 - val_acc: 0.1601\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9666 - acc: 0.2466 - val_loss: 1.5176 - val_acc: 0.1631\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.9458 - acc: 0.2529 - val_loss: 1.5949 - val_acc: 0.1662\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.9823 - acc: 0.2437 - val_loss: 1.5866 - val_acc: 0.1964\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9680 - acc: 0.2712 - val_loss: 1.4947 - val_acc: 0.1601\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.9537 - acc: 0.2557 - val_loss: 1.5889 - val_acc: 0.1631\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.9618 - acc: 0.2434 - val_loss: 1.5097 - val_acc: 0.1601\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9450 - acc: 0.2688 - val_loss: 1.5466 - val_acc: 0.1631\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9532 - acc: 0.2483 - val_loss: 1.5788 - val_acc: 0.1934\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9573 - acc: 0.2494 - val_loss: 1.5405 - val_acc: 0.1480\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9377 - acc: 0.2638 - val_loss: 1.4818 - val_acc: 0.1541\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9340 - acc: 0.2557 - val_loss: 1.5334 - val_acc: 0.1752\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9417 - acc: 0.2494 - val_loss: 1.5965 - val_acc: 0.1601\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9650 - acc: 0.2445 - val_loss: 1.6101 - val_acc: 0.1752\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9542 - acc: 0.2497 - val_loss: 1.5135 - val_acc: 0.1631\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9346 - acc: 0.2864 - val_loss: 1.5601 - val_acc: 0.1601\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9433 - acc: 0.2621 - val_loss: 1.4989 - val_acc: 0.1964\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9320 - acc: 0.2814 - val_loss: 1.5641 - val_acc: 0.2266\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9498 - acc: 0.2828 - val_loss: 1.5488 - val_acc: 0.1601\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9357 - acc: 0.2607 - val_loss: 1.5301 - val_acc: 0.2085\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9325 - acc: 0.2765 - val_loss: 1.5250 - val_acc: 0.1903\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9418 - acc: 0.2673 - val_loss: 1.6170 - val_acc: 0.2054\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9469 - acc: 0.2529 - val_loss: 1.4566 - val_acc: 0.3172\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9241 - acc: 0.2941 - val_loss: 1.5039 - val_acc: 0.2840\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9143 - acc: 0.2938 - val_loss: 1.4068 - val_acc: 0.3172\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9216 - acc: 0.2990 - val_loss: 1.4096 - val_acc: 0.3112\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9407 - acc: 0.2839 - val_loss: 1.4566 - val_acc: 0.1873\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9277 - acc: 0.2747 - val_loss: 1.4364 - val_acc: 0.2931\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9177 - acc: 0.3054 - val_loss: 1.4107 - val_acc: 0.3082\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9259 - acc: 0.2959 - val_loss: 1.4824 - val_acc: 0.3595\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9149 - acc: 0.2934 - val_loss: 1.5134 - val_acc: 0.2115\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9199 - acc: 0.2920 - val_loss: 1.6228 - val_acc: 0.2296\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.9420 - acc: 0.2656 - val_loss: 1.4324 - val_acc: 0.4230\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9070 - acc: 0.3283 - val_loss: 1.4614 - val_acc: 0.3656\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9049 - acc: 0.3026 - val_loss: 1.5182 - val_acc: 0.3807\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9286 - acc: 0.3001 - val_loss: 1.6591 - val_acc: 0.2719\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9576 - acc: 0.2420 - val_loss: 1.4993 - val_acc: 0.3595\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9080 - acc: 0.3050 - val_loss: 1.4705 - val_acc: 0.2628\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9004 - acc: 0.3072 - val_loss: 1.4494 - val_acc: 0.2538\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9012 - acc: 0.2917 - val_loss: 1.4236 - val_acc: 0.3867\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9097 - acc: 0.2980 - val_loss: 1.4305 - val_acc: 0.2659\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9081 - acc: 0.3019 - val_loss: 1.4222 - val_acc: 0.3021\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9107 - acc: 0.3029 - val_loss: 1.4857 - val_acc: 0.1662\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9029 - acc: 0.2857 - val_loss: 1.4294 - val_acc: 0.3897\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8916 - acc: 0.3258 - val_loss: 1.4652 - val_acc: 0.3202\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8818 - acc: 0.3153 - val_loss: 1.4347 - val_acc: 0.3323\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8971 - acc: 0.2917 - val_loss: 1.4163 - val_acc: 0.3776\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9000 - acc: 0.3093 - val_loss: 1.4626 - val_acc: 0.3867\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8855 - acc: 0.3068 - val_loss: 1.5647 - val_acc: 0.2719\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9163 - acc: 0.2779 - val_loss: 1.6081 - val_acc: 0.1964\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9157 - acc: 0.2776 - val_loss: 1.4908 - val_acc: 0.3776\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8947 - acc: 0.3339 - val_loss: 1.5936 - val_acc: 0.2205\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9015 - acc: 0.2895 - val_loss: 1.4980 - val_acc: 0.2598\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8744 - acc: 0.3103 - val_loss: 1.4861 - val_acc: 0.3897\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8843 - acc: 0.3205 - val_loss: 1.5245 - val_acc: 0.2810\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8919 - acc: 0.2614 - val_loss: 1.5069 - val_acc: 0.2628\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8799 - acc: 0.3001 - val_loss: 1.3791 - val_acc: 0.4773\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9088 - acc: 0.3244 - val_loss: 1.4917 - val_acc: 0.2508\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8839 - acc: 0.3005 - val_loss: 1.3963 - val_acc: 0.4018\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9084 - acc: 0.3308 - val_loss: 1.5307 - val_acc: 0.2024\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8827 - acc: 0.2839 - val_loss: 1.4624 - val_acc: 0.3807\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8717 - acc: 0.3251 - val_loss: 1.5234 - val_acc: 0.3021\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8748 - acc: 0.3068 - val_loss: 1.5128 - val_acc: 0.2961\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8703 - acc: 0.3036 - val_loss: 1.4620 - val_acc: 0.3656\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8597 - acc: 0.3336 - val_loss: 1.5480 - val_acc: 0.2628\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8779 - acc: 0.3082 - val_loss: 1.5356 - val_acc: 0.2628\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8692 - acc: 0.3128 - val_loss: 1.7841 - val_acc: 0.1450\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9405 - acc: 0.2504 - val_loss: 1.4515 - val_acc: 0.3021\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8730 - acc: 0.3251 - val_loss: 1.5079 - val_acc: 0.2508\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8623 - acc: 0.3008 - val_loss: 1.4834 - val_acc: 0.3082\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8595 - acc: 0.3325 - val_loss: 1.5086 - val_acc: 0.2659\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8541 - acc: 0.3244 - val_loss: 1.4890 - val_acc: 0.2689\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8572 - acc: 0.3283 - val_loss: 1.4000 - val_acc: 0.3807\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8667 - acc: 0.3392 - val_loss: 1.4288 - val_acc: 0.3595\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8425 - acc: 0.3494 - val_loss: 1.4433 - val_acc: 0.3384\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8683 - acc: 0.3329 - val_loss: 1.5501 - val_acc: 0.2840\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8879 - acc: 0.3110 - val_loss: 1.6715 - val_acc: 0.2145\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9245 - acc: 0.2723 - val_loss: 1.5019 - val_acc: 0.2840\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8837 - acc: 0.2716 - val_loss: 1.4648 - val_acc: 0.3716\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8465 - acc: 0.3477 - val_loss: 1.5578 - val_acc: 0.2236\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8616 - acc: 0.3181 - val_loss: 1.5975 - val_acc: 0.2115\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.8709 - acc: 0.2836 - val_loss: 1.4481 - val_acc: 0.3625\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.8269 - acc: 0.3462 - val_loss: 1.4617 - val_acc: 0.3384\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8455 - acc: 0.3283 - val_loss: 1.4400 - val_acc: 0.3384\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8636 - acc: 0.3149 - val_loss: 1.4710 - val_acc: 0.3293\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8552 - acc: 0.3420 - val_loss: 1.4579 - val_acc: 0.3414\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9083 - acc: 0.3308 - val_loss: 1.4489 - val_acc: 0.2840\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8591 - acc: 0.3061 - val_loss: 1.4250 - val_acc: 0.3776\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8610 - acc: 0.3212 - val_loss: 1.4169 - val_acc: 0.3897\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8369 - acc: 0.3515 - val_loss: 1.4557 - val_acc: 0.3414\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8428 - acc: 0.3470 - val_loss: 1.4852 - val_acc: 0.3112\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8376 - acc: 0.3410 - val_loss: 1.4302 - val_acc: 0.3927\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8282 - acc: 0.3660 - val_loss: 1.4205 - val_acc: 0.3807\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8610 - acc: 0.3279 - val_loss: 1.4865 - val_acc: 0.3535\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8393 - acc: 0.3501 - val_loss: 1.6339 - val_acc: 0.2326\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.8849 - acc: 0.2807 - val_loss: 1.6069 - val_acc: 0.2054\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8666 - acc: 0.2800 - val_loss: 1.3686 - val_acc: 0.4320\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8493 - acc: 0.3695 - val_loss: 1.4585 - val_acc: 0.3172\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8257 - acc: 0.3364 - val_loss: 1.4528 - val_acc: 0.3112\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.8212 - acc: 0.3529 - val_loss: 1.5605 - val_acc: 0.2508\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.8580 - acc: 0.3040 - val_loss: 1.6021 - val_acc: 0.2326\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8480 - acc: 0.3286 - val_loss: 1.5865 - val_acc: 0.2387\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8422 - acc: 0.3226 - val_loss: 1.5685 - val_acc: 0.2628\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8288 - acc: 0.3318 - val_loss: 1.5662 - val_acc: 0.2568\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8526 - acc: 0.2966 - val_loss: 1.4543 - val_acc: 0.3686\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8102 - acc: 0.3716 - val_loss: 1.4371 - val_acc: 0.3595\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8271 - acc: 0.3515 - val_loss: 1.4645 - val_acc: 0.3535\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8310 - acc: 0.3389 - val_loss: 1.4270 - val_acc: 0.3927\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8228 - acc: 0.3737 - val_loss: 1.4523 - val_acc: 0.3746\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8056 - acc: 0.3734 - val_loss: 1.4667 - val_acc: 0.3595\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8325 - acc: 0.3364 - val_loss: 1.5883 - val_acc: 0.2447\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8320 - acc: 0.3392 - val_loss: 1.6223 - val_acc: 0.2356\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8313 - acc: 0.3248 - val_loss: 1.4623 - val_acc: 0.3353\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8345 - acc: 0.3230 - val_loss: 1.4179 - val_acc: 0.3867\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8201 - acc: 0.3536 - val_loss: 1.4105 - val_acc: 0.4018\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8288 - acc: 0.3544 - val_loss: 1.4534 - val_acc: 0.3353\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8082 - acc: 0.3498 - val_loss: 1.5194 - val_acc: 0.2749\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8243 - acc: 0.3131 - val_loss: 1.4833 - val_acc: 0.3625\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7886 - acc: 0.3758 - val_loss: 1.4898 - val_acc: 0.3384\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8042 - acc: 0.3413 - val_loss: 1.5341 - val_acc: 0.3293\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8352 - acc: 0.3339 - val_loss: 1.6065 - val_acc: 0.2870\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8599 - acc: 0.3600 - val_loss: 1.6328 - val_acc: 0.2296\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8351 - acc: 0.3131 - val_loss: 1.5635 - val_acc: 0.2749\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8130 - acc: 0.3607 - val_loss: 1.5917 - val_acc: 0.2538\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8199 - acc: 0.3339 - val_loss: 1.4870 - val_acc: 0.3535\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7812 - acc: 0.3741 - val_loss: 1.6721 - val_acc: 0.2387\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8383 - acc: 0.2994 - val_loss: 1.5590 - val_acc: 0.3233\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8211 - acc: 0.3755 - val_loss: 1.5136 - val_acc: 0.3021\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8042 - acc: 0.3494 - val_loss: 1.5550 - val_acc: 0.2900\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8112 - acc: 0.3600 - val_loss: 1.7153 - val_acc: 0.2054\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8347 - acc: 0.3241 - val_loss: 1.4654 - val_acc: 0.3776\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8062 - acc: 0.3653 - val_loss: 1.4224 - val_acc: 0.3807\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8163 - acc: 0.3572 - val_loss: 1.4923 - val_acc: 0.3535\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8100 - acc: 0.3646 - val_loss: 1.5918 - val_acc: 0.2538\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8008 - acc: 0.3374 - val_loss: 1.6207 - val_acc: 0.2477\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7915 - acc: 0.3441 - val_loss: 1.5354 - val_acc: 0.3142\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7751 - acc: 0.3639 - val_loss: 1.5728 - val_acc: 0.2870\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8077 - acc: 0.3403 - val_loss: 1.5947 - val_acc: 0.2417\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8402 - acc: 0.2899 - val_loss: 1.5697 - val_acc: 0.2870\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7871 - acc: 0.3406 - val_loss: 1.6461 - val_acc: 0.2417\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8018 - acc: 0.3290 - val_loss: 1.5202 - val_acc: 0.3082\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7801 - acc: 0.3617 - val_loss: 1.5167 - val_acc: 0.3716\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7741 - acc: 0.3677 - val_loss: 1.4961 - val_acc: 0.3656\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.7772 - acc: 0.3540 - val_loss: 1.6051 - val_acc: 0.2508\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8090 - acc: 0.3262 - val_loss: 1.6834 - val_acc: 0.2296\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8153 - acc: 0.3293 - val_loss: 1.6268 - val_acc: 0.2447\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7980 - acc: 0.3272 - val_loss: 1.5503 - val_acc: 0.2900\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7672 - acc: 0.3709 - val_loss: 1.6704 - val_acc: 0.2266\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.8060 - acc: 0.3184 - val_loss: 1.5536 - val_acc: 0.2900\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.7750 - acc: 0.3617 - val_loss: 1.5546 - val_acc: 0.2870\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.7733 - acc: 0.3716 - val_loss: 1.6396 - val_acc: 0.2598\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8068 - acc: 0.3205 - val_loss: 1.5924 - val_acc: 0.2719\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7861 - acc: 0.3431 - val_loss: 1.5324 - val_acc: 0.2870\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8016 - acc: 0.3082 - val_loss: 1.4294 - val_acc: 0.3595\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7865 - acc: 0.3625 - val_loss: 1.4033 - val_acc: 0.4350\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7736 - acc: 0.3797 - val_loss: 1.3877 - val_acc: 0.4230\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.8136 - acc: 0.4026 - val_loss: 1.4604 - val_acc: 0.3474\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7790 - acc: 0.3406 - val_loss: 1.4883 - val_acc: 0.3263\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7866 - acc: 0.3424 - val_loss: 1.4888 - val_acc: 0.3686\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7394 - acc: 0.3892 - val_loss: 1.4872 - val_acc: 0.3414\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7367 - acc: 0.3903 - val_loss: 1.4948 - val_acc: 0.3353\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7464 - acc: 0.3906 - val_loss: 1.6308 - val_acc: 0.2900\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8042 - acc: 0.3283 - val_loss: 1.7996 - val_acc: 0.2145\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8490 - acc: 0.3005 - val_loss: 1.4674 - val_acc: 0.3656\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7598 - acc: 0.3977 - val_loss: 1.4537 - val_acc: 0.4441\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7502 - acc: 0.3889 - val_loss: 1.4931 - val_acc: 0.3172\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8128 - acc: 0.3040 - val_loss: 1.3898 - val_acc: 0.4713\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7630 - acc: 0.3938 - val_loss: 1.4046 - val_acc: 0.4290\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7413 - acc: 0.3846 - val_loss: 1.4158 - val_acc: 0.4381\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7630 - acc: 0.3917 - val_loss: 1.5332 - val_acc: 0.3444\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7969 - acc: 0.3466 - val_loss: 1.6199 - val_acc: 0.3021\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7845 - acc: 0.3515 - val_loss: 1.5892 - val_acc: 0.2689\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7672 - acc: 0.3392 - val_loss: 1.5185 - val_acc: 0.3142\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7299 - acc: 0.3924 - val_loss: 1.6346 - val_acc: 0.2870\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7665 - acc: 0.3677 - val_loss: 1.5355 - val_acc: 0.3142\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7459 - acc: 0.3765 - val_loss: 1.5172 - val_acc: 0.3263\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.7276 - acc: 0.3889 - val_loss: 1.5269 - val_acc: 0.3263\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7352 - acc: 0.3642 - val_loss: 1.7001 - val_acc: 0.2417\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8029 - acc: 0.3399 - val_loss: 1.5456 - val_acc: 0.3202\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7621 - acc: 0.3547 - val_loss: 1.7788 - val_acc: 0.2326\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8274 - acc: 0.3177 - val_loss: 1.5450 - val_acc: 0.2810\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7464 - acc: 0.3628 - val_loss: 1.4607 - val_acc: 0.3897\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7114 - acc: 0.3857 - val_loss: 1.4977 - val_acc: 0.3535\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7480 - acc: 0.3628 - val_loss: 1.5578 - val_acc: 0.3202\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7565 - acc: 0.3632 - val_loss: 1.4482 - val_acc: 0.4320\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7236 - acc: 0.4037 - val_loss: 1.3943 - val_acc: 0.4471\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7600 - acc: 0.3991 - val_loss: 1.4079 - val_acc: 0.4018\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7384 - acc: 0.3839 - val_loss: 1.4773 - val_acc: 0.3293\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7806 - acc: 0.3371 - val_loss: 1.4431 - val_acc: 0.4139\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7146 - acc: 0.3903 - val_loss: 1.4547 - val_acc: 0.4109\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7565 - acc: 0.3934 - val_loss: 1.4458 - val_acc: 0.3776\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7462 - acc: 0.3674 - val_loss: 1.5551 - val_acc: 0.3233\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7475 - acc: 0.3720 - val_loss: 1.6288 - val_acc: 0.2719\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7475 - acc: 0.3787 - val_loss: 1.4995 - val_acc: 0.3142\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7153 - acc: 0.3871 - val_loss: 1.4282 - val_acc: 0.3867\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7408 - acc: 0.3861 - val_loss: 1.4278 - val_acc: 0.3595\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7759 - acc: 0.3540 - val_loss: 1.3924 - val_acc: 0.4653\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7341 - acc: 0.3991 - val_loss: 1.4149 - val_acc: 0.3958\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7306 - acc: 0.3861 - val_loss: 1.5352 - val_acc: 0.3565\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7724 - acc: 0.3283 - val_loss: 1.5377 - val_acc: 0.3293\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7290 - acc: 0.3984 - val_loss: 1.6174 - val_acc: 0.2659\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7305 - acc: 0.3741 - val_loss: 1.5305 - val_acc: 0.3323\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7154 - acc: 0.3783 - val_loss: 1.5555 - val_acc: 0.3233\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7267 - acc: 0.3617 - val_loss: 1.4729 - val_acc: 0.3746\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6975 - acc: 0.4019 - val_loss: 1.5899 - val_acc: 0.3535\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7246 - acc: 0.3762 - val_loss: 1.5678 - val_acc: 0.2779\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7328 - acc: 0.3649 - val_loss: 1.4721 - val_acc: 0.4048\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7362 - acc: 0.3963 - val_loss: 1.4760 - val_acc: 0.3807\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7168 - acc: 0.3917 - val_loss: 1.3785 - val_acc: 0.4381\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7381 - acc: 0.3949 - val_loss: 1.3574 - val_acc: 0.4653\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7563 - acc: 0.4132 - val_loss: 1.4655 - val_acc: 0.3535\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6809 - acc: 0.4160 - val_loss: 1.5923 - val_acc: 0.3051\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7663 - acc: 0.3646 - val_loss: 1.7563 - val_acc: 0.2477\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7775 - acc: 0.3283 - val_loss: 1.4438 - val_acc: 0.3595\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7131 - acc: 0.3882 - val_loss: 1.4365 - val_acc: 0.3746\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7287 - acc: 0.3790 - val_loss: 1.4941 - val_acc: 0.3595\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6812 - acc: 0.4199 - val_loss: 1.5402 - val_acc: 0.2991\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7294 - acc: 0.3498 - val_loss: 1.4463 - val_acc: 0.3505\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6938 - acc: 0.4089 - val_loss: 1.4416 - val_acc: 0.3353\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7297 - acc: 0.3589 - val_loss: 1.4620 - val_acc: 0.3384\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7863 - acc: 0.3399 - val_loss: 1.4493 - val_acc: 0.3776\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6900 - acc: 0.4125 - val_loss: 1.4384 - val_acc: 0.4290\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6798 - acc: 0.4030 - val_loss: 1.3709 - val_acc: 0.4743\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7200 - acc: 0.4192 - val_loss: 1.3611 - val_acc: 0.4864\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7597 - acc: 0.4139 - val_loss: 1.4362 - val_acc: 0.3776\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6902 - acc: 0.3994 - val_loss: 1.5200 - val_acc: 0.3565\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7394 - acc: 0.3663 - val_loss: 1.4341 - val_acc: 0.3988\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6701 - acc: 0.4304 - val_loss: 1.4352 - val_acc: 0.3867\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6544 - acc: 0.4178 - val_loss: 1.4002 - val_acc: 0.3927\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6885 - acc: 0.4026 - val_loss: 1.3592 - val_acc: 0.4079\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7616 - acc: 0.3706 - val_loss: 1.4213 - val_acc: 0.3595\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6807 - acc: 0.4097 - val_loss: 1.4812 - val_acc: 0.4048\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6746 - acc: 0.4170 - val_loss: 1.5870 - val_acc: 0.3293\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6981 - acc: 0.3853 - val_loss: 1.6888 - val_acc: 0.3082\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7503 - acc: 0.3769 - val_loss: 1.5893 - val_acc: 0.2719\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7649 - acc: 0.3364 - val_loss: 1.5184 - val_acc: 0.3142\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7323 - acc: 0.3522 - val_loss: 1.3680 - val_acc: 0.4048\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.6707 - acc: 0.4220 - val_loss: 1.3379 - val_acc: 0.4592\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.7338 - acc: 0.4097 - val_loss: 1.3994 - val_acc: 0.3867\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6664 - acc: 0.4167 - val_loss: 1.4297 - val_acc: 0.3444\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6723 - acc: 0.3945 - val_loss: 1.5346 - val_acc: 0.3021\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7463 - acc: 0.3519 - val_loss: 1.5013 - val_acc: 0.3595\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6650 - acc: 0.4128 - val_loss: 1.6514 - val_acc: 0.3082\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7269 - acc: 0.3632 - val_loss: 1.4175 - val_acc: 0.3958\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6568 - acc: 0.4149 - val_loss: 1.4260 - val_acc: 0.4018\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6592 - acc: 0.4209 - val_loss: 1.4737 - val_acc: 0.3958\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7221 - acc: 0.3811 - val_loss: 1.3435 - val_acc: 0.4592\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6748 - acc: 0.4389 - val_loss: 1.3584 - val_acc: 0.4290\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7039 - acc: 0.4220 - val_loss: 1.3827 - val_acc: 0.3776\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6647 - acc: 0.4251 - val_loss: 1.4355 - val_acc: 0.3837\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6295 - acc: 0.4315 - val_loss: 1.3945 - val_acc: 0.3958\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6714 - acc: 0.4019 - val_loss: 1.3786 - val_acc: 0.3897\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7126 - acc: 0.3850 - val_loss: 1.3749 - val_acc: 0.4230\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6784 - acc: 0.4442 - val_loss: 1.3711 - val_acc: 0.4924\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7485 - acc: 0.3998 - val_loss: 1.4158 - val_acc: 0.4139\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7191 - acc: 0.3737 - val_loss: 1.5518 - val_acc: 0.3535\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7036 - acc: 0.4012 - val_loss: 1.3953 - val_acc: 0.4260\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6396 - acc: 0.4280 - val_loss: 1.4262 - val_acc: 0.4048\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6380 - acc: 0.4230 - val_loss: 1.4821 - val_acc: 0.4018\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6450 - acc: 0.4170 - val_loss: 1.6167 - val_acc: 0.3565\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7312 - acc: 0.3843 - val_loss: 1.6451 - val_acc: 0.3021\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7082 - acc: 0.3758 - val_loss: 1.5081 - val_acc: 0.3263\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6711 - acc: 0.4047 - val_loss: 1.5195 - val_acc: 0.3263\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6412 - acc: 0.4086 - val_loss: 1.4381 - val_acc: 0.3323\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6233 - acc: 0.4093 - val_loss: 1.3705 - val_acc: 0.3927\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.7093 - acc: 0.3843 - val_loss: 1.3830 - val_acc: 0.3897\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7069 - acc: 0.4026 - val_loss: 1.4870 - val_acc: 0.3263\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6542 - acc: 0.4065 - val_loss: 1.4787 - val_acc: 0.3535\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6253 - acc: 0.4329 - val_loss: 1.5033 - val_acc: 0.3384\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6267 - acc: 0.4301 - val_loss: 1.4753 - val_acc: 0.3444\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7127 - acc: 0.3660 - val_loss: 1.4493 - val_acc: 0.3414\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6972 - acc: 0.3779 - val_loss: 1.4615 - val_acc: 0.3746\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6258 - acc: 0.4354 - val_loss: 1.4394 - val_acc: 0.3474\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6233 - acc: 0.4315 - val_loss: 1.7257 - val_acc: 0.3293\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7910 - acc: 0.3927 - val_loss: 1.7322 - val_acc: 0.2296\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7671 - acc: 0.3036 - val_loss: 1.5168 - val_acc: 0.3414\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6593 - acc: 0.4093 - val_loss: 1.4842 - val_acc: 0.3353\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6713 - acc: 0.3674 - val_loss: 1.3737 - val_acc: 0.3776\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6744 - acc: 0.4097 - val_loss: 1.4332 - val_acc: 0.3746\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6090 - acc: 0.4526 - val_loss: 1.5183 - val_acc: 0.3384\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6472 - acc: 0.4163 - val_loss: 1.6220 - val_acc: 0.2931\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6457 - acc: 0.4079 - val_loss: 1.5720 - val_acc: 0.3384\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6822 - acc: 0.3734 - val_loss: 1.4654 - val_acc: 0.3988\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6280 - acc: 0.4604 - val_loss: 1.4689 - val_acc: 0.3837\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5924 - acc: 0.4551 - val_loss: 1.5055 - val_acc: 0.3656\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6230 - acc: 0.4487 - val_loss: 1.6300 - val_acc: 0.2931\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6594 - acc: 0.4068 - val_loss: 1.5584 - val_acc: 0.3293\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6360 - acc: 0.4033 - val_loss: 1.4925 - val_acc: 0.4018\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6576 - acc: 0.4008 - val_loss: 1.4375 - val_acc: 0.4139\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6263 - acc: 0.4237 - val_loss: 1.4429 - val_acc: 0.3988\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6271 - acc: 0.4442 - val_loss: 1.5193 - val_acc: 0.3927\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6313 - acc: 0.4185 - val_loss: 1.6297 - val_acc: 0.3535\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6876 - acc: 0.4195 - val_loss: 1.6436 - val_acc: 0.2749\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6742 - acc: 0.3769 - val_loss: 1.5414 - val_acc: 0.3233\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6393 - acc: 0.4111 - val_loss: 1.4823 - val_acc: 0.3535\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7405 - acc: 0.3607 - val_loss: 1.4075 - val_acc: 0.4139\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6089 - acc: 0.4223 - val_loss: 1.5027 - val_acc: 0.4048\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5949 - acc: 0.4554 - val_loss: 1.4544 - val_acc: 0.4109\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5812 - acc: 0.4618 - val_loss: 1.4692 - val_acc: 0.4169\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6096 - acc: 0.4533 - val_loss: 1.5866 - val_acc: 0.3807\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7443 - acc: 0.3607 - val_loss: 1.3649 - val_acc: 0.4743\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6111 - acc: 0.4745 - val_loss: 1.3224 - val_acc: 0.5347\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6551 - acc: 0.4632 - val_loss: 1.4076 - val_acc: 0.4260\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5805 - acc: 0.4466 - val_loss: 1.4058 - val_acc: 0.4230\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5863 - acc: 0.4586 - val_loss: 1.4231 - val_acc: 0.4290\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6099 - acc: 0.4470 - val_loss: 1.5742 - val_acc: 0.4079\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6677 - acc: 0.3956 - val_loss: 1.6297 - val_acc: 0.3625\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6628 - acc: 0.4237 - val_loss: 1.5314 - val_acc: 0.3807\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5902 - acc: 0.4262 - val_loss: 1.4851 - val_acc: 0.3837\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5999 - acc: 0.4199 - val_loss: 1.6047 - val_acc: 0.3595\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6510 - acc: 0.4089 - val_loss: 1.6784 - val_acc: 0.3535\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6291 - acc: 0.4385 - val_loss: 1.6229 - val_acc: 0.3082\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6470 - acc: 0.3984 - val_loss: 1.6314 - val_acc: 0.3082\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6182 - acc: 0.4132 - val_loss: 1.5921 - val_acc: 0.3082\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6060 - acc: 0.4350 - val_loss: 1.5497 - val_acc: 0.3535\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6053 - acc: 0.4153 - val_loss: 1.5393 - val_acc: 0.3353\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6964 - acc: 0.3558 - val_loss: 1.4027 - val_acc: 0.4230\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6036 - acc: 0.4723 - val_loss: 1.3973 - val_acc: 0.3988\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5724 - acc: 0.4452 - val_loss: 1.3823 - val_acc: 0.4713\n",
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6190 - acc: 0.4611 - val_loss: 1.3524 - val_acc: 0.4834\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.6167 - acc: 0.4502 - val_loss: 1.4111 - val_acc: 0.3988\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5881 - acc: 0.4516 - val_loss: 1.3766 - val_acc: 0.4350\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6266 - acc: 0.4533 - val_loss: 1.4390 - val_acc: 0.3656\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6980 - acc: 0.3952 - val_loss: 1.5912 - val_acc: 0.3051\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6506 - acc: 0.4290 - val_loss: 1.6559 - val_acc: 0.2931\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.6187 - acc: 0.4174 - val_loss: 1.4460 - val_acc: 0.4048\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5740 - acc: 0.4544 - val_loss: 1.4639 - val_acc: 0.3716\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.5710 - acc: 0.4593 - val_loss: 1.4112 - val_acc: 0.4773\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.5799 - acc: 0.4808 - val_loss: 1.4249 - val_acc: 0.4592\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5734 - acc: 0.4910 - val_loss: 1.3937 - val_acc: 0.4653\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6372 - acc: 0.4445 - val_loss: 1.4351 - val_acc: 0.4502\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5789 - acc: 0.4801 - val_loss: 1.6055 - val_acc: 0.4199\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6573 - acc: 0.4167 - val_loss: 1.4932 - val_acc: 0.4139\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.5998 - acc: 0.4607 - val_loss: 1.4790 - val_acc: 0.4018\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.5570 - acc: 0.4727 - val_loss: 1.5492 - val_acc: 0.3837\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6050 - acc: 0.4551 - val_loss: 1.7113 - val_acc: 0.3263\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.6514 - acc: 0.4033 - val_loss: 1.5111 - val_acc: 0.3958\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.5712 - acc: 0.4632 - val_loss: 1.4810 - val_acc: 0.4139\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5796 - acc: 0.4505 - val_loss: 1.5311 - val_acc: 0.4502\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.8160 - acc: 0.4132 - val_loss: 1.4009 - val_acc: 0.4230\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5951 - acc: 0.4523 - val_loss: 1.4293 - val_acc: 0.4109\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.5598 - acc: 0.4731 - val_loss: 1.4718 - val_acc: 0.3807\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5675 - acc: 0.4635 - val_loss: 1.4854 - val_acc: 0.3535\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6188 - acc: 0.4030 - val_loss: 1.3982 - val_acc: 0.4350\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6658 - acc: 0.4304 - val_loss: 1.3962 - val_acc: 0.4502\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6018 - acc: 0.4537 - val_loss: 1.4409 - val_acc: 0.4411\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5500 - acc: 0.4635 - val_loss: 1.4435 - val_acc: 0.4230\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5644 - acc: 0.4593 - val_loss: 1.4315 - val_acc: 0.4048\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6722 - acc: 0.4188 - val_loss: 1.4758 - val_acc: 0.3746\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5931 - acc: 0.4667 - val_loss: 1.6022 - val_acc: 0.3414\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6105 - acc: 0.4259 - val_loss: 1.5236 - val_acc: 0.3353\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5568 - acc: 0.4540 - val_loss: 1.5244 - val_acc: 0.3776\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5438 - acc: 0.4752 - val_loss: 1.5893 - val_acc: 0.3535\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5730 - acc: 0.4600 - val_loss: 1.7009 - val_acc: 0.3112\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6622 - acc: 0.4385 - val_loss: 1.6736 - val_acc: 0.2628\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6356 - acc: 0.3899 - val_loss: 1.4817 - val_acc: 0.3837\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5337 - acc: 0.4738 - val_loss: 1.5185 - val_acc: 0.4079\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5414 - acc: 0.4769 - val_loss: 1.5975 - val_acc: 0.4109\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6868 - acc: 0.4146 - val_loss: 1.5488 - val_acc: 0.4018\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5823 - acc: 0.4678 - val_loss: 1.4987 - val_acc: 0.4441\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6247 - acc: 0.4674 - val_loss: 1.3962 - val_acc: 0.4683\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6230 - acc: 0.4297 - val_loss: 1.4036 - val_acc: 0.4290\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5408 - acc: 0.4984 - val_loss: 1.4017 - val_acc: 0.4079\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5560 - acc: 0.4755 - val_loss: 1.4399 - val_acc: 0.3656\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6115 - acc: 0.4343 - val_loss: 1.4396 - val_acc: 0.3988\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5705 - acc: 0.4723 - val_loss: 1.5431 - val_acc: 0.3776\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5639 - acc: 0.4709 - val_loss: 1.4830 - val_acc: 0.3565\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.5822 - acc: 0.4417 - val_loss: 1.5977 - val_acc: 0.3565\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6519 - acc: 0.4297 - val_loss: 1.5241 - val_acc: 0.3263\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5620 - acc: 0.4480 - val_loss: 1.4916 - val_acc: 0.4109\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5233 - acc: 0.4826 - val_loss: 1.6945 - val_acc: 0.3263\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6455 - acc: 0.4414 - val_loss: 1.7317 - val_acc: 0.2659\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6116 - acc: 0.3882 - val_loss: 1.4924 - val_acc: 0.3958\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5512 - acc: 0.4769 - val_loss: 1.4357 - val_acc: 0.4471\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5241 - acc: 0.4949 - val_loss: 1.5105 - val_acc: 0.4441\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5584 - acc: 0.4805 - val_loss: 1.7851 - val_acc: 0.3958\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6689 - acc: 0.4015 - val_loss: 1.4861 - val_acc: 0.3807\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5706 - acc: 0.4505 - val_loss: 1.5738 - val_acc: 0.3625\n",
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5354 - acc: 0.4914 - val_loss: 1.5007 - val_acc: 0.3897\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5072 - acc: 0.4819 - val_loss: 1.4998 - val_acc: 0.4230\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5054 - acc: 0.4945 - val_loss: 1.5990 - val_acc: 0.4199\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.6192 - acc: 0.4251 - val_loss: 1.6053 - val_acc: 0.4230\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6066 - acc: 0.4667 - val_loss: 1.5608 - val_acc: 0.3927\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5268 - acc: 0.4836 - val_loss: 1.5896 - val_acc: 0.4018\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5253 - acc: 0.4699 - val_loss: 1.5686 - val_acc: 0.4260\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5442 - acc: 0.4797 - val_loss: 1.6399 - val_acc: 0.3776\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5861 - acc: 0.4259 - val_loss: 1.5377 - val_acc: 0.4381\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6031 - acc: 0.4512 - val_loss: 1.4788 - val_acc: 0.4713\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5671 - acc: 0.4917 - val_loss: 1.5030 - val_acc: 0.4441\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5299 - acc: 0.4931 - val_loss: 1.4975 - val_acc: 0.4441\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5289 - acc: 0.4829 - val_loss: 1.4968 - val_acc: 0.4592\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5671 - acc: 0.4540 - val_loss: 1.4875 - val_acc: 0.4169\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5652 - acc: 0.4600 - val_loss: 1.5704 - val_acc: 0.4381\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5430 - acc: 0.4808 - val_loss: 1.6434 - val_acc: 0.3958\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6522 - acc: 0.4551 - val_loss: 1.9833 - val_acc: 0.2266\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7027 - acc: 0.3480 - val_loss: 1.5409 - val_acc: 0.3927\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5364 - acc: 0.4921 - val_loss: 1.5317 - val_acc: 0.3837\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5185 - acc: 0.4822 - val_loss: 1.5781 - val_acc: 0.4169\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5170 - acc: 0.4868 - val_loss: 1.5317 - val_acc: 0.4109\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5008 - acc: 0.4790 - val_loss: 1.5610 - val_acc: 0.4350\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5581 - acc: 0.4843 - val_loss: 1.8304 - val_acc: 0.2779\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6168 - acc: 0.4142 - val_loss: 1.7632 - val_acc: 0.2870\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6349 - acc: 0.4008 - val_loss: 1.6554 - val_acc: 0.3414\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6419 - acc: 0.3808 - val_loss: 1.3996 - val_acc: 0.4411\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5574 - acc: 0.4878 - val_loss: 1.4404 - val_acc: 0.4441\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5129 - acc: 0.5167 - val_loss: 1.4770 - val_acc: 0.4320\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4990 - acc: 0.5174 - val_loss: 1.4874 - val_acc: 0.4441\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5218 - acc: 0.4935 - val_loss: 1.5622 - val_acc: 0.4350\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6509 - acc: 0.4375 - val_loss: 1.5384 - val_acc: 0.4199\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5720 - acc: 0.4745 - val_loss: 1.6521 - val_acc: 0.3202\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5269 - acc: 0.4815 - val_loss: 1.6114 - val_acc: 0.3656\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5217 - acc: 0.4628 - val_loss: 1.6602 - val_acc: 0.3565\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5250 - acc: 0.4635 - val_loss: 1.6504 - val_acc: 0.3746\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5429 - acc: 0.4593 - val_loss: 1.6703 - val_acc: 0.3958\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5618 - acc: 0.4723 - val_loss: 1.6118 - val_acc: 0.3897\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5350 - acc: 0.4727 - val_loss: 1.6073 - val_acc: 0.4260\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5532 - acc: 0.4773 - val_loss: 1.7017 - val_acc: 0.3353\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5977 - acc: 0.4410 - val_loss: 1.5328 - val_acc: 0.3837\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5211 - acc: 0.4773 - val_loss: 1.5406 - val_acc: 0.4079\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5204 - acc: 0.4797 - val_loss: 1.6749 - val_acc: 0.3353\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5725 - acc: 0.4466 - val_loss: 1.6367 - val_acc: 0.3323\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5425 - acc: 0.4459 - val_loss: 1.5963 - val_acc: 0.3565\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4953 - acc: 0.4861 - val_loss: 1.5383 - val_acc: 0.4169\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4920 - acc: 0.5086 - val_loss: 1.5274 - val_acc: 0.4350\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4817 - acc: 0.5111 - val_loss: 1.5689 - val_acc: 0.4320\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5436 - acc: 0.4903 - val_loss: 1.7714 - val_acc: 0.3867\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6242 - acc: 0.4132 - val_loss: 1.7559 - val_acc: 0.3776\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6228 - acc: 0.4780 - val_loss: 1.7978 - val_acc: 0.3202\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5563 - acc: 0.4723 - val_loss: 1.6150 - val_acc: 0.3474\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5189 - acc: 0.4593 - val_loss: 1.6689 - val_acc: 0.3656\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5339 - acc: 0.4681 - val_loss: 1.5445 - val_acc: 0.3988\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5044 - acc: 0.4893 - val_loss: 1.5752 - val_acc: 0.4381\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5148 - acc: 0.4893 - val_loss: 1.5574 - val_acc: 0.4864\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5471 - acc: 0.5139 - val_loss: 1.5050 - val_acc: 0.4562\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5296 - acc: 0.4875 - val_loss: 1.4646 - val_acc: 0.4622\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5702 - acc: 0.4910 - val_loss: 1.4430 - val_acc: 0.4743\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5014 - acc: 0.5192 - val_loss: 1.5851 - val_acc: 0.3837\n",
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5368 - acc: 0.4826 - val_loss: 1.4966 - val_acc: 0.4169\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5310 - acc: 0.4857 - val_loss: 1.4770 - val_acc: 0.4441\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5340 - acc: 0.5012 - val_loss: 1.4997 - val_acc: 0.4743\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4835 - acc: 0.5143 - val_loss: 1.5272 - val_acc: 0.4562\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5523 - acc: 0.4917 - val_loss: 1.5044 - val_acc: 0.4471\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5751 - acc: 0.4928 - val_loss: 1.7527 - val_acc: 0.3233\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5992 - acc: 0.4350 - val_loss: 1.6747 - val_acc: 0.3776\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6388 - acc: 0.4311 - val_loss: 1.5918 - val_acc: 0.3505\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5251 - acc: 0.4692 - val_loss: 1.5104 - val_acc: 0.4079\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4728 - acc: 0.5012 - val_loss: 1.5178 - val_acc: 0.4471\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4728 - acc: 0.5284 - val_loss: 1.5509 - val_acc: 0.4622\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4742 - acc: 0.5354 - val_loss: 1.5370 - val_acc: 0.4653\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4586 - acc: 0.5456 - val_loss: 1.5322 - val_acc: 0.4955\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4734 - acc: 0.5446 - val_loss: 1.5609 - val_acc: 0.4532\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5995 - acc: 0.4822 - val_loss: 1.5107 - val_acc: 0.4592\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6859 - acc: 0.4635 - val_loss: 1.6084 - val_acc: 0.3505\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5325 - acc: 0.4628 - val_loss: 1.5903 - val_acc: 0.3746\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5715 - acc: 0.4477 - val_loss: 1.4792 - val_acc: 0.4230\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5342 - acc: 0.4956 - val_loss: 1.5101 - val_acc: 0.3776\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5027 - acc: 0.5041 - val_loss: 1.5102 - val_acc: 0.4230\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5037 - acc: 0.5019 - val_loss: 1.5200 - val_acc: 0.4592\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4952 - acc: 0.5266 - val_loss: 1.5950 - val_acc: 0.3927\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4947 - acc: 0.4956 - val_loss: 1.6878 - val_acc: 0.3474\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5403 - acc: 0.4667 - val_loss: 1.6002 - val_acc: 0.3958\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5367 - acc: 0.4886 - val_loss: 1.6321 - val_acc: 0.3837\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.5228 - acc: 0.4815 - val_loss: 1.6478 - val_acc: 0.4109\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4834 - acc: 0.5100 - val_loss: 1.7794 - val_acc: 0.3142\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5392 - acc: 0.4516 - val_loss: 1.8334 - val_acc: 0.3233\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6206 - acc: 0.4403 - val_loss: 1.7086 - val_acc: 0.3353\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5400 - acc: 0.4523 - val_loss: 1.6393 - val_acc: 0.3625\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5364 - acc: 0.4706 - val_loss: 1.8094 - val_acc: 0.2900\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5167 - acc: 0.4590 - val_loss: 1.5978 - val_acc: 0.4350\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4607 - acc: 0.5298 - val_loss: 1.5692 - val_acc: 0.4562\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4795 - acc: 0.5287 - val_loss: 1.6190 - val_acc: 0.4018\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.5125 - val_loss: 1.6339 - val_acc: 0.3897\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.4952 - val_loss: 1.7600 - val_acc: 0.3474\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6189 - acc: 0.4371 - val_loss: 1.5455 - val_acc: 0.3927\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5018 - acc: 0.5058 - val_loss: 1.5327 - val_acc: 0.4139\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4661 - acc: 0.5301 - val_loss: 1.6367 - val_acc: 0.4109\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4732 - acc: 0.5439 - val_loss: 1.7700 - val_acc: 0.3384\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.4884 - acc: 0.4907 - val_loss: 1.7950 - val_acc: 0.3353\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5411 - acc: 0.4808 - val_loss: 1.7950 - val_acc: 0.3384\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5418 - acc: 0.4579 - val_loss: 1.6514 - val_acc: 0.3867\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5019 - acc: 0.4801 - val_loss: 1.6173 - val_acc: 0.4381\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4796 - acc: 0.4956 - val_loss: 1.6442 - val_acc: 0.4441\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6215 - acc: 0.4576 - val_loss: 1.6352 - val_acc: 0.3837\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.5317 - acc: 0.4843 - val_loss: 1.5290 - val_acc: 0.4502\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4683 - acc: 0.5231 - val_loss: 1.6002 - val_acc: 0.4350\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4488 - acc: 0.5417 - val_loss: 1.7090 - val_acc: 0.4079\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4533 - acc: 0.5111 - val_loss: 1.6076 - val_acc: 0.4532\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4746 - acc: 0.5305 - val_loss: 1.6881 - val_acc: 0.4924\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6054 - acc: 0.4664 - val_loss: 1.4837 - val_acc: 0.4622\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5206 - acc: 0.5403 - val_loss: 1.5814 - val_acc: 0.4592\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4596 - acc: 0.5206 - val_loss: 1.5633 - val_acc: 0.4471\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4620 - acc: 0.5350 - val_loss: 1.5875 - val_acc: 0.4653\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4960 - acc: 0.5153 - val_loss: 1.5224 - val_acc: 0.4773\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5175 - acc: 0.5308 - val_loss: 1.5695 - val_acc: 0.4199\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4665 - acc: 0.5277 - val_loss: 1.6920 - val_acc: 0.3927\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4903 - acc: 0.4893 - val_loss: 1.5967 - val_acc: 0.4592\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 98us/step - loss: 0.5032 - acc: 0.5368 - val_loss: 1.6421 - val_acc: 0.4199\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4860 - acc: 0.5122 - val_loss: 1.6600 - val_acc: 0.4320\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5195 - acc: 0.5019 - val_loss: 1.6670 - val_acc: 0.4169\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5146 - acc: 0.5058 - val_loss: 1.6523 - val_acc: 0.4018\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4668 - acc: 0.5129 - val_loss: 1.7986 - val_acc: 0.3444\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.5248 - val_loss: 1.8545 - val_acc: 0.3444\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5338 - acc: 0.4716 - val_loss: 1.8880 - val_acc: 0.2991\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5556 - acc: 0.4565 - val_loss: 1.6702 - val_acc: 0.3776\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4988 - acc: 0.4857 - val_loss: 1.6001 - val_acc: 0.3988\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5478 - acc: 0.4907 - val_loss: 1.7027 - val_acc: 0.4260\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5800 - acc: 0.4787 - val_loss: 1.5413 - val_acc: 0.4139\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4575 - acc: 0.5238 - val_loss: 1.5843 - val_acc: 0.4411\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.4218 - acc: 0.5400 - val_loss: 1.6225 - val_acc: 0.4381\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4483 - acc: 0.5403 - val_loss: 1.6313 - val_acc: 0.4683\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4635 - acc: 0.5132 - val_loss: 1.5746 - val_acc: 0.4683\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5996 - acc: 0.542 - 0s 70us/step - loss: 0.5805 - acc: 0.5051 - val_loss: 1.5444 - val_acc: 0.4290\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5294 - acc: 0.5076 - val_loss: 1.6194 - val_acc: 0.4562\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4844 - acc: 0.5185 - val_loss: 1.7016 - val_acc: 0.3897\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5729 - acc: 0.4621 - val_loss: 1.5614 - val_acc: 0.4441\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4970 - acc: 0.5122 - val_loss: 1.6055 - val_acc: 0.4350\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4378 - acc: 0.5498 - val_loss: 1.6656 - val_acc: 0.4260\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4566 - acc: 0.5157 - val_loss: 1.5970 - val_acc: 0.4350\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4740 - acc: 0.5259 - val_loss: 1.6344 - val_acc: 0.4471\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4740 - acc: 0.5308 - val_loss: 1.5098 - val_acc: 0.4834\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4837 - acc: 0.5231 - val_loss: 1.4967 - val_acc: 0.5015\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4816 - acc: 0.5192 - val_loss: 1.5536 - val_acc: 0.4834\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5001 - acc: 0.5326 - val_loss: 1.5896 - val_acc: 0.4592\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4990 - acc: 0.5266 - val_loss: 1.5448 - val_acc: 0.4441\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4579 - acc: 0.5467 - val_loss: 1.7097 - val_acc: 0.3837\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4942 - acc: 0.5041 - val_loss: 1.7214 - val_acc: 0.3776\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4931 - acc: 0.5467 - val_loss: 1.8373 - val_acc: 0.3535\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5317 - acc: 0.4716 - val_loss: 1.5963 - val_acc: 0.4411\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4852 - acc: 0.5160 - val_loss: 1.6169 - val_acc: 0.4169\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4628 - acc: 0.5284 - val_loss: 1.5983 - val_acc: 0.4502\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4296 - acc: 0.5636 - val_loss: 1.6880 - val_acc: 0.4109\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4911 - acc: 0.5322 - val_loss: 1.7009 - val_acc: 0.3927\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5708 - acc: 0.4945 - val_loss: 1.6778 - val_acc: 0.4230\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5383 - acc: 0.5100 - val_loss: 1.7115 - val_acc: 0.3686\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4570 - acc: 0.5111 - val_loss: 1.7122 - val_acc: 0.3927\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4477 - acc: 0.5414 - val_loss: 1.6948 - val_acc: 0.3958\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4173 - acc: 0.5315 - val_loss: 1.7210 - val_acc: 0.4169\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4285 - acc: 0.5530 - val_loss: 1.7611 - val_acc: 0.3776\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4439 - acc: 0.532 - 0s 70us/step - loss: 0.4850 - acc: 0.5315 - val_loss: 2.1321 - val_acc: 0.2931\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6392 - acc: 0.4075 - val_loss: 1.6361 - val_acc: 0.3686\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4713 - acc: 0.5329 - val_loss: 1.6865 - val_acc: 0.3746\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4571 - acc: 0.5291 - val_loss: 1.8135 - val_acc: 0.3353\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5197 - acc: 0.4878 - val_loss: 1.9720 - val_acc: 0.3233\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5056 - acc: 0.4783 - val_loss: 1.7398 - val_acc: 0.3927\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4526 - acc: 0.5199 - val_loss: 1.6564 - val_acc: 0.4199\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4313 - acc: 0.5505 - val_loss: 1.6848 - val_acc: 0.4199\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4358 - acc: 0.5562 - val_loss: 1.7819 - val_acc: 0.3565\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5195 - acc: 0.4681 - val_loss: 1.6251 - val_acc: 0.4079\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4603 - acc: 0.5375 - val_loss: 1.6873 - val_acc: 0.3988\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4427 - acc: 0.5350 - val_loss: 1.6200 - val_acc: 0.4592\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4371 - acc: 0.5530 - val_loss: 1.6895 - val_acc: 0.4743\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5472 - acc: 0.4967 - val_loss: 1.6665 - val_acc: 0.4562\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6006 - acc: 0.4988 - val_loss: 1.6095 - val_acc: 0.4653\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4599 - acc: 0.5358 - val_loss: 1.6206 - val_acc: 0.4381\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4170 - acc: 0.5562 - val_loss: 1.6587 - val_acc: 0.4622\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4059 - acc: 0.5770 - val_loss: 1.7023 - val_acc: 0.4562\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4163 - acc: 0.5643 - val_loss: 1.7251 - val_acc: 0.4502\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4179 - acc: 0.5653 - val_loss: 1.8518 - val_acc: 0.3958\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5036 - acc: 0.5005 - val_loss: 1.8656 - val_acc: 0.3807\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6991 - acc: 0.4907 - val_loss: 2.1215 - val_acc: 0.2779\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6408 - acc: 0.3910 - val_loss: 1.9021 - val_acc: 0.3082\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5103 - acc: 0.4533 - val_loss: 1.6093 - val_acc: 0.4320\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4239 - acc: 0.5498 - val_loss: 1.6620 - val_acc: 0.4169\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4093 - acc: 0.5583 - val_loss: 1.7231 - val_acc: 0.4048\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4320 - acc: 0.5576 - val_loss: 1.7727 - val_acc: 0.4169\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4695 - acc: 0.5122 - val_loss: 1.8135 - val_acc: 0.3625\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5102 - acc: 0.5153 - val_loss: 1.6434 - val_acc: 0.4381\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4451 - acc: 0.5597 - val_loss: 1.7445 - val_acc: 0.4320\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4291 - acc: 0.5583 - val_loss: 1.7093 - val_acc: 0.4048\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4572 - acc: 0.5439 - val_loss: 1.6387 - val_acc: 0.4864\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4322 - acc: 0.5787 - val_loss: 1.7208 - val_acc: 0.4532\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4220 - acc: 0.5756 - val_loss: 1.7090 - val_acc: 0.4653\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4292 - acc: 0.5671 - val_loss: 1.7831 - val_acc: 0.4683\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6591 - acc: 0.4759 - val_loss: 1.6115 - val_acc: 0.4350\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5255 - acc: 0.5181 - val_loss: 1.5729 - val_acc: 0.4683\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4458 - acc: 0.5632 - val_loss: 1.6149 - val_acc: 0.4683\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4104 - acc: 0.5720 - val_loss: 1.7020 - val_acc: 0.4471\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4565 - acc: 0.5336 - val_loss: 1.7267 - val_acc: 0.3958\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5146 - acc: 0.4790 - val_loss: 1.7956 - val_acc: 0.3686\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4645 - acc: 0.5150 - val_loss: 1.7016 - val_acc: 0.4169\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4056 - acc: 0.5703 - val_loss: 1.6970 - val_acc: 0.4562\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4344 - acc: 0.5710 - val_loss: 1.7546 - val_acc: 0.4230\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4728 - acc: 0.5090 - val_loss: 1.6713 - val_acc: 0.4834\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4309 - acc: 0.5766 - val_loss: 1.7457 - val_acc: 0.4381\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4348 - acc: 0.5431 - val_loss: 1.6986 - val_acc: 0.4411\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4331 - acc: 0.5379 - val_loss: 1.6644 - val_acc: 0.4562\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4018 - acc: 0.6023 - val_loss: 1.8559 - val_acc: 0.3867\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4152 - acc: 0.5586 - val_loss: 2.0015 - val_acc: 0.3444\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4445 - acc: 0.5439 - val_loss: 1.8650 - val_acc: 0.3746\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4473 - acc: 0.5379 - val_loss: 1.7874 - val_acc: 0.3656\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4671 - acc: 0.5245 - val_loss: 1.9940 - val_acc: 0.3293\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5134 - acc: 0.4667 - val_loss: 1.8622 - val_acc: 0.3384\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5904 - acc: 0.4509 - val_loss: 1.5833 - val_acc: 0.4985\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4869 - acc: 0.5502 - val_loss: 1.6244 - val_acc: 0.4592\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4347 - acc: 0.5608 - val_loss: 1.6692 - val_acc: 0.4804\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4244 - acc: 0.5548 - val_loss: 1.6774 - val_acc: 0.4864\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4385 - acc: 0.5558 - val_loss: 1.7171 - val_acc: 0.4320\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4389 - acc: 0.5453 - val_loss: 1.7710 - val_acc: 0.4350\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4339 - acc: 0.5766 - val_loss: 1.7510 - val_acc: 0.4441\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4151 - acc: 0.5667 - val_loss: 1.7707 - val_acc: 0.4622\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4533 - acc: 0.5601 - val_loss: 1.7351 - val_acc: 0.4350\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4187 - acc: 0.5685 - val_loss: 1.7960 - val_acc: 0.4320\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4443 - acc: 0.5696 - val_loss: 1.6463 - val_acc: 0.4743\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4526 - acc: 0.5752 - val_loss: 1.7032 - val_acc: 0.4683\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4823 - acc: 0.5435 - val_loss: 1.7120 - val_acc: 0.4743\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4653 - acc: 0.5548 - val_loss: 1.7582 - val_acc: 0.4713\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4910 - acc: 0.5551 - val_loss: 1.6665 - val_acc: 0.4622\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4594 - acc: 0.5315 - val_loss: 1.6824 - val_acc: 0.4411\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4661 - acc: 0.5491 - val_loss: 1.8284 - val_acc: 0.3746\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4478 - acc: 0.5241 - val_loss: 1.8775 - val_acc: 0.3837\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4106 - acc: 0.5322 - val_loss: 1.7708 - val_acc: 0.4381\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4230 - acc: 0.5424 - val_loss: 1.8151 - val_acc: 0.4199\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4560 - acc: 0.5400 - val_loss: 1.7229 - val_acc: 0.4562\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4425 - acc: 0.5410 - val_loss: 1.8267 - val_acc: 0.4320\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4616 - acc: 0.5449 - val_loss: 1.6721 - val_acc: 0.4743\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4145 - acc: 0.5724 - val_loss: 1.7559 - val_acc: 0.4230\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3894 - acc: 0.5699 - val_loss: 1.8364 - val_acc: 0.4290\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4335 - acc: 0.5601 - val_loss: 1.7663 - val_acc: 0.4834\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4942 - acc: 0.5347 - val_loss: 1.7296 - val_acc: 0.4441\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4673 - acc: 0.5516 - val_loss: 1.7794 - val_acc: 0.4169\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4290 - acc: 0.5347 - val_loss: 1.8343 - val_acc: 0.3988\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4074 - acc: 0.5505 - val_loss: 1.8935 - val_acc: 0.3535\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4153 - acc: 0.5372 - val_loss: 1.8675 - val_acc: 0.3867\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4240 - acc: 0.5601 - val_loss: 1.9327 - val_acc: 0.4048\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4864 - acc: 0.5181 - val_loss: 1.9573 - val_acc: 0.3142\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4944 - acc: 0.5023 - val_loss: 1.7477 - val_acc: 0.4139\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4233 - acc: 0.5481 - val_loss: 2.0040 - val_acc: 0.3776\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6235 - acc: 0.4628 - val_loss: 1.6281 - val_acc: 0.4230\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4363 - acc: 0.5692 - val_loss: 1.7092 - val_acc: 0.4653\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3837 - acc: 0.5851 - val_loss: 1.7830 - val_acc: 0.4562\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3865 - acc: 0.5791 - val_loss: 1.7763 - val_acc: 0.4260\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4028 - acc: 0.5907 - val_loss: 1.9711 - val_acc: 0.3897\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4626 - acc: 0.5766 - val_loss: 2.1236 - val_acc: 0.3474\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4730 - acc: 0.4924 - val_loss: 1.7734 - val_acc: 0.4109\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4643 - acc: 0.5280 - val_loss: 1.7459 - val_acc: 0.4713\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4843 - acc: 0.5343 - val_loss: 1.6245 - val_acc: 0.4985\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4286 - acc: 0.5763 - val_loss: 1.6821 - val_acc: 0.4441\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3624 - acc: 0.6157 - val_loss: 1.7856 - val_acc: 0.4653\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3748 - acc: 0.6051 - val_loss: 1.9287 - val_acc: 0.4169\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4027 - acc: 0.5777 - val_loss: 1.9570 - val_acc: 0.3958\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4103 - acc: 0.5653 - val_loss: 1.9018 - val_acc: 0.4290\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4244 - acc: 0.5741 - val_loss: 1.9312 - val_acc: 0.4079\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4109 - acc: 0.5463 - val_loss: 1.8156 - val_acc: 0.3867\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5253 - acc: 0.4646 - val_loss: 1.6238 - val_acc: 0.4864\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4607 - acc: 0.5601 - val_loss: 1.7312 - val_acc: 0.4804\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4118 - acc: 0.5805 - val_loss: 1.8496 - val_acc: 0.4713\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4486 - acc: 0.5819 - val_loss: 1.7006 - val_acc: 0.4713\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4164 - acc: 0.5903 - val_loss: 1.9198 - val_acc: 0.3988\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5435 - acc: 0.5051 - val_loss: 1.9443 - val_acc: 0.3807\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4773 - acc: 0.5639 - val_loss: 1.8068 - val_acc: 0.3927\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4288 - acc: 0.5513 - val_loss: 1.7616 - val_acc: 0.4502\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3860 - acc: 0.5854 - val_loss: 1.7435 - val_acc: 0.4743\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4012 - acc: 0.5935 - val_loss: 1.8268 - val_acc: 0.4350\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4084 - acc: 0.5502 - val_loss: 1.7852 - val_acc: 0.4290\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.4148 - acc: 0.5911 - val_loss: 1.8582 - val_acc: 0.4139\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4208 - acc: 0.5622 - val_loss: 1.9653 - val_acc: 0.3837\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4654 - acc: 0.5350 - val_loss: 1.9323 - val_acc: 0.4048\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3840 - acc: 0.5643 - val_loss: 1.8015 - val_acc: 0.4592\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3929 - acc: 0.608 - 0s 70us/step - loss: 0.3892 - acc: 0.6048 - val_loss: 1.7856 - val_acc: 0.4411\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4003 - acc: 0.6108 - val_loss: 1.7625 - val_acc: 0.4532\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3842 - acc: 0.6006 - val_loss: 1.8725 - val_acc: 0.3867\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4278 - acc: 0.5618 - val_loss: 2.0276 - val_acc: 0.3746\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4677 - acc: 0.5090 - val_loss: 1.8537 - val_acc: 0.4109\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5057 - acc: 0.5005 - val_loss: 1.7985 - val_acc: 0.4592\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5124 - acc: 0.5280 - val_loss: 1.7193 - val_acc: 0.4743\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4781 - acc: 0.5678 - val_loss: 1.7161 - val_acc: 0.4743\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4259 - acc: 0.5685 - val_loss: 1.7659 - val_acc: 0.4773\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4004 - acc: 0.5854 - val_loss: 1.7002 - val_acc: 0.4743\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3826 - acc: 0.6066 - val_loss: 1.7989 - val_acc: 0.4502\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3807 - acc: 0.6076 - val_loss: 1.8171 - val_acc: 0.4622\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4034 - acc: 0.5844 - val_loss: 1.7752 - val_acc: 0.4924\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4374 - acc: 0.5815 - val_loss: 1.7751 - val_acc: 0.4713\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4426 - acc: 0.5893 - val_loss: 1.8518 - val_acc: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4129 - acc: 0.5629 - val_loss: 1.8655 - val_acc: 0.4079\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4165 - acc: 0.5664 - val_loss: 2.2811 - val_acc: 0.3505\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5894 - acc: 0.4579 - val_loss: 1.7339 - val_acc: 0.4653\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4168 - acc: 0.5918 - val_loss: 1.8183 - val_acc: 0.4350\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3647 - acc: 0.6164 - val_loss: 1.8989 - val_acc: 0.4230\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3855 - acc: 0.5942 - val_loss: 1.8721 - val_acc: 0.4048\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4007 - acc: 0.5579 - val_loss: 1.8019 - val_acc: 0.4471\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3831 - acc: 0.5840 - val_loss: 1.7661 - val_acc: 0.4804\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4528 - acc: 0.5594 - val_loss: 1.7387 - val_acc: 0.4834\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4163 - acc: 0.5794 - val_loss: 1.8067 - val_acc: 0.4381\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4055 - acc: 0.5608 - val_loss: 1.8203 - val_acc: 0.4411\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4043 - acc: 0.5918 - val_loss: 1.9037 - val_acc: 0.3927\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4235 - acc: 0.5488 - val_loss: 2.0186 - val_acc: 0.3776\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4628 - acc: 0.5322 - val_loss: 2.0802 - val_acc: 0.3837\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4513 - acc: 0.5481 - val_loss: 1.9737 - val_acc: 0.4199\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4295 - acc: 0.5579 - val_loss: 1.9724 - val_acc: 0.3746\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3807 - acc: 0.5675 - val_loss: 1.8547 - val_acc: 0.4411\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3766 - acc: 0.6069 - val_loss: 1.9898 - val_acc: 0.4139\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4008 - acc: 0.5893 - val_loss: 1.9043 - val_acc: 0.4502\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3953 - acc: 0.6069 - val_loss: 1.9245 - val_acc: 0.4230\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3999 - acc: 0.5995 - val_loss: 1.9816 - val_acc: 0.4290\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5317 - acc: 0.5241 - val_loss: 1.9607 - val_acc: 0.3958\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4963 - acc: 0.5555 - val_loss: 1.9506 - val_acc: 0.3656\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4159 - acc: 0.5502 - val_loss: 1.9156 - val_acc: 0.3716\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3898 - acc: 0.5639 - val_loss: 1.8505 - val_acc: 0.4350\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3789 - acc: 0.6178 - val_loss: 1.8509 - val_acc: 0.4350\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3606 - acc: 0.6080 - val_loss: 1.8667 - val_acc: 0.4592\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3692 - acc: 0.6168 - val_loss: 1.8401 - val_acc: 0.4592\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3938 - acc: 0.6027 - val_loss: 1.8029 - val_acc: 0.4955\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4021 - acc: 0.6228 - val_loss: 1.9728 - val_acc: 0.4169\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5560 - acc: 0.4928 - val_loss: 1.7211 - val_acc: 0.4773\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4136 - acc: 0.5886 - val_loss: 1.7860 - val_acc: 0.4532\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3685 - acc: 0.6062 - val_loss: 1.8737 - val_acc: 0.4502\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3713 - acc: 0.6016 - val_loss: 1.9590 - val_acc: 0.4290\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3851 - acc: 0.6002 - val_loss: 2.2051 - val_acc: 0.3716\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4674 - acc: 0.5305 - val_loss: 2.2010 - val_acc: 0.3323\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4718 - acc: 0.5509 - val_loss: 1.9714 - val_acc: 0.3958\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3860 - acc: 0.5488 - val_loss: 1.9218 - val_acc: 0.4441\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3727 - acc: 0.5854 - val_loss: 1.8978 - val_acc: 0.4683\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3915 - acc: 0.6030 - val_loss: 1.9261 - val_acc: 0.4230\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4390 - acc: 0.5689 - val_loss: 1.9436 - val_acc: 0.4260\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4234 - acc: 0.5692 - val_loss: 1.9149 - val_acc: 0.4169\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4385 - acc: 0.5569 - val_loss: 1.9107 - val_acc: 0.3897\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4031 - acc: 0.5548 - val_loss: 1.9115 - val_acc: 0.4562\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3593 - acc: 0.6002 - val_loss: 1.8899 - val_acc: 0.4622\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3710 - acc: 0.6087 - val_loss: 1.9175 - val_acc: 0.4743\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3676 - acc: 0.5918 - val_loss: 2.0397 - val_acc: 0.4471\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4648 - acc: 0.5446 - val_loss: 1.7570 - val_acc: 0.5015\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5607 - acc: 0.5618 - val_loss: 1.6974 - val_acc: 0.4773\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4072 - acc: 0.5713 - val_loss: 1.7681 - val_acc: 0.4864\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3777 - acc: 0.5865 - val_loss: 1.8264 - val_acc: 0.4713\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3582 - acc: 0.6196 - val_loss: 1.8321 - val_acc: 0.4804\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3446 - acc: 0.6340 - val_loss: 1.9324 - val_acc: 0.4502\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4045 - acc: 0.6034 - val_loss: 1.9796 - val_acc: 0.4411\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6361 - acc: 0.4805 - val_loss: 2.1034 - val_acc: 0.3565\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.5371 - acc: 0.4900 - val_loss: 1.7561 - val_acc: 0.4320\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3833 - acc: 0.5875 - val_loss: 1.8725 - val_acc: 0.4350\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3784 - acc: 0.5826 - val_loss: 1.8455 - val_acc: 0.4924\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4043 - acc: 0.5928 - val_loss: 1.8154 - val_acc: 0.4804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3497 - acc: 0.6386 - val_loss: 1.8948 - val_acc: 0.4653\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3265 - acc: 0.6386 - val_loss: 1.8998 - val_acc: 0.4713\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3666 - acc: 0.6221 - val_loss: 1.8874 - val_acc: 0.4955\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3985 - acc: 0.6027 - val_loss: 1.9396 - val_acc: 0.4562\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4203 - acc: 0.5837 - val_loss: 1.8781 - val_acc: 0.4622\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3806 - acc: 0.6136 - val_loss: 1.8568 - val_acc: 0.4743\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3852 - acc: 0.6182 - val_loss: 1.9979 - val_acc: 0.4653\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4151 - acc: 0.5903 - val_loss: 1.8431 - val_acc: 0.4804\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3951 - acc: 0.5988 - val_loss: 1.8938 - val_acc: 0.4290\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4547 - acc: 0.5583 - val_loss: 2.2317 - val_acc: 0.3202\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4634 - acc: 0.5164 - val_loss: 1.9079 - val_acc: 0.4109\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4098 - acc: 0.5675 - val_loss: 1.7769 - val_acc: 0.4562\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3715 - acc: 0.6058 - val_loss: 1.8720 - val_acc: 0.4834\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3571 - acc: 0.6175 - val_loss: 1.9030 - val_acc: 0.4743\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3561 - acc: 0.6231 - val_loss: 1.9633 - val_acc: 0.4743\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4383 - acc: 0.5551 - val_loss: 1.9166 - val_acc: 0.3927\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5230 - acc: 0.5051 - val_loss: 1.7767 - val_acc: 0.4381\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3815 - acc: 0.6020 - val_loss: 1.8942 - val_acc: 0.4320\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3532 - acc: 0.6101 - val_loss: 1.9300 - val_acc: 0.4381\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3903 - acc: 0.6097 - val_loss: 2.2191 - val_acc: 0.3776\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4410 - acc: 0.5569 - val_loss: 2.0447 - val_acc: 0.3414\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.4271 - acc: 0.5277 - val_loss: 1.9152 - val_acc: 0.4260\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3437 - acc: 0.6108 - val_loss: 1.9767 - val_acc: 0.4502\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3589 - acc: 0.6051 - val_loss: 2.0039 - val_acc: 0.4592\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3855 - acc: 0.6087 - val_loss: 2.0452 - val_acc: 0.4350\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4785 - acc: 0.5534 - val_loss: 1.8860 - val_acc: 0.4411\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3879 - acc: 0.6083 - val_loss: 1.8629 - val_acc: 0.4622\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3415 - acc: 0.6587 - val_loss: 1.9608 - val_acc: 0.4773\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3538 - acc: 0.5985 - val_loss: 1.9201 - val_acc: 0.4683\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3520 - acc: 0.6530 - val_loss: 1.9723 - val_acc: 0.5076\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4382 - acc: 0.5907 - val_loss: 1.9564 - val_acc: 0.4683\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4704 - acc: 0.5752 - val_loss: 2.0713 - val_acc: 0.4320\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.5794 - val_loss: 2.3639 - val_acc: 0.3384\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4332 - acc: 0.5696 - val_loss: 2.0018 - val_acc: 0.4109\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3575 - acc: 0.6080 - val_loss: 2.1080 - val_acc: 0.4139\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3546 - acc: 0.6073 - val_loss: 1.9802 - val_acc: 0.4441\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3323 - acc: 0.6379 - val_loss: 2.1231 - val_acc: 0.4290\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3454 - acc: 0.6414 - val_loss: 2.0718 - val_acc: 0.4230\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3975 - acc: 0.6129 - val_loss: 2.0198 - val_acc: 0.4260\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3743 - acc: 0.5886 - val_loss: 2.0489 - val_acc: 0.4350\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3855 - acc: 0.5822 - val_loss: 2.1277 - val_acc: 0.4471\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4866 - acc: 0.5611 - val_loss: 2.0011 - val_acc: 0.4230\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.4430 - acc: 0.5625 - val_loss: 1.9981 - val_acc: 0.4048\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4282 - acc: 0.5791 - val_loss: 1.9317 - val_acc: 0.4381\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3691 - acc: 0.6312 - val_loss: 1.9727 - val_acc: 0.4290\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3648 - acc: 0.6083 - val_loss: 2.0213 - val_acc: 0.4350\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3588 - acc: 0.6203 - val_loss: 2.0595 - val_acc: 0.4532\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3527 - acc: 0.6340 - val_loss: 2.0630 - val_acc: 0.4320\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3447 - acc: 0.6393 - val_loss: 2.0641 - val_acc: 0.4653\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4295 - acc: 0.6073 - val_loss: 1.9497 - val_acc: 0.5106\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4778 - acc: 0.5896 - val_loss: 2.0048 - val_acc: 0.4381\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4714 - acc: 0.5590 - val_loss: 1.8722 - val_acc: 0.4532\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3726 - acc: 0.6235 - val_loss: 1.9455 - val_acc: 0.4592\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3299 - acc: 0.6252 - val_loss: 2.0229 - val_acc: 0.4471\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3395 - acc: 0.6309 - val_loss: 1.9383 - val_acc: 0.4834\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3312 - acc: 0.6471 - val_loss: 2.0557 - val_acc: 0.4320\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3637 - acc: 0.6027 - val_loss: 2.0156 - val_acc: 0.4562\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3906 - acc: 0.5903 - val_loss: 1.9581 - val_acc: 0.4562\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3897 - acc: 0.5914 - val_loss: 1.9865 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3957 - acc: 0.6210 - val_loss: 1.9429 - val_acc: 0.4713\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3692 - acc: 0.6118 - val_loss: 1.8433 - val_acc: 0.4864\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4352 - acc: 0.6175 - val_loss: 2.0047 - val_acc: 0.4713\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4900 - acc: 0.5727 - val_loss: 1.8167 - val_acc: 0.4804\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3907 - acc: 0.6182 - val_loss: 1.9308 - val_acc: 0.4441\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3343 - acc: 0.6439 - val_loss: 2.0983 - val_acc: 0.4350\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3486 - acc: 0.6210 - val_loss: 2.0630 - val_acc: 0.4683\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3377 - acc: 0.6467 - val_loss: 2.1722 - val_acc: 0.4230\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3859 - acc: 0.5946 - val_loss: 2.0481 - val_acc: 0.3958\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3814 - acc: 0.6154 - val_loss: 2.0999 - val_acc: 0.4109\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4000 - acc: 0.6034 - val_loss: 2.0146 - val_acc: 0.4562\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4626 - acc: 0.5667 - val_loss: 1.9320 - val_acc: 0.4350\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4297 - acc: 0.5879 - val_loss: 1.9672 - val_acc: 0.4653\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3624 - acc: 0.6361 - val_loss: 2.0017 - val_acc: 0.4260\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3721 - acc: 0.6097 - val_loss: 2.0462 - val_acc: 0.4683\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4521 - acc: 0.5911 - val_loss: 1.9576 - val_acc: 0.4592\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3712 - acc: 0.6185 - val_loss: 2.0119 - val_acc: 0.4471\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3237 - acc: 0.6231 - val_loss: 1.9970 - val_acc: 0.4622\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3298 - acc: 0.6523 - val_loss: 2.0721 - val_acc: 0.4683\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3183 - acc: 0.6527 - val_loss: 2.2004 - val_acc: 0.4320\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3685 - acc: 0.6340 - val_loss: 2.0922 - val_acc: 0.4804\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4895 - acc: 0.5717 - val_loss: 2.2752 - val_acc: 0.3565\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5534 - acc: 0.5122 - val_loss: 2.1754 - val_acc: 0.3353\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4466 - acc: 0.5315 - val_loss: 1.8446 - val_acc: 0.4683\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3360 - acc: 0.6259 - val_loss: 1.9395 - val_acc: 0.4653\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3361 - acc: 0.6414 - val_loss: 1.9640 - val_acc: 0.4562\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3108 - acc: 0.6548 - val_loss: 2.0807 - val_acc: 0.4562\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3309 - acc: 0.6559 - val_loss: 2.1427 - val_acc: 0.4381\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3675 - acc: 0.6161 - val_loss: 2.0443 - val_acc: 0.4562\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3420 - acc: 0.6266 - val_loss: 2.1656 - val_acc: 0.4381\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4655 - acc: 0.5579 - val_loss: 2.0667 - val_acc: 0.4260\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4720 - acc: 0.5537 - val_loss: 1.9442 - val_acc: 0.3988\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3375 - acc: 0.6266 - val_loss: 1.9890 - val_acc: 0.4471\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3331 - acc: 0.6302 - val_loss: 2.0133 - val_acc: 0.4713\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3398 - acc: 0.6386 - val_loss: 2.1334 - val_acc: 0.4532\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4020 - acc: 0.6375 - val_loss: 2.0282 - val_acc: 0.4924\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4785 - acc: 0.6090 - val_loss: 1.8360 - val_acc: 0.4804\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3493 - acc: 0.6368 - val_loss: 1.9912 - val_acc: 0.4502\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3339 - acc: 0.6502 - val_loss: 2.1741 - val_acc: 0.4109\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3601 - acc: 0.6171 - val_loss: 2.2517 - val_acc: 0.4139\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4624 - acc: 0.5618 - val_loss: 2.1733 - val_acc: 0.3867\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4039 - acc: 0.6006 - val_loss: 1.9526 - val_acc: 0.4592\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3342 - acc: 0.6523 - val_loss: 1.9970 - val_acc: 0.4713\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3217 - acc: 0.6516 - val_loss: 2.2316 - val_acc: 0.4048\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3630 - acc: 0.6147 - val_loss: 2.1095 - val_acc: 0.4109\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4051 - acc: 0.5946 - val_loss: 1.8378 - val_acc: 0.5015\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4152 - acc: 0.6361 - val_loss: 2.0638 - val_acc: 0.4713\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3466 - acc: 0.6291 - val_loss: 1.9945 - val_acc: 0.4894\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3753 - acc: 0.6492 - val_loss: 1.9396 - val_acc: 0.4713\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4437 - acc: 0.6132 - val_loss: 1.9206 - val_acc: 0.4683\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3414 - acc: 0.6626 - val_loss: 2.0213 - val_acc: 0.4743\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3430 - acc: 0.6474 - val_loss: 2.1352 - val_acc: 0.4441\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3998 - acc: 0.5830 - val_loss: 2.1943 - val_acc: 0.3897\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3824 - acc: 0.5865 - val_loss: 1.9256 - val_acc: 0.4864\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3865 - acc: 0.6245 - val_loss: 2.1083 - val_acc: 0.4350\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4332 - acc: 0.6097 - val_loss: 1.9453 - val_acc: 0.4683\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3494 - acc: 0.6580 - val_loss: 2.0878 - val_acc: 0.4199\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3296 - acc: 0.6354 - val_loss: 2.0828 - val_acc: 0.4592\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3430 - acc: 0.6594 - val_loss: 1.9709 - val_acc: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3266 - acc: 0.6671 - val_loss: 2.0353 - val_acc: 0.4773\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3659 - acc: 0.6488 - val_loss: 2.1127 - val_acc: 0.4804\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5176 - acc: 0.5224 - val_loss: 1.8774 - val_acc: 0.4864\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4446 - acc: 0.6023 - val_loss: 1.9654 - val_acc: 0.4471\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3581 - acc: 0.6414 - val_loss: 1.9495 - val_acc: 0.4320\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3335 - acc: 0.6404 - val_loss: 1.9375 - val_acc: 0.4743\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3268 - acc: 0.6566 - val_loss: 2.1052 - val_acc: 0.4592\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3441 - acc: 0.6330 - val_loss: 1.9728 - val_acc: 0.4834\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3567 - acc: 0.6664 - val_loss: 2.1079 - val_acc: 0.4592\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3211 - acc: 0.6710 - val_loss: 2.1231 - val_acc: 0.4592\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3178 - acc: 0.6784 - val_loss: 2.1519 - val_acc: 0.4804\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3201 - acc: 0.6795 - val_loss: 2.1193 - val_acc: 0.4743\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3490 - acc: 0.6791 - val_loss: 2.1521 - val_acc: 0.4199\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4061 - acc: 0.5780 - val_loss: 2.3040 - val_acc: 0.3958\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4506 - acc: 0.5576 - val_loss: 1.9442 - val_acc: 0.4894\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3901 - acc: 0.6287 - val_loss: 2.0831 - val_acc: 0.4743\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4110 - acc: 0.5977 - val_loss: 1.9202 - val_acc: 0.4924\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3419 - acc: 0.6745 - val_loss: 2.0742 - val_acc: 0.4713\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3368 - acc: 0.6668 - val_loss: 2.0186 - val_acc: 0.4834\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3233 - acc: 0.6682 - val_loss: 2.1491 - val_acc: 0.4653\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3577 - acc: 0.6231 - val_loss: 2.1501 - val_acc: 0.4350\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3539 - acc: 0.6407 - val_loss: 2.0772 - val_acc: 0.4441\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3235 - acc: 0.6647 - val_loss: 2.1830 - val_acc: 0.4502\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3058 - acc: 0.6657 - val_loss: 2.1268 - val_acc: 0.4864\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3446 - acc: 0.6703 - val_loss: 2.2538 - val_acc: 0.4502\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4456 - acc: 0.5896 - val_loss: 2.0160 - val_acc: 0.4592\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4042 - acc: 0.6337 - val_loss: 2.0971 - val_acc: 0.4471\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3611 - acc: 0.6266 - val_loss: 2.0200 - val_acc: 0.4924\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3711 - acc: 0.6439 - val_loss: 2.1392 - val_acc: 0.4592\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3703 - acc: 0.6291 - val_loss: 2.1314 - val_acc: 0.4290\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3379 - acc: 0.6400 - val_loss: 2.2038 - val_acc: 0.4169\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3192 - acc: 0.6516 - val_loss: 2.2789 - val_acc: 0.4018\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3458 - acc: 0.6442 - val_loss: 2.3933 - val_acc: 0.3746\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4123 - acc: 0.5872 - val_loss: 2.2602 - val_acc: 0.3807\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4503 - acc: 0.545 - 0s 70us/step - loss: 0.4376 - acc: 0.5801 - val_loss: 2.0815 - val_acc: 0.4139\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3691 - acc: 0.6238 - val_loss: 2.1176 - val_acc: 0.3958\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3419 - acc: 0.6361 - val_loss: 2.1297 - val_acc: 0.4471\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3177 - acc: 0.6777 - val_loss: 2.2818 - val_acc: 0.4139\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3132 - acc: 0.6492 - val_loss: 2.3177 - val_acc: 0.4048\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3796 - acc: 0.5999 - val_loss: 2.3125 - val_acc: 0.3776\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.5435 - val_loss: 2.0757 - val_acc: 0.4109\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3557 - acc: 0.6319 - val_loss: 2.0147 - val_acc: 0.4622\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3361 - acc: 0.6629 - val_loss: 2.0726 - val_acc: 0.4320\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3391 - acc: 0.6520 - val_loss: 2.0736 - val_acc: 0.4381\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3291 - acc: 0.6819 - val_loss: 1.9662 - val_acc: 0.4924\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3684 - acc: 0.6492 - val_loss: 2.1278 - val_acc: 0.4320\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3484 - acc: 0.6495 - val_loss: 1.9780 - val_acc: 0.4894\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3434 - acc: 0.6499 - val_loss: 2.1677 - val_acc: 0.4199\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4348 - acc: 0.5611 - val_loss: 1.9727 - val_acc: 0.4653\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4658 - acc: 0.5738 - val_loss: 1.9771 - val_acc: 0.4713\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3947 - acc: 0.6442 - val_loss: 2.0017 - val_acc: 0.4713\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3102 - acc: 0.6883 - val_loss: 2.0887 - val_acc: 0.4653\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3296 - acc: 0.6619 - val_loss: 2.2974 - val_acc: 0.4381\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3166 - acc: 0.6805 - val_loss: 2.2130 - val_acc: 0.4622\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3129 - acc: 0.6936 - val_loss: 2.3951 - val_acc: 0.4018\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3754 - acc: 0.6337 - val_loss: 2.2304 - val_acc: 0.4381\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3836 - acc: 0.6365 - val_loss: 2.3584 - val_acc: 0.3897\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3617 - acc: 0.6273 - val_loss: 2.3045 - val_acc: 0.3716\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3690 - acc: 0.6213 - val_loss: 2.1446 - val_acc: 0.3867\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3794 - acc: 0.6372 - val_loss: 2.1464 - val_acc: 0.4048\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3464 - acc: 0.6171 - val_loss: 2.1270 - val_acc: 0.4532\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3354 - acc: 0.6414 - val_loss: 2.1109 - val_acc: 0.4471\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3150 - acc: 0.6819 - val_loss: 2.1875 - val_acc: 0.4471\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3223 - acc: 0.6675 - val_loss: 2.1544 - val_acc: 0.4713\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3669 - acc: 0.6111 - val_loss: 2.1154 - val_acc: 0.4532\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3430 - acc: 0.6506 - val_loss: 2.1653 - val_acc: 0.4622\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3349 - acc: 0.6414 - val_loss: 2.3130 - val_acc: 0.4411\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3106 - acc: 0.6534 - val_loss: 2.2414 - val_acc: 0.4260\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3284 - acc: 0.6566 - val_loss: 2.1576 - val_acc: 0.4502\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3379 - acc: 0.6541 - val_loss: 2.3159 - val_acc: 0.4230\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3695 - acc: 0.6171 - val_loss: 2.3156 - val_acc: 0.3686\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4175 - acc: 0.5562 - val_loss: 2.1877 - val_acc: 0.3746\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4008 - acc: 0.5766 - val_loss: 2.0188 - val_acc: 0.4683\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4368 - acc: 0.6066 - val_loss: 1.9456 - val_acc: 0.4834\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.4530 - acc: 0.6125 - val_loss: 2.0489 - val_acc: 0.4683\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3455 - acc: 0.6668 - val_loss: 2.1298 - val_acc: 0.4622\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3079 - acc: 0.6830 - val_loss: 2.1608 - val_acc: 0.4592\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2963 - acc: 0.6809 - val_loss: 2.1278 - val_acc: 0.4683\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3126 - acc: 0.6777 - val_loss: 2.2272 - val_acc: 0.4290\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3245 - acc: 0.6538 - val_loss: 2.2911 - val_acc: 0.4199\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4104 - acc: 0.5731 - val_loss: 2.0858 - val_acc: 0.4048\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.4171 - acc: 0.5801 - val_loss: 2.0370 - val_acc: 0.4834\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3316 - acc: 0.6435 - val_loss: 2.0753 - val_acc: 0.4773\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3406 - acc: 0.6626 - val_loss: 2.1826 - val_acc: 0.4924\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4081 - acc: 0.6552 - val_loss: 2.0672 - val_acc: 0.4683\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.3591 - acc: 0.6471 - val_loss: 2.0761 - val_acc: 0.4804\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3188 - acc: 0.6795 - val_loss: 2.2075 - val_acc: 0.4350\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.3233 - acc: 0.6766 - val_loss: 2.1822 - val_acc: 0.4713\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.2942 - acc: 0.7034 - val_loss: 2.1314 - val_acc: 0.4743\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3112 - acc: 0.6950 - val_loss: 2.1083 - val_acc: 0.4743\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3081 - acc: 0.6756 - val_loss: 2.1856 - val_acc: 0.4804\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3786 - acc: 0.6383 - val_loss: 2.1609 - val_acc: 0.4773\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5127 - acc: 0.5527 - val_loss: 1.9491 - val_acc: 0.4743\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4542 - acc: 0.6132 - val_loss: 2.0255 - val_acc: 0.4441\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3605 - acc: 0.6418 - val_loss: 2.0464 - val_acc: 0.4290\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3077 - acc: 0.6449 - val_loss: 2.0428 - val_acc: 0.4683\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3170 - acc: 0.6707 - val_loss: 2.1016 - val_acc: 0.4441\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3056 - acc: 0.6893 - val_loss: 2.2898 - val_acc: 0.4230\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3036 - acc: 0.6890 - val_loss: 2.4094 - val_acc: 0.4109\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 97us/step - loss: 0.3462 - acc: 0.6404 - val_loss: 2.3870 - val_acc: 0.3807\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3643 - acc: 0.6206 - val_loss: 2.2336 - val_acc: 0.4320\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3761 - acc: 0.6312 - val_loss: 2.2549 - val_acc: 0.4199\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3643 - acc: 0.6280 - val_loss: 2.0759 - val_acc: 0.4894\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3346 - acc: 0.6569 - val_loss: 2.1367 - val_acc: 0.4592\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3539 - acc: 0.6735 - val_loss: 2.1702 - val_acc: 0.4562\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3214 - acc: 0.6756 - val_loss: 2.2792 - val_acc: 0.4471\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3351 - acc: 0.6668 - val_loss: 2.4146 - val_acc: 0.4109\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3891 - acc: 0.6034 - val_loss: 2.1066 - val_acc: 0.4532\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3363 - acc: 0.6608 - val_loss: 2.1839 - val_acc: 0.4471\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2945 - acc: 0.6883 - val_loss: 2.1194 - val_acc: 0.4653\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2963 - acc: 0.6914 - val_loss: 2.2822 - val_acc: 0.4502\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3311 - acc: 0.6784 - val_loss: 2.1694 - val_acc: 0.4743\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3372 - acc: 0.6710 - val_loss: 2.2536 - val_acc: 0.5045\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3997 - acc: 0.6710 - val_loss: 2.1028 - val_acc: 0.4834\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4581 - acc: 0.6238 - val_loss: 2.0391 - val_acc: 0.4804\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3651 - acc: 0.6368 - val_loss: 2.1546 - val_acc: 0.4199\n"
     ]
    }
   ],
   "source": [
    "w2v_model = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCWDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x198ec7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model.history['acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 3s 997us/step - loss: 1.2628 - acc: 0.1740 - val_loss: 1.3151 - val_acc: 0.4109\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0710 - acc: 0.3202 - val_loss: 1.3482 - val_acc: 0.3323\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.0089 - acc: 0.3593 - val_loss: 1.3161 - val_acc: 0.3323\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9648 - acc: 0.3878 - val_loss: 1.3395 - val_acc: 0.3323\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9652 - acc: 0.3811 - val_loss: 1.3089 - val_acc: 0.3323\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9466 - acc: 0.3857 - val_loss: 1.2963 - val_acc: 0.3353\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9318 - acc: 0.3857 - val_loss: 1.3542 - val_acc: 0.3353\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9340 - acc: 0.3913 - val_loss: 1.3138 - val_acc: 0.3384\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9368 - acc: 0.3850 - val_loss: 1.3218 - val_acc: 0.3323\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9399 - acc: 0.3885 - val_loss: 1.3301 - val_acc: 0.3323\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9232 - acc: 0.4023 - val_loss: 1.3259 - val_acc: 0.3353\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9015 - acc: 0.4093 - val_loss: 1.2777 - val_acc: 0.3414\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9081 - acc: 0.4012 - val_loss: 1.3217 - val_acc: 0.3293\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9111 - acc: 0.3945 - val_loss: 1.2687 - val_acc: 0.3384\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8921 - acc: 0.4068 - val_loss: 1.3547 - val_acc: 0.3323\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9008 - acc: 0.4019 - val_loss: 1.3196 - val_acc: 0.3353\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8857 - acc: 0.4086 - val_loss: 1.3147 - val_acc: 0.3323\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8960 - acc: 0.4040 - val_loss: 1.3181 - val_acc: 0.3353\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8766 - acc: 0.4047 - val_loss: 1.2905 - val_acc: 0.3384\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8759 - acc: 0.4054 - val_loss: 1.3207 - val_acc: 0.3384\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8866 - acc: 0.4132 - val_loss: 1.3267 - val_acc: 0.3414\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8855 - acc: 0.4044 - val_loss: 1.3184 - val_acc: 0.3353\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8713 - acc: 0.4079 - val_loss: 1.2852 - val_acc: 0.3323\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8593 - acc: 0.4079 - val_loss: 1.3043 - val_acc: 0.3353\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8750 - acc: 0.4054 - val_loss: 1.3624 - val_acc: 0.3353\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8734 - acc: 0.4121 - val_loss: 1.3154 - val_acc: 0.3384\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8782 - acc: 0.4142 - val_loss: 1.3329 - val_acc: 0.3353\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8708 - acc: 0.4023 - val_loss: 1.2946 - val_acc: 0.3293\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8548 - acc: 0.4100 - val_loss: 1.3324 - val_acc: 0.3323\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8551 - acc: 0.4093 - val_loss: 1.2951 - val_acc: 0.3414\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8447 - acc: 0.4223 - val_loss: 1.3960 - val_acc: 0.3384\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8806 - acc: 0.4139 - val_loss: 1.2881 - val_acc: 0.3323\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8399 - acc: 0.4089 - val_loss: 1.2959 - val_acc: 0.3263\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8366 - acc: 0.4244 - val_loss: 1.2641 - val_acc: 0.3263\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8306 - acc: 0.4244 - val_loss: 1.2662 - val_acc: 0.3263\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8498 - acc: 0.4195 - val_loss: 1.2929 - val_acc: 0.3263\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8514 - acc: 0.4213 - val_loss: 1.2931 - val_acc: 0.3233\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8303 - acc: 0.4195 - val_loss: 1.2587 - val_acc: 0.3353\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8228 - acc: 0.4280 - val_loss: 1.2277 - val_acc: 0.3807\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8341 - acc: 0.4280 - val_loss: 1.2635 - val_acc: 0.3202\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8415 - acc: 0.4237 - val_loss: 1.3007 - val_acc: 0.3263\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8421 - acc: 0.4178 - val_loss: 1.2808 - val_acc: 0.3293\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8177 - acc: 0.4276 - val_loss: 1.2659 - val_acc: 0.3263\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8093 - acc: 0.4333 - val_loss: 1.3282 - val_acc: 0.3233\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8056 - acc: 0.4185 - val_loss: 1.2778 - val_acc: 0.3233\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8054 - acc: 0.4269 - val_loss: 1.2875 - val_acc: 0.3142\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.8162 - acc: 0.423 - 0s 70us/step - loss: 0.8296 - acc: 0.4283 - val_loss: 1.2760 - val_acc: 0.3414\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8380 - acc: 0.4438 - val_loss: 1.2500 - val_acc: 0.3384\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8166 - acc: 0.4287 - val_loss: 1.2654 - val_acc: 0.3172\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8138 - acc: 0.4234 - val_loss: 1.2621 - val_acc: 0.3233\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8063 - acc: 0.4188 - val_loss: 1.2887 - val_acc: 0.3172\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8089 - acc: 0.4269 - val_loss: 1.2603 - val_acc: 0.3233\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8083 - acc: 0.4304 - val_loss: 1.2486 - val_acc: 0.3444\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.8071 - acc: 0.434 - 0s 70us/step - loss: 0.8113 - acc: 0.4329 - val_loss: 1.2516 - val_acc: 0.3444\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8094 - acc: 0.4251 - val_loss: 1.2388 - val_acc: 0.3353\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8133 - acc: 0.4385 - val_loss: 1.2737 - val_acc: 0.3202\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7987 - acc: 0.4329 - val_loss: 1.2796 - val_acc: 0.3233\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7957 - acc: 0.4304 - val_loss: 1.2687 - val_acc: 0.3323\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7750 - acc: 0.4470 - val_loss: 1.2605 - val_acc: 0.3233\n",
      "Epoch 60/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7960 - acc: 0.4421 - val_loss: 1.2932 - val_acc: 0.3233\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8008 - acc: 0.4301 - val_loss: 1.2942 - val_acc: 0.3202\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7953 - acc: 0.4237 - val_loss: 1.2549 - val_acc: 0.3172\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7946 - acc: 0.4297 - val_loss: 1.2263 - val_acc: 0.3414\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7844 - acc: 0.4364 - val_loss: 1.2594 - val_acc: 0.3172\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7715 - acc: 0.4315 - val_loss: 1.2454 - val_acc: 0.3505\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7962 - acc: 0.4333 - val_loss: 1.2456 - val_acc: 0.3263\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7613 - acc: 0.4466 - val_loss: 1.3190 - val_acc: 0.3202\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7796 - acc: 0.4364 - val_loss: 1.3989 - val_acc: 0.3233\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8184 - acc: 0.4318 - val_loss: 1.3269 - val_acc: 0.3233\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7803 - acc: 0.4414 - val_loss: 1.3064 - val_acc: 0.3625\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7778 - acc: 0.4322 - val_loss: 1.3253 - val_acc: 0.3384\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7699 - acc: 0.4438 - val_loss: 1.4074 - val_acc: 0.3172\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7941 - acc: 0.4315 - val_loss: 1.2943 - val_acc: 0.3263\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7701 - acc: 0.4382 - val_loss: 1.3367 - val_acc: 0.3202\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7562 - acc: 0.4350 - val_loss: 1.3406 - val_acc: 0.3202\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7704 - acc: 0.4406 - val_loss: 1.3823 - val_acc: 0.3202\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7738 - acc: 0.4378 - val_loss: 1.3505 - val_acc: 0.3233\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7819 - acc: 0.4484 - val_loss: 1.3906 - val_acc: 0.3233\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7825 - acc: 0.4329 - val_loss: 1.3101 - val_acc: 0.3233\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7580 - acc: 0.4431 - val_loss: 1.3292 - val_acc: 0.3233\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7620 - acc: 0.4297 - val_loss: 1.3441 - val_acc: 0.3202\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.7585 - acc: 0.4403 - val_loss: 1.3750 - val_acc: 0.3142\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7732 - acc: 0.4389 - val_loss: 1.3028 - val_acc: 0.3202\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7544 - acc: 0.4466 - val_loss: 1.3373 - val_acc: 0.3263\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7575 - acc: 0.4438 - val_loss: 1.3327 - val_acc: 0.3233\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7483 - acc: 0.4533 - val_loss: 1.3137 - val_acc: 0.3384\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7564 - acc: 0.4502 - val_loss: 1.4024 - val_acc: 0.3202\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7720 - acc: 0.4410 - val_loss: 1.2806 - val_acc: 0.3263\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7482 - acc: 0.4435 - val_loss: 1.3065 - val_acc: 0.3323\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7567 - acc: 0.4565 - val_loss: 1.2979 - val_acc: 0.3414\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7423 - acc: 0.4569 - val_loss: 1.3432 - val_acc: 0.3263\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7643 - acc: 0.4463 - val_loss: 1.3421 - val_acc: 0.3263\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7441 - acc: 0.4435 - val_loss: 1.3520 - val_acc: 0.3293\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7330 - acc: 0.4357 - val_loss: 1.3383 - val_acc: 0.3384\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7389 - acc: 0.4428 - val_loss: 1.3754 - val_acc: 0.3263\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7547 - acc: 0.4431 - val_loss: 1.3223 - val_acc: 0.3384\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7491 - acc: 0.4572 - val_loss: 1.3282 - val_acc: 0.3474\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7260 - acc: 0.4537 - val_loss: 1.2858 - val_acc: 0.3414\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7228 - acc: 0.4540 - val_loss: 1.3351 - val_acc: 0.3414\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7344 - acc: 0.4558 - val_loss: 1.3571 - val_acc: 0.3323\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7493 - acc: 0.4590 - val_loss: 1.3094 - val_acc: 0.3293\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7627 - acc: 0.4435 - val_loss: 1.2668 - val_acc: 0.3323\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7333 - acc: 0.4569 - val_loss: 1.3756 - val_acc: 0.3535\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7608 - acc: 0.4579 - val_loss: 1.2945 - val_acc: 0.3384\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.7142 - acc: 0.4417 - val_loss: 1.3000 - val_acc: 0.3565\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7250 - acc: 0.4530 - val_loss: 1.2807 - val_acc: 0.3474\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7262 - acc: 0.4561 - val_loss: 1.2427 - val_acc: 0.3867\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7229 - acc: 0.4762 - val_loss: 1.2084 - val_acc: 0.4139\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7193 - acc: 0.4586 - val_loss: 1.2394 - val_acc: 0.4048\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.7486 - acc: 0.4614 - val_loss: 1.2096 - val_acc: 0.4139\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7395 - acc: 0.4759 - val_loss: 1.2154 - val_acc: 0.3927\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7226 - acc: 0.4773 - val_loss: 1.2394 - val_acc: 0.3897\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7096 - acc: 0.4685 - val_loss: 1.2304 - val_acc: 0.4199\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7288 - acc: 0.4759 - val_loss: 1.2148 - val_acc: 0.4139\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7410 - acc: 0.4752 - val_loss: 1.3073 - val_acc: 0.3505\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7365 - acc: 0.4600 - val_loss: 1.2525 - val_acc: 0.3988\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7156 - acc: 0.4674 - val_loss: 1.2238 - val_acc: 0.4381\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7122 - acc: 0.4797 - val_loss: 1.1999 - val_acc: 0.4622\n",
      "Epoch 119/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7261 - acc: 0.4635 - val_loss: 1.2317 - val_acc: 0.4079\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7141 - acc: 0.4745 - val_loss: 1.2609 - val_acc: 0.4139\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7357 - acc: 0.4709 - val_loss: 1.2237 - val_acc: 0.4079\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6935 - acc: 0.4692 - val_loss: 1.2401 - val_acc: 0.4139\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7027 - acc: 0.4720 - val_loss: 1.2565 - val_acc: 0.4048\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7269 - acc: 0.4692 - val_loss: 1.1939 - val_acc: 0.4411\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7250 - acc: 0.4805 - val_loss: 1.2375 - val_acc: 0.4018\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6968 - acc: 0.4723 - val_loss: 1.2324 - val_acc: 0.4290\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7020 - acc: 0.4745 - val_loss: 1.2044 - val_acc: 0.4048\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6999 - acc: 0.4769 - val_loss: 1.1984 - val_acc: 0.4441\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7182 - acc: 0.4924 - val_loss: 1.2206 - val_acc: 0.4169\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7398 - acc: 0.4653 - val_loss: 1.2235 - val_acc: 0.3776\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7102 - acc: 0.4639 - val_loss: 1.2081 - val_acc: 0.4109\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6918 - acc: 0.4808 - val_loss: 1.2969 - val_acc: 0.3837\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7034 - acc: 0.4752 - val_loss: 1.3616 - val_acc: 0.3595\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7189 - acc: 0.4561 - val_loss: 1.2483 - val_acc: 0.3776\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6937 - acc: 0.4716 - val_loss: 1.2346 - val_acc: 0.4109\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6748 - acc: 0.4875 - val_loss: 1.2431 - val_acc: 0.4199\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6798 - acc: 0.4882 - val_loss: 1.4107 - val_acc: 0.3595\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7381 - acc: 0.4551 - val_loss: 1.2279 - val_acc: 0.3565\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6762 - acc: 0.4716 - val_loss: 1.2402 - val_acc: 0.4230\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6758 - acc: 0.4833 - val_loss: 1.2273 - val_acc: 0.4532\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6772 - acc: 0.4977 - val_loss: 1.2731 - val_acc: 0.4109\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6999 - acc: 0.4847 - val_loss: 1.3430 - val_acc: 0.3807\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7141 - acc: 0.4607 - val_loss: 1.2283 - val_acc: 0.3656\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6759 - acc: 0.4667 - val_loss: 1.2233 - val_acc: 0.4048\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6616 - acc: 0.4864 - val_loss: 1.2474 - val_acc: 0.4079\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6642 - acc: 0.4917 - val_loss: 1.2654 - val_acc: 0.3988\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6662 - acc: 0.4871 - val_loss: 1.2314 - val_acc: 0.4290\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7006 - acc: 0.4900 - val_loss: 1.1985 - val_acc: 0.4532\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7087 - acc: 0.5033 - val_loss: 1.2415 - val_acc: 0.4139\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6574 - acc: 0.4967 - val_loss: 1.2712 - val_acc: 0.4260\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6781 - acc: 0.4787 - val_loss: 1.2453 - val_acc: 0.4320\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6823 - acc: 0.4900 - val_loss: 1.2505 - val_acc: 0.4169\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6623 - acc: 0.4945 - val_loss: 1.2552 - val_acc: 0.4290\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.6808 - acc: 0.4903 - val_loss: 1.4095 - val_acc: 0.3686\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.7066 - acc: 0.4576 - val_loss: 1.2257 - val_acc: 0.3927\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6577 - acc: 0.4797 - val_loss: 1.2496 - val_acc: 0.4290\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6574 - acc: 0.4988 - val_loss: 1.3861 - val_acc: 0.3897\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6991 - acc: 0.4857 - val_loss: 1.2267 - val_acc: 0.3807\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.6418 - acc: 0.493 - 0s 69us/step - loss: 0.6396 - acc: 0.4886 - val_loss: 1.2160 - val_acc: 0.4350\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6439 - acc: 0.5051 - val_loss: 1.2426 - val_acc: 0.4199\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6748 - acc: 0.4956 - val_loss: 1.2947 - val_acc: 0.4109\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6941 - acc: 0.4907 - val_loss: 1.2950 - val_acc: 0.3807\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6573 - acc: 0.4829 - val_loss: 1.3031 - val_acc: 0.3867\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6705 - acc: 0.4974 - val_loss: 1.2727 - val_acc: 0.4018\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6397 - acc: 0.4907 - val_loss: 1.3093 - val_acc: 0.3656\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6725 - acc: 0.4868 - val_loss: 1.2313 - val_acc: 0.3927\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6418 - acc: 0.4882 - val_loss: 1.2712 - val_acc: 0.4230\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6537 - acc: 0.4967 - val_loss: 1.3234 - val_acc: 0.3958\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6724 - acc: 0.4854 - val_loss: 1.2527 - val_acc: 0.3867\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6854 - acc: 0.4766 - val_loss: 1.2392 - val_acc: 0.4320\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6424 - acc: 0.5044 - val_loss: 1.2659 - val_acc: 0.4048\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6308 - acc: 0.5143 - val_loss: 1.3266 - val_acc: 0.3625\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6603 - acc: 0.4974 - val_loss: 1.2569 - val_acc: 0.3776\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6543 - acc: 0.4850 - val_loss: 1.2650 - val_acc: 0.3958\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6798 - acc: 0.4914 - val_loss: 1.2724 - val_acc: 0.4079\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6701 - acc: 0.4861 - val_loss: 1.2362 - val_acc: 0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6290 - acc: 0.5090 - val_loss: 1.3075 - val_acc: 0.3716\n",
      "Epoch 178/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6496 - acc: 0.4861 - val_loss: 1.3004 - val_acc: 0.3474\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6370 - acc: 0.4935 - val_loss: 1.2710 - val_acc: 0.4109\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6407 - acc: 0.5062 - val_loss: 1.3353 - val_acc: 0.4018\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6751 - acc: 0.4843 - val_loss: 1.2583 - val_acc: 0.3958\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6306 - acc: 0.5072 - val_loss: 1.2582 - val_acc: 0.4471\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6170 - acc: 0.5213 - val_loss: 1.2942 - val_acc: 0.4139\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6642 - acc: 0.4942 - val_loss: 1.2970 - val_acc: 0.3927\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6667 - acc: 0.4945 - val_loss: 1.2432 - val_acc: 0.4381\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6167 - acc: 0.5143 - val_loss: 1.2626 - val_acc: 0.4350\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6052 - acc: 0.5407 - val_loss: 1.2723 - val_acc: 0.4139\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6218 - acc: 0.5238 - val_loss: 1.3106 - val_acc: 0.3656\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6457 - acc: 0.4914 - val_loss: 1.3015 - val_acc: 0.3625\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6329 - acc: 0.4889 - val_loss: 1.4008 - val_acc: 0.3807\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7345 - acc: 0.4868 - val_loss: 1.1830 - val_acc: 0.4773\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6404 - acc: 0.5361 - val_loss: 1.2110 - val_acc: 0.4653\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6046 - acc: 0.5354 - val_loss: 1.2534 - val_acc: 0.4139\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6115 - acc: 0.5431 - val_loss: 1.2252 - val_acc: 0.4350\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6301 - acc: 0.5227 - val_loss: 1.2646 - val_acc: 0.4502\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6912 - acc: 0.5199 - val_loss: 1.2484 - val_acc: 0.4169\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6219 - acc: 0.5298 - val_loss: 1.2366 - val_acc: 0.4320\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6119 - acc: 0.5234 - val_loss: 1.3242 - val_acc: 0.3958\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6737 - acc: 0.4942 - val_loss: 1.2393 - val_acc: 0.4713\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6645 - acc: 0.5241 - val_loss: 1.2616 - val_acc: 0.4048\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6112 - acc: 0.5150 - val_loss: 1.2897 - val_acc: 0.4169\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6139 - acc: 0.5213 - val_loss: 1.2926 - val_acc: 0.4169\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6209 - acc: 0.5284 - val_loss: 1.3386 - val_acc: 0.3776\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6450 - acc: 0.5086 - val_loss: 1.2673 - val_acc: 0.3807\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6000 - acc: 0.5100 - val_loss: 1.2684 - val_acc: 0.4230\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5859 - acc: 0.5248 - val_loss: 1.3057 - val_acc: 0.4260\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5942 - acc: 0.5453 - val_loss: 1.2788 - val_acc: 0.3958\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6071 - acc: 0.5354 - val_loss: 1.3980 - val_acc: 0.3807\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6979 - acc: 0.4931 - val_loss: 1.2433 - val_acc: 0.4411\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6122 - acc: 0.5164 - val_loss: 1.2487 - val_acc: 0.4743\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6109 - acc: 0.5333 - val_loss: 1.2418 - val_acc: 0.4532\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5921 - acc: 0.5301 - val_loss: 1.2435 - val_acc: 0.4320\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5822 - acc: 0.5375 - val_loss: 1.2734 - val_acc: 0.4562\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6199 - acc: 0.5358 - val_loss: 1.3549 - val_acc: 0.3897\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6540 - acc: 0.5051 - val_loss: 1.2689 - val_acc: 0.3897\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5907 - acc: 0.5308 - val_loss: 1.2828 - val_acc: 0.4018\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5768 - acc: 0.5308 - val_loss: 1.2838 - val_acc: 0.4230\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5827 - acc: 0.5453 - val_loss: 1.3663 - val_acc: 0.3807\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5942 - acc: 0.5262 - val_loss: 1.3537 - val_acc: 0.3625\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6025 - acc: 0.5076 - val_loss: 1.3690 - val_acc: 0.3988\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6672 - acc: 0.4991 - val_loss: 1.2925 - val_acc: 0.4109\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6196 - acc: 0.5058 - val_loss: 1.2894 - val_acc: 0.4502\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5712 - acc: 0.5484 - val_loss: 1.2713 - val_acc: 0.4743\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5748 - acc: 0.5731 - val_loss: 1.3041 - val_acc: 0.4653\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5905 - acc: 0.5555 - val_loss: 1.2560 - val_acc: 0.4864\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6120 - acc: 0.5382 - val_loss: 1.2400 - val_acc: 0.4713\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5731 - acc: 0.5622 - val_loss: 1.3324 - val_acc: 0.4290\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6204 - acc: 0.5343 - val_loss: 1.3568 - val_acc: 0.3927\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.6979 - acc: 0.5210 - val_loss: 1.3045 - val_acc: 0.3746\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5851 - acc: 0.5354 - val_loss: 1.2902 - val_acc: 0.4139\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5722 - acc: 0.5417 - val_loss: 1.2450 - val_acc: 0.4834\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5858 - acc: 0.5470 - val_loss: 1.2584 - val_acc: 0.4773\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5736 - acc: 0.5516 - val_loss: 1.2967 - val_acc: 0.4864\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5689 - acc: 0.5667 - val_loss: 1.2624 - val_acc: 0.5015\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5762 - acc: 0.5678 - val_loss: 1.3547 - val_acc: 0.4260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6305 - acc: 0.5481 - val_loss: 1.3218 - val_acc: 0.4260\n",
      "Epoch 237/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6117 - acc: 0.5527 - val_loss: 1.2843 - val_acc: 0.4320\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5768 - acc: 0.5703 - val_loss: 1.2940 - val_acc: 0.4804\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5941 - acc: 0.5734 - val_loss: 1.3145 - val_acc: 0.4834\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5913 - acc: 0.5780 - val_loss: 1.3196 - val_acc: 0.4199\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5496 - acc: 0.5608 - val_loss: 1.3095 - val_acc: 0.4441\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5681 - acc: 0.5678 - val_loss: 1.4401 - val_acc: 0.3927\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6582 - acc: 0.5358 - val_loss: 1.3064 - val_acc: 0.4320\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5832 - acc: 0.5618 - val_loss: 1.3040 - val_acc: 0.5076\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5855 - acc: 0.5727 - val_loss: 1.2861 - val_acc: 0.4894\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5801 - acc: 0.5632 - val_loss: 1.3475 - val_acc: 0.4350\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5556 - acc: 0.5717 - val_loss: 1.3831 - val_acc: 0.4381\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6065 - acc: 0.5608 - val_loss: 1.3206 - val_acc: 0.4562\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5989 - acc: 0.5935 - val_loss: 1.2749 - val_acc: 0.4592\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5425 - acc: 0.5724 - val_loss: 1.2829 - val_acc: 0.4713\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5688 - acc: 0.5629 - val_loss: 1.3304 - val_acc: 0.4622\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6055 - acc: 0.5470 - val_loss: 1.3552 - val_acc: 0.4018\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6174 - acc: 0.5322 - val_loss: 1.3299 - val_acc: 0.4139\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5368 - acc: 0.5530 - val_loss: 1.3318 - val_acc: 0.4894\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5477 - acc: 0.5773 - val_loss: 1.3591 - val_acc: 0.4834\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5993 - acc: 0.5625 - val_loss: 1.2626 - val_acc: 0.4592\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5631 - acc: 0.5618 - val_loss: 1.2746 - val_acc: 0.4683\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5355 - acc: 0.5745 - val_loss: 1.3375 - val_acc: 0.4320\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5824 - acc: 0.5534 - val_loss: 1.4016 - val_acc: 0.4169\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.6411 - acc: 0.5150 - val_loss: 1.2866 - val_acc: 0.4683\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5558 - acc: 0.5699 - val_loss: 1.3558 - val_acc: 0.4653\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5355 - acc: 0.5801 - val_loss: 1.3084 - val_acc: 0.4653\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5274 - acc: 0.5752 - val_loss: 1.4102 - val_acc: 0.4804\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5984 - acc: 0.5713 - val_loss: 1.2474 - val_acc: 0.5106\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5422 - acc: 0.5854 - val_loss: 1.2992 - val_acc: 0.4924\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5483 - acc: 0.5808 - val_loss: 1.3413 - val_acc: 0.4804\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5951 - acc: 0.5586 - val_loss: 1.3676 - val_acc: 0.4199\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6078 - acc: 0.5227 - val_loss: 1.2931 - val_acc: 0.4532\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5430 - acc: 0.5622 - val_loss: 1.2900 - val_acc: 0.5015\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5305 - acc: 0.5939 - val_loss: 1.3069 - val_acc: 0.5015\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5507 - acc: 0.5784 - val_loss: 1.4074 - val_acc: 0.4441\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6055 - acc: 0.5671 - val_loss: 1.3866 - val_acc: 0.4411\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5425 - acc: 0.6034 - val_loss: 1.4327 - val_acc: 0.4290\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5457 - acc: 0.5847 - val_loss: 1.2919 - val_acc: 0.5166\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5421 - acc: 0.6080 - val_loss: 1.4007 - val_acc: 0.4622\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5350 - acc: 0.6013 - val_loss: 1.3901 - val_acc: 0.4350\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5268 - acc: 0.5925 - val_loss: 1.5230 - val_acc: 0.4139\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6268 - acc: 0.5583 - val_loss: 1.4235 - val_acc: 0.4381\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5725 - acc: 0.5893 - val_loss: 1.3258 - val_acc: 0.4894\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5327 - acc: 0.5970 - val_loss: 1.3264 - val_acc: 0.5015\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5208 - acc: 0.6030 - val_loss: 1.3826 - val_acc: 0.4955\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5322 - acc: 0.5967 - val_loss: 1.2917 - val_acc: 0.5408\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5558 - acc: 0.5777 - val_loss: 1.2917 - val_acc: 0.4834\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5091 - acc: 0.5918 - val_loss: 1.4060 - val_acc: 0.4441\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5019 - acc: 0.6090 - val_loss: 1.3677 - val_acc: 0.4471\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5026 - acc: 0.5985 - val_loss: 1.4678 - val_acc: 0.4230\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5424 - acc: 0.5903 - val_loss: 1.4496 - val_acc: 0.4230\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6381 - acc: 0.5477 - val_loss: 1.4640 - val_acc: 0.3867\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5432 - acc: 0.5914 - val_loss: 1.4926 - val_acc: 0.4048\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5255 - acc: 0.6023 - val_loss: 1.4154 - val_acc: 0.3958\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5495 - acc: 0.5636 - val_loss: 1.4513 - val_acc: 0.4260\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5593 - acc: 0.5977 - val_loss: 1.4034 - val_acc: 0.4471\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5869 - acc: 0.5907 - val_loss: 1.3579 - val_acc: 0.4894\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5214 - acc: 0.6048 - val_loss: 1.3563 - val_acc: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5024 - acc: 0.6182 - val_loss: 1.3613 - val_acc: 0.4955\n",
      "Epoch 296/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5147 - acc: 0.6058 - val_loss: 1.4339 - val_acc: 0.4894\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5366 - acc: 0.6048 - val_loss: 1.5139 - val_acc: 0.4381\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5446 - acc: 0.6097 - val_loss: 1.3730 - val_acc: 0.4532\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5681 - acc: 0.5946 - val_loss: 1.5184 - val_acc: 0.4532\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5245 - acc: 0.6055 - val_loss: 1.4380 - val_acc: 0.4743\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5129 - acc: 0.6076 - val_loss: 1.4570 - val_acc: 0.4622\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5439 - acc: 0.6073 - val_loss: 1.4297 - val_acc: 0.4653\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5122 - acc: 0.6235 - val_loss: 1.4771 - val_acc: 0.4622\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5024 - acc: 0.6143 - val_loss: 1.7178 - val_acc: 0.4018\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.6109 - acc: 0.5653 - val_loss: 1.3647 - val_acc: 0.5227\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5464 - acc: 0.6231 - val_loss: 1.3424 - val_acc: 0.5257\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5181 - acc: 0.6302 - val_loss: 1.3809 - val_acc: 0.4743\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4859 - acc: 0.6136 - val_loss: 1.4045 - val_acc: 0.4381\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5290 - acc: 0.5946 - val_loss: 1.4120 - val_acc: 0.4350\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4944 - acc: 0.5981 - val_loss: 1.4543 - val_acc: 0.4381\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4901 - acc: 0.6136 - val_loss: 1.5870 - val_acc: 0.3535\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5249 - acc: 0.5798 - val_loss: 1.4969 - val_acc: 0.4079\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4987 - acc: 0.5977 - val_loss: 1.4710 - val_acc: 0.4381\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5225 - acc: 0.6023 - val_loss: 1.4858 - val_acc: 0.4109\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6495 - acc: 0.5329 - val_loss: 1.3048 - val_acc: 0.4773\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5450 - acc: 0.5766 - val_loss: 1.4082 - val_acc: 0.4441\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4828 - acc: 0.6094 - val_loss: 1.4968 - val_acc: 0.3927\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5088 - acc: 0.5815 - val_loss: 1.4066 - val_acc: 0.4230\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4836 - acc: 0.6016 - val_loss: 1.3581 - val_acc: 0.4955\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5248 - acc: 0.5882 - val_loss: 1.6080 - val_acc: 0.4320\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6161 - acc: 0.5601 - val_loss: 1.3608 - val_acc: 0.4199\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5022 - acc: 0.5717 - val_loss: 1.3817 - val_acc: 0.4562\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4727 - acc: 0.6168 - val_loss: 1.4558 - val_acc: 0.4441\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4850 - acc: 0.6316 - val_loss: 1.6513 - val_acc: 0.3656\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5206 - acc: 0.5900 - val_loss: 1.5426 - val_acc: 0.4109\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5020 - acc: 0.6066 - val_loss: 1.5502 - val_acc: 0.4048\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5170 - acc: 0.6020 - val_loss: 1.5949 - val_acc: 0.3988\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5877 - acc: 0.5819 - val_loss: 1.5548 - val_acc: 0.4502\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5202 - acc: 0.6316 - val_loss: 1.4120 - val_acc: 0.4653\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4669 - acc: 0.6305 - val_loss: 1.4433 - val_acc: 0.4834\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4700 - acc: 0.6383 - val_loss: 1.3985 - val_acc: 0.5015\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5192 - acc: 0.6231 - val_loss: 1.4870 - val_acc: 0.4653\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5025 - acc: 0.6291 - val_loss: 1.4528 - val_acc: 0.4532\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4661 - acc: 0.6386 - val_loss: 1.4261 - val_acc: 0.5106\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4837 - acc: 0.6509 - val_loss: 1.5425 - val_acc: 0.4804\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5198 - acc: 0.6115 - val_loss: 1.4228 - val_acc: 0.5015\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5179 - acc: 0.6136 - val_loss: 1.4602 - val_acc: 0.4320\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4772 - acc: 0.6129 - val_loss: 1.6866 - val_acc: 0.3897\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5212 - acc: 0.5995 - val_loss: 1.8362 - val_acc: 0.3565\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6463 - acc: 0.5520 - val_loss: 1.4561 - val_acc: 0.4713\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5745 - acc: 0.6023 - val_loss: 1.4391 - val_acc: 0.4169\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4676 - acc: 0.6108 - val_loss: 1.4258 - val_acc: 0.4683\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4582 - acc: 0.6407 - val_loss: 1.4337 - val_acc: 0.4683\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4563 - acc: 0.6411 - val_loss: 1.4817 - val_acc: 0.5045\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4656 - acc: 0.6460 - val_loss: 1.4394 - val_acc: 0.5257\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4836 - acc: 0.6294 - val_loss: 1.4233 - val_acc: 0.4864\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4587 - acc: 0.6467 - val_loss: 1.4544 - val_acc: 0.4864\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4568 - acc: 0.6393 - val_loss: 1.5327 - val_acc: 0.4955\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4869 - acc: 0.6287 - val_loss: 1.5468 - val_acc: 0.4562\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5352 - acc: 0.6150 - val_loss: 1.7699 - val_acc: 0.3988\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6239 - acc: 0.5851 - val_loss: 1.5575 - val_acc: 0.4260\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5204 - acc: 0.6291 - val_loss: 1.4263 - val_acc: 0.4985\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4649 - acc: 0.6464 - val_loss: 1.4504 - val_acc: 0.4653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4471 - acc: 0.6513 - val_loss: 1.5784 - val_acc: 0.4622\n",
      "Epoch 355/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4820 - acc: 0.6397 - val_loss: 1.6802 - val_acc: 0.4079\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5255 - acc: 0.5963 - val_loss: 1.4118 - val_acc: 0.4199\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4678 - acc: 0.6136 - val_loss: 1.5055 - val_acc: 0.4834\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4553 - acc: 0.6478 - val_loss: 1.4146 - val_acc: 0.5529\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4813 - acc: 0.6351 - val_loss: 1.4758 - val_acc: 0.4955\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4662 - acc: 0.6421 - val_loss: 1.5614 - val_acc: 0.4924\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4530 - acc: 0.6499 - val_loss: 1.5757 - val_acc: 0.4985\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4951 - acc: 0.6323 - val_loss: 1.5340 - val_acc: 0.4411\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5420 - acc: 0.6150 - val_loss: 1.8586 - val_acc: 0.3686\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5498 - acc: 0.6129 - val_loss: 1.5853 - val_acc: 0.4471\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4822 - acc: 0.6414 - val_loss: 1.4819 - val_acc: 0.4804\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4379 - acc: 0.6647 - val_loss: 1.4900 - val_acc: 0.4532\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4425 - acc: 0.6495 - val_loss: 1.6007 - val_acc: 0.4260\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4541 - acc: 0.6235 - val_loss: 1.6401 - val_acc: 0.4532\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4535 - acc: 0.6590 - val_loss: 1.6606 - val_acc: 0.4109\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4450 - acc: 0.6520 - val_loss: 1.7674 - val_acc: 0.3686\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5254 - acc: 0.6037 - val_loss: 1.4650 - val_acc: 0.4230\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5200 - acc: 0.5942 - val_loss: 1.4699 - val_acc: 0.4894\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4726 - acc: 0.6333 - val_loss: 1.5307 - val_acc: 0.4532\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4720 - acc: 0.6316 - val_loss: 1.5664 - val_acc: 0.4381\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4503 - acc: 0.6375 - val_loss: 1.5251 - val_acc: 0.4471\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4512 - acc: 0.6361 - val_loss: 1.6127 - val_acc: 0.4139\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4908 - acc: 0.6069 - val_loss: 1.4592 - val_acc: 0.4411\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4498 - acc: 0.6224 - val_loss: 1.6010 - val_acc: 0.4230\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4344 - acc: 0.6474 - val_loss: 1.5675 - val_acc: 0.4260\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4806 - acc: 0.6185 - val_loss: 1.6237 - val_acc: 0.4562\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5085 - acc: 0.5992 - val_loss: 1.5310 - val_acc: 0.5136\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5722 - acc: 0.6048 - val_loss: 1.3900 - val_acc: 0.5015\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4422 - acc: 0.6523 - val_loss: 1.4697 - val_acc: 0.4713\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4297 - acc: 0.6590 - val_loss: 1.5254 - val_acc: 0.4592\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4238 - acc: 0.6474 - val_loss: 1.7152 - val_acc: 0.3958\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4800 - acc: 0.6189 - val_loss: 1.5642 - val_acc: 0.4199\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4651 - acc: 0.6210 - val_loss: 1.5970 - val_acc: 0.4079\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4925 - acc: 0.6104 - val_loss: 1.5398 - val_acc: 0.4471\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5179 - acc: 0.6020 - val_loss: 1.4327 - val_acc: 0.4441\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4657 - acc: 0.6252 - val_loss: 1.5326 - val_acc: 0.4441\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4209 - acc: 0.6541 - val_loss: 1.5766 - val_acc: 0.4290\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4454 - acc: 0.6442 - val_loss: 1.5395 - val_acc: 0.4350\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4494 - acc: 0.6287 - val_loss: 1.5745 - val_acc: 0.4109\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4567 - acc: 0.6168 - val_loss: 1.5424 - val_acc: 0.4622\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4208 - acc: 0.6481 - val_loss: 1.6071 - val_acc: 0.4260\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4395 - acc: 0.6407 - val_loss: 1.5542 - val_acc: 0.4260\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4578 - acc: 0.6259 - val_loss: 1.4906 - val_acc: 0.4924\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4415 - acc: 0.6467 - val_loss: 1.5542 - val_acc: 0.4864\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4955 - acc: 0.6421 - val_loss: 1.5399 - val_acc: 0.4864\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4631 - acc: 0.6390 - val_loss: 1.5979 - val_acc: 0.4290\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4546 - acc: 0.6287 - val_loss: 1.5610 - val_acc: 0.4260\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4894 - acc: 0.6080 - val_loss: 1.4587 - val_acc: 0.4713\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4435 - acc: 0.6421 - val_loss: 1.5555 - val_acc: 0.5045\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4624 - acc: 0.6534 - val_loss: 1.5483 - val_acc: 0.5196\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.4651 - acc: 0.6456 - val_loss: 1.4487 - val_acc: 0.5045\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4169 - acc: 0.6784 - val_loss: 1.5646 - val_acc: 0.4411\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4801 - acc: 0.6185 - val_loss: 1.5598 - val_acc: 0.4260\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4468 - acc: 0.6284 - val_loss: 1.5562 - val_acc: 0.4502\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4490 - acc: 0.6383 - val_loss: 1.5875 - val_acc: 0.4653\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4758 - acc: 0.6287 - val_loss: 1.5112 - val_acc: 0.4924\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4241 - acc: 0.6527 - val_loss: 1.6739 - val_acc: 0.4532\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4116 - acc: 0.6671 - val_loss: 1.6956 - val_acc: 0.4290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4102 - acc: 0.6784 - val_loss: 1.7744 - val_acc: 0.4018\n",
      "Epoch 414/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4617 - acc: 0.6139 - val_loss: 1.7834 - val_acc: 0.4169\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4422 - acc: 0.6559 - val_loss: 1.7632 - val_acc: 0.4079\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4275 - acc: 0.6562 - val_loss: 1.7108 - val_acc: 0.4532\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4112 - acc: 0.6774 - val_loss: 1.8068 - val_acc: 0.4199\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5416 - acc: 0.6333 - val_loss: 1.9721 - val_acc: 0.4048\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6101 - acc: 0.5896 - val_loss: 1.5375 - val_acc: 0.4199\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4433 - acc: 0.6421 - val_loss: 1.5613 - val_acc: 0.4381\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3975 - acc: 0.6756 - val_loss: 1.5988 - val_acc: 0.4653\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3961 - acc: 0.6862 - val_loss: 1.5645 - val_acc: 0.4773\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3910 - acc: 0.6928 - val_loss: 1.6601 - val_acc: 0.4864\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3996 - acc: 0.6971 - val_loss: 1.6991 - val_acc: 0.4592\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4159 - acc: 0.6826 - val_loss: 1.6315 - val_acc: 0.4834\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4158 - acc: 0.6918 - val_loss: 1.7461 - val_acc: 0.4713\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4475 - acc: 0.6615 - val_loss: 1.6517 - val_acc: 0.4773\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4500 - acc: 0.6664 - val_loss: 1.6244 - val_acc: 0.4683\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4371 - acc: 0.6763 - val_loss: 1.7029 - val_acc: 0.4320\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4443 - acc: 0.6738 - val_loss: 1.6982 - val_acc: 0.4109\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4279 - acc: 0.6604 - val_loss: 1.5693 - val_acc: 0.4773\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3837 - acc: 0.6974 - val_loss: 1.5314 - val_acc: 0.5468\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4524 - acc: 0.6650 - val_loss: 1.7762 - val_acc: 0.4381\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4780 - acc: 0.6538 - val_loss: 1.5791 - val_acc: 0.4743\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4116 - acc: 0.6981 - val_loss: 1.7065 - val_acc: 0.4532\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4274 - acc: 0.6890 - val_loss: 1.8977 - val_acc: 0.3897\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4943 - acc: 0.6164 - val_loss: 1.7172 - val_acc: 0.4683\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4280 - acc: 0.6770 - val_loss: 1.5843 - val_acc: 0.4864\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4148 - acc: 0.6928 - val_loss: 1.6202 - val_acc: 0.4834\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4179 - acc: 0.6897 - val_loss: 1.6672 - val_acc: 0.4804\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4340 - acc: 0.6742 - val_loss: 1.7587 - val_acc: 0.4622\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4365 - acc: 0.6763 - val_loss: 1.7656 - val_acc: 0.4653\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4196 - acc: 0.6943 - val_loss: 1.8086 - val_acc: 0.4199\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4432 - acc: 0.6692 - val_loss: 1.6525 - val_acc: 0.4834\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4206 - acc: 0.6886 - val_loss: 1.6190 - val_acc: 0.5347\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4410 - acc: 0.6950 - val_loss: 1.5833 - val_acc: 0.4773\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3816 - acc: 0.6974 - val_loss: 1.6361 - val_acc: 0.4622\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3645 - acc: 0.7126 - val_loss: 1.8072 - val_acc: 0.4592\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3783 - acc: 0.7122 - val_loss: 1.9485 - val_acc: 0.3988\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4520 - acc: 0.6516 - val_loss: 1.7899 - val_acc: 0.4079\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4478 - acc: 0.6597 - val_loss: 1.8418 - val_acc: 0.4199\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5214 - acc: 0.6495 - val_loss: 1.5374 - val_acc: 0.5106\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4390 - acc: 0.6840 - val_loss: 1.6653 - val_acc: 0.4532\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 93us/step - loss: 0.3824 - acc: 0.7069 - val_loss: 1.6930 - val_acc: 0.4955\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3609 - acc: 0.7161 - val_loss: 1.7128 - val_acc: 0.5106\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3770 - acc: 0.7091 - val_loss: 1.7663 - val_acc: 0.4653\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4305 - acc: 0.6872 - val_loss: 1.6795 - val_acc: 0.4894\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4113 - acc: 0.6925 - val_loss: 1.7508 - val_acc: 0.4864\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4352 - acc: 0.6661 - val_loss: 1.6275 - val_acc: 0.4622\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4345 - acc: 0.6847 - val_loss: 1.8195 - val_acc: 0.4441\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4053 - acc: 0.6872 - val_loss: 1.7459 - val_acc: 0.4683\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4159 - acc: 0.6883 - val_loss: 1.9103 - val_acc: 0.4199\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4294 - acc: 0.6890 - val_loss: 1.6311 - val_acc: 0.4985\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4086 - acc: 0.7062 - val_loss: 1.7444 - val_acc: 0.4592\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4014 - acc: 0.6995 - val_loss: 1.9855 - val_acc: 0.4350\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4317 - acc: 0.6770 - val_loss: 1.5968 - val_acc: 0.5196\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3793 - acc: 0.7154 - val_loss: 1.6947 - val_acc: 0.5227\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3678 - acc: 0.7207 - val_loss: 1.6717 - val_acc: 0.5378\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4008 - acc: 0.6985 - val_loss: 1.5732 - val_acc: 0.5257\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3804 - acc: 0.7150 - val_loss: 1.6610 - val_acc: 0.5136\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3704 - acc: 0.7133 - val_loss: 1.7868 - val_acc: 0.4955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4044 - acc: 0.7048 - val_loss: 1.7508 - val_acc: 0.4622\n",
      "Epoch 473/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4522 - acc: 0.6826 - val_loss: 1.9482 - val_acc: 0.4048\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4219 - acc: 0.7013 - val_loss: 1.7370 - val_acc: 0.4562\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4023 - acc: 0.7059 - val_loss: 1.7338 - val_acc: 0.4411\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3845 - acc: 0.7083 - val_loss: 1.8892 - val_acc: 0.4713\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3975 - acc: 0.6918 - val_loss: 1.8281 - val_acc: 0.4622\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4393 - acc: 0.6809 - val_loss: 1.6311 - val_acc: 0.5196\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4134 - acc: 0.6921 - val_loss: 1.5783 - val_acc: 0.5227\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3633 - acc: 0.7136 - val_loss: 1.6799 - val_acc: 0.5378\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3580 - acc: 0.7214 - val_loss: 1.7818 - val_acc: 0.4955\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3982 - acc: 0.6978 - val_loss: 1.7748 - val_acc: 0.5166\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4238 - acc: 0.6851 - val_loss: 1.6628 - val_acc: 0.5227\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3773 - acc: 0.7168 - val_loss: 1.7168 - val_acc: 0.5106\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4410 - acc: 0.6735 - val_loss: 1.6102 - val_acc: 0.4773\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5047 - acc: 0.6284 - val_loss: 1.7024 - val_acc: 0.4471\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3879 - acc: 0.6717 - val_loss: 1.7230 - val_acc: 0.4441\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3584 - acc: 0.7013 - val_loss: 1.8043 - val_acc: 0.4471\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3599 - acc: 0.7175 - val_loss: 1.8759 - val_acc: 0.4320\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3903 - acc: 0.6851 - val_loss: 1.7726 - val_acc: 0.4562\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3665 - acc: 0.6893 - val_loss: 1.7260 - val_acc: 0.4743\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3969 - acc: 0.6858 - val_loss: 2.0133 - val_acc: 0.4683\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5088 - acc: 0.6428 - val_loss: 1.6456 - val_acc: 0.4260\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4343 - acc: 0.6351 - val_loss: 1.7079 - val_acc: 0.4804\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3557 - acc: 0.7168 - val_loss: 1.8851 - val_acc: 0.4350\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3766 - acc: 0.6939 - val_loss: 1.8686 - val_acc: 0.4260\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3891 - acc: 0.6869 - val_loss: 1.7673 - val_acc: 0.4471\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3657 - acc: 0.7013 - val_loss: 1.7861 - val_acc: 0.4502\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3871 - acc: 0.652 - 0s 70us/step - loss: 0.3923 - acc: 0.6763 - val_loss: 1.7234 - val_acc: 0.4683\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4423 - acc: 0.6566 - val_loss: 1.7006 - val_acc: 0.4985\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4355 - acc: 0.6907 - val_loss: 1.6275 - val_acc: 0.5227\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3619 - acc: 0.7214 - val_loss: 1.7841 - val_acc: 0.4864\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3514 - acc: 0.7105 - val_loss: 1.9207 - val_acc: 0.4230\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4350 - acc: 0.6552 - val_loss: 1.7175 - val_acc: 0.4411\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4283 - acc: 0.6270 - val_loss: 1.6284 - val_acc: 0.5136\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4104 - acc: 0.6805 - val_loss: 1.7214 - val_acc: 0.5045\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3709 - acc: 0.7031 - val_loss: 1.9222 - val_acc: 0.4773\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3595 - acc: 0.7263 - val_loss: 1.7955 - val_acc: 0.4894\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3368 - acc: 0.7351 - val_loss: 1.8638 - val_acc: 0.4985\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3347 - acc: 0.7496 - val_loss: 1.8542 - val_acc: 0.4955\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3463 - acc: 0.7372 - val_loss: 1.9705 - val_acc: 0.4683\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4300 - acc: 0.728 - 0s 70us/step - loss: 0.4739 - acc: 0.6777 - val_loss: 1.8825 - val_acc: 0.4411\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4317 - acc: 0.6872 - val_loss: 1.7879 - val_acc: 0.4834\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3540 - acc: 0.7309 - val_loss: 2.0870 - val_acc: 0.4230\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3744 - acc: 0.698 - 0s 69us/step - loss: 0.3907 - acc: 0.6999 - val_loss: 2.0806 - val_acc: 0.4169\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3855 - acc: 0.7031 - val_loss: 1.8259 - val_acc: 0.4653\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3390 - acc: 0.7429 - val_loss: 1.7953 - val_acc: 0.5076\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3465 - acc: 0.7312 - val_loss: 1.9491 - val_acc: 0.4411\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4430 - acc: 0.6745 - val_loss: 1.8803 - val_acc: 0.4562\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3842 - acc: 0.7242 - val_loss: 1.7770 - val_acc: 0.4653\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3463 - acc: 0.7312 - val_loss: 1.9423 - val_acc: 0.4804\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3209 - acc: 0.7510 - val_loss: 1.9704 - val_acc: 0.4562\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3495 - acc: 0.7309 - val_loss: 2.0371 - val_acc: 0.4502\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4047 - acc: 0.6837 - val_loss: 2.3042 - val_acc: 0.3988\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4699 - acc: 0.6766 - val_loss: 1.9334 - val_acc: 0.4562\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4513 - acc: 0.6851 - val_loss: 1.7404 - val_acc: 0.4773\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3467 - acc: 0.7386 - val_loss: 1.8298 - val_acc: 0.5015\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3137 - acc: 0.7510 - val_loss: 1.8451 - val_acc: 0.5106\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3213 - acc: 0.7457 - val_loss: 1.8515 - val_acc: 0.5287\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3505 - acc: 0.7411 - val_loss: 1.9075 - val_acc: 0.4834\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4344 - acc: 0.6904 - val_loss: 2.0905 - val_acc: 0.4290\n",
      "Epoch 532/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4193 - acc: 0.7048 - val_loss: 1.8449 - val_acc: 0.4894\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3702 - acc: 0.7334 - val_loss: 1.7486 - val_acc: 0.5257\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3231 - acc: 0.7654 - val_loss: 1.8965 - val_acc: 0.4955\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3439 - acc: 0.7422 - val_loss: 1.9532 - val_acc: 0.4683\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3505 - acc: 0.7372 - val_loss: 2.0604 - val_acc: 0.4350\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4251 - acc: 0.6876 - val_loss: 1.8756 - val_acc: 0.4592\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3686 - acc: 0.7372 - val_loss: 1.8764 - val_acc: 0.4743\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3168 - acc: 0.7640 - val_loss: 1.9376 - val_acc: 0.5076\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3329 - acc: 0.7499 - val_loss: 2.0288 - val_acc: 0.5076\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4429 - acc: 0.6897 - val_loss: 1.7747 - val_acc: 0.4924\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3695 - acc: 0.7267 - val_loss: 1.8313 - val_acc: 0.5136\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3145 - acc: 0.7573 - val_loss: 1.8675 - val_acc: 0.5378\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3432 - acc: 0.7242 - val_loss: 1.9863 - val_acc: 0.4743\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3523 - acc: 0.7400 - val_loss: 2.1790 - val_acc: 0.4471\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4668 - acc: 0.7010 - val_loss: 2.0932 - val_acc: 0.4169\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4757 - acc: 0.6936 - val_loss: 1.7559 - val_acc: 0.4653\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3380 - acc: 0.7563 - val_loss: 1.7410 - val_acc: 0.5106\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3316 - acc: 0.7379 - val_loss: 1.8468 - val_acc: 0.5196\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3269 - acc: 0.7376 - val_loss: 1.9620 - val_acc: 0.4955\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3836 - acc: 0.7263 - val_loss: 1.9339 - val_acc: 0.4834\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3637 - acc: 0.7256 - val_loss: 1.8210 - val_acc: 0.5015\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3047 - acc: 0.7686 - val_loss: 1.9369 - val_acc: 0.4773\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3127 - acc: 0.7658 - val_loss: 1.9415 - val_acc: 0.4924\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3158 - acc: 0.7510 - val_loss: 1.9071 - val_acc: 0.5166\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3787 - acc: 0.7235 - val_loss: 1.8577 - val_acc: 0.4924\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3687 - acc: 0.7319 - val_loss: 2.1154 - val_acc: 0.4804\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3647 - acc: 0.7298 - val_loss: 2.0930 - val_acc: 0.4260\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4102 - acc: 0.7154 - val_loss: 1.9153 - val_acc: 0.5015\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3523 - acc: 0.7369 - val_loss: 1.9543 - val_acc: 0.4562\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3192 - acc: 0.7555 - val_loss: 2.0153 - val_acc: 0.4894\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3129 - acc: 0.7626 - val_loss: 1.9835 - val_acc: 0.4653\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3100 - acc: 0.7573 - val_loss: 2.1025 - val_acc: 0.4139\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3812 - acc: 0.6925 - val_loss: 1.9603 - val_acc: 0.4471\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3503 - acc: 0.6992 - val_loss: 1.7990 - val_acc: 0.4864\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3576 - acc: 0.7189 - val_loss: 1.9347 - val_acc: 0.4320\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4684 - acc: 0.6513 - val_loss: 1.9186 - val_acc: 0.5166\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4723 - acc: 0.6745 - val_loss: 1.7577 - val_acc: 0.5045\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3177 - acc: 0.7418 - val_loss: 1.9507 - val_acc: 0.4985\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3002 - acc: 0.7661 - val_loss: 2.0330 - val_acc: 0.5106\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3050 - acc: 0.7644 - val_loss: 2.0795 - val_acc: 0.4985\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3153 - acc: 0.7485 - val_loss: 1.8984 - val_acc: 0.4562\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3484 - acc: 0.7129 - val_loss: 1.8634 - val_acc: 0.4441\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3823 - acc: 0.6904 - val_loss: 2.0129 - val_acc: 0.4411\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3251 - acc: 0.7168 - val_loss: 1.9368 - val_acc: 0.4864\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3111 - acc: 0.7555 - val_loss: 1.9556 - val_acc: 0.4864\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3541 - acc: 0.7334 - val_loss: 1.9626 - val_acc: 0.5257\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5430 - acc: 0.6626 - val_loss: 1.7556 - val_acc: 0.5076\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3851 - acc: 0.6981 - val_loss: 1.8740 - val_acc: 0.4562\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3335 - acc: 0.7298 - val_loss: 2.0720 - val_acc: 0.4441\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3302 - acc: 0.7270 - val_loss: 2.0066 - val_acc: 0.4622\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3092 - acc: 0.7460 - val_loss: 1.8907 - val_acc: 0.5196\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3108 - acc: 0.7467 - val_loss: 2.0889 - val_acc: 0.4230\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3684 - acc: 0.6862 - val_loss: 2.0468 - val_acc: 0.4260\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3565 - acc: 0.7020 - val_loss: 1.8441 - val_acc: 0.4834\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3337 - acc: 0.7242 - val_loss: 1.8990 - val_acc: 0.4683\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4450 - acc: 0.6957 - val_loss: 1.8838 - val_acc: 0.5015\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3923 - acc: 0.694 - 0s 70us/step - loss: 0.3718 - acc: 0.7179 - val_loss: 1.8605 - val_acc: 0.5106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3103 - acc: 0.7577 - val_loss: 1.9443 - val_acc: 0.4924\n",
      "Epoch 590/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3023 - acc: 0.7587 - val_loss: 2.1125 - val_acc: 0.4320\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3865 - acc: 0.6862 - val_loss: 1.9183 - val_acc: 0.4502\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3259 - acc: 0.7256 - val_loss: 2.0336 - val_acc: 0.4713\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3150 - acc: 0.7443 - val_loss: 1.8954 - val_acc: 0.4622\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3540 - acc: 0.7091 - val_loss: 1.9165 - val_acc: 0.4653\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3612 - acc: 0.7006 - val_loss: 1.9024 - val_acc: 0.5196\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3685 - acc: 0.7207 - val_loss: 1.8783 - val_acc: 0.5166\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3042 - acc: 0.7619 - val_loss: 1.9823 - val_acc: 0.5166\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2950 - acc: 0.7788 - val_loss: 2.1005 - val_acc: 0.4924\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3038 - acc: 0.793 - 0s 70us/step - loss: 0.3490 - acc: 0.7446 - val_loss: 2.0697 - val_acc: 0.4622\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4099 - acc: 0.7126 - val_loss: 2.2057 - val_acc: 0.4350\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3524 - acc: 0.7492 - val_loss: 2.0416 - val_acc: 0.4532\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3036 - acc: 0.7633 - val_loss: 1.9796 - val_acc: 0.4804\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3002 - acc: 0.7707 - val_loss: 2.0785 - val_acc: 0.4320\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3526 - acc: 0.7161 - val_loss: 2.0769 - val_acc: 0.4562\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.3516 - acc: 0.7041 - val_loss: 2.0771 - val_acc: 0.4653\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3092 - acc: 0.7591 - val_loss: 2.0331 - val_acc: 0.4592\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3013 - acc: 0.7700 - val_loss: 2.1493 - val_acc: 0.4985\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3679 - acc: 0.7362 - val_loss: 2.1534 - val_acc: 0.4502\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3630 - acc: 0.7379 - val_loss: 1.9870 - val_acc: 0.4864\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2816 - acc: 0.7880 - val_loss: 2.1492 - val_acc: 0.4592\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2891 - acc: 0.7700 - val_loss: 2.3743 - val_acc: 0.4320\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3563 - acc: 0.7231 - val_loss: 2.5653 - val_acc: 0.3776\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3740 - acc: 0.6914 - val_loss: 2.0525 - val_acc: 0.4502\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3097 - acc: 0.7439 - val_loss: 2.1386 - val_acc: 0.5196\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3096 - acc: 0.7563 - val_loss: 2.2877 - val_acc: 0.4502\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4179 - acc: 0.7013 - val_loss: 2.2452 - val_acc: 0.4502\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3642 - acc: 0.7510 - val_loss: 2.0866 - val_acc: 0.4773\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2983 - acc: 0.7788 - val_loss: 2.0775 - val_acc: 0.5045\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2760 - acc: 0.7915 - val_loss: 2.1437 - val_acc: 0.4955\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2826 - acc: 0.7707 - val_loss: 2.1604 - val_acc: 0.4562\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3197 - acc: 0.7295 - val_loss: 2.1004 - val_acc: 0.4562\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3236 - acc: 0.7323 - val_loss: 2.1899 - val_acc: 0.4592\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3206 - acc: 0.7471 - val_loss: 2.0417 - val_acc: 0.4199\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3973 - acc: 0.6742 - val_loss: 2.0128 - val_acc: 0.4955\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3630 - acc: 0.7337 - val_loss: 2.1373 - val_acc: 0.5166\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3639 - acc: 0.7397 - val_loss: 2.2272 - val_acc: 0.5227\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2942 - acc: 0.7707 - val_loss: 2.0803 - val_acc: 0.4894\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2685 - acc: 0.7894 - val_loss: 2.1693 - val_acc: 0.4804\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.2798 - acc: 0.7897 - val_loss: 2.1738 - val_acc: 0.4985\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2825 - acc: 0.7844 - val_loss: 2.3791 - val_acc: 0.4622\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3901 - acc: 0.7334 - val_loss: 2.8428 - val_acc: 0.3656\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5713 - acc: 0.6636 - val_loss: 1.7001 - val_acc: 0.5166\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3385 - acc: 0.7411 - val_loss: 1.9679 - val_acc: 0.4894\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2796 - acc: 0.7700 - val_loss: 2.1485 - val_acc: 0.4894\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2780 - acc: 0.7901 - val_loss: 2.0717 - val_acc: 0.4834\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2821 - acc: 0.7749 - val_loss: 2.0905 - val_acc: 0.4894\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3055 - acc: 0.7636 - val_loss: 2.0315 - val_acc: 0.4592\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3303 - acc: 0.7291 - val_loss: 2.0024 - val_acc: 0.4864\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2733 - acc: 0.7806 - val_loss: 2.1161 - val_acc: 0.4894\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2740 - acc: 0.7897 - val_loss: 2.0675 - val_acc: 0.4955\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3011 - acc: 0.7573 - val_loss: 2.1138 - val_acc: 0.4471\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3236 - acc: 0.7376 - val_loss: 2.3071 - val_acc: 0.4350\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2991 - acc: 0.7513 - val_loss: 2.2036 - val_acc: 0.4713\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3154 - acc: 0.7555 - val_loss: 2.5256 - val_acc: 0.4169\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3707 - acc: 0.7161 - val_loss: 2.2821 - val_acc: 0.4411\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3081 - acc: 0.755 - 0s 70us/step - loss: 0.3178 - acc: 0.7503 - val_loss: 2.3377 - val_acc: 0.4411\n",
      "Epoch 647/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3375 - acc: 0.7534 - val_loss: 2.1891 - val_acc: 0.4502\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2822 - acc: 0.7714 - val_loss: 2.1975 - val_acc: 0.4804\n",
      "Epoch 649/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2687 - acc: 0.7897 - val_loss: 2.1972 - val_acc: 0.4622\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2801 - acc: 0.7774 - val_loss: 2.1537 - val_acc: 0.4441\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4759 - acc: 0.6629 - val_loss: 1.7583 - val_acc: 0.4622\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.4153 - acc: 0.6650 - val_loss: 1.9084 - val_acc: 0.5166\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2961 - acc: 0.7541 - val_loss: 1.9939 - val_acc: 0.5136\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2621 - acc: 0.7982 - val_loss: 2.0510 - val_acc: 0.4864\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2681 - acc: 0.7799 - val_loss: 2.0513 - val_acc: 0.4955\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2572 - acc: 0.7936 - val_loss: 2.1804 - val_acc: 0.5136\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2793 - acc: 0.7872 - val_loss: 2.2012 - val_acc: 0.4381\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3956 - acc: 0.6911 - val_loss: 2.1144 - val_acc: 0.4381\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3341 - acc: 0.6960 - val_loss: 2.1423 - val_acc: 0.4441\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3136 - acc: 0.7524 - val_loss: 2.3445 - val_acc: 0.4320\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3461 - acc: 0.7186 - val_loss: 2.2203 - val_acc: 0.4622\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2798 - acc: 0.7887 - val_loss: 2.1844 - val_acc: 0.4622\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2520 - acc: 0.8094 - val_loss: 2.1403 - val_acc: 0.4924\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2588 - acc: 0.8077 - val_loss: 2.2744 - val_acc: 0.4411\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3325 - acc: 0.7355 - val_loss: 2.2046 - val_acc: 0.4381\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3661 - acc: 0.6928 - val_loss: 2.0349 - val_acc: 0.4804\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4033 - acc: 0.7270 - val_loss: 1.9153 - val_acc: 0.5136\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3163 - acc: 0.7471 - val_loss: 2.1749 - val_acc: 0.4320\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3153 - acc: 0.7393 - val_loss: 2.1761 - val_acc: 0.4653\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2785 - acc: 0.7791 - val_loss: 2.1315 - val_acc: 0.4592\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2750 - acc: 0.7710 - val_loss: 2.1391 - val_acc: 0.4834\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2847 - acc: 0.7689 - val_loss: 2.3315 - val_acc: 0.4260\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3449 - acc: 0.7091 - val_loss: 2.0010 - val_acc: 0.4562\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2741 - acc: 0.7746 - val_loss: 2.2536 - val_acc: 0.4894\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3099 - acc: 0.7682 - val_loss: 2.2263 - val_acc: 0.4320\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4107 - acc: 0.6812 - val_loss: 1.9479 - val_acc: 0.5136\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3079 - acc: 0.7584 - val_loss: 2.1454 - val_acc: 0.5076\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2429 - acc: 0.7978 - val_loss: 2.3357 - val_acc: 0.5257\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2662 - acc: 0.7932 - val_loss: 2.3780 - val_acc: 0.4955\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2956 - acc: 0.7841 - val_loss: 2.3772 - val_acc: 0.4985\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2847 - acc: 0.7925 - val_loss: 2.3996 - val_acc: 0.4683\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3037 - acc: 0.7700 - val_loss: 2.2903 - val_acc: 0.4683\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3137 - acc: 0.7791 - val_loss: 2.4080 - val_acc: 0.4773\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.3110 - acc: 0.7710 - val_loss: 2.4055 - val_acc: 0.4622\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3031 - acc: 0.7806 - val_loss: 2.5691 - val_acc: 0.4562\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3372 - acc: 0.7679 - val_loss: 2.2370 - val_acc: 0.4804\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2821 - acc: 0.7968 - val_loss: 2.2539 - val_acc: 0.5106\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2501 - acc: 0.8035 - val_loss: 2.2955 - val_acc: 0.5076\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2480 - acc: 0.8052 - val_loss: 2.2489 - val_acc: 0.4622\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2839 - acc: 0.7791 - val_loss: 2.5999 - val_acc: 0.4139\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3235 - acc: 0.7460 - val_loss: 2.7007 - val_acc: 0.4018\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3446 - acc: 0.7207 - val_loss: 2.1723 - val_acc: 0.4683\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2901 - acc: 0.7661 - val_loss: 2.6771 - val_acc: 0.4290\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3889 - acc: 0.7393 - val_loss: 2.2428 - val_acc: 0.4622\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3304 - acc: 0.7580 - val_loss: 2.2761 - val_acc: 0.4713\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2594 - acc: 0.7954 - val_loss: 2.2784 - val_acc: 0.4924\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2491 - acc: 0.8105 - val_loss: 2.4322 - val_acc: 0.4864\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2740 - acc: 0.7961 - val_loss: 2.3136 - val_acc: 0.5015\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2562 - acc: 0.8038 - val_loss: 2.5435 - val_acc: 0.4955\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3155 - acc: 0.7594 - val_loss: 2.2198 - val_acc: 0.4864\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2758 - acc: 0.8013 - val_loss: 2.4269 - val_acc: 0.4864\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2787 - acc: 0.7932 - val_loss: 2.6801 - val_acc: 0.4562\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3137 - acc: 0.7767 - val_loss: 2.6367 - val_acc: 0.4199\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3752 - acc: 0.7422 - val_loss: 2.3752 - val_acc: 0.4804\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2930 - acc: 0.7968 - val_loss: 2.3021 - val_acc: 0.4743\n",
      "Epoch 706/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2623 - acc: 0.8024 - val_loss: 2.2774 - val_acc: 0.4532\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2607 - acc: 0.7848 - val_loss: 2.2408 - val_acc: 0.4924\n",
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2540 - acc: 0.7901 - val_loss: 2.3469 - val_acc: 0.4562\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.2885 - acc: 0.7703 - val_loss: 2.2401 - val_acc: 0.4532\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3398 - acc: 0.7231 - val_loss: 2.1206 - val_acc: 0.4743\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3282 - acc: 0.7400 - val_loss: 2.2396 - val_acc: 0.5136\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2703 - acc: 0.7961 - val_loss: 2.2995 - val_acc: 0.5136\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2708 - acc: 0.8003 - val_loss: 2.2663 - val_acc: 0.5045\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2629 - acc: 0.8080 - val_loss: 2.3837 - val_acc: 0.4955\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2854 - acc: 0.7915 - val_loss: 2.4494 - val_acc: 0.4743\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2594 - acc: 0.7996 - val_loss: 2.5781 - val_acc: 0.4834\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2593 - acc: 0.8066 - val_loss: 2.4738 - val_acc: 0.4502\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2990 - acc: 0.7841 - val_loss: 2.3010 - val_acc: 0.4985\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2789 - acc: 0.7985 - val_loss: 2.7844 - val_acc: 0.4532\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3299 - acc: 0.7732 - val_loss: 2.8968 - val_acc: 0.4199\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3949 - acc: 0.7443 - val_loss: 2.4128 - val_acc: 0.4592\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3110 - acc: 0.7823 - val_loss: 2.2735 - val_acc: 0.4713\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2516 - acc: 0.8013 - val_loss: 2.2627 - val_acc: 0.4773\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2315 - acc: 0.8179 - val_loss: 2.3296 - val_acc: 0.4955\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2299 - acc: 0.8263 - val_loss: 2.3621 - val_acc: 0.4985\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2315 - acc: 0.8239 - val_loss: 2.2494 - val_acc: 0.4955\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2941 - acc: 0.7739 - val_loss: 2.5436 - val_acc: 0.4109\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4107 - acc: 0.6759 - val_loss: 2.2847 - val_acc: 0.4653\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2628 - acc: 0.7791 - val_loss: 2.3477 - val_acc: 0.4924\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2396 - acc: 0.8204 - val_loss: 2.3958 - val_acc: 0.4924\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2331 - acc: 0.8214 - val_loss: 2.5628 - val_acc: 0.4743\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2404 - acc: 0.8158 - val_loss: 2.7543 - val_acc: 0.4471\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3643 - acc: 0.7615 - val_loss: 2.3778 - val_acc: 0.4471\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3314 - acc: 0.7601 - val_loss: 2.3230 - val_acc: 0.5227\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.2772 - acc: 0.7996 - val_loss: 2.3586 - val_acc: 0.5045\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2424 - acc: 0.8197 - val_loss: 2.3442 - val_acc: 0.4924\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2857 - acc: 0.7848 - val_loss: 2.3814 - val_acc: 0.4834\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3405 - acc: 0.7443 - val_loss: 2.1526 - val_acc: 0.4864\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3057 - acc: 0.7400 - val_loss: 2.2839 - val_acc: 0.4592\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2838 - acc: 0.7577 - val_loss: 2.2658 - val_acc: 0.4955\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2377 - acc: 0.8010 - val_loss: 2.3585 - val_acc: 0.5045\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2313 - acc: 0.8225 - val_loss: 2.4214 - val_acc: 0.4834\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2320 - acc: 0.8221 - val_loss: 2.6434 - val_acc: 0.4381\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.2861 - acc: 0.7763 - val_loss: 2.7701 - val_acc: 0.4109\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3360 - acc: 0.7238 - val_loss: 2.5788 - val_acc: 0.4532\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2640 - acc: 0.7858 - val_loss: 2.5842 - val_acc: 0.4532\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2583 - acc: 0.8020 - val_loss: 2.5168 - val_acc: 0.4743\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3267 - acc: 0.7767 - val_loss: 2.9215 - val_acc: 0.4109\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.4058 - acc: 0.7302 - val_loss: 2.6607 - val_acc: 0.4320\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2850 - acc: 0.8059 - val_loss: 2.3126 - val_acc: 0.5045\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2310 - acc: 0.8274 - val_loss: 2.3763 - val_acc: 0.4955\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2299 - acc: 0.8344 - val_loss: 2.6236 - val_acc: 0.4713\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2286 - acc: 0.8260 - val_loss: 2.5610 - val_acc: 0.4864\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2852 - acc: 0.7848 - val_loss: 2.5169 - val_acc: 0.4894\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2942 - acc: 0.7848 - val_loss: 2.2962 - val_acc: 0.4985\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2301 - acc: 0.8225 - val_loss: 2.4328 - val_acc: 0.4985\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2232 - acc: 0.8221 - val_loss: 2.3735 - val_acc: 0.4985\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2311 - acc: 0.8126 - val_loss: 2.4401 - val_acc: 0.4683\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2948 - acc: 0.7587 - val_loss: 2.5214 - val_acc: 0.4350\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.4006 - acc: 0.6985 - val_loss: 2.1221 - val_acc: 0.4804\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3170 - acc: 0.7351 - val_loss: 2.2736 - val_acc: 0.5136\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2810 - acc: 0.7784 - val_loss: 2.2285 - val_acc: 0.5196\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2478 - acc: 0.8119 - val_loss: 2.1713 - val_acc: 0.5257\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2206 - acc: 0.8274 - val_loss: 2.3908 - val_acc: 0.4773\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2456 - acc: 0.8116 - val_loss: 2.6182 - val_acc: 0.4079\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3343 - acc: 0.7231 - val_loss: 2.2856 - val_acc: 0.4502\n",
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.2694 - acc: 0.7658 - val_loss: 2.4588 - val_acc: 0.5015\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.2426 - acc: 0.8101 - val_loss: 2.4892 - val_acc: 0.5227\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2623 - acc: 0.8024 - val_loss: 2.3846 - val_acc: 0.5166\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2518 - acc: 0.8130 - val_loss: 2.3773 - val_acc: 0.5196\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2406 - acc: 0.8190 - val_loss: 2.4360 - val_acc: 0.4924\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2406 - acc: 0.8137 - val_loss: 2.3853 - val_acc: 0.4955\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2184 - acc: 0.8302 - val_loss: 2.4397 - val_acc: 0.4713\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2955 - acc: 0.7756 - val_loss: 2.8968 - val_acc: 0.3807\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4239 - acc: 0.6731 - val_loss: 2.1290 - val_acc: 0.4804\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2785 - acc: 0.7725 - val_loss: 2.3542 - val_acc: 0.4955\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2266 - acc: 0.8309 - val_loss: 2.4660 - val_acc: 0.5076\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.2595 - acc: 0.8013 - val_loss: 2.5362 - val_acc: 0.5136\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2703 - acc: 0.8052 - val_loss: 2.5354 - val_acc: 0.4955\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2383 - acc: 0.8288 - val_loss: 2.4973 - val_acc: 0.5076\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2372 - acc: 0.8168 - val_loss: 2.6763 - val_acc: 0.4683\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2829 - acc: 0.7943 - val_loss: 3.2204 - val_acc: 0.3837\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4479 - acc: 0.7091 - val_loss: 2.5155 - val_acc: 0.4320\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2883 - acc: 0.7922 - val_loss: 2.3952 - val_acc: 0.4834\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2197 - acc: 0.8323 - val_loss: 2.4328 - val_acc: 0.4864\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2133 - acc: 0.8436 - val_loss: 2.5144 - val_acc: 0.4924\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2314 - acc: 0.8302 - val_loss: 2.5966 - val_acc: 0.4834\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2461 - acc: 0.8168 - val_loss: 2.7712 - val_acc: 0.4502\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3162 - acc: 0.7739 - val_loss: 2.5783 - val_acc: 0.4562\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2702 - acc: 0.7992 - val_loss: 2.6068 - val_acc: 0.4713\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2225 - acc: 0.8285 - val_loss: 2.6334 - val_acc: 0.5015\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2011 - acc: 0.8411 - val_loss: 2.6679 - val_acc: 0.5015\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1936 - acc: 0.8492 - val_loss: 2.5915 - val_acc: 0.4985\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2050 - acc: 0.8503 - val_loss: 2.6744 - val_acc: 0.4773\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2228 - acc: 0.8327 - val_loss: 2.6350 - val_acc: 0.4924\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2230 - acc: 0.8302 - val_loss: 2.8368 - val_acc: 0.4502\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2400 - acc: 0.8292 - val_loss: 3.0707 - val_acc: 0.4230\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3026 - acc: 0.7872 - val_loss: 3.5141 - val_acc: 0.3746\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5052 - acc: 0.6668 - val_loss: 2.4478 - val_acc: 0.4653\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3364 - acc: 0.7679 - val_loss: 2.4693 - val_acc: 0.4502\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2602 - acc: 0.8232 - val_loss: 2.4888 - val_acc: 0.4804\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2119 - acc: 0.8507 - val_loss: 2.5538 - val_acc: 0.4864\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2054 - acc: 0.8422 - val_loss: 2.6803 - val_acc: 0.4955\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2048 - acc: 0.8426 - val_loss: 2.8445 - val_acc: 0.4955\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2421 - acc: 0.8168 - val_loss: 2.7612 - val_acc: 0.4260\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3546 - acc: 0.7672 - val_loss: 3.1501 - val_acc: 0.4260\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3916 - acc: 0.7485 - val_loss: 2.7873 - val_acc: 0.4290\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3717 - acc: 0.7555 - val_loss: 2.4301 - val_acc: 0.4562\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2546 - acc: 0.7869 - val_loss: 2.4155 - val_acc: 0.4894\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2104 - acc: 0.8299 - val_loss: 2.4549 - val_acc: 0.5045\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1998 - acc: 0.8337 - val_loss: 2.7094 - val_acc: 0.4743\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.1878 - acc: 0.8591 - val_loss: 2.7674 - val_acc: 0.4773\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2313 - acc: 0.8320 - val_loss: 2.8614 - val_acc: 0.4532\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2872 - acc: 0.8010 - val_loss: 2.5712 - val_acc: 0.4864\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2422 - acc: 0.8186 - val_loss: 2.8038 - val_acc: 0.4773\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2317 - acc: 0.8267 - val_loss: 3.0030 - val_acc: 0.4350\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3026 - acc: 0.7887 - val_loss: 2.6660 - val_acc: 0.4562\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2749 - acc: 0.8123 - val_loss: 2.6931 - val_acc: 0.4713\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2100 - acc: 0.8411 - val_loss: 2.6677 - val_acc: 0.4924\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.1898 - acc: 0.8595 - val_loss: 2.7030 - val_acc: 0.4592\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1942 - acc: 0.8482 - val_loss: 2.7217 - val_acc: 0.4804\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2006 - acc: 0.8433 - val_loss: 2.7073 - val_acc: 0.4713\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2601 - acc: 0.7999 - val_loss: 2.9446 - val_acc: 0.4320\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4418 - acc: 0.6738 - val_loss: 2.4598 - val_acc: 0.4502\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2672 - acc: 0.7848 - val_loss: 2.6252 - val_acc: 0.4834\n",
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2152 - acc: 0.8337 - val_loss: 2.4955 - val_acc: 0.5015\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2810 - acc: 0.8035 - val_loss: 2.4978 - val_acc: 0.4864\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3689 - acc: 0.7337 - val_loss: 2.2270 - val_acc: 0.5196\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2600 - acc: 0.8006 - val_loss: 2.7530 - val_acc: 0.4804\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2212 - acc: 0.8306 - val_loss: 2.5938 - val_acc: 0.4894\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.1982 - acc: 0.8499 - val_loss: 2.6736 - val_acc: 0.4955\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1878 - acc: 0.8588 - val_loss: 2.7686 - val_acc: 0.4532\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2226 - acc: 0.8207 - val_loss: 2.8162 - val_acc: 0.4411\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3024 - acc: 0.7605 - val_loss: 2.7554 - val_acc: 0.4109\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2659 - acc: 0.7742 - val_loss: 2.4950 - val_acc: 0.4894\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2289 - acc: 0.8246 - val_loss: 2.6364 - val_acc: 0.4713\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2608 - acc: 0.7763 - val_loss: 2.4867 - val_acc: 0.5106\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2653 - acc: 0.8010 - val_loss: 2.6134 - val_acc: 0.4592\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2843 - acc: 0.7700 - val_loss: 2.5479 - val_acc: 0.4471\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2382 - acc: 0.8003 - val_loss: 2.5947 - val_acc: 0.4471\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2586 - acc: 0.7788 - val_loss: 2.8546 - val_acc: 0.4683\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2156 - acc: 0.8281 - val_loss: 2.8762 - val_acc: 0.4411\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2534 - acc: 0.8168 - val_loss: 2.8106 - val_acc: 0.4411\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2432 - acc: 0.8031 - val_loss: 2.7736 - val_acc: 0.4320\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2350 - acc: 0.8017 - val_loss: 2.5841 - val_acc: 0.4894\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2221 - acc: 0.8267 - val_loss: 2.5695 - val_acc: 0.4713\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2985 - acc: 0.7615 - val_loss: 2.3794 - val_acc: 0.4894\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2714 - acc: 0.7939 - val_loss: 2.5627 - val_acc: 0.5015\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2355 - acc: 0.8137 - val_loss: 2.5862 - val_acc: 0.5015\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1968 - acc: 0.8524 - val_loss: 2.6782 - val_acc: 0.4955\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2098 - acc: 0.8348 - val_loss: 2.6294 - val_acc: 0.4834\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.2221 - acc: 0.8126 - val_loss: 2.7670 - val_acc: 0.4350\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3455 - acc: 0.7164 - val_loss: 2.4869 - val_acc: 0.4532\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2760 - acc: 0.7598 - val_loss: 2.4760 - val_acc: 0.5257\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2483 - acc: 0.8091 - val_loss: 2.6343 - val_acc: 0.4894\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2361 - acc: 0.8207 - val_loss: 2.6127 - val_acc: 0.4713\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2144 - acc: 0.8309 - val_loss: 2.5005 - val_acc: 0.5045\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2291 - acc: 0.8232 - val_loss: 2.7259 - val_acc: 0.4441\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3054 - acc: 0.7555 - val_loss: 2.6859 - val_acc: 0.4441\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2432 - acc: 0.7844 - val_loss: 2.9190 - val_acc: 0.4622\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2169 - acc: 0.8235 - val_loss: 2.9851 - val_acc: 0.4653\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2049 - acc: 0.8373 - val_loss: 2.7733 - val_acc: 0.4773\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.1931 - acc: 0.8464 - val_loss: 2.9287 - val_acc: 0.4653\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2116 - acc: 0.8387 - val_loss: 3.1236 - val_acc: 0.4260\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.2865 - acc: 0.7982 - val_loss: 2.6378 - val_acc: 0.4441\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3556 - acc: 0.7161 - val_loss: 2.3225 - val_acc: 0.4864\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3556 - acc: 0.7506 - val_loss: 2.5656 - val_acc: 0.5015\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2088 - acc: 0.8320 - val_loss: 2.6287 - val_acc: 0.5045\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1992 - acc: 0.8549 - val_loss: 2.8695 - val_acc: 0.4804\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.2188 - acc: 0.8337 - val_loss: 3.1998 - val_acc: 0.4350\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.2868 - acc: 0.8027 - val_loss: 2.9942 - val_acc: 0.4441\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3120 - acc: 0.7894 - val_loss: 2.7824 - val_acc: 0.4773\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2196 - acc: 0.8429 - val_loss: 2.8038 - val_acc: 0.4955\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2088 - acc: 0.8471 - val_loss: 2.9128 - val_acc: 0.4955\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2048 - acc: 0.8499 - val_loss: 2.8698 - val_acc: 0.5045\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.1982 - acc: 0.8517 - val_loss: 3.0299 - val_acc: 0.4592\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.2537 - acc: 0.8052 - val_loss: 2.8290 - val_acc: 0.4471\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2641 - acc: 0.8116 - val_loss: 2.7523 - val_acc: 0.5136\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2315 - acc: 0.8362 - val_loss: 2.9231 - val_acc: 0.4894\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2337 - acc: 0.8295 - val_loss: 2.7818 - val_acc: 0.4804\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2254 - acc: 0.8404 - val_loss: 2.9437 - val_acc: 0.4894\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2615 - acc: 0.8116 - val_loss: 2.6127 - val_acc: 0.5136\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2012 - acc: 0.8542 - val_loss: 2.7292 - val_acc: 0.5045\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.1994 - acc: 0.8531 - val_loss: 2.8304 - val_acc: 0.5076\n",
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1977 - acc: 0.8535 - val_loss: 3.2795 - val_acc: 0.4441\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2771 - acc: 0.8119 - val_loss: 3.4896 - val_acc: 0.4109\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4702 - acc: 0.7052 - val_loss: 2.8961 - val_acc: 0.4532\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2816 - acc: 0.7915 - val_loss: 2.8164 - val_acc: 0.4773\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2039 - acc: 0.8426 - val_loss: 2.8251 - val_acc: 0.4592\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.1990 - acc: 0.8362 - val_loss: 2.6575 - val_acc: 0.4773\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1931 - acc: 0.8482 - val_loss: 2.7902 - val_acc: 0.4804\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.1915 - acc: 0.8559 - val_loss: 2.7686 - val_acc: 0.4562\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2329 - acc: 0.8186 - val_loss: 2.8103 - val_acc: 0.4411\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2582 - acc: 0.7887 - val_loss: 2.5496 - val_acc: 0.4985\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2496 - acc: 0.8049 - val_loss: 2.5463 - val_acc: 0.5196\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2113 - acc: 0.8387 - val_loss: 2.7667 - val_acc: 0.4924\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1990 - acc: 0.8447 - val_loss: 2.7071 - val_acc: 0.4713\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2492 - acc: 0.8126 - val_loss: 2.9921 - val_acc: 0.4230\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3202 - acc: 0.7471 - val_loss: 2.6172 - val_acc: 0.5136\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2508 - acc: 0.7996 - val_loss: 2.7462 - val_acc: 0.4834\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.1821 - acc: 0.8514 - val_loss: 2.8423 - val_acc: 0.4864\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.1644 - acc: 0.8721 - val_loss: 3.0242 - val_acc: 0.4834\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2069 - acc: 0.8468 - val_loss: 3.1085 - val_acc: 0.4743\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2970 - acc: 0.7985 - val_loss: 3.0991 - val_acc: 0.4260\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2893 - acc: 0.8006 - val_loss: 3.0995 - val_acc: 0.4592\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2411 - acc: 0.8292 - val_loss: 3.0122 - val_acc: 0.4350\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2465 - acc: 0.8232 - val_loss: 2.6196 - val_acc: 0.4985\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2027 - acc: 0.8440 - val_loss: 2.6069 - val_acc: 0.4864\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2153 - acc: 0.8267 - val_loss: 2.7014 - val_acc: 0.4713\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2838 - acc: 0.7876 - val_loss: 2.6292 - val_acc: 0.4592\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2589 - acc: 0.7897 - val_loss: 2.7404 - val_acc: 0.4653\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.2294 - acc: 0.798 - 0s 70us/step - loss: 0.2174 - acc: 0.8140 - val_loss: 2.8922 - val_acc: 0.4653\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1769 - acc: 0.8588 - val_loss: 2.8594 - val_acc: 0.4864\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1797 - acc: 0.8644 - val_loss: 2.9425 - val_acc: 0.4804\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1752 - acc: 0.8630 - val_loss: 2.8183 - val_acc: 0.4955\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.1868 - acc: 0.8489 - val_loss: 2.7580 - val_acc: 0.4622\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2851 - acc: 0.7834 - val_loss: 2.7044 - val_acc: 0.4441\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3962 - acc: 0.7038 - val_loss: 2.4426 - val_acc: 0.5317\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3644 - acc: 0.7601 - val_loss: 2.9041 - val_acc: 0.5076\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2193 - acc: 0.8411 - val_loss: 2.7712 - val_acc: 0.4804\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.1786 - acc: 0.8707 - val_loss: 2.8299 - val_acc: 0.4924\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.1685 - acc: 0.8788 - val_loss: 3.0128 - val_acc: 0.4864\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.1718 - acc: 0.8676 - val_loss: 3.0119 - val_acc: 0.4894\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2113 - acc: 0.8552 - val_loss: 3.2041 - val_acc: 0.4653\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2285 - acc: 0.8302 - val_loss: 2.9885 - val_acc: 0.4864\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2224 - acc: 0.8401 - val_loss: 2.8531 - val_acc: 0.5045\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1769 - acc: 0.8683 - val_loss: 2.8905 - val_acc: 0.5076\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1805 - acc: 0.8605 - val_loss: 3.1949 - val_acc: 0.4834\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2711 - acc: 0.8151 - val_loss: 3.0822 - val_acc: 0.4683\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2843 - acc: 0.8070 - val_loss: 2.8347 - val_acc: 0.4834\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.2084 - acc: 0.864 - 0s 70us/step - loss: 0.2056 - acc: 0.8507 - val_loss: 2.9090 - val_acc: 0.4713\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.1990 - acc: 0.8563 - val_loss: 2.9849 - val_acc: 0.4471\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2410 - acc: 0.8108 - val_loss: 2.8991 - val_acc: 0.4592\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2152 - acc: 0.8415 - val_loss: 3.1294 - val_acc: 0.4350\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2567 - acc: 0.8137 - val_loss: 2.8194 - val_acc: 0.4532\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2651 - acc: 0.7791 - val_loss: 2.6919 - val_acc: 0.4713\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3387 - acc: 0.7379 - val_loss: 2.4233 - val_acc: 0.4894\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3265 - acc: 0.7788 - val_loss: 2.6113 - val_acc: 0.4924\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.1796 - acc: 0.8672 - val_loss: 2.7950 - val_acc: 0.4773\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.1797 - acc: 0.8616 - val_loss: 2.8690 - val_acc: 0.4864\n",
      "Epoch 941/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2015 - acc: 0.8334 - val_loss: 2.6971 - val_acc: 0.4864\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2057 - acc: 0.8239 - val_loss: 2.6950 - val_acc: 0.4834\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1973 - acc: 0.8478 - val_loss: 2.9253 - val_acc: 0.4653\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2038 - acc: 0.8422 - val_loss: 2.9466 - val_acc: 0.4441\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3009 - acc: 0.7661 - val_loss: 2.7075 - val_acc: 0.4773\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2042 - acc: 0.8355 - val_loss: 2.8491 - val_acc: 0.4864\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1814 - acc: 0.8665 - val_loss: 2.8545 - val_acc: 0.4924\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2099 - acc: 0.8334 - val_loss: 2.7941 - val_acc: 0.4653\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2773 - acc: 0.7626 - val_loss: 2.9801 - val_acc: 0.4502\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2630 - acc: 0.7918 - val_loss: 2.6819 - val_acc: 0.4834\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1963 - acc: 0.8450 - val_loss: 2.8938 - val_acc: 0.4502\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2244 - acc: 0.8175 - val_loss: 2.6570 - val_acc: 0.5045\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2220 - acc: 0.8218 - val_loss: 2.8860 - val_acc: 0.4924\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.1797 - acc: 0.8619 - val_loss: 3.1032 - val_acc: 0.5045\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.1775 - acc: 0.8662 - val_loss: 3.2841 - val_acc: 0.4653\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2103 - acc: 0.8485 - val_loss: 3.0415 - val_acc: 0.5136\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2270 - acc: 0.8362 - val_loss: 3.0646 - val_acc: 0.5015\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2154 - acc: 0.8401 - val_loss: 2.9180 - val_acc: 0.4743\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2084 - acc: 0.8521 - val_loss: 2.9006 - val_acc: 0.5136\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.2066 - acc: 0.8549 - val_loss: 2.5825 - val_acc: 0.5136\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2725 - acc: 0.7992 - val_loss: 2.7616 - val_acc: 0.4622\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3332 - acc: 0.7506 - val_loss: 2.5067 - val_acc: 0.4924\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2405 - acc: 0.8003 - val_loss: 2.8391 - val_acc: 0.4834\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.1729 - acc: 0.8584 - val_loss: 2.8252 - val_acc: 0.4955\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1624 - acc: 0.8704 - val_loss: 3.0005 - val_acc: 0.4864\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1725 - acc: 0.8760 - val_loss: 2.9544 - val_acc: 0.5136\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1660 - acc: 0.8771 - val_loss: 2.8750 - val_acc: 0.5045\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1577 - acc: 0.8774 - val_loss: 2.8247 - val_acc: 0.4743\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1873 - acc: 0.8514 - val_loss: 3.1501 - val_acc: 0.4562\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2927 - acc: 0.7978 - val_loss: 3.2736 - val_acc: 0.4230\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5090 - acc: 0.6601 - val_loss: 2.5836 - val_acc: 0.4955\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3506 - acc: 0.7598 - val_loss: 2.7120 - val_acc: 0.5015\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1802 - acc: 0.8489 - val_loss: 2.9225 - val_acc: 0.4894\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1657 - acc: 0.8760 - val_loss: 2.9762 - val_acc: 0.4773\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1665 - acc: 0.8785 - val_loss: 2.9779 - val_acc: 0.5136\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1783 - acc: 0.8676 - val_loss: 3.1854 - val_acc: 0.4713\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.1908 - acc: 0.8591 - val_loss: 3.5462 - val_acc: 0.4592\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2756 - acc: 0.8154 - val_loss: 2.9582 - val_acc: 0.4653\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2067 - acc: 0.8549 - val_loss: 3.1824 - val_acc: 0.5045\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1719 - acc: 0.8781 - val_loss: 3.1548 - val_acc: 0.4773\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.1706 - acc: 0.8746 - val_loss: 3.0379 - val_acc: 0.4955\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.1658 - acc: 0.8809 - val_loss: 3.0713 - val_acc: 0.5076\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.1524 - acc: 0.8827 - val_loss: 3.4171 - val_acc: 0.5106\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2550 - acc: 0.8242 - val_loss: 3.1545 - val_acc: 0.4502\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2889 - acc: 0.8017 - val_loss: 3.1939 - val_acc: 0.4592\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2452 - acc: 0.8330 - val_loss: 3.6603 - val_acc: 0.4109\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3301 - acc: 0.7971 - val_loss: 3.3020 - val_acc: 0.4411\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2439 - acc: 0.8302 - val_loss: 2.9043 - val_acc: 0.4864\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.1696 - acc: 0.8764 - val_loss: 3.2241 - val_acc: 0.4562\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.1783 - acc: 0.8647 - val_loss: 3.2615 - val_acc: 0.4441\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1872 - acc: 0.8619 - val_loss: 3.0147 - val_acc: 0.4985\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1701 - acc: 0.8848 - val_loss: 3.0910 - val_acc: 0.4713\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1644 - acc: 0.8714 - val_loss: 3.4281 - val_acc: 0.4471\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2479 - acc: 0.8235 - val_loss: 3.2148 - val_acc: 0.4683\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2825 - acc: 0.8020 - val_loss: 3.1504 - val_acc: 0.4592\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.2005 - acc: 0.8602 - val_loss: 3.2225 - val_acc: 0.4713\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1751 - acc: 0.8707 - val_loss: 3.0683 - val_acc: 0.4804\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1552 - acc: 0.8764 - val_loss: 3.1314 - val_acc: 0.4622\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.1627 - acc: 0.8806 - val_loss: 3.0942 - val_acc: 0.4955\n",
      "Epoch 1000/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.1670 - acc: 0.8820 - val_loss: 3.0295 - val_acc: 0.4653\n"
     ]
    }
   ],
   "source": [
    "w2v_model = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None,\n",
    "          class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkQIFBRERKVBQEBGRgv8HFuArBgF/gQsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x163ea6ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model.history['acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991869918699187\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_w2v)\n",
    "model_metrics(predictions, X_test, y_cat_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod = model.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df = pd.DataFrame(X_test_cat_mod )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df['loss'] = np.where(X_test_cat_mod_df[0]> X_test_cat_mod_df[3], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df['gain'] = np.where(X_test_cat_mod_df[4]> X_test_cat_mod_df[1], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2 = pd.merge(X_test_cat_mod_df, y_cat_test_w2v, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_large'] = np.where(X_test_cat_mod_df[4]> X_test_cat_mod_df[2], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_large'] = np.where(X_test_cat_mod_df[0]> X_test_cat_mod_df[2], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_large_true'] = np.where((X_test_cat_mod_df_2['loss_large'] == 1) & (X_test_cat_mod_df_2['2'] == 1) | (X_test_cat_mod_df_2['1'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_large_true'] = np.where((X_test_cat_mod_df_2['gain_large'] == 1) & (X_test_cat_mod_df_2['4'] == 1) | (X_test_cat_mod_df_2['5'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'] = np.where((X_test_cat_mod_df_2['gain'] == 1) & (X_test_cat_mod_df_2['4'] == 1) | (X_test_cat_mod_df_2['5'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_large'] = np.where(X_test_cat_mod_df[0]> X_test_cat_mod_df[2], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_stay'] = np.where((X_test_cat_mod_df_2['gain'] == 1) & (X_test_cat_mod_df_2['3'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_true_true'] = np.where((X_test_cat_mod_df_2['loss'] == 1) & (X_test_cat_mod_df_2['2'] == 1) | (X_test_cat_mod_df_2['1'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_stay'] = np.where((X_test_cat_mod_df_2['loss'] == 1) & (X_test_cat_mod_df_2['3'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991869918699187"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'].sum() / X_test_cat_mod_df_2['gain'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791666666666666"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_large_true'].sum() / X_test_cat_mod_df_2['gain_large'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_large_true'].sum() / X_test_cat_mod_df_2['loss_large'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2926829268292683"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_stay'].sum() / X_test_cat_mod_df_2['gain'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_true_true'].sum() / X_test_cat_mod_df_2['loss'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_stay'].sum() / X_test_cat_mod_df_2['loss'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6615384615384615"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'].sum() / (X_test_cat_mod_df_2['4'].sum() + X_test_cat_mod_df_2['5'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.105263157894737"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss'].sum() / (X_test_cat_mod_df_2['1'].sum() + X_test_cat_mod_df_2['2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_true_true'].sum() / (X_test_cat_mod_df_2['1'].sum() + X_test_cat_mod_df_2['2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.105263157894737"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss'].sum() / (X_test_cat_mod_df_2['1'].sum() + X_test_cat_mod_df_2['2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_stay'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_large_true'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
