{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean notebook to be only new \n",
    "- Be able to merge train features and train targets\n",
    "- same with test\n",
    "- be able to then split and run program\n",
    "- test for overfit\n",
    "- create additional features (business/extra features from swing/ extra features from bugs)\n",
    "- run reviews for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "list_of_file_names_org = list_of_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_MedianListingPricePerSqft_AllHomes.csv'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset].copy()\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(str)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_df = build_useful_df(read_data_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_list = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 10000:\n",
    "        sixteen_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_columns = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    columns = file.columns\n",
    "    if '2017-01' in columns:\n",
    "        good_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_good = []\n",
    "for num in sixteen_list:\n",
    "    if num in good_columns:\n",
    "        sixteen_good.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_data = useful_df[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data_list = []\n",
    "for i, data in enumerate(useful_df):\n",
    "    if i in sixteen_good:\n",
    "        final_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10066"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PctPriceCut</th>\n",
       "      <th>DaysOnMarket</th>\n",
       "      <th>BuyerSellerIndex</th>\n",
       "      <th>BuyerSellerIndexMetro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99654</th>\n",
       "      <td>11.142857</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99645</th>\n",
       "      <td>7.589286</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99577</th>\n",
       "      <td>8.108108</td>\n",
       "      <td>79.5</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99567</th>\n",
       "      <td>9.836066</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99518</th>\n",
       "      <td>14.925373</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.260083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PctPriceCut  DaysOnMarket  BuyerSellerIndex  BuyerSellerIndexMetro\n",
       "RegionName                                                                    \n",
       "99654         11.142857          82.0          9.230769               7.260083\n",
       "99645          7.589286          74.0          0.769231               7.260083\n",
       "99577          8.108108          79.5          4.615385               7.260083\n",
       "99567          9.836066          76.0          2.307692               7.260083\n",
       "99518         14.925373          85.0         10.000000               7.260083"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "useful_df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(df, past_time_string, now_string):\n",
    "    #df.dropna(inplace=True)\n",
    "    features = pd.DataFrame()\n",
    "    #features['RegionName'] = df['RegionName']\n",
    "    mean = df.loc[:, past_time_string : now_string].mean(axis=1)\n",
    "    features['mean'] = mean\n",
    "    std = df.loc[:, past_time_string : now_string].std(axis=1)\n",
    "    features['std'] = std\n",
    "    mn = df.loc[:, past_time_string : now_string].min(axis=1)\n",
    "    features['min'] = mn\n",
    "    mx = df.loc[:, past_time_string : now_string].max(axis=1)\n",
    "    features['max'] = mx\n",
    "    features['swing'] = mx - mn\n",
    "    change = df[now_string] - df[past_time_string]\n",
    "    features['change'] = change\n",
    "    mean_swing = features['swing'].mean()\n",
    "    features['swing_pos'] = np.where(features['swing']>mean_swing, 1, 0)\n",
    "    big_swing = features['swing'].std() + mean_swing\n",
    "    features['swing_big'] = np.where(features['swing']>big_swing, 1, 0)\n",
    "    features['swing_neg'] = np.where(features['swing']<mean_swing, 1, 0)\n",
    "    swing_big_loss = mean_swing - features['swing'].std() \n",
    "    features['swing_loss_big'] = np.where(features['swing']<swing_big_loss, 1, 0)\n",
    "    return features\n",
    "    \n",
    "\n",
    "def make_modeling_data(df_list, df_for_target, now_string):\n",
    "    df_one = pd.DataFrame()\n",
    "    target = pd.DataFrame()\n",
    "    now_time = pd.to_datetime(now_string)\n",
    "    now_value = df_for_target[now_string]\n",
    "    future_time = now_time + timedelta(days=6*31)\n",
    "    future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    future_value = df_for_target[future_time_string]\n",
    "    target['target'] = future_value/now_value\n",
    "    \n",
    "    \n",
    "    past_time = now_time - timedelta(days=6*31)\n",
    "    past_time_string= past_time.strftime(\"%Y-%m\")\n",
    "    df_to_use_for_features_org= df_list[0].loc[:, :now_string]\n",
    "    features_org = make_features(df_to_use_for_features_org, past_time_string, now_string)\n",
    "    df_one = pd.merge(df_one, features_org, left_index=True, right_index=True, how = 'right')\n",
    "    for i, df in enumerate(df_list[1:]):\n",
    "        ind = str(i)\n",
    "        columns = df.columns\n",
    "        if '2011-01' in columns and '2012-01' in columns and '2013-01' in columns and '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "            df_to_use_for_features= df.loc[:, :now_string]\n",
    "            features = make_features(df_to_use_for_features, past_time_string, now_string)\n",
    "            df_one = pd.merge(df_one, features, right_index=True, left_index=True, how='inner')\n",
    "    target = target.loc[df_one.index]    \n",
    "    \n",
    "\n",
    "    \n",
    "    return df_one, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_features, test_targets = make_modeling_data(final_data_list, target_data, \"2017-06\")\n",
    "train_features, train_targets = make_modeling_data(final_data_list, target_data, \"2017-01\")\n",
    "train_features = train_features.append(train_features)\n",
    "train_targets = train_targets.append(train_targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "date_counter = 0\n",
    "for year in [\"2012\", \"2013\", \"2014\", \"2015\", \"2016\"]:\n",
    "    for month in [\"06\",\"12\"]:\n",
    "            new_time = year+\"-\"+month\n",
    "            date_counter += 1\n",
    "            extra_train_features, extra_train_targets = make_modeling_data(final_data_list, target_data, new_time)\n",
    "            train_features = train_features.append(extra_train_features)\n",
    "            train_targets = train_targets.append(extra_train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have not worked on w2v today; focused on business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features = pd.read_csv('real_business_w2v_features_3_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features['postal_code'] = w2v_features['postal_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 512)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features.index = w2v_features['postal_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_features = w2v_features.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>average_review_count</th>\n",
       "      <th>business_count</th>\n",
       "      <th>zip_review_count</th>\n",
       "      <th>average_review_max</th>\n",
       "      <th>average_review_min</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.499208</td>\n",
       "      <td>-81.536689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>-0.050745</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>-0.067859</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.073559</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>-0.062522</td>\n",
       "      <td>0.054272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.964078</td>\n",
       "      <td>-73.285549</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>0.043280</td>\n",
       "      <td>-0.032233</td>\n",
       "      <td>-0.017144</td>\n",
       "      <td>0.060047</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>0.063483</td>\n",
       "      <td>-0.041164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.780821</td>\n",
       "      <td>-74.150722</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032312</td>\n",
       "      <td>-0.024693</td>\n",
       "      <td>-0.019165</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>-0.044335</td>\n",
       "      <td>-0.020998</td>\n",
       "      <td>0.041530</td>\n",
       "      <td>-0.048317</td>\n",
       "      <td>0.086379</td>\n",
       "      <td>-0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.083200</td>\n",
       "      <td>11.858200</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014649</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.033006</td>\n",
       "      <td>-0.015937</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.094979</td>\n",
       "      <td>0.085854</td>\n",
       "      <td>-0.037768</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>0.033392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.213256</td>\n",
       "      <td>11.763245</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013431</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.083113</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>0.023717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_open   latitude  longitude  review_count     stars  \\\n",
       "postal_code                                                          \n",
       "2224             1.0  41.499208 -81.536689      7.000000  2.500000   \n",
       "5440             1.0  44.964078 -73.285549      4.000000  4.250000   \n",
       "5452             1.0  40.780821 -74.150722     49.000000  4.000000   \n",
       "6618             1.0  51.083200  11.858200      8.000000  3.500000   \n",
       "6632             1.0  51.213256  11.763245      5.888889  4.222222   \n",
       "\n",
       "             average_review_count  business_count  zip_review_count  \\\n",
       "postal_code                                                           \n",
       "2224                     7.000000             1.0               7.0   \n",
       "5440                     4.000000             2.0               8.0   \n",
       "5452                    49.000000             1.0              49.0   \n",
       "6618                     8.000000             1.0               8.0   \n",
       "6632                     5.888889             9.0              53.0   \n",
       "\n",
       "             average_review_max  average_review_min    ...          490  \\\n",
       "postal_code                                            ...                \n",
       "2224                        7.0                 7.0    ...    -0.007905   \n",
       "5440                        5.0                 3.0    ...     0.024744   \n",
       "5452                       49.0                49.0    ...    -0.032312   \n",
       "6618                        8.0                 8.0    ...    -0.014649   \n",
       "6632                        8.0                 3.0    ...    -0.013431   \n",
       "\n",
       "                  491       492       493       494       495       496  \\\n",
       "postal_code                                                               \n",
       "2224        -0.050745  0.019509  0.089886 -0.067859 -0.057686 -0.073559   \n",
       "5440         0.024881  0.039596  0.043280 -0.032233 -0.017144  0.060047   \n",
       "5452        -0.024693 -0.019165  0.015924 -0.044335 -0.020998  0.041530   \n",
       "6618         0.000344  0.033006 -0.015937  0.011044  0.094979  0.085854   \n",
       "6632         0.007048  0.017738 -0.013003  0.016217  0.083113  0.092610   \n",
       "\n",
       "                  497       498       499  \n",
       "postal_code                                \n",
       "2224         0.004500 -0.062522  0.054272  \n",
       "5440        -0.002217  0.063483 -0.041164  \n",
       "5452        -0.048317  0.086379 -0.008370  \n",
       "6618        -0.037768 -0.038649  0.033392  \n",
       "6632        -0.032904 -0.048000  0.023717  \n",
       "\n",
       "[5 rows x 511 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is where business is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features = pd.read_csv('real_business_features_3_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 11)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features['postal_code'] = business_features['postal_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features = business_features.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>average_review_count</th>\n",
       "      <th>business_count</th>\n",
       "      <th>zip_review_count</th>\n",
       "      <th>average_review_max</th>\n",
       "      <th>average_review_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.499208</td>\n",
       "      <td>-81.536689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.964078</td>\n",
       "      <td>-73.285549</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.780821</td>\n",
       "      <td>-74.150722</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.083200</td>\n",
       "      <td>11.858200</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.213256</td>\n",
       "      <td>11.763245</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_open   latitude  longitude  review_count     stars  \\\n",
       "postal_code                                                          \n",
       "2224             1.0  41.499208 -81.536689      7.000000  2.500000   \n",
       "5440             1.0  44.964078 -73.285549      4.000000  4.250000   \n",
       "5452             1.0  40.780821 -74.150722     49.000000  4.000000   \n",
       "6618             1.0  51.083200  11.858200      8.000000  3.500000   \n",
       "6632             1.0  51.213256  11.763245      5.888889  4.222222   \n",
       "\n",
       "             average_review_count  business_count  zip_review_count  \\\n",
       "postal_code                                                           \n",
       "2224                     7.000000             1.0               7.0   \n",
       "5440                     4.000000             2.0               8.0   \n",
       "5452                    49.000000             1.0              49.0   \n",
       "6618                     8.000000             1.0               8.0   \n",
       "6632                     5.888889             9.0              53.0   \n",
       "\n",
       "             average_review_max  average_review_min  \n",
       "postal_code                                          \n",
       "2224                        7.0                 7.0  \n",
       "5440                        5.0                 3.0  \n",
       "5452                       49.0                49.0  \n",
       "6618                        8.0                 8.0  \n",
       "6632                        8.0                 3.0  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66132, 120)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test_features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_targets = train_targets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_targets = test_targets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging on index for train features and targets so it doesn't multiply \n",
    "train_merge = pd.merge(train_features, train_targets, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = pd.merge(test_features, test_targets, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merge = train_merge.set_index('RegionName_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = test_merge.set_index('RegionName_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66132, 122)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 10)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_train_merge = pd.merge(train_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_test_merge = pd.merge(test_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_merge = pd.merge(train_merge, w2v_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_test_merge = pd.merge(test_merge, w2v_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_zillow_test_merge = pd.merge(test_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nztmc = new_zillow_test_merge.columns\n",
    "test_merge = new_zillow_test_merge.iloc[:, :-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_zillow_train_merge = pd.merge(train_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge = new_zillow_train_merge.iloc[:, :-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_merge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_merge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3996, 132)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should have all instances of the train and test. \n",
    "business_train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3996, 633)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merge = train_merge.drop('RegionName_y', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge = test_merge.drop('RegionName_y', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_x', 'std_x', 'min_x', 'max_x', 'swing_x', 'change_x',\n",
       "       'swing_pos_x', 'swing_big_x', 'swing_neg_x', 'swing_loss_big_x',\n",
       "       ...\n",
       "       'std_y', 'min_y', 'max_y', 'swing_y', 'change_y', 'swing_pos_y',\n",
       "       'swing_big_y', 'swing_neg_y', 'swing_loss_big_y', 'target'],\n",
       "      dtype='object', length=121)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_test_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_test_merge.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_merge.iloc[:, :-1].values\n",
    "y_train = train_merge.iloc[:, -1].values\n",
    "X_test = test_merge.iloc[:, :-1].values\n",
    "y_test = test_merge.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_train_merge = business_train_merge.drop('RegionName_y', 1)\n",
    "business_test_merge = business_test_merge.drop('RegionName_y', 1)\n",
    "y_train_business = business_train_merge.loc[:, 'target'].values\n",
    "y_test_business = business_test_merge.loc[:, 'target'].values\n",
    "business_train = pd.DataFrame()\n",
    "business_train_features = business_train_merge.drop('target', 1).values\n",
    "X_train_business = pd.DataFrame()\n",
    "X_train_business = business_train_features\n",
    "X_test_business_features = pd.DataFrame()\n",
    "X_test_business_features = business_test_merge.drop('target', 1).values\n",
    "X_test_business = pd.DataFrame()\n",
    "X_test_business = X_test_business_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_train_merge = w2v_train_merge.drop('RegionName_y', 1)\n",
    "w2v_test_merge = w2v_test_merge.drop('RegionName_y', 1)\n",
    "y_train_w2v = w2v_train_merge.loc[:, 'target'].values\n",
    "y_test_w2v = w2v_test_merge.loc[:, 'target'].values\n",
    "w2v_train = pd.DataFrame()\n",
    "w2v_train_features = w2v_train_merge.drop('target', 1).values\n",
    "X_train_w2v = pd.DataFrame()\n",
    "X_train_w2v = w2v_train_features\n",
    "X_test_w2v_features = pd.DataFrame()\n",
    "X_test_w2v_features = w2v_test_merge.drop('target', 1).values\n",
    "X_test_w2v = pd.DataFrame()\n",
    "X_test_w2v = X_test_w2v_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_per_column(X):\n",
    "    new_array = []\n",
    "    shape = X.shape\n",
    "    columns = shape[1]\n",
    "    for num in range(columns):\n",
    "        mx = X[:, num].max()\n",
    "        if mx == 0:\n",
    "            new_array.append(X[:, num])\n",
    "        else:\n",
    "            X[:, num] = X[:, num] / mx\n",
    "            new_array.append(X[:, num])\n",
    "    new_array = np.array(new_array)\n",
    "    new_array = np.transpose(new_array)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = norm_per_column(X_train)\n",
    "X_test = norm_per_column(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_business = norm_per_column(X_train_business)\n",
    "X_test_business = norm_per_column(X_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_w2v = norm_per_column(X_train_w2v)\n",
    "X_test_w2v = norm_per_column(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028560998107322942"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03568676443\n",
      "0.809566962437\n",
      "1.32300764356\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean())\n",
    "print(y_train.min())\n",
    "print(y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01812630226\n",
      "0.833675690212\n",
      "1.18704258259\n"
     ]
    }
   ],
   "source": [
    "print(y_test.mean())\n",
    "print(y_test.min())\n",
    "print(y_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_y_class_2(y_list):\n",
    "    y_df = pd.DataFrame()\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    y_3 = []\n",
    "    y_4 = []\n",
    "    y_5 = []\n",
    "    \n",
    "    for y in y_list:\n",
    "        if y <= .9:\n",
    "            y_1.append(1)\n",
    "        else:\n",
    "            y_1.append(0)\n",
    "        if y > .9 and y <= .97:\n",
    "            y_2.append(1)\n",
    "        else:\n",
    "            y_2.append(0)\n",
    "        if y > .97 and y < 1.03:\n",
    "            y_3.append(1)\n",
    "        else:\n",
    "            y_3.append(0)\n",
    "        if y >= 1.03 and y < 1.1:\n",
    "            y_4.append(1)\n",
    "        else:\n",
    "            y_4.append(0)\n",
    "        if y >= 1.1:\n",
    "            y_5.append(1)\n",
    "        else:\n",
    "            y_5.append(0)\n",
    "    y_df['1'] = y_1\n",
    "    y_df['2'] = y_2\n",
    "    y_df['3'] = y_3\n",
    "    y_df['4'] = y_4\n",
    "    y_df['5'] = y_5\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = create_y_class_2(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test = create_y_class_2(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_train_w2v = create_y_class_2(y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_test_w2v = create_y_class_2(y_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_train_business = create_y_class_2(y_train_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_test_business = create_y_class_2(y_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028560998107322942"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_business.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold overfit model for now\n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(110,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.005)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 2.4648 - val_loss: 1.7106\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.2855 - val_loss: 0.1537\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.3109 - val_loss: 0.1096\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2574 - val_loss: 0.1539\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.2579 - val_loss: 0.1283\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.2167 - val_loss: 0.0970\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1962 - val_loss: 0.1111\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1968 - val_loss: 0.1375\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.1932 - val_loss: 0.1611\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1972 - val_loss: 0.1335\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1687 - val_loss: 0.1073\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1510 - val_loss: 0.1419\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1655 - val_loss: 0.1780\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1719 - val_loss: 0.1590\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1576 - val_loss: 0.1539\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1512 - val_loss: 0.1357\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1372 - val_loss: 0.1861\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1562 - val_loss: 0.1777\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1614 - val_loss: 0.2200\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1699 - val_loss: 0.1103\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1272 - val_loss: 0.1843\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.1403 - val_loss: 0.1314\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.125 - 0s 35us/step - loss: 0.1212 - val_loss: 0.1353\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1211 - val_loss: 0.1382\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1250 - val_loss: 0.1611\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1397 - val_loss: 0.1712\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1308 - val_loss: 0.1114\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1086 - val_loss: 0.1727\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1309 - val_loss: 0.1041\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0950 - val_loss: 0.1143\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.1132 - val_loss: 0.1937\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.1387 - val_loss: 0.0824\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0849 - val_loss: 0.0788\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0866 - val_loss: 0.1122\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1069 - val_loss: 0.1915\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1402 - val_loss: 0.0771\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0780 - val_loss: 0.0931\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0912 - val_loss: 0.1346\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1165 - val_loss: 0.1183\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0958 - val_loss: 0.0655\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0732 - val_loss: 0.0834\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0801 - val_loss: 0.0769\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0807 - val_loss: 0.0958\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0836 - val_loss: 0.0828\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0801 - val_loss: 0.0660\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0685 - val_loss: 0.0766\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0713 - val_loss: 0.0580\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0643 - val_loss: 0.0618\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0618 - val_loss: 0.0576\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0669 - val_loss: 0.0717\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0642 - val_loss: 0.0417\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0522 - val_loss: 0.0550\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0591 - val_loss: 0.0600\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0682 - val_loss: 0.0487\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0566 - val_loss: 0.0402\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0482 - val_loss: 0.0212\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0420 - val_loss: 0.0283\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0466 - val_loss: 0.0445\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0502 - val_loss: 0.0276\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0378 - val_loss: 0.0179\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0357 - val_loss: 0.0155\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0330 - val_loss: 0.0129\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0327 - val_loss: 0.0169\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0328 - val_loss: 0.0161\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0315 - val_loss: 0.0150\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0310 - val_loss: 0.0081\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0264 - val_loss: 0.0056\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0269 - val_loss: 0.0050\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0247 - val_loss: 0.0035\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0223 - val_loss: 0.0033\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0229 - val_loss: 0.0028\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0214 - val_loss: 0.0042\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0221 - val_loss: 0.0073\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0220 - val_loss: 0.0051\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0199 - val_loss: 0.0035\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0198 - val_loss: 0.0029\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0190 - val_loss: 0.0033\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0191 - val_loss: 0.0030\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0188 - val_loss: 0.0032\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0188 - val_loss: 0.0041\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0190 - val_loss: 0.0053\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0206 - val_loss: 0.0064\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0197 - val_loss: 0.0031\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0172 - val_loss: 0.0027\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0175 - val_loss: 0.0029\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0177 - val_loss: 0.0027\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0156 - val_loss: 0.0028\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0162 - val_loss: 0.0042\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0177 - val_loss: 0.0033\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0169 - val_loss: 0.0029\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0162 - val_loss: 0.0033\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0168 - val_loss: 0.0031\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0145 - val_loss: 0.0028\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0143 - val_loss: 0.0028\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.015 - 0s 29us/step - loss: 0.0151 - val_loss: 0.0032\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0140 - val_loss: 0.0027\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0136 - val_loss: 0.0029\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0056\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0173 - val_loss: 0.0027\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0125 - val_loss: 0.0028\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0132 - val_loss: 0.0039\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0141 - val_loss: 0.0035\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0129 - val_loss: 0.0028\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0120 - val_loss: 0.0026\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0114 - val_loss: 0.0035\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0139 - val_loss: 0.0042\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0129 - val_loss: 0.0027\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0118 - val_loss: 0.0025\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0109 - val_loss: 0.0025\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0111 - val_loss: 0.0026\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0116 - val_loss: 0.0047\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0128 - val_loss: 0.0029\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0109 - val_loss: 0.0027\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0103 - val_loss: 0.0026\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0096 - val_loss: 0.0029\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0100 - val_loss: 0.0028\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0106 - val_loss: 0.0033\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0111 - val_loss: 0.0027\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0096 - val_loss: 0.0026\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0090 - val_loss: 0.0026\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0085 - val_loss: 0.0027\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0095 - val_loss: 0.0040\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0092 - val_loss: 0.0034\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0085 - val_loss: 0.0029\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0080 - val_loss: 0.0028\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0091 - val_loss: 0.0036\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0074 - val_loss: 0.0027\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0071 - val_loss: 0.0030\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0091 - val_loss: 0.0035\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.006 - 0s 30us/step - loss: 0.0066 - val_loss: 0.0027\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0075 - val_loss: 0.0032\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0073\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0069\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 29us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 29us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.001 - 0s 30us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17891c978>"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(zillow_model.history['loss'])\n",
    "plt.plot(zillow_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.01)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0055 - val_loss: 0.0088\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0160 - val_loss: 0.0030\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0053 - val_loss: 0.1210\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5420 - val_loss: 0.1706\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2718 - val_loss: 0.0036\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0186 - val_loss: 0.0032\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0106 - val_loss: 0.0034\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0082 - val_loss: 0.0111\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0190 - val_loss: 0.0035\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0062 - val_loss: 0.4126\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6169 - val_loss: 0.3842\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4058 - val_loss: 0.0042\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0046 - val_loss: 0.0164\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0922 - val_loss: 1.0088\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2131 - val_loss: 0.0246\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0393 - val_loss: 0.0048\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0087 - val_loss: 0.0030\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0095 - val_loss: 0.0556\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1012 - val_loss: 0.0047\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0991 - val_loss: 0.8047\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.8528 - val_loss: 9.5942\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 11.2623 - val_loss: 1.8581\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4809 - val_loss: 0.0179\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0347 - val_loss: 0.0039\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0207 - val_loss: 0.0038\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0180 - val_loss: 0.0033\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0137 - val_loss: 0.0038\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0088 - val_loss: 0.0035\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0056 - val_loss: 0.0225\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0384 - val_loss: 0.3079\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7884 - val_loss: 3.0779\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.3607 - val_loss: 0.0446\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0363 - val_loss: 0.0121\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0095 - val_loss: 0.0067\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0085 - val_loss: 0.0226\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0290 - val_loss: 0.1125\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1538 - val_loss: 0.2634\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2671 - val_loss: 0.2698\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2900 - val_loss: 0.8574\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 4.1008 - val_loss: 30.9265\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 37.3535 - val_loss: 24.0820\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 18.2658 - val_loss: 0.0029\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0098 - val_loss: 0.0029\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0070 - val_loss: 0.0029\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0069 - val_loss: 0.0214\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0375 - val_loss: 0.3485\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8947 - val_loss: 7.7936\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 12.0376 - val_loss: 19.0341\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 14.7902 - val_loss: 0.0914\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0736 - val_loss: 0.0077\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0271 - val_loss: 0.1794\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4322 - val_loss: 7.0663\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 11.6984 - val_loss: 1.5417\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.2566 - val_loss: 0.0320\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0238 - val_loss: 0.0042\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0112 - val_loss: 0.0867\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2202 - val_loss: 3.8801\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 5.0471 - val_loss: 0.0526\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0450 - val_loss: 0.0060\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0080 - val_loss: 0.0341\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1079 - val_loss: 2.4706\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 6.7249 - val_loss: 18.3961\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 31.2690 - val_loss: 23.2112\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 18.4562 - val_loss: 0.0401\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0472 - val_loss: 0.0029\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0168 - val_loss: 0.1399\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4274 - val_loss: 5.2691\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 11.3014 - val_loss: 67.5562\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 60.0220 - val_loss: 0.3208\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2505 - val_loss: 0.0073\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0096\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0126 - val_loss: 0.0939\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1889 - val_loss: 2.0366\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 5.0588 - val_loss: 16.2810\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 12.2137 - val_loss: 0.5355\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5032 - val_loss: 0.2358\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2301 - val_loss: 0.1611\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1714 - val_loss: 0.2214\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2493 - val_loss: 0.4269\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5756 - val_loss: 2.5519\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 6.1397 - val_loss: 19.9508\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 15.5076 - val_loss: 0.0581\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0629 - val_loss: 0.0029\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0104 - val_loss: 0.0328\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0726 - val_loss: 0.5266\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.5459 - val_loss: 23.9728\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 34.7491 - val_loss: 20.9841\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 16.6981 - val_loss: 0.0029\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0192 - val_loss: 0.0029\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0133 - val_loss: 0.0029\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0052 - val_loss: 0.0224\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0499 - val_loss: 0.8239\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.6580 - val_loss: 13.1671\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 10.5746 - val_loss: 0.0645\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0595 - val_loss: 0.0029\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0103 - val_loss: 0.1003\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4130 - val_loss: 4.4048\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 4.0120 - val_loss: 0.0670\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0672 - val_loss: 0.0059\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0174 - val_loss: 0.1153\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2134 - val_loss: 0.0084\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0142 - val_loss: 0.0028\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0135 - val_loss: 0.0028\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0388 - val_loss: 0.0664\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2143 - val_loss: 0.9015\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.6988 - val_loss: 5.7502\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 8.9211 - val_loss: 5.0362\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 6.955 - 0s 29us/step - loss: 4.9079 - val_loss: 0.0048\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0186 - val_loss: 0.0035\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0162 - val_loss: 0.0031\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0137 - val_loss: 0.0032\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0100 - val_loss: 0.0029\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0087 - val_loss: 0.0027\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0085 - val_loss: 0.0236\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0608 - val_loss: 0.4231\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4826 - val_loss: 2.4886\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.7621 - val_loss: 0.0174\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0204 - val_loss: 0.0031\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0056 - val_loss: 0.0159\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0566 - val_loss: 0.5200\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.8449 - val_loss: 2.5200\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 2.7800 - val_loss: 0.0028\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0106 - val_loss: 0.0345\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0952 - val_loss: 0.3965\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5595 - val_loss: 0.0336\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0377 - val_loss: 0.0028\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0508\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2127 - val_loss: 0.5418\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6122 - val_loss: 0.0032\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0070 - val_loss: 0.0123\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0224 - val_loss: 0.0033\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 49us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0074 - val_loss: 0.0031\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0204 - val_loss: 0.1557\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2628 - val_loss: 0.0043\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0134 - val_loss: 0.0031\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_business, y=y_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_test_business),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.002)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 3.1253 - val_loss: 0.3215\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3927 - val_loss: 0.2637\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3240 - val_loss: 0.2399\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2909 - val_loss: 0.1291\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2447 - val_loss: 0.1072\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2297 - val_loss: 0.1186\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2025 - val_loss: 0.2005\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2366 - val_loss: 0.2338\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2277 - val_loss: 0.1693\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1877 - val_loss: 0.1282\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1745 - val_loss: 0.1411\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1660 - val_loss: 0.1104\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.1478 - val_loss: 0.1603\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.1639 - val_loss: 0.2238\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.1798 - val_loss: 0.2185\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1586 - val_loss: 0.1309\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1269 - val_loss: 0.1460\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1226 - val_loss: 0.1419\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1188 - val_loss: 0.1322\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1142 - val_loss: 0.2100\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.1477 - val_loss: 0.1941\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1351 - val_loss: 0.1434\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.1089 - val_loss: 0.1333\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1087 - val_loss: 0.1734\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1242 - val_loss: 0.1681\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.1236 - val_loss: 0.1397\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.1041 - val_loss: 0.1265\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0930 - val_loss: 0.1414\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1073 - val_loss: 0.1549\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1063 - val_loss: 0.1308\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0955 - val_loss: 0.1328\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0950 - val_loss: 0.1184\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0840 - val_loss: 0.1127\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0848 - val_loss: 0.1371\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0962 - val_loss: 0.1347\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0994 - val_loss: 0.1492\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0920 - val_loss: 0.1038\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0761 - val_loss: 0.0920\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0710 - val_loss: 0.0986\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0798 - val_loss: 0.1339\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0883 - val_loss: 0.1173\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0795 - val_loss: 0.0971\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0691 - val_loss: 0.0996\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0750 - val_loss: 0.1234\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0834 - val_loss: 0.1221\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0818 - val_loss: 0.1055\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0705 - val_loss: 0.0837\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0635 - val_loss: 0.0809\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0631 - val_loss: 0.0942\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0679 - val_loss: 0.0971\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0705 - val_loss: 0.0994\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0712 - val_loss: 0.0786\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0592 - val_loss: 0.0679\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0567 - val_loss: 0.0868\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0620 - val_loss: 0.0766\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0638 - val_loss: 0.0971\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0646 - val_loss: 0.0700\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0572 - val_loss: 0.0794\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0543 - val_loss: 0.0706\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0554 - val_loss: 0.0651\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0532 - val_loss: 0.0694\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0542 - val_loss: 0.0654\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0492 - val_loss: 0.0531\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0471 - val_loss: 0.0646\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0525 - val_loss: 0.0713\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.0543 - val_loss: 0.0587\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0473 - val_loss: 0.0570\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0506 - val_loss: 0.0612\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0480 - val_loss: 0.0486\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0421 - val_loss: 0.0495\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0411 - val_loss: 0.0367\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0426 - val_loss: 0.0547\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0467 - val_loss: 0.0652\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0512 - val_loss: 0.0473\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0435 - val_loss: 0.0434\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0426 - val_loss: 0.0540\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0461 - val_loss: 0.0432\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0405 - val_loss: 0.0397\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0409 - val_loss: 0.0388\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0398 - val_loss: 0.0345\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0397 - val_loss: 0.0410\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0402 - val_loss: 0.0232\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0334 - val_loss: 0.0252\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0347 - val_loss: 0.0287\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0369 - val_loss: 0.0343\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0397 - val_loss: 0.0283\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0375 - val_loss: 0.0205\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0336 - val_loss: 0.0163\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0323 - val_loss: 0.0138\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0308 - val_loss: 0.0162\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0325 - val_loss: 0.0127\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0316 - val_loss: 0.0122\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0298 - val_loss: 0.0091\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0280 - val_loss: 0.0096\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0303 - val_loss: 0.0185\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0353 - val_loss: 0.0118\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0315 - val_loss: 0.0122\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0300 - val_loss: 0.0083\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0289 - val_loss: 0.0099\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0297 - val_loss: 0.0118\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0289 - val_loss: 0.0102\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0298 - val_loss: 0.0130\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0317 - val_loss: 0.0071\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0276 - val_loss: 0.0070\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0258 - val_loss: 0.0045\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0256 - val_loss: 0.0035\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0262 - val_loss: 0.0028\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0267 - val_loss: 0.0028\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0265 - val_loss: 0.0028\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0280 - val_loss: 0.0032\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0266 - val_loss: 0.0030\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0248 - val_loss: 0.0033\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0248 - val_loss: 0.0028\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0243 - val_loss: 0.0028\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0261 - val_loss: 0.0030\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0241 - val_loss: 0.0030\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0244 - val_loss: 0.0027\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0254 - val_loss: 0.0030\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0259 - val_loss: 0.0031\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0246 - val_loss: 0.0030\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0234 - val_loss: 0.0045\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0246 - val_loss: 0.0070\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0249 - val_loss: 0.0037\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0230 - val_loss: 0.0038\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0220 - val_loss: 0.0029\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0240 - val_loss: 0.0032\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0256 - val_loss: 0.0029\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0233 - val_loss: 0.0034\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0240 - val_loss: 0.0028\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0220 - val_loss: 0.0029\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0219 - val_loss: 0.0034\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0223 - val_loss: 0.0039\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0229 - val_loss: 0.0040\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0219 - val_loss: 0.0068\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0240 - val_loss: 0.0035\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0211 - val_loss: 0.0039\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0218 - val_loss: 0.0035\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0218 - val_loss: 0.0049\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0227 - val_loss: 0.0059\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0232 - val_loss: 0.0054\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0234 - val_loss: 0.0033\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0207 - val_loss: 0.0037\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0210 - val_loss: 0.0057\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 93us/step - loss: 0.0216 - val_loss: 0.0045\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0204 - val_loss: 0.0030\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0206 - val_loss: 0.0029\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0211 - val_loss: 0.0028\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0212 - val_loss: 0.0029\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0203 - val_loss: 0.0028\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0195 - val_loss: 0.0028\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0199 - val_loss: 0.0028\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0196 - val_loss: 0.0032\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0210 - val_loss: 0.0034\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0207 - val_loss: 0.0028\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0199 - val_loss: 0.0030\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0184 - val_loss: 0.0029\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0193 - val_loss: 0.0029\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0183 - val_loss: 0.0029\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0184 - val_loss: 0.0027\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0198 - val_loss: 0.0031\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0197 - val_loss: 0.0031\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0185 - val_loss: 0.0030\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0189 - val_loss: 0.0029\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0177 - val_loss: 0.0028\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0187 - val_loss: 0.0028\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0177 - val_loss: 0.0033\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0199 - val_loss: 0.0032\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0178 - val_loss: 0.0029\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0177 - val_loss: 0.0029\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0176 - val_loss: 0.0028\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0179 - val_loss: 0.0029\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0177 - val_loss: 0.0028\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0176 - val_loss: 0.0028\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0178 - val_loss: 0.0030\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0180 - val_loss: 0.0031\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0166 - val_loss: 0.0030\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0175 - val_loss: 0.0030\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0161 - val_loss: 0.0028\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0159 - val_loss: 0.0029\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0171 - val_loss: 0.0031\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0166 - val_loss: 0.0028\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0161 - val_loss: 0.0038\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0169 - val_loss: 0.0045\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0168 - val_loss: 0.0034\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0157 - val_loss: 0.0029\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0158 - val_loss: 0.0030\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0152 - val_loss: 0.0034\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0163 - val_loss: 0.0051\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0171 - val_loss: 0.0030\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0157 - val_loss: 0.0030\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0152 - val_loss: 0.0046\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0164 - val_loss: 0.0031\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0147 - val_loss: 0.0030\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0143 - val_loss: 0.0036\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0153 - val_loss: 0.0045\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0153 - val_loss: 0.0029\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0140 - val_loss: 0.0030\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0144 - val_loss: 0.0027\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0146 - val_loss: 0.0031\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0140 - val_loss: 0.0029\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0143 - val_loss: 0.0030\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0139 - val_loss: 0.0031\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0142 - val_loss: 0.0031\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0141 - val_loss: 0.0029\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0137 - val_loss: 0.0028\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0136 - val_loss: 0.0035\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0138 - val_loss: 0.0031\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0127 - val_loss: 0.0028\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0128 - val_loss: 0.0027\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0126 - val_loss: 0.0029\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0137 - val_loss: 0.0034\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0134 - val_loss: 0.0030\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0139 - val_loss: 0.0033\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0127 - val_loss: 0.0028\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0125 - val_loss: 0.0027\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0127 - val_loss: 0.0027\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0129 - val_loss: 0.0032\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0129 - val_loss: 0.0029\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0126 - val_loss: 0.0028\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0120 - val_loss: 0.0029\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0114 - val_loss: 0.0027\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0119 - val_loss: 0.0029\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0123 - val_loss: 0.0043\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0126 - val_loss: 0.0028\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0113 - val_loss: 0.0028\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0113 - val_loss: 0.0027\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0121 - val_loss: 0.0030\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0109 - val_loss: 0.0028\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0109 - val_loss: 0.0030\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0120 - val_loss: 0.0031\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0102 - val_loss: 0.0034\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0114 - val_loss: 0.0028\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0099 - val_loss: 0.0028\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0104 - val_loss: 0.0029\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0100 - val_loss: 0.0031\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0098 - val_loss: 0.0028\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0113 - val_loss: 0.0030\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0098 - val_loss: 0.0028\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0098 - val_loss: 0.0027\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0097 - val_loss: 0.0034\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0096 - val_loss: 0.0028\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0095 - val_loss: 0.0027\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0092 - val_loss: 0.0034\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0092 - val_loss: 0.0026\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0088 - val_loss: 0.0030\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0101 - val_loss: 0.0041\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0104 - val_loss: 0.0027\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.008 - 0s 70us/step - loss: 0.0085 - val_loss: 0.0028\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0090 - val_loss: 0.0027\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0082 - val_loss: 0.0031\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 97us/step - loss: 0.0089 - val_loss: 0.0029\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 107us/step - loss: 0.0090 - val_loss: 0.0032\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0080 - val_loss: 0.0035\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0072 - val_loss: 0.0027\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0086 - val_loss: 0.0028\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0098 - val_loss: 0.0027\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0071 - val_loss: 0.0025\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0071 - val_loss: 0.0025\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 100us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0028 - val_loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b561c50>"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_w2v, y=y_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_test_w2v),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_metrics(predictions, y_test):\n",
    "    df = pd.DataFrame(predictions)\n",
    "    # predicting a loss 3% or larger by seeing if max loss probability is higher then slight gain\n",
    "    df['loss'] = np.where(df[0] > df[3], 1, 0)\n",
    "    # predicting a gain 3% or larger by seeing if max gain probability is higher then slight loss\n",
    "    df['gain'] = np.where(df[4] > df[1], 1, 0)\n",
    "    df = pd.merge(df, y_test, left_index=True, right_index=True, how='inner')\n",
    "    # predicting a loss 3% or larger by seeing if max loss probability is higher then mean probibility \n",
    "    df['loss_large'] = np.where(df[0] > df[2], 1, 0)\n",
    "    # predicting a gain 3% or larger by seeing if max gain probability is higher then mean probibility \n",
    "    df['gain_large'] = np.where(df[4] > df[2], 1, 0)\n",
    "    # Cheching if loss is predicted and a loss of 3% or more occurs\n",
    "    df['loss_true_true'] = np.where((df['loss'] == 1) & ((df['2'] == 1) | (df['1'] == 1)), 1, 0)\n",
    "    # Checking if loss is predicted and price stays at the mean\n",
    "    df['loss_stay'] = np.where((df['loss'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if large loss is predicted and a loss of 3% or more occurs\n",
    "    df['loss_large_true'] = np.where((df['loss_large'] == 1) & ((df['2'] == 1) | (df['1'] == 1)), 1, 0)\n",
    "    # Cheching if large loss is predicted and price stays at the mean\n",
    "    df['loss_large_stay'] = np.where((df['loss_large'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if gain is predicted and a loss of 3% or more occurs\n",
    "    df['gain_true_true'] = np.where((df['gain'] == 1) & ((df['4'] == 1) | (df['5'] == 1)), 1, 0)\n",
    "    # Checking if gain is predicted and price stays at the mean\n",
    "    df['gain_stay'] = np.where((df['gain'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if large gain is predicted and a gain of 3% or more occurs\n",
    "    df['gain_large_true'] = np.where((df['gain_large'] == 1) & ((df['4'] == 1) | (df['5'] == 1)), 1, 0)\n",
    "    # Cheching if large gain is predicted and price stays at the mean\n",
    "    df['gain_large_stay'] = np.where((df['gain_large'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    #df['gain_large_large'] = np.where((df['gain_large'] == 1) & (df['5'] == 1), 1, 0)\n",
    "    # Checking if both loss and gain are selected. This appears to mean high volitility\n",
    "    df['volitile'] = np.where((df['loss'] == 1) & (df['gain'] == 1), 1, 0)\n",
    "    \n",
    "    \n",
    "    gain_pred = df['gain'].sum()\n",
    "    gain_large_pred = df['gain_large'].sum()\n",
    "    \n",
    "    gain_stay_true = (df['gain_true_true'].sum() + df['gain_stay'].sum()) / df['gain'].sum()\n",
    "    \n",
    "    gain_true = df['gain_true_true'].sum() / df['gain'].sum()\n",
    "    loss_stay_true = (df['loss_true_true'].sum() + df['loss_stay'].sum()) / df['loss'].sum()\n",
    "    loss_stay_true = df['loss_true_true'].sum() / df['loss'].sum()\n",
    "    gain_stay_large_true = (df['gain_large_true'].sum() + df['gain_large_stay'].sum()) / df['gain_large'].sum()\n",
    "    gain_large_true = df['gain_large_true'].sum() / df['gain_large'].sum()\n",
    "    loss_stay_large_true = (df['loss_large_true'].sum() + df['loss_large_stay']) / df['loss_large'].sum()\n",
    "    loss_large_true = df['loss_large_true'].sum() / df['loss_large'].sum()\n",
    "    volitile = df['volitile'].sum()\n",
    "    print(gain_pred)\n",
    "    print(gain_true)\n",
    "    print(gain_stay_true)\n",
    "    print(gain_large_pred)\n",
    "    print(gain_large_true)\n",
    "    print(gain_stay_large_true)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.00001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 1.6097 - acc: 0.2843 - val_loss: 1.6527 - val_acc: 0.1511\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.6000 - acc: 0.2931 - val_loss: 1.6506 - val_acc: 0.1541\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.6074 - acc: 0.2864 - val_loss: 1.6488 - val_acc: 0.1662\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5984 - acc: 0.3008 - val_loss: 1.6471 - val_acc: 0.1692\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.6178 - acc: 0.2892 - val_loss: 1.6456 - val_acc: 0.1722\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.6057 - acc: 0.2987 - val_loss: 1.6443 - val_acc: 0.1752\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5995 - acc: 0.2892 - val_loss: 1.6430 - val_acc: 0.1782\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5987 - acc: 0.2878 - val_loss: 1.6418 - val_acc: 0.1782\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.6003 - acc: 0.2938 - val_loss: 1.6406 - val_acc: 0.1843\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5993 - acc: 0.2881 - val_loss: 1.6395 - val_acc: 0.1873\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5990 - acc: 0.2867 - val_loss: 1.6383 - val_acc: 0.1903\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.6087 - acc: 0.2990 - val_loss: 1.6372 - val_acc: 0.1934\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.6035 - acc: 0.2959 - val_loss: 1.6362 - val_acc: 0.1994\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.6007 - acc: 0.2973 - val_loss: 1.6351 - val_acc: 0.1994\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.5931 - acc: 0.2983 - val_loss: 1.6341 - val_acc: 0.2024\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.6077 - acc: 0.2924 - val_loss: 1.6331 - val_acc: 0.2085\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.6002 - acc: 0.3050 - val_loss: 1.6321 - val_acc: 0.2115\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.6007 - acc: 0.2966 - val_loss: 1.6312 - val_acc: 0.2115\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5892 - acc: 0.3064 - val_loss: 1.6302 - val_acc: 0.2115\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5918 - acc: 0.2966 - val_loss: 1.6293 - val_acc: 0.2145\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5904 - acc: 0.3043 - val_loss: 1.6283 - val_acc: 0.2175\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5910 - acc: 0.3029 - val_loss: 1.6274 - val_acc: 0.2175\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.5790 - acc: 0.3036 - val_loss: 1.6265 - val_acc: 0.2236\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5799 - acc: 0.3103 - val_loss: 1.6257 - val_acc: 0.2296\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5855 - acc: 0.3072 - val_loss: 1.6248 - val_acc: 0.2326\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5902 - acc: 0.3089 - val_loss: 1.6238 - val_acc: 0.2356\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5912 - acc: 0.3086 - val_loss: 1.6229 - val_acc: 0.2387\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5878 - acc: 0.3033 - val_loss: 1.6221 - val_acc: 0.2447\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5770 - acc: 0.3015 - val_loss: 1.6212 - val_acc: 0.2568\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5981 - acc: 0.3029 - val_loss: 1.6203 - val_acc: 0.2598\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5867 - acc: 0.3040 - val_loss: 1.6195 - val_acc: 0.2628\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5851 - acc: 0.3036 - val_loss: 1.6186 - val_acc: 0.2659\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5813 - acc: 0.3160 - val_loss: 1.6178 - val_acc: 0.2659\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5829 - acc: 0.3082 - val_loss: 1.6169 - val_acc: 0.2659\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5760 - acc: 0.3198 - val_loss: 1.6159 - val_acc: 0.2719\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5627 - acc: 0.3279 - val_loss: 1.6150 - val_acc: 0.2719\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5780 - acc: 0.3149 - val_loss: 1.6142 - val_acc: 0.2749\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5856 - acc: 0.3005 - val_loss: 1.6133 - val_acc: 0.2810\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5902 - acc: 0.2955 - val_loss: 1.6124 - val_acc: 0.2870\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5734 - acc: 0.3195 - val_loss: 1.6116 - val_acc: 0.2870\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5837 - acc: 0.3145 - val_loss: 1.6107 - val_acc: 0.2870\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5736 - acc: 0.3160 - val_loss: 1.6099 - val_acc: 0.2900\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5772 - acc: 0.3188 - val_loss: 1.6091 - val_acc: 0.2931\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5693 - acc: 0.3121 - val_loss: 1.6082 - val_acc: 0.2961\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5740 - acc: 0.3082 - val_loss: 1.6075 - val_acc: 0.3021\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5713 - acc: 0.3191 - val_loss: 1.6066 - val_acc: 0.3021\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5724 - acc: 0.3054 - val_loss: 1.6058 - val_acc: 0.3021\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5770 - acc: 0.3086 - val_loss: 1.6050 - val_acc: 0.3051\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5700 - acc: 0.3205 - val_loss: 1.6042 - val_acc: 0.3082\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5683 - acc: 0.3170 - val_loss: 1.6034 - val_acc: 0.3112\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5797 - acc: 0.3036 - val_loss: 1.6026 - val_acc: 0.3112\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5760 - acc: 0.3082 - val_loss: 1.6018 - val_acc: 0.3112\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5627 - acc: 0.3216 - val_loss: 1.6010 - val_acc: 0.3142\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5583 - acc: 0.3230 - val_loss: 1.6002 - val_acc: 0.3142\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5577 - acc: 0.3195 - val_loss: 1.5994 - val_acc: 0.3142\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5649 - acc: 0.3177 - val_loss: 1.5986 - val_acc: 0.3142\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5615 - acc: 0.3290 - val_loss: 1.5979 - val_acc: 0.3142\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5658 - acc: 0.3188 - val_loss: 1.5971 - val_acc: 0.3142\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5776 - acc: 0.3103 - val_loss: 1.5962 - val_acc: 0.3142\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5643 - acc: 0.3138 - val_loss: 1.5954 - val_acc: 0.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5618 - acc: 0.3269 - val_loss: 1.5947 - val_acc: 0.3142\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5619 - acc: 0.3300 - val_loss: 1.5939 - val_acc: 0.3142\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5592 - acc: 0.3315 - val_loss: 1.5932 - val_acc: 0.3142\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5533 - acc: 0.3318 - val_loss: 1.5924 - val_acc: 0.3142\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5605 - acc: 0.3117 - val_loss: 1.5917 - val_acc: 0.3142\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5601 - acc: 0.3297 - val_loss: 1.5909 - val_acc: 0.3142\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5491 - acc: 0.3353 - val_loss: 1.5901 - val_acc: 0.3142\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5550 - acc: 0.3276 - val_loss: 1.5893 - val_acc: 0.3142\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.5550 - acc: 0.3272 - val_loss: 1.5886 - val_acc: 0.3142\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5437 - acc: 0.3336 - val_loss: 1.5878 - val_acc: 0.3142\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5645 - acc: 0.3216 - val_loss: 1.5871 - val_acc: 0.3142\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5546 - acc: 0.3241 - val_loss: 1.5864 - val_acc: 0.3142\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 22us/step - loss: 1.5546 - acc: 0.3304 - val_loss: 1.5857 - val_acc: 0.3142\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5430 - acc: 0.3315 - val_loss: 1.5849 - val_acc: 0.3142\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5507 - acc: 0.3378 - val_loss: 1.5842 - val_acc: 0.3172\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5481 - acc: 0.3311 - val_loss: 1.5834 - val_acc: 0.3202\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5502 - acc: 0.3286 - val_loss: 1.5827 - val_acc: 0.3202\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5431 - acc: 0.3360 - val_loss: 1.5820 - val_acc: 0.3202\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5459 - acc: 0.3269 - val_loss: 1.5812 - val_acc: 0.3202\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5510 - acc: 0.3315 - val_loss: 1.5805 - val_acc: 0.3233\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5431 - acc: 0.3276 - val_loss: 1.5797 - val_acc: 0.3233\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5444 - acc: 0.3248 - val_loss: 1.5790 - val_acc: 0.3233\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5495 - acc: 0.3255 - val_loss: 1.5783 - val_acc: 0.3233\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5563 - acc: 0.3297 - val_loss: 1.5776 - val_acc: 0.3233\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5479 - acc: 0.3374 - val_loss: 1.5769 - val_acc: 0.3263\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5457 - acc: 0.3269 - val_loss: 1.5762 - val_acc: 0.3263\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5423 - acc: 0.3357 - val_loss: 1.5755 - val_acc: 0.3263\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5428 - acc: 0.3403 - val_loss: 1.5748 - val_acc: 0.3263\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5423 - acc: 0.3293 - val_loss: 1.5741 - val_acc: 0.3263\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5431 - acc: 0.3276 - val_loss: 1.5735 - val_acc: 0.3293\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5472 - acc: 0.3353 - val_loss: 1.5728 - val_acc: 0.3293\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5365 - acc: 0.3339 - val_loss: 1.5721 - val_acc: 0.3293\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5389 - acc: 0.3399 - val_loss: 1.5714 - val_acc: 0.3293\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5401 - acc: 0.3283 - val_loss: 1.5707 - val_acc: 0.3293\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5315 - acc: 0.3385 - val_loss: 1.5699 - val_acc: 0.3293\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5365 - acc: 0.3505 - val_loss: 1.5693 - val_acc: 0.3293\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5457 - acc: 0.3381 - val_loss: 1.5686 - val_acc: 0.3293\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5413 - acc: 0.3515 - val_loss: 1.5680 - val_acc: 0.3293\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5388 - acc: 0.3311 - val_loss: 1.5674 - val_acc: 0.3293\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5403 - acc: 0.3462 - val_loss: 1.5667 - val_acc: 0.3293\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5327 - acc: 0.3410 - val_loss: 1.5661 - val_acc: 0.3293\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5366 - acc: 0.3424 - val_loss: 1.5654 - val_acc: 0.3293\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5344 - acc: 0.3424 - val_loss: 1.5648 - val_acc: 0.3293\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5247 - acc: 0.3536 - val_loss: 1.5642 - val_acc: 0.3293\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5228 - acc: 0.3350 - val_loss: 1.5635 - val_acc: 0.3293\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5313 - acc: 0.3459 - val_loss: 1.5628 - val_acc: 0.3293\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5292 - acc: 0.3417 - val_loss: 1.5621 - val_acc: 0.3293\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5305 - acc: 0.3413 - val_loss: 1.5615 - val_acc: 0.3293\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5317 - acc: 0.3508 - val_loss: 1.5609 - val_acc: 0.3293\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5198 - acc: 0.3480 - val_loss: 1.5602 - val_acc: 0.3293\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5229 - acc: 0.3498 - val_loss: 1.5596 - val_acc: 0.3293\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5246 - acc: 0.3424 - val_loss: 1.5590 - val_acc: 0.3293\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5164 - acc: 0.3579 - val_loss: 1.5584 - val_acc: 0.3293\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5154 - acc: 0.3526 - val_loss: 1.5577 - val_acc: 0.3293\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5302 - acc: 0.3473 - val_loss: 1.5571 - val_acc: 0.3293\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5191 - acc: 0.3403 - val_loss: 1.5564 - val_acc: 0.3293\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5192 - acc: 0.3515 - val_loss: 1.5558 - val_acc: 0.3293\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5208 - acc: 0.3448 - val_loss: 1.5552 - val_acc: 0.3293\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5200 - acc: 0.3494 - val_loss: 1.5545 - val_acc: 0.3293\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5180 - acc: 0.3399 - val_loss: 1.5539 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5244 - acc: 0.3533 - val_loss: 1.5533 - val_acc: 0.3293\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5235 - acc: 0.3410 - val_loss: 1.5527 - val_acc: 0.3293\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5215 - acc: 0.3364 - val_loss: 1.5521 - val_acc: 0.3293\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5240 - acc: 0.3406 - val_loss: 1.5515 - val_acc: 0.3293\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5170 - acc: 0.3529 - val_loss: 1.5509 - val_acc: 0.3293\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5168 - acc: 0.3512 - val_loss: 1.5503 - val_acc: 0.3293\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5201 - acc: 0.3420 - val_loss: 1.5496 - val_acc: 0.3293\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5239 - acc: 0.3434 - val_loss: 1.5491 - val_acc: 0.3293\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5142 - acc: 0.3477 - val_loss: 1.5485 - val_acc: 0.3293\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5126 - acc: 0.3498 - val_loss: 1.5478 - val_acc: 0.3293\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5265 - acc: 0.3339 - val_loss: 1.5472 - val_acc: 0.3293\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5082 - acc: 0.3501 - val_loss: 1.5467 - val_acc: 0.3293\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5086 - acc: 0.3501 - val_loss: 1.5461 - val_acc: 0.3293\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5072 - acc: 0.3614 - val_loss: 1.5456 - val_acc: 0.3293\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5070 - acc: 0.3646 - val_loss: 1.5450 - val_acc: 0.3293\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5069 - acc: 0.3554 - val_loss: 1.5444 - val_acc: 0.3293\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5146 - acc: 0.3582 - val_loss: 1.5438 - val_acc: 0.3293\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5163 - acc: 0.3470 - val_loss: 1.5432 - val_acc: 0.3293\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5097 - acc: 0.3519 - val_loss: 1.5426 - val_acc: 0.3293\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5084 - acc: 0.3582 - val_loss: 1.5420 - val_acc: 0.3293\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5039 - acc: 0.3568 - val_loss: 1.5414 - val_acc: 0.3293\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5135 - acc: 0.3462 - val_loss: 1.5409 - val_acc: 0.3293\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5046 - acc: 0.3558 - val_loss: 1.5403 - val_acc: 0.3293\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5185 - acc: 0.3551 - val_loss: 1.5397 - val_acc: 0.3293\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5064 - acc: 0.3529 - val_loss: 1.5391 - val_acc: 0.3293\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4953 - acc: 0.3656 - val_loss: 1.5385 - val_acc: 0.3293\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5085 - acc: 0.3470 - val_loss: 1.5380 - val_acc: 0.3293\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5045 - acc: 0.3593 - val_loss: 1.5374 - val_acc: 0.3293\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5097 - acc: 0.3558 - val_loss: 1.5368 - val_acc: 0.3293\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4976 - acc: 0.3551 - val_loss: 1.5362 - val_acc: 0.3293\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5070 - acc: 0.3515 - val_loss: 1.5355 - val_acc: 0.3293\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4976 - acc: 0.3677 - val_loss: 1.5349 - val_acc: 0.3293\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5036 - acc: 0.3635 - val_loss: 1.5343 - val_acc: 0.3293\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5038 - acc: 0.3540 - val_loss: 1.5337 - val_acc: 0.3293\n",
      "Epoch 155/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4981 - acc: 0.3536 - val_loss: 1.5330 - val_acc: 0.3293\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4926 - acc: 0.3663 - val_loss: 1.5324 - val_acc: 0.3293\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4948 - acc: 0.3667 - val_loss: 1.5318 - val_acc: 0.3293\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4974 - acc: 0.3607 - val_loss: 1.5312 - val_acc: 0.3293\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5005 - acc: 0.3515 - val_loss: 1.5307 - val_acc: 0.3293\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4924 - acc: 0.3670 - val_loss: 1.5301 - val_acc: 0.3293\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.5022 - acc: 0.3572 - val_loss: 1.5295 - val_acc: 0.3293\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4969 - acc: 0.3596 - val_loss: 1.5289 - val_acc: 0.3293\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4998 - acc: 0.3596 - val_loss: 1.5283 - val_acc: 0.3293\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5025 - acc: 0.3498 - val_loss: 1.5277 - val_acc: 0.3293\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4937 - acc: 0.3646 - val_loss: 1.5272 - val_acc: 0.3293\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4837 - acc: 0.3667 - val_loss: 1.5266 - val_acc: 0.3293\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4939 - acc: 0.3628 - val_loss: 1.5260 - val_acc: 0.3293\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4985 - acc: 0.3603 - val_loss: 1.5254 - val_acc: 0.3293\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4965 - acc: 0.3723 - val_loss: 1.5248 - val_acc: 0.3293\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4969 - acc: 0.3508 - val_loss: 1.5242 - val_acc: 0.3293\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4948 - acc: 0.3632 - val_loss: 1.5236 - val_acc: 0.3293\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4779 - acc: 0.3769 - val_loss: 1.5230 - val_acc: 0.3293\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4936 - acc: 0.3635 - val_loss: 1.5224 - val_acc: 0.3293\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4919 - acc: 0.3600 - val_loss: 1.5219 - val_acc: 0.3293\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4833 - acc: 0.3688 - val_loss: 1.5213 - val_acc: 0.3293\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4849 - acc: 0.3755 - val_loss: 1.5208 - val_acc: 0.3293\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4817 - acc: 0.3727 - val_loss: 1.5202 - val_acc: 0.3293\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4934 - acc: 0.3617 - val_loss: 1.5197 - val_acc: 0.3293\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4771 - acc: 0.3695 - val_loss: 1.5191 - val_acc: 0.3293\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4792 - acc: 0.3603 - val_loss: 1.5185 - val_acc: 0.3263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4962 - acc: 0.3473 - val_loss: 1.5180 - val_acc: 0.3263\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4967 - acc: 0.3565 - val_loss: 1.5174 - val_acc: 0.3263\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4852 - acc: 0.3674 - val_loss: 1.5169 - val_acc: 0.3263\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4870 - acc: 0.3681 - val_loss: 1.5163 - val_acc: 0.3263\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4845 - acc: 0.3681 - val_loss: 1.5158 - val_acc: 0.3263\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4815 - acc: 0.3843 - val_loss: 1.5152 - val_acc: 0.3263\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4756 - acc: 0.3765 - val_loss: 1.5146 - val_acc: 0.3263\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4750 - acc: 0.3716 - val_loss: 1.5140 - val_acc: 0.3263\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4852 - acc: 0.3758 - val_loss: 1.5135 - val_acc: 0.3263\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4853 - acc: 0.3610 - val_loss: 1.5130 - val_acc: 0.3263\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4738 - acc: 0.3575 - val_loss: 1.5125 - val_acc: 0.3263\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4831 - acc: 0.3625 - val_loss: 1.5120 - val_acc: 0.3293\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4914 - acc: 0.3558 - val_loss: 1.5114 - val_acc: 0.3293\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4691 - acc: 0.3776 - val_loss: 1.5108 - val_acc: 0.3293\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4705 - acc: 0.3794 - val_loss: 1.5102 - val_acc: 0.3293\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4802 - acc: 0.3801 - val_loss: 1.5097 - val_acc: 0.3293\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4742 - acc: 0.3758 - val_loss: 1.5091 - val_acc: 0.3293\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4802 - acc: 0.3674 - val_loss: 1.5085 - val_acc: 0.3293\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4730 - acc: 0.3734 - val_loss: 1.5080 - val_acc: 0.3293\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4663 - acc: 0.3818 - val_loss: 1.5074 - val_acc: 0.3293\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4786 - acc: 0.3670 - val_loss: 1.5069 - val_acc: 0.3293\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4642 - acc: 0.3832 - val_loss: 1.5063 - val_acc: 0.3293\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4754 - acc: 0.3815 - val_loss: 1.5057 - val_acc: 0.3293\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4676 - acc: 0.3677 - val_loss: 1.5052 - val_acc: 0.3293\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4635 - acc: 0.3639 - val_loss: 1.5047 - val_acc: 0.3293\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4719 - acc: 0.3769 - val_loss: 1.5041 - val_acc: 0.3293\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4725 - acc: 0.3744 - val_loss: 1.5036 - val_acc: 0.3293\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4696 - acc: 0.3758 - val_loss: 1.5031 - val_acc: 0.3293\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4743 - acc: 0.3737 - val_loss: 1.5025 - val_acc: 0.3293\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4702 - acc: 0.3801 - val_loss: 1.5020 - val_acc: 0.3293\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4737 - acc: 0.3720 - val_loss: 1.5014 - val_acc: 0.3293\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4616 - acc: 0.3794 - val_loss: 1.5008 - val_acc: 0.3293\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4705 - acc: 0.3667 - val_loss: 1.5003 - val_acc: 0.3323\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4696 - acc: 0.3769 - val_loss: 1.4997 - val_acc: 0.3323\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4635 - acc: 0.3772 - val_loss: 1.4991 - val_acc: 0.3323\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4749 - acc: 0.3561 - val_loss: 1.4986 - val_acc: 0.3323\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4678 - acc: 0.3815 - val_loss: 1.4980 - val_acc: 0.3323\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4674 - acc: 0.3639 - val_loss: 1.4975 - val_acc: 0.3323\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4546 - acc: 0.3917 - val_loss: 1.4970 - val_acc: 0.3323\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4549 - acc: 0.3853 - val_loss: 1.4964 - val_acc: 0.3323\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4698 - acc: 0.3706 - val_loss: 1.4958 - val_acc: 0.3323\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4641 - acc: 0.3765 - val_loss: 1.4953 - val_acc: 0.3323\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4493 - acc: 0.3896 - val_loss: 1.4948 - val_acc: 0.3323\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4593 - acc: 0.3790 - val_loss: 1.4943 - val_acc: 0.3323\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4719 - acc: 0.3702 - val_loss: 1.4938 - val_acc: 0.3323\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4662 - acc: 0.3744 - val_loss: 1.4932 - val_acc: 0.3293\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4636 - acc: 0.3706 - val_loss: 1.4927 - val_acc: 0.3293\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4672 - acc: 0.3769 - val_loss: 1.4922 - val_acc: 0.3293\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4518 - acc: 0.3839 - val_loss: 1.4916 - val_acc: 0.3293\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4607 - acc: 0.3794 - val_loss: 1.4910 - val_acc: 0.3293\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4540 - acc: 0.3843 - val_loss: 1.4905 - val_acc: 0.3293\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4647 - acc: 0.3839 - val_loss: 1.4899 - val_acc: 0.3293\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4647 - acc: 0.3832 - val_loss: 1.4894 - val_acc: 0.3293\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4541 - acc: 0.3808 - val_loss: 1.4889 - val_acc: 0.3293\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4510 - acc: 0.3737 - val_loss: 1.4883 - val_acc: 0.3293\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4632 - acc: 0.3797 - val_loss: 1.4878 - val_acc: 0.3293\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4590 - acc: 0.3818 - val_loss: 1.4874 - val_acc: 0.3293\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4598 - acc: 0.3794 - val_loss: 1.4869 - val_acc: 0.3293\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4664 - acc: 0.3698 - val_loss: 1.4864 - val_acc: 0.3293\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4567 - acc: 0.3811 - val_loss: 1.4858 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4652 - acc: 0.3797 - val_loss: 1.4853 - val_acc: 0.3293\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4619 - acc: 0.3825 - val_loss: 1.4847 - val_acc: 0.3293\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4480 - acc: 0.3896 - val_loss: 1.4842 - val_acc: 0.3293\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4502 - acc: 0.3892 - val_loss: 1.4837 - val_acc: 0.3293\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4606 - acc: 0.3818 - val_loss: 1.4831 - val_acc: 0.3293\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4633 - acc: 0.3755 - val_loss: 1.4827 - val_acc: 0.3293\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4659 - acc: 0.3755 - val_loss: 1.4823 - val_acc: 0.3293\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4556 - acc: 0.3716 - val_loss: 1.4817 - val_acc: 0.3293\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4484 - acc: 0.3931 - val_loss: 1.4812 - val_acc: 0.3263\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4437 - acc: 0.3857 - val_loss: 1.4807 - val_acc: 0.3263\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4483 - acc: 0.3839 - val_loss: 1.4802 - val_acc: 0.3263\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4512 - acc: 0.3811 - val_loss: 1.4797 - val_acc: 0.3263\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4503 - acc: 0.3737 - val_loss: 1.4792 - val_acc: 0.3263\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4554 - acc: 0.3727 - val_loss: 1.4787 - val_acc: 0.3263\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4501 - acc: 0.3706 - val_loss: 1.4782 - val_acc: 0.3263\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4571 - acc: 0.3698 - val_loss: 1.4778 - val_acc: 0.3263\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4482 - acc: 0.3924 - val_loss: 1.4773 - val_acc: 0.3263\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4505 - acc: 0.3882 - val_loss: 1.4768 - val_acc: 0.3263\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4457 - acc: 0.3857 - val_loss: 1.4764 - val_acc: 0.3263\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4505 - acc: 0.3853 - val_loss: 1.4758 - val_acc: 0.3293\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4363 - acc: 0.3917 - val_loss: 1.4752 - val_acc: 0.3293\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4497 - acc: 0.3861 - val_loss: 1.4748 - val_acc: 0.3293\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4378 - acc: 0.3896 - val_loss: 1.4743 - val_acc: 0.3293\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4554 - acc: 0.3818 - val_loss: 1.4738 - val_acc: 0.3293\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4308 - acc: 0.3959 - val_loss: 1.4733 - val_acc: 0.3293\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4471 - acc: 0.3836 - val_loss: 1.4728 - val_acc: 0.3293\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4521 - acc: 0.3734 - val_loss: 1.4723 - val_acc: 0.3293\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4506 - acc: 0.3762 - val_loss: 1.4718 - val_acc: 0.3293\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4307 - acc: 0.3987 - val_loss: 1.4713 - val_acc: 0.3293\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4450 - acc: 0.3878 - val_loss: 1.4709 - val_acc: 0.3323\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4439 - acc: 0.3850 - val_loss: 1.4704 - val_acc: 0.3323\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4403 - acc: 0.3790 - val_loss: 1.4700 - val_acc: 0.3323\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4441 - acc: 0.3829 - val_loss: 1.4696 - val_acc: 0.3323\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4427 - acc: 0.3903 - val_loss: 1.4690 - val_acc: 0.3323\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4237 - acc: 0.3991 - val_loss: 1.4685 - val_acc: 0.3323\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4408 - acc: 0.3885 - val_loss: 1.4679 - val_acc: 0.3353\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4419 - acc: 0.3850 - val_loss: 1.4675 - val_acc: 0.3353\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4414 - acc: 0.3706 - val_loss: 1.4671 - val_acc: 0.3353\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4364 - acc: 0.3899 - val_loss: 1.4665 - val_acc: 0.3353\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4461 - acc: 0.3829 - val_loss: 1.4661 - val_acc: 0.3353\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4358 - acc: 0.3973 - val_loss: 1.4655 - val_acc: 0.3353\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4464 - acc: 0.3772 - val_loss: 1.4651 - val_acc: 0.3353\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4418 - acc: 0.3832 - val_loss: 1.4647 - val_acc: 0.3353\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4371 - acc: 0.3910 - val_loss: 1.4643 - val_acc: 0.3353\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4405 - acc: 0.3776 - val_loss: 1.4638 - val_acc: 0.3353\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4253 - acc: 0.3977 - val_loss: 1.4633 - val_acc: 0.3353\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4410 - acc: 0.3801 - val_loss: 1.4629 - val_acc: 0.3353\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4258 - acc: 0.3938 - val_loss: 1.4624 - val_acc: 0.3353\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4301 - acc: 0.3938 - val_loss: 1.4619 - val_acc: 0.3353\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4324 - acc: 0.3846 - val_loss: 1.4615 - val_acc: 0.3353\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4332 - acc: 0.3934 - val_loss: 1.4611 - val_acc: 0.3353\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4318 - acc: 0.3977 - val_loss: 1.4607 - val_acc: 0.3353\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4380 - acc: 0.3829 - val_loss: 1.4603 - val_acc: 0.3353\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4269 - acc: 0.3899 - val_loss: 1.4598 - val_acc: 0.3353\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4381 - acc: 0.3892 - val_loss: 1.4593 - val_acc: 0.3353\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4355 - acc: 0.3945 - val_loss: 1.4589 - val_acc: 0.3353\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4343 - acc: 0.3903 - val_loss: 1.4585 - val_acc: 0.3353\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4306 - acc: 0.3815 - val_loss: 1.4580 - val_acc: 0.3353\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4394 - acc: 0.3829 - val_loss: 1.4575 - val_acc: 0.3353\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4253 - acc: 0.3913 - val_loss: 1.4571 - val_acc: 0.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4343 - acc: 0.3882 - val_loss: 1.4566 - val_acc: 0.3384\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4336 - acc: 0.3857 - val_loss: 1.4561 - val_acc: 0.3384\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4354 - acc: 0.3815 - val_loss: 1.4556 - val_acc: 0.3384\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4365 - acc: 0.3913 - val_loss: 1.4552 - val_acc: 0.3414\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4324 - acc: 0.3931 - val_loss: 1.4548 - val_acc: 0.3414\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4351 - acc: 0.3938 - val_loss: 1.4543 - val_acc: 0.3414\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4149 - acc: 0.4030 - val_loss: 1.4539 - val_acc: 0.3414\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4291 - acc: 0.3882 - val_loss: 1.4536 - val_acc: 0.3414\n",
      "Epoch 309/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4209 - acc: 0.4019 - val_loss: 1.4531 - val_acc: 0.3414\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4332 - acc: 0.3899 - val_loss: 1.4526 - val_acc: 0.3444\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4254 - acc: 0.3952 - val_loss: 1.4521 - val_acc: 0.3444\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4150 - acc: 0.3952 - val_loss: 1.4517 - val_acc: 0.3444\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4276 - acc: 0.3882 - val_loss: 1.4513 - val_acc: 0.3444\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4352 - acc: 0.3808 - val_loss: 1.4508 - val_acc: 0.3444\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4328 - acc: 0.3829 - val_loss: 1.4504 - val_acc: 0.3444\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4301 - acc: 0.3762 - val_loss: 1.4499 - val_acc: 0.3444\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4212 - acc: 0.3889 - val_loss: 1.4495 - val_acc: 0.3444\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4303 - acc: 0.3871 - val_loss: 1.4491 - val_acc: 0.3444\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4297 - acc: 0.3861 - val_loss: 1.4485 - val_acc: 0.3444\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4344 - acc: 0.3822 - val_loss: 1.4481 - val_acc: 0.3444\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4171 - acc: 0.3889 - val_loss: 1.4476 - val_acc: 0.3444\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4254 - acc: 0.3822 - val_loss: 1.4473 - val_acc: 0.3444\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4277 - acc: 0.3864 - val_loss: 1.4469 - val_acc: 0.3444\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4196 - acc: 0.3758 - val_loss: 1.4464 - val_acc: 0.3444\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4258 - acc: 0.3868 - val_loss: 1.4460 - val_acc: 0.3444\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4317 - acc: 0.3727 - val_loss: 1.4457 - val_acc: 0.3444\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4362 - acc: 0.3927 - val_loss: 1.4452 - val_acc: 0.3444\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4309 - acc: 0.3716 - val_loss: 1.4448 - val_acc: 0.3414\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4285 - acc: 0.3861 - val_loss: 1.4443 - val_acc: 0.3414\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4300 - acc: 0.3896 - val_loss: 1.4439 - val_acc: 0.3414\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4073 - acc: 0.3920 - val_loss: 1.4436 - val_acc: 0.3414\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4231 - acc: 0.3920 - val_loss: 1.4432 - val_acc: 0.3414\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4210 - acc: 0.3861 - val_loss: 1.4427 - val_acc: 0.3414\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4162 - acc: 0.3850 - val_loss: 1.4424 - val_acc: 0.3414\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4177 - acc: 0.3924 - val_loss: 1.4419 - val_acc: 0.3414\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4209 - acc: 0.3927 - val_loss: 1.4416 - val_acc: 0.3414\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4262 - acc: 0.3878 - val_loss: 1.4411 - val_acc: 0.3414\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4199 - acc: 0.3973 - val_loss: 1.4408 - val_acc: 0.3444\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4359 - acc: 0.3642 - val_loss: 1.4404 - val_acc: 0.3444\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4127 - acc: 0.3963 - val_loss: 1.4400 - val_acc: 0.3444\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4135 - acc: 0.3878 - val_loss: 1.4395 - val_acc: 0.3474\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4061 - acc: 0.4054 - val_loss: 1.4390 - val_acc: 0.3474\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4189 - acc: 0.3945 - val_loss: 1.4386 - val_acc: 0.3474\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4147 - acc: 0.3998 - val_loss: 1.4382 - val_acc: 0.3474\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4195 - acc: 0.3868 - val_loss: 1.4377 - val_acc: 0.3474\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4242 - acc: 0.3934 - val_loss: 1.4373 - val_acc: 0.3474\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4129 - acc: 0.3931 - val_loss: 1.4368 - val_acc: 0.3474\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4066 - acc: 0.4001 - val_loss: 1.4364 - val_acc: 0.3474\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4170 - acc: 0.3963 - val_loss: 1.4361 - val_acc: 0.3444\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4148 - acc: 0.3878 - val_loss: 1.4357 - val_acc: 0.3444\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4012 - acc: 0.4015 - val_loss: 1.4352 - val_acc: 0.3444\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4197 - acc: 0.3927 - val_loss: 1.4348 - val_acc: 0.3444\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4105 - acc: 0.3931 - val_loss: 1.4344 - val_acc: 0.3444\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4172 - acc: 0.3899 - val_loss: 1.4340 - val_acc: 0.3474\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4051 - acc: 0.3963 - val_loss: 1.4336 - val_acc: 0.3474\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4142 - acc: 0.4051 - val_loss: 1.4333 - val_acc: 0.3505\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4168 - acc: 0.3917 - val_loss: 1.4330 - val_acc: 0.3474\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4170 - acc: 0.3846 - val_loss: 1.4327 - val_acc: 0.3474\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4316 - acc: 0.3783 - val_loss: 1.4324 - val_acc: 0.3474\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4057 - acc: 0.3980 - val_loss: 1.4320 - val_acc: 0.3474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4100 - acc: 0.3952 - val_loss: 1.4317 - val_acc: 0.3505\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4175 - acc: 0.3963 - val_loss: 1.4313 - val_acc: 0.3505\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4121 - acc: 0.3808 - val_loss: 1.4310 - val_acc: 0.3505\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4244 - acc: 0.3889 - val_loss: 1.4305 - val_acc: 0.3505\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4210 - acc: 0.3853 - val_loss: 1.4303 - val_acc: 0.3505\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4115 - acc: 0.3934 - val_loss: 1.4299 - val_acc: 0.3505\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4215 - acc: 0.3783 - val_loss: 1.4295 - val_acc: 0.3505\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4005 - acc: 0.4012 - val_loss: 1.4291 - val_acc: 0.3505\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 22us/step - loss: 1.4058 - acc: 0.3949 - val_loss: 1.4287 - val_acc: 0.3505\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3967 - acc: 0.4023 - val_loss: 1.4283 - val_acc: 0.3505\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4098 - acc: 0.3889 - val_loss: 1.4279 - val_acc: 0.3505\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4024 - acc: 0.3938 - val_loss: 1.4275 - val_acc: 0.3505\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4157 - acc: 0.3794 - val_loss: 1.4271 - val_acc: 0.3535\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4141 - acc: 0.3825 - val_loss: 1.4268 - val_acc: 0.3535\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4084 - acc: 0.3927 - val_loss: 1.4264 - val_acc: 0.3535\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4030 - acc: 0.3963 - val_loss: 1.4260 - val_acc: 0.3535\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4117 - acc: 0.4015 - val_loss: 1.4256 - val_acc: 0.3565\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4049 - acc: 0.3984 - val_loss: 1.4252 - val_acc: 0.3535\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3933 - acc: 0.3875 - val_loss: 1.4249 - val_acc: 0.3535\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4050 - acc: 0.3853 - val_loss: 1.4246 - val_acc: 0.3535\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4107 - acc: 0.3924 - val_loss: 1.4243 - val_acc: 0.3535\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4055 - acc: 0.3949 - val_loss: 1.4239 - val_acc: 0.3535\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4001 - acc: 0.4015 - val_loss: 1.4235 - val_acc: 0.3535\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4108 - acc: 0.3896 - val_loss: 1.4231 - val_acc: 0.3535\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3966 - acc: 0.3938 - val_loss: 1.4227 - val_acc: 0.3535\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3961 - acc: 0.3850 - val_loss: 1.4223 - val_acc: 0.3565\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4000 - acc: 0.4051 - val_loss: 1.4220 - val_acc: 0.3565\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4167 - acc: 0.3892 - val_loss: 1.4216 - val_acc: 0.3535\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4192 - acc: 0.3903 - val_loss: 1.4213 - val_acc: 0.3535\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4114 - acc: 0.3861 - val_loss: 1.4210 - val_acc: 0.3535\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4108 - acc: 0.3994 - val_loss: 1.4205 - val_acc: 0.3535\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3950 - acc: 0.3952 - val_loss: 1.4201 - val_acc: 0.3535\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3991 - acc: 0.4058 - val_loss: 1.4198 - val_acc: 0.3565\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3867 - acc: 0.4005 - val_loss: 1.4195 - val_acc: 0.3565\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4092 - acc: 0.3945 - val_loss: 1.4192 - val_acc: 0.3565\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4079 - acc: 0.3892 - val_loss: 1.4189 - val_acc: 0.3565\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4000 - acc: 0.4068 - val_loss: 1.4185 - val_acc: 0.3595\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3940 - acc: 0.4033 - val_loss: 1.4182 - val_acc: 0.3625\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4086 - acc: 0.3977 - val_loss: 1.4178 - val_acc: 0.3625\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4131 - acc: 0.3839 - val_loss: 1.4176 - val_acc: 0.3595\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4014 - acc: 0.3980 - val_loss: 1.4173 - val_acc: 0.3625\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4054 - acc: 0.4033 - val_loss: 1.4169 - val_acc: 0.3656\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4091 - acc: 0.3832 - val_loss: 1.4167 - val_acc: 0.3686\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3975 - acc: 0.3991 - val_loss: 1.4164 - val_acc: 0.3656\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4034 - acc: 0.3963 - val_loss: 1.4159 - val_acc: 0.3686\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3957 - acc: 0.4061 - val_loss: 1.4156 - val_acc: 0.3686\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3989 - acc: 0.3980 - val_loss: 1.4152 - val_acc: 0.3686\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4097 - acc: 0.3836 - val_loss: 1.4147 - val_acc: 0.3716\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4011 - acc: 0.4012 - val_loss: 1.4144 - val_acc: 0.3716\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3881 - acc: 0.3938 - val_loss: 1.4140 - val_acc: 0.3716\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3921 - acc: 0.4097 - val_loss: 1.4136 - val_acc: 0.3716\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4060 - acc: 0.3875 - val_loss: 1.4132 - val_acc: 0.3716\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4087 - acc: 0.3952 - val_loss: 1.4130 - val_acc: 0.3716\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3783 - acc: 0.4178 - val_loss: 1.4126 - val_acc: 0.3716\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3800 - acc: 0.4139 - val_loss: 1.4122 - val_acc: 0.3686\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3964 - acc: 0.4026 - val_loss: 1.4119 - val_acc: 0.3686\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3907 - acc: 0.3903 - val_loss: 1.4115 - val_acc: 0.3686\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3941 - acc: 0.3882 - val_loss: 1.4112 - val_acc: 0.3686\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4008 - acc: 0.3984 - val_loss: 1.4108 - val_acc: 0.3686\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3915 - acc: 0.3970 - val_loss: 1.4104 - val_acc: 0.3686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3891 - acc: 0.4037 - val_loss: 1.4100 - val_acc: 0.3686\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3853 - acc: 0.4005 - val_loss: 1.4097 - val_acc: 0.3686\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3987 - acc: 0.3868 - val_loss: 1.4093 - val_acc: 0.3686\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4042 - acc: 0.3910 - val_loss: 1.4090 - val_acc: 0.3686\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3947 - acc: 0.3994 - val_loss: 1.4085 - val_acc: 0.3686\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3861 - acc: 0.4065 - val_loss: 1.4081 - val_acc: 0.3716\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3992 - acc: 0.3920 - val_loss: 1.4079 - val_acc: 0.3716\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3879 - acc: 0.4047 - val_loss: 1.4076 - val_acc: 0.3716\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3946 - acc: 0.3913 - val_loss: 1.4074 - val_acc: 0.3716\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3917 - acc: 0.3938 - val_loss: 1.4072 - val_acc: 0.3716\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3909 - acc: 0.3942 - val_loss: 1.4068 - val_acc: 0.3686\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3915 - acc: 0.3949 - val_loss: 1.4064 - val_acc: 0.3686\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4008 - acc: 0.3920 - val_loss: 1.4059 - val_acc: 0.3686\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3825 - acc: 0.4107 - val_loss: 1.4056 - val_acc: 0.3716\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3980 - acc: 0.4072 - val_loss: 1.4054 - val_acc: 0.3716\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4007 - acc: 0.3896 - val_loss: 1.4051 - val_acc: 0.3716\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3940 - acc: 0.3920 - val_loss: 1.4049 - val_acc: 0.3686\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4020 - acc: 0.3843 - val_loss: 1.4045 - val_acc: 0.3746\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3882 - acc: 0.4026 - val_loss: 1.4042 - val_acc: 0.3746\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3945 - acc: 0.4008 - val_loss: 1.4038 - val_acc: 0.3746\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3884 - acc: 0.4026 - val_loss: 1.4034 - val_acc: 0.3746\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3838 - acc: 0.4075 - val_loss: 1.4031 - val_acc: 0.3746\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3997 - acc: 0.3949 - val_loss: 1.4027 - val_acc: 0.3837\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3946 - acc: 0.3949 - val_loss: 1.4025 - val_acc: 0.3837\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3964 - acc: 0.3811 - val_loss: 1.4022 - val_acc: 0.3837\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3967 - acc: 0.3987 - val_loss: 1.4019 - val_acc: 0.3867\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3970 - acc: 0.3991 - val_loss: 1.4016 - val_acc: 0.3867\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3764 - acc: 0.4023 - val_loss: 1.4013 - val_acc: 0.3867\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3997 - acc: 0.3783 - val_loss: 1.4010 - val_acc: 0.3867\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3811 - acc: 0.4153 - val_loss: 1.4007 - val_acc: 0.3867\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3816 - acc: 0.3966 - val_loss: 1.4005 - val_acc: 0.3867\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3946 - acc: 0.3931 - val_loss: 1.4003 - val_acc: 0.3867\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3830 - acc: 0.4054 - val_loss: 1.4000 - val_acc: 0.3867\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3952 - acc: 0.3924 - val_loss: 1.3996 - val_acc: 0.3867\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3841 - acc: 0.4058 - val_loss: 1.3991 - val_acc: 0.3927\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3887 - acc: 0.4054 - val_loss: 1.3988 - val_acc: 0.3958\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3878 - acc: 0.4012 - val_loss: 1.3985 - val_acc: 0.3927\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3668 - acc: 0.4015 - val_loss: 1.3983 - val_acc: 0.3897\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3896 - acc: 0.4075 - val_loss: 1.3979 - val_acc: 0.3867\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3935 - acc: 0.3938 - val_loss: 1.3978 - val_acc: 0.3867\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3753 - acc: 0.4030 - val_loss: 1.3975 - val_acc: 0.3867\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3892 - acc: 0.3963 - val_loss: 1.3974 - val_acc: 0.3867\n",
      "Epoch 463/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3953 - acc: 0.4033 - val_loss: 1.3972 - val_acc: 0.3867\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3803 - acc: 0.4008 - val_loss: 1.3969 - val_acc: 0.3897\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3912 - acc: 0.3963 - val_loss: 1.3965 - val_acc: 0.3897\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3846 - acc: 0.4089 - val_loss: 1.3961 - val_acc: 0.3867\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3903 - acc: 0.3839 - val_loss: 1.3959 - val_acc: 0.3867\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3936 - acc: 0.4040 - val_loss: 1.3957 - val_acc: 0.3867\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3803 - acc: 0.4075 - val_loss: 1.3953 - val_acc: 0.3867\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3690 - acc: 0.4047 - val_loss: 1.3949 - val_acc: 0.3867\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3932 - acc: 0.3850 - val_loss: 1.3947 - val_acc: 0.3867\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3844 - acc: 0.4072 - val_loss: 1.3944 - val_acc: 0.3867\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3795 - acc: 0.4142 - val_loss: 1.3942 - val_acc: 0.3867\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3867 - acc: 0.3913 - val_loss: 1.3940 - val_acc: 0.3897\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3696 - acc: 0.4149 - val_loss: 1.3937 - val_acc: 0.3927\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3874 - acc: 0.3899 - val_loss: 1.3934 - val_acc: 0.3927\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3754 - acc: 0.4118 - val_loss: 1.3931 - val_acc: 0.3958\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3790 - acc: 0.4040 - val_loss: 1.3927 - val_acc: 0.3958\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3895 - acc: 0.4037 - val_loss: 1.3925 - val_acc: 0.3958\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3772 - acc: 0.4047 - val_loss: 1.3924 - val_acc: 0.3958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3716 - acc: 0.3934 - val_loss: 1.3921 - val_acc: 0.3927\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3717 - acc: 0.4030 - val_loss: 1.3917 - val_acc: 0.3927\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3856 - acc: 0.3882 - val_loss: 1.3916 - val_acc: 0.3958\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3911 - acc: 0.3980 - val_loss: 1.3912 - val_acc: 0.3988\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3922 - acc: 0.4015 - val_loss: 1.3910 - val_acc: 0.4018\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3643 - acc: 0.4195 - val_loss: 1.3906 - val_acc: 0.3988\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3797 - acc: 0.4082 - val_loss: 1.3902 - val_acc: 0.3988\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3943 - acc: 0.3843 - val_loss: 1.3899 - val_acc: 0.3988\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3819 - acc: 0.3959 - val_loss: 1.3898 - val_acc: 0.3988\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3793 - acc: 0.3913 - val_loss: 1.3894 - val_acc: 0.3958\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4011 - acc: 0.3959 - val_loss: 1.3893 - val_acc: 0.3988\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3838 - acc: 0.4015 - val_loss: 1.3890 - val_acc: 0.4018\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3932 - acc: 0.4058 - val_loss: 1.3887 - val_acc: 0.4018\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3858 - acc: 0.3839 - val_loss: 1.3884 - val_acc: 0.4048\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3850 - acc: 0.3977 - val_loss: 1.3880 - val_acc: 0.4048\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3956 - acc: 0.4037 - val_loss: 1.3878 - val_acc: 0.4018\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3769 - acc: 0.3973 - val_loss: 1.3876 - val_acc: 0.4048\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3747 - acc: 0.4082 - val_loss: 1.3873 - val_acc: 0.4018\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3868 - acc: 0.3924 - val_loss: 1.3870 - val_acc: 0.4018\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3747 - acc: 0.3987 - val_loss: 1.3868 - val_acc: 0.4018\n"
     ]
    }
   ],
   "source": [
    "zillow_model = model.fit(x=X_train, y=y_cat_train, \n",
    "          batch_size=20000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_cat_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-754-5bac093a14be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-730-9d1a245b8a9e>\u001b[0m in \u001b[0;36mmodel_metrics\u001b[0;34m(predictions, y_test)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mgain_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mloss_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mgain_stay_large_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model_metrics(predictions, y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXecFOX9x9/P7l7vd9SjHb33IjYEsaAo2GJPNIkSNdao\niVF/thjFaBJj1FgSEo29xwJSBEQBBQSkSD045I5yvdfdfX5/zOzebLljD2659n2/Xvfa3ZlnZp49\njvnM861Ka40gCIIgHAlbS09AEARBaBuIYAiCIAghIYIhCIIghIQIhiAIghASIhiCIAhCSIhgCIIg\nCCEhgiEIgFLqP0qpR0Mcm6WUOiPccxKE1oYIhiAIghASIhiC0I5QSjlaeg5C+0UEQ2gzmKagu5VS\nm5RSFUqpfymluiqlFiilypRSS5RSKZbxs5RSW5VSxUqp5UqpoZZ9Y5VS683j3gai/a51nlJqo3ns\nKqXUqBDnOFMptUEpVaqU2q+Ueshv/ynm+YrN/dea22OUUn9WSu1TSpUopb42t01VSmUH+T2cYb5/\nSCn1nlLqNaVUKXCtUmqSUmq1eY2DSqlnlVKRluOHK6UWK6UKlVKHlVL3KqW6KaUqlVJplnHjlFJ5\nSqmIUL670P4RwRDaGhcDZwKDgPOBBcC9QGeMv+dbAZRSg4A3gdvNffOBT5RSkebN8yPgv0Aq8K55\nXsxjxwLzgF8BacCLwMdKqagQ5lcB/AxIBmYCNyqlLjDP28ec79/NOY0BNprHPQWMB04y5/RbwB3i\n72Q28J55zdcBF3AH0Ak4EZgO3GTOIQFYAnwOpAMDgC+01oeA5cCllvP+FHhLa10X4jyEdo4IhtDW\n+LvW+rDWOgf4CvhWa71Ba10NfAiMNcddBnymtV5s3vCeAmIwbsiTgQjgaa11ndb6PWCt5RpzgBe1\n1t9qrV1a61eAGvO4RtFaL9dab9Zau7XWmzBE6zRz95XAEq31m+Z1C7TWG5VSNuAXwG1a6xzzmqu0\n1jUh/k5Wa60/Mq9ZpbX+Tmv9jdbaqbXOwhA8zxzOAw5prf+sta7WWpdprb81970CXA2glLIDV2CI\nqiAAIhhC2+Ow5X1VkM/x5vt0YJ9nh9baDewHepj7crRv5c19lvd9gDtNk06xUqoY6GUe1yhKqROU\nUstMU04JcAPGkz7mOTKDHNYJwyQWbF8o7PebwyCl1KdKqUOmmeqxEOYA8D9gmFKqL8YqrkRrveYo\n5yS0Q0QwhPbKAYwbPwBKKYVxs8wBDgI9zG0eelve7wf+qLVOtvzEaq3fDOG6bwAfA7201knAC4Dn\nOvuB/kGOyQeqG9hXAcRavocdw5xlxb/k9D+A7cBArXUihsnOOod+wSZurtLewVhl/BRZXQh+iGAI\n7ZV3gJlKqemm0/ZODLPSKmA14ARuVUpFKKUuAiZZjn0ZuMFcLSilVJzpzE4I4boJQKHWulopNQnD\nDOXhdeAMpdSlSimHUipNKTXGXP3MA/6ilEpXStmVUieaPpOdQLR5/QjgfuBIvpQEoBQoV0oNAW60\n7PsU6K6Uul0pFaWUSlBKnWDZ/ypwLTALEQzBDxEMoV2itd6B8aT8d4wn+POB87XWtVrrWuAijBtj\nIYa/4wPLseuA64FngSJgtzk2FG4CHlFKlQEPYAiX57w/AudiiFchhsN7tLn7LmAzhi+lEHgCsGmt\nS8xz/hNjdVQB+ERNBeEuDKEqwxC/ty1zKMMwN50PHAJ2AdMs+1diONvXa62tZjpBQEkDJUEQrCil\nlgJvaK3/2dJzEVoXIhiCIHhRSk0EFmP4YMpaej5C60JMUoIgAKCUegUjR+N2EQshGLLCEARBEEJC\nVhiCIAhCSLSrQmWdOnXSGRkZLT0NQRCENsN3332Xr7X2z+0JSrsSjIyMDNatW9fS0xAEQWgzKKVC\nDp8Wk5QgCIIQEiIYgiAIQkiIYAiCIAgh0a58GMGoq6sjOzub6urqlp5KWImOjqZnz55EREivG0EQ\nwkO7F4zs7GwSEhLIyMjAtzhp+0FrTUFBAdnZ2fTt27elpyMIQjul3ZukqqurSUtLa7diAaCUIi0t\nrd2vogRBaFnavWAA7VosPHSE7ygIQsvSIQRDEAShLaK15v3vsqmocbb0VAARjLBTXFzM888/3+Tj\nzj33XIqLi8MwI0Ho2OSV1eByt40aet9nl3Dnu9/zfx9taempACIYYachwXA6G39imD9/PsnJyeGa\nliB0SKrrXEz84xLubyU34CNR63QDsK+wsoVnYiCCEWbuueceMjMzGTNmDBMnTuTUU09l1qxZDBs2\nDIALLriA8ePHM3z4cF566SXvcRkZGeTn55OVlcXQoUO5/vrrGT58OGeddRZVVVUt9XUEoU1Tbpp2\n3lzzY7Ofe83eQqrrXEd1bJ3LHXTV46km7hGOlqbdh9VaefiTrfxwoLRZzzksPZEHzx/e4P65c+ey\nZcsWNm7cyPLly5k5cyZbtmzxhr/OmzeP1NRUqqqqmDhxIhdffDFpaWk+59i1axdvvvkmL7/8Mpde\neinvv/8+V199dbN+D0HoCFTVHt0N/UhkF1Vy6YuruWBMOk9fPjbk47TW/OvrvTz62TZG90zifzef\n4rO/0hSg1iIYssI4zkyaNMknV+KZZ55h9OjRTJ48mf3797Nr166AY/r27cuYMWMAGD9+PFlZWcdr\nuoLQrqhx1gtGSVVds53Xs7LYlFPSpOP25Ffw6GfbAMNf4U9ljXFe67xbkg61wmhsJXC8iIuL875f\nvnw5S5YsYfXq1cTGxjJ16tSguRRRUVHe93a7XUxSgnCUVNfVP6kXV9aSFNM8lRFsZli709U0Z3pe\nWY3P56cW7uCuswd7P1fUGiY0WWF0EBISEigrC97tsqSkhJSUFGJjY9m+fTvffPPNcZ6dIHQcCspr\nKKio9X4urgxthTHr2a+59c0NjY7x+B/qXE27sR8u9X1AfHbZbp/PlabPpbaJQhQuOtQKoyVIS0vj\n5JNPZsSIEcTExNC1a1fvvhkzZvDCCy8wdOhQBg8ezOTJk1twpoLQvhn/6BKfz8UhmqQ2ZZewKbuE\nZ65o2DdR5wpNMHLLqnl6yS4ePH8YUQ47B4oDLQrlNU7io4xbc70PI7hJqqy6DofNRkykPaTvcqyI\nYBwH3njjjaDbo6KiWLBgQdB9Hj9Fp06d2LKlPgTwrrvuavb5CUJbx+3WlNc6SYwO3cRUXFl75EEW\ncsuq6ZIQDcBzy3Zz6sBOjOpphL57hKLObyXwzZ4Cdhwq45qTMgB46OOtzN98iE5xkQAUBpnDoZJq\nBnSJB+p9GFZTmpWRDy2ie1I0q38/vUnf5WgRk5QgCMdErdONu4US4bYfKuVQSTX/XpXFqIcWcbDE\n17/32jf7+H5/sTc81Uowp/ffv9jFUwt3BL3WzkPl3uOeXLiDq//5rXdfvWC4qa5zsTarkP2FlVz+\n0jc8+PFW77hyUwCeWbqbZ5buZnVmQcB1rGYqrw/DEnbr+c4eDpYcvxpyssIQBOGYGHT/An4yvidP\n/mR00P2rMwt4cuF23ppzIpGOY3tGnb/5IK9/u4/XrzPMtze+tp7h6YneJ/Bv9xRywdgegBGy6knQ\n2/bIjIBzBfNhLNhyiL35FaQnx3DlCb19TEyem/fuXMMnabfV12+rNcdV1roY8n+fB5xXa41Sihq/\nPI3MvIqAsS98mYnLrZkyqLN3hQFGJFZspJ3Ln57PEzGv0HXMAO535PG488qAc4SLsK4wlFIzlFI7\nlFK7lVL3NDJuolLKqZS6pKnHCoIQGlprtjQx7PNIOM0b5bvfZTc45q53v2f9j8UBT/9Hw02vr2fl\n7gLvdQ+XVrM7t5z+nY3ow805JRRX1vKvr/d6k/QAymoCxcEjGM8t280/v9rjPV9VnYt7P9yM0+Wm\n0pK3UVnrRGvNzsPGSqNrYrR335Gio9ZmFfHil5nk+kVFBeOrXfn8bN4asvIrvCIFUON0k1tWw0z7\nt5ytV6E2vMp1jgWMVYGh+OEibCsMpZQdeA44E8gG1iqlPtZa/xBk3BPAoqYeKwhC6HgSxC6d0JPf\nnzOUFNOOfixUNpDZXF3nIre0ht5psd4cgqpGsqCfWriDET2SmDGiGwCl1XWUVztJT44BjMS4VMt8\nK2pcREVoKmtd7M2vYHI/I9l1S04Jd7y9kWU78khPivYZbyUlNoLiKsN/8KRpgrp6ch+fKKqyaifV\nFmdzRY2La/69lhU78wBIiDZun/sLK/nlK2sb/G4Al764utH9HhKjHZRWGyIx9anl/LxvCSNUAVt0\nP6rrXGTu2c3vHG/6HHOj4xP4Jg4m3xDSNY6FcK4wJgG7tdZ7tNa1wFvA7CDjbgHeB3KP4lhBEELk\nu31FALyzLpvfvLOxWc5Z6Xcj1lqzv7CSe97fxJQnl1Fd5/Kai0qrAuunlVTVkXHPZzy7bDc3vPad\nd/tVL3/LSXOX4nZrtNac8sQy5rxav7+81kmR6TCucbrJzDOe+rMKKthiVnPIt9z8pz213Oe6XROj\nKams8/G9rN7j608ora7zWWFU1Di9YgGGoADc/vbGAGf30XL+6HQuHtfT+/nBgzfyadT9gCHCCeue\nI1FV8W/n2ZRqQ0yn2zfAV39ulusfiXD6MHoA+y2fs4ETrAOUUj2AC4FpwMSmHCsI7RGny01ZtdP7\n9L9xfzEJ0Q76d44/5nPXWJK/coqbJ/nTajL59RvrOWtYV257q16M8strvFnQZdWBZqG8suAO282m\n6Wxnbpl3ZfH17nzv/tKqOh9nssfUdri03uTz4peZQc8dabeRFh9JcVWdj4lo2fZcn3GlVU6sbWYq\nag0fQmWtixP7pZFVUEGN0+UVYn8eOG8Y2UVVzFu5N+j+YETYbcREGCGy3akXsLNsa+FgCt3yV7HS\nNZyHndfwsPMaQBOJk0+vP4VBIV/l6GnpKKmngd9prY86jVEpNUcptU4ptS4vL+/IBxxnjra8OcDT\nTz9NZWXrqFIpHB/u+3ALY/+w2Gujv+C5lUz/85fe/aWWm+6XO/O8N+PS6jpWWm6owbAWxjvWoCat\nNWXVdT4rjM82HWSrX622vLIanObFSqvreHbpLjZbSmAES1uwRjStziwgu8gQN4dN4fEz78otZ83e\nQu+4oiAObM9x/kRF2EiOiaSospbJj3/h3b7zsG+CbVl1nU8fisoaJw6b4poT+zAsPZHSqjpe/HJP\n0GsAnD6kC+eN7t7g/oSo4M/rnoeFU+ybvdteivwr/T44h261+1jqHmMZraglgvP+0bhJrLkIp2Dk\nAL0sn3ua26xMAN5SSmUBlwDPK6UuCPFYALTWL2mtJ2itJ3Tu3Lm55t5siGAIoeAJTf1k0wEgeMjn\n9kOljHpoER9uyGbbwVKumbeGhz8xnrKvmbeGq/75LZW1DZfNr/IRjGNTjOeW7WbkQ4t4e51v1Vf/\n8FrrE3xRRR1PLdrJ+c9+zd78ioA5ebCuEg4UV5Fj3vjjox3eyKTc0sCViefJ/EhER9hJio0gu9BX\nUHaZzmwPpdV1Pj6ailoXVXUuYqMcJMVEUFHrajSkNTEmotG8kNT4QB+SXdeRGg2gmWLbxGGdzJIp\n73Nt7W+9Y75yjwo8V+yx+6NCIZyCsRYYqJTqq5SKBC4HPrYO0Fr31VpnaK0zgPeAm7TWH4VybFvB\nWt787rvv5sknn2TixImMGjWKBx98EICKigpmzpzJ6NGjGTFiBG+//TbPPPMMBw4cYNq0aUybNq2F\nv4UQbgbdv4Bb39rgvekVVdYGdFnbmmM8vX+5I88rKJ6b3IYfjWZbZdVOr93fnxpL8teevAoe/mRr\nowLTGG+uMSzGr33jKxj+N9DdufU34cMW85MnhyFYOfBth+pXKYUVdd6VQlykw1uzyWpS8zi3uydH\nEwrRETaSYyK8obADu8TjsCkfhzcYor3KsmorqaqlzqWJjbCTaDq81+wNzKMAmGVbRcrTGSTZ6uc5\nuGuCz5g0v6CDOx3v8H8bTuOKheOZ63iZU2xb+Mo9iviMsSy3rCp2asPHMbR7Ir+a0g/AJyAgnITN\nh6G1diqlbgYWAnZgntZ6q1LqBnP/C0099pgnteAeOLT5yOOaQreRcM7cBndby5svWrSI9957jzVr\n1qC1ZtasWaxYsYK8vDzS09P57LPPAKPGVFJSEn/5y19YtmwZnTp1at45C60Kz839000H6WFGBRVV\nGiUfrHgSt+w2m/fGuW5fkU+iWUF5LSc89gV3njmIW6YP9G53u3VA3aJ/r8zitEGdmTq4S5PnXBrE\nHwHw+dZDPp83/Fhv38+1rByq6ly43Zr1P/ra/5duP8z6fcXYbYreqbEUV9ay7aAhIFaROGiW1EiI\ncjCuTwoHNh2ke1I0e/zyGv508Sh++/4mn21RDjvJsfVP/vfOHMqd73xPoZ9g/O79+ntFQrSD/DJj\nf2yUg95psYCRRxEXaafCr2z6gxGvoOoqSDq0GuMWBvNvOxWtNQPuM6o7+Bc+nGVbxaGYgThiEri8\ncDkAK1wjucFcpZxdM5c4qhnUNYGdh8vpFB/J+D4pwPETjLD6MLTW87XWg7TW/bXWfzS3vRBMLLTW\n12qt32vs2LbOokWLWLRoEWPHjmXcuHFs376dXbt2MXLkSBYvXszvfvc7vvrqK5KSklp6qkIz8Yv/\nrOUki50cYFVmPpuy69vvWiNxPDWBiipqySuvv8G63NrrC3DYlNfHAb4F67YcMPwDf1680+eaf/ti\nV8ATNDSeJVzrdHPzG+vZnVtGYUUtK3fnU1Xr4qGPt3ojhDx4Sln4NwFasq3ekWwVrOSYCF76ag9/\n+twQu6mDDXPyL/6zjrVZhYxIT6RHcgwHS6r5YtvhIPM2xON/N5/svXbXhMAVRs+UmIBtyTERJMfU\n32BTYyO9IbIOSzKelc4JUXxniltcpJ3Th3RlZA/j/6m/acmGmxiM33VE1pcM7prAk5eMwm5TOOz1\nt9zYyPrn9T86/kUfWy4bO8+iauwvvdtXukcQHWEcs0P3Zr0exLjehkgkRDu8uSbNESIdCh0r07uR\nlcDxQGvN73//e371q18F7Fu/fj3z58/n/vvvZ/r06TzwwAMtMEPBQ7/ff8YdZ/g+pR8NS/0ibwCu\nfNkwx8y7dgK/+M86Pr2lvmmO1STltNx8S6rqcLrN8hNuN69/G7xj3Mb99UL05c481u4t5KZp/Zm3\nci9nD+/Kwq2+N98DjURLfZ9dzKebDnKwpJqYCDtf787nzGFdWfxD4A380gk9eWz+dgBuPX0Azyz1\nrbraLTHaW84iKSaCshon31jCWDPS4gAjaOXHwkpOHtCJ6jqXNzJqSLcEth+qd0ofMM+VGBNB305x\n3vf+dLPkYtx11iCeWrSTpJgIkiwrjNS4SK+vYWzvZNZm1a96LhiTzkcbD+CwKa8YekR9YNd4NueU\nkBoXxX7TH/LWnMn8b9kqYvcbYq/2LGXhHcFDXmPN88RRxaX25VToKLanncGMSaMoylrCqzuggCSi\n/XwznlVoTISDyf3SsNsU153SN+D84aClo6TaPdby5meffTbz5s2jvNyw6+bk5JCbm8uBAweIjY3l\n6quv5u6772b9+vUBxwrHD6fLjVsbT+mHSqqD1vtpiOo6F+9/lx1Q2C5YP4MXlhsRNtb+0vWCUefT\nK+H77GIe+J9hlf1gfQ6fbT4Y9PpvWITkmnlreHbZbtZlFVFW7eSCMT18xipF0Gqp/hRV1HpzFL7c\nGTwSsVuScRPrFB/F6F5GQb5JfVO9+wd0iedHsy91l4QoyqudPhFW1pIhBRW1pMVF+phZovxKinh+\nN9aQ49ggFVutguGpAJsUG0GyRVzS4iO915/cL41v753OnWcOYt61E/jzpWP49t7p3uxuMHwpgFdk\nUi3iMykjlcenmiHQQ86Dwj1QaIbVHtoCC+5hqNrn851/OzSfCOXi+ro7qYpMgah4bBe/zF+dPwHw\nEYyHzh/mFawIuyI9OYbMx871/s7DjQhGmLGWN1+8eDFXXnklJ554IiNHjuSSSy6hrKyMzZs3M2nS\nJMaMGcPDDz/M/fcbiTpz5sxhxowZ4vQ+ztRazD0XPr+SK17+JqgTORifbjrIne9+z5z/fuez3d9/\nAEb2MviuCjAtIkWVtT7moptfXx/q9AP4bJMhLp0S6htxXT25N2N7JXOguIrc0mqmPrmM7/YV8pt3\nNvJ/poB5vvKe/Arv03VDjXw81VcTox0kmxE71XUunrliLHeeOYieKTHeFVPnhCiq6lysyaoPi7UK\nQq3TTWpcpPc8AL86rX/Q60Y57PTtFEeUw0Zny/fzYDX7ePJQkmMiGdEjyWeMZ6U1PD2RronR3DJ9\nIKcP6YrdpuiaGO11Lhvj7d7vCpBgiYSy2RQUmQIx0TQtZS41Xr98Ar79B7c6PjDGmn6oSa6NaEcM\nXYadxg1TjO8ZF1UvEh6TFMC1J/f1ms0i7Mf/9t2xTFIthH9589tuu83nc//+/Tn77LMDjrvlllu4\n5ZZbwjo3IRBrNJHnpl1e4/S5MTTEfvMpOivf1/l6oLiKXqmxvtuC+A88UUsHi6sDksZC5ffnDOHx\nBdu9n99bb9R5SouLZFzvZHKKq3j0gpHc/MZ6tuSUsPVgKVkFlVwzb63XJn7vuUN9spoTohycOqgT\n8zcfCurk9TwtJ8REeJ/qR/dMZtbodACeXVpf76hLkBv7L0/py8ffH2BfgfH7S4mLJMpR7yc5d2R3\nnrxkFHe/t4nRPZN82pnGRTlYcNuppCfH8PAnR64elJ4cTVyUgxnDu3kTBD3/zlYhsfL7c4fy4gpj\nRRgbVS8USZQztvQLsJlmrM1VsPsLsEdC39MgqRdsfheik2CvkU9zsm0rs2yrGFW0k1m2fHrmrUBl\nnMLTV9f3w/H4Oq49KYNoh+/KySO8IhiC0AqoCfIUXVBeG5JgeJ5UCypqfRzT1tVCpN3ms4qx4slB\nWLk7n36d45iUkcqe/Aryy49ctM7DtCFdfATDszpIi4vig5tO9m5PT45h0Q+HvaYha7G+oQ/4Vlwd\n2yfF6ytIjY/kgWkDvFFE//n5RHqmGGJ41Qm96ZEcw6e3nMLArvXZ6Z79QNCVQGJ0BLdNH8hv3vne\nnGskw7on+ozxmJSMon++RRT7hZAJf81JGTjdmp+dmAHAP64e59139eTevPbNj17/QDA8dZ68K4wY\nB79xvMs1Bxfzc89i6H3zNX0s2Oww+FxY8yL8aNaSGvczEte/yjORz8I++EkkUAUMvjPgellzZwad\nh+dvJ8IR3EEfTkQwhDaP1ppXV+9j9ph0HzPG0RLM7FJQUUNGpzh+LKgkM7+cffkV/GRCL+L8snUP\nmNE7LrfmUGk18VFGJMviHw5zwdgeuNyaWpeb7knRHCyp5oS+qXxryVj22OYLKmopqKhl9ph0UuMi\nA8JVG8MaLTSyR5L3KToxxneu6UnR1DrdZBUEltj2p1+nOGaOTOe5ZZmkxkUxske9zXxIt0S6JUWz\n64/neJ96/Z/Ue1iilYIJhs2mvIIAhiN6RI8kIh02xpr2ec85eqXG8tovT2gwtLchoiPs/HraAO9n\nZVnC/WH2CB48f7jPNn8SoiMorXZ6TUKp7kIG2b7nh5jx3Fx8BQBL75xqDjYzvM9+DCZdb7y3R0Jy\nb05ZPZ5I6rhp6gCeX76bB2aNYuqESSF/jzqnucKwyQojLHhq0bdnQrWxt0d+OFjKgx9vZcXOPP51\n7cQGx+3JK+fPi3by+MUjG83ArQnSDjO/3HBiT3lymXfb++tz+OCmk3xMAweKq0mKiaCkqo6coipv\nRvX8LQfJK6vx2qavPSmDK0/oTWykg/73zve51vg+Kd76RN2Son1MZMG4f+ZQ0uIjueNt4+ncKgzT\nh3bxCob//4Hu5tO0p1prMFOTh/goB8PSE/no1yeTFhfp8zvymKMaM5FYw1s9Xev6dY7zyZuwruDS\n4gxR2fTgWV5b/6ieyfz3l5OYmJEaEDnk4aT+aaxqQpCCB6UUEfbG7xGPXjiCez/YbFTQ3bWYMxdc\nAjZ4PfYy9hQZpjc6+UXV2R0B20qjulNa7eSiM6eS1mc4pw3uDEe4P03ok8IZw4z2zmN7BwYVHC/a\nvWBER0dTUFBAWlpauxUNrTUFBQVER4eW6dre8Gjl3kaelL/alcfP/70Wp1uTEhfBoxeMDDrO7da8\nsSYwZLWgvDYgK3lzTgkrd+d7Vw/JMRHkFFUxbUhnFm49TE5xFVV1LqYP6cIX23NZviOX04cYSXLR\nEfYGTVyDusZ7BaN3aiyHj9BRbdbodLokRvPWmv0MS0/0+TufNrgLTy8J3i8hPcnX/HLa4M7M3xx8\nJePJUxhjPu3vs/yuj3SjBUMkIuyKOpf2Clqn+Cg/wai/HaWZuQ3+wnDqwMbL//zn55OocbpYuj3X\nW0ZkyW9Oa9BZ3xSmDe5S3wo1zxDZu+vmUBJ7NlDa8IF+rLnvDNxaY7Mppg0JLWnyvRtP8r6fMqgz\nG/7vzOOWe2Gl3QtGz549yc7OpjUWJmxOoqOj6dmz55EHtkM8JTTK/ZLJtNYs2ZbLxIwUfvqvNd7t\na/fWx9kXVtSyKbvYm+382eaD/HtlVsA1CsprfDKNb50+kHlf7+XBj7eyr6DSJy/ikvG9WLj1MHvy\nKtAaxvVJ4fvsElZnFnDSACNr31r36J1fncjr3+7jfxuNOlJJlqSy0T2TWVVj5CL0SI7BYVdex7AH\nj/C8/asTvdsuGJNOeY2L0b2SmTKoM/FRgU/k6X6lNP50yWjOHt6Nr3flBzRE8hc3axhsKF307DZF\n96QY9hdVEhNh3Hb6dYrzKSBoFQx/U1+oRDpsRDpszLaEEHsS+5qVilzctkjedZ3G7/qns2hX6ILR\n0OqoKbSEWEAHEIyIiAj69j0+SS1Cy+Apse2fffznRTt5dtlufnGy77+/JwEOjEzsjfuLUQq+vGta\ng3bxgopabxE8gJ7JMQztnuCT5OVhyqBOdIqP9NZRio20069THNlFVd5VSpQlVHJS31QGd0vwCoY1\njHJwtwSvScnpdlNYEVj7yTrew9OXj/W+f/UXwe3jafFR/Hpaf55bZpQBj49yMHtMDwZ3SwgQjPho\n31uF1fyfcuY+AAAgAElEQVQUGWK0Ts+UGArKa5jcL5W5F41k1ph03lpb38XAYybskxbb0ClaD+W5\n2BK68uWvp9ErJZYnPt9+5GPaAZKHIbR6XG7tE3HkT3lNYEc3T5tOgB2HfZ/+Kmtd1DrduNzamwOh\nNcxbuZf1+4oJRn55jbcI3i9O7suF43oEjaj5x1XjiHLY6ZEcw26zqU9MhJ3uydEcLK2iyvQR+FdW\nTbTckKMj7Dx5yShuOX0AEXab98nb5dYB1V2z5s48JlPrzdMCM9mDVT5N8BMM66oi1Ov36xxHanwk\nSikun9TbJ0cCjKfmxy4cybuWlVKrpfwwxHWmT1qckXvRQWj3Kwyh7XPpi6v5bl8RWXNn4nJrr23a\ng7Wq63f7ChnfJ5UfDpZSVeeiV2pMQI+G0qo6Bt2/ICBs8z+rshqcQ2FFLdlFlThsivtmDsVuU972\noZ6IJ4CxZp2f9OQYFmwx/AExkXa6JRmlMTw3fH+zhFIKpQzhiomw85MJ9dX9PdFDLrfmsgm9eHvd\nfm4/YyB1jYhoqMQEyY4OFmmW6C8YR5EDcNdZgwNWe9/eO92nBMqVJ/Ru8nlbhPI8SKo3Aa+5d3qD\nodLtCREModXjcQDvzi3jjL+s4D8/n+hTYdUqGBf/YzVvXH+C1/QzKSON99f7mlc8kUA/HAzN7hwf\n5WDHoTJcbk335GivYKWYN9ZeqbFewfBUQe1tMatEOeykJ8VQ59Jes1YwO7bHeW/kGdTj8R843Zq5\nF4/k0QtHNGvS1iXje3pzLCC4TyI+yteHcTTXT46NDBAj/+/aqqkqgu/fAlcdFP8IPerNfl3a0vc4\nBsQkJbQZNu43bPkv+LXeLPfrG1FR46Kq1nja69c5jmNlXJ8UCipq+XZvIT2T64XAIxwZFnHwCMF1\np9SXkoiJtNPdzH72lOpurNnPyQPSfD4nWkxSRvhn8/63feono33yEwC2PTLD57O/Scp/ldch2PgG\nfH4PLP4/qCmBboGNjNo7ssIQWi2bsov52HQEQ309Jv+eB/6Nhupcbq/pp3dqww7UX0/rT0WNq1FT\nFMCI9ERvmQxrKevLJvZid145d501mHfW+a5iOidEMTw9ka0HSrErxfg+KaTGRXrLSwRzVM+Z0o/d\nueUBEUnxFsE4XvibqvwFo01RVewNgwWMDOzuo8EeJKy5qgjyzNLwUfHQdTiUHYaiLNi3yijxcccP\nRt5E5LE/jLQ12vBfgdDeufgfq6hz1d8kPSYk/xVFeY2LTvGR3uS6suo6as3jGou4Gdo9kfNGpfP1\n7nyfznD+WB3NJZbe0XFRDh67MHg+Bximnq0HfiAxxkFafBR3njWI+z40CvsFM0nde+7QoOfxCMjx\nFAyA+beeyi9fWcvBkmpvhdY2yfvXwe7FvtvO/AOcfGvg2Heu8dZ8AuC6L+CD642qswDdxxhC0kER\nk5TQarGKBdSbcyprXTzyyQ/eG2hFjZO4KAeL7pgCGOG1NeZN3lrDyB9PGOeS35wWdP/Q7olM6JNC\nP4t9/6omOGWvPSmDpXeexqieRrKbpxAfBHc2N0ScOfb2M46tN0dTGZaeyLK7prLyntPbbiRQbQXs\nXQEjLoGrPzB+Og2GnQsNp5H1p7oU9q2EUZfDFW+DssE3zxti0X20cT5X08qRtDfa8GOD0FbZebiM\npJiIJjs8raaoeSv3MmtMOnGRdj7+/gDDuid6+yKU1zixm6GejZlSgjXcsfLJzSfjsNtwuzXj+6Qy\nLD2xwbGvX3dC0Mgna1G8hOgIlvzmNFbszAvo59wYSqkGC9GFm+gIe6MF+Vot7/0Ctrxf/3nMFTDA\nzNIePANW/g0ebqCHxNiroO8U6DG+/hxn/RFeOQ/iG880b++IYAjHnbP+ugIwHKuvfbOPET2SmLdy\nLxeN7cE5I7tTVFHLq6v3BT02LS7S22q0us7FzW8YfSLOGNoFu00RF2mnrNpJlMOGw9a4g9g/VNQf\nT4lpm001KhYAJw8Ire/6gC7x4ck8Fuqpq66/0Sf1gsk3QT9LT5nJv4aoBHAHqZsVnQx9zA6I5z5p\nrESSekHfU+HS/0Kv0IsEtkdEMISw8+XOPP63MYe/XDrGZ/v767P54/xt3vabi384TNbcmdz30eYG\naxoN7BpPwR6jnMShkmqyi6q4bfpA7jhzEGA4iMurnegoh/eJf+mdpxHpsLFsRx4TM1KY8fRXgNEq\n1MM95wxh6bZcn6Y+Qhvlx1X179PHwIk3+e5P6ApT7j7yedLHGj8ehs1qnvm1YcSHITQLm7NLyLjn\nM7bklATsu2beGj5YnxPgtPU4mvf6NRtqrCXq4K4J3ve7co32tZ0skUsJ0RGU1zipqnN5BaNf53h6\npsTy08l9GNIt0WeshxtO689LPxt/xO8ptAE8He5GXmqYkoRmQ1YYQrPw6uosAL7ZU9Bg17LKWqeP\nnd9TeM7asEhrHRAFZWWgRTA8fZathdjioxzsK6wgM7eCTgnB/QT3nTuUN9f8GJCgZp1bc+RvtHee\n+slonx4WLc72+ZC9Frb+z/BBXPxyS8+o3dGK/rWFtszOw2VHHFNV6/JZZXhqLVmpcboDoqOsDLII\nhmeFkhJrXWE4+GpXvvd6wbh+Sj+ut/Ro9mDtK+1thCM0yCXjW1F1ZLfbcHQ7zQKRE3/RsvNpp4hJ\nSmgWPDkQntdg5JbV+FSUDdajwFMw8LRBwaNRuidF89yV40iJjfCasqyC0Sm+vptbY3MJRnvtl9Ih\nOLSpXiwA+p/ecnNpx4hgCAG43brJhe1Kqoz49KXbD1NSVcfXu/IDBOG8v3/Nlzt9+5L0SvUN2fR0\nf5s1Op05llXAO786kZkju9M9KZqZo7r7RC2lxNX7IjzdyIQORuYXxmuvycZr14YTKoWjRwRDCGDu\n59u5/KVvQh5f63R7/Q47D5dz4fMrufpf33LH2xsDxr7p182uX6fgIaaJMRH8yhSM6Agbk/qm8txV\n47yhrtYWq9YVxjizWqzQxnG7gyfJVZcYyXge6qqh9ADsWmyIxDWfwD37oQX6XXcE5LcqBLAnr4Lv\n9xeHvMoorvI1/XgS7D7bfJB/LPctFOhfarxzQr0JyWpOio9yeLOhg/Xf9myLjrD5OKuHdU/kTjPE\nVmjDfHQDPNG3voQvQEkO/Kkf/HUEOM2/uX+dCX8ZCj+uhgGngyMSohvPmRGOHnF6CwGU19ThdGv2\nFVSGlGRWXNlwuYSGOpF1io8iv7zGJxfiiztPY/TDiwDDeR3tMAUjSEa2tS+0FZtNccv0gazJKvT2\npmgKf71sNKlxUUceKIQPrWHT28b7wj2Q1t94v3sJuJ1QVWhEQyX1NHwXo6+APifDkJbJhu9IhFUw\nlFIzgL8BduCfWuu5fvtnA38A3IATuF1r/bW5LwsoA1yAU2s9IZxz7Yjkl9cw4dElzLt2AqcP6erd\nXmF2sMvMK/cKxjtr92O3Kc4d2Z35mw9ywdge3hLXRWbm9bxrJ/DoZ9sCqskGY2SPRJbtyCMltl4M\n4iz1leKjHNhsikiHzUdUPHi2BdsH8N9fnnDEOQTjwrGtKPKno+GsgVfON1YSHv51JkSY9cCqiiEy\nAeoq4a0rwWbevk65AzoPPv7z7YCETTCUUnbgOeBMIBtYq5T6WGv9g2XYF8DHWmutlBoFvAMMseyf\nprXOD9ccOyJbD5QQ5bAzoEs8m7KNdqSvrNrnIxgef8Tu3HJc7oOcNawrv31/EwDVThf3fbiFw2XV\n3DTV6KFQbDq8uyRE0yc1NiTBeGT2CFZnFjBtSBeeWmSUk3ZYynh4akDFRNiDlvDwrDqCNfsR2ig/\nfgP7v4WBZ8OgsyEyFir9Mu8Hnml0uzto+seSe0MnMUEeL8K5wpgE7NZa7wFQSr0FzAa8gqG1tgbi\nxwHHt35zB+O5Zbu9UUhZc2dSU2f4KKIcNmqcLi54bhW/ntaf4kpjxfDil5mUVju544z6/5BuM4/i\nnbX7uWnqAMqq6/hog/FEmBwb4XVAd02M4nBpDQBbHz6b4Q8uBOB3M4bwxOfb6ZYUzaUTjTakV0zq\nzbvr9vvM1dMDIjbSHnQV4fFhHE2rUOE4U5AJ378JU++Fkv2w7DFwBQl5LtgFtgi4ZF6HLiHemgmn\nYPQArHeBbCDATqCUuhB4HOgCWI2QGliilHIBL2qtXwp2EaXUHGAOQO/ebaQfcAtQUeP0ioUHT4Z1\npMNGdlEV2w6WcvMbG7z7S82cib8u2RmwraLWxUcbcrjdEgnVKT7K+8R/Qt80Pv7eaH5k7S5349T+\n3Di1v888Hr9oJI9fZIRBjuiRyJacUqJM/8Ujs0cErZYaZ2YYywqjDfDBHMhZZ6wcdn4Om9+B1P7B\nx078pYhFK6bFnd5a6w+BD5VSUzD8GWeYu07RWucopboAi5VS27XWK4Ic/xLwEsCECRNkhdIARZWB\nT3Rl1YYpKcphp7AitCQ3z+qjtKqORz6tty4+dP4woiPs3mS5cb2TvYLRlF4Kb1w/mUNmf2yAM4d1\nDTrOkzEeJYLRshTvhx3zfaOZohIMR7TNZqwuctYZ21f9DXK3Qc9J8MuFLTNf4ZgIp2DkAL0sn3ua\n24KitV6hlOqnlOqktc7XWueY23OVUh9imLgCBEMIDf9IpvmbD3q35ZZVBxQA7J0ay4+FlQHnOWSa\nmWqcbmqc9SLTyQyPTU82elyM6xMYodRYH2sPidERQcNo/fE442eM6H7EsUIYWfKgb98JD4ndjWzr\n+XfVb9v2ifE6Qcp2tFXCKRhrgYFKqb4YQnE5cKV1gFJqAJBpOr3HAVFAgVIqDrBprcvM92cBj4Rx\nru0e/xXETa+v59qTMgD4ale+t/7SxIwU1mYVMbhbQlDBCLYN6k1E95wzhDOGdmVUz2SGdEvgSrND\n3cc3n9zkhkmNMaBLPJseOiskcRH8cNXB4a2gg9fa8sEWAV1HBCbCuV3GOTKXwcifwDl/MrY7a+Bv\no2Dz+0ZEU9ZKGPtTOO9pqCk1utjFSDZ+WyVsgqG1diqlbgYWYoTVztNab1VK3WDufwG4GPiZUqoO\nqAIuM8WjK4aZyjPHN7TWn4drrh2BYCYpT5SUlT5pcazNKvJJqLPyY0HwCChP1dLYSAdTzDpQn98+\nxbvf06a0ORGxOEpW/g2W/iH08bOfg7FX+25b/yp8ervxftAMiE2t35dxCmx8zfgBGH4h2B2+Y4Q2\nSVh9GFrr+cB8v20vWN4/ATwR5Lg9wOhwzq2jESy5bv2PvoIRG2kn1SwVbo1M8jQ4AiiqrKNHcgw5\nxVU+x8ZFtrg7TAiVnQuhy3A448Ejj/3kdmO8v2DsXAhJvWH23yHjVN99F74IB8zgiYhYQ0CEdoH8\nL2+nVNW6iLArb25DsBWGP3ab4obT+rO/sJI5p/bzlvXwdyyP6JFIXnkNvz17MI9+tg2gdfVFEHwp\nz4V/nGxkSIORLT3lt0auw5EYMB02/BceSfPd7nbChF9Cv6mBx8R3Ce3cQptD/pe3U4Y+8DlnDevK\nSz+bwG/e2cgH6wPjDZ67chz3fbSZ4so6Zo7qzk/G9yQ1LpJ/XO3bea5zQjRQ30kvIy2O7Y+Mx2ZT\nXsGIizqyQ1toIXYthopcmDTHiGCyRRjhq6Ew5S5I6Abar66YssO4nzb/XIVWjQhGG2V/YSXREfag\nvgZP6OuiHw6jtQ4qFqcN6szMUd25693vAZhzaj9G9/L1M6y4expRETYi7DbeXrvfWxdqWHpiQKhs\nnKwwWh9aw6d3GOajuC4w44mmV3FNyYDT7w/L9IS2hwSxt1FO/dMyTpr7RcD2Wc9+zZhHFns/FzVQ\nGNBTB6raaUTKWEuEe+idFkvXxGhS4yJ9ku2Gpwe2YJV8iFZI4R747t9GVNLU30nJb+GYkcfCNsDm\n7BKq6lxM6mtEmXjKc9S5NBn3fMbdZw/m19OMuk6bsutNRymxETy1qD67e+rgzlw8rie3vLnBKxie\nfCtrE6KGOG9Udz7ddJB+nQL7XUu3ujDhrIGVz0BtYDvbI5Jn/ttf9lp9xVdBOAZEMNoA5z/7NQAb\n/u9MoiPslFb7rhqeXLjDKxhWiirreOPb+oZFKbGRXqGwmzf4s4Z1ZdEPh0NyWv/l0jH8YfaIJmVu\nC8fIjgWw7FGwRwJH8XvvfRKkBvYvF4SjQQSjDTH2D4sZ0SORB88f7rPda16qazwRKykmwltSw243\njvn7lWMpqaoLaYUQ6bAR6fA1XZ0/Op0tOSUNHNGGKM+D7DUN749OOn7hoXk7jUJ8AN+/BVGJ8Nu9\nRi6DILQg8hfYSqmqdXH72xu8vbI9bMkpDSjj4XJrPt9yiCHdEoKea+bI7ny2+SARduUVDIcpMlEO\nO10Sjj7C6e9XjD3qY1sVn94O2z9tfMz1y6DHuPDOw+2G/5wLFZbe58MvErEQWgXyV9hKeeHLTBZu\nPRx039+W7ArYdsNr3/HWnMk+2xRuUiinb0wyqZQS5yxmTFocqZRy0aB+UNGGW41ExEBkoC/FS2Vh\nYChoQ7hdsGc5jLgETr41cH9tJfz7HENQkptYEdkRZYSyBqOuOtA3cXirIRZnPAz9pxnb0gY27ZqC\nECZEMFoRf/p8OymxkVx3al/e+y67wXE5xVU8ftFIfv/BZp/t2w769st+zPEvrnAsg01wVzSwwfhZ\nHw183PzzP65ExMJt3xtJYv589wp8EuTGfySGXwjdGygwkD4Gvvqz8dMUbA646Rvo5HfTd9XBM2Og\n7GCQgxSMuTL4dxOEFkQEI0zc8uYG5m8+SOZj54Z8zPNmZvWZw7qSU1zFgC7x7M4NHh2TkRbHA+cN\n8ykxbnVwD+ocw4zStXzjHkq3Ey/nX1/v5aeT+zCoawNPu22JygJY/rjR43nMlYH7f/ifUbYi2Gqh\nISJiYfA5De+/4B+Q9XXT5umsgUX3GeW/O93mu2//GkMsJv0qUEyS+4hYCK0SEYww8YnZC+Jo2Ljf\nqPE0dVBnr2CcOrCTt6IsQK/UGE7sb5Rr8IjGrtxy7o3/lLNqvyC11kaiKsc95hoyzrmRu6bWNdj/\nus3hdsPaf8Ln98CXfwrcX/wjTLre+Gkuugw1fprKhteMOa77t+/2mlIjW3ravVK9VWgziGCEGZdb\ne6OYGsOTWwH1dZ/6pMV6t71w9Xj++80+5i4wsq27Jxld6K49KYPzRndnzqvf8f3+Qq5iAVGdOmHv\nMRai4jnpTKN8Q7sRCzAS0M5+zCh5EYzeJ8LE647vnBrijAdhywfB96WPFbEQ2hQiGGGmvMZ5xJv1\n3vwKMi2mp/xyo0lRF0v/iJgIO8nmeaIcNq8I2WyKLlmf8lL8J+R2LSaupAhOmwujL2/ur9K6GHWp\n8dPaGXxO46YuQWhDiGCEAaerPjqntKpxU1Ct0820p5b7bNuTV0F8lIMESzKdzaa8IjG2t+WpVGv4\n/Pd0cVbTJSbFcNoOPKt5voggCIIFEYww4OlrDVBW7Qw6ZnVmAfnlNXQJUjxwb34FidEOoiN98yOG\ndk8E4NbTBxp2/M3vGvb6ilyY/TyMvaoZv4UgCIIvIhhh4HBptc/7Rz/7gQfPH05VnYvkmAjWZBXy\n2/c2AfDC1YGJYHvyKujXOY5YP8EY0SOJ3X88x+hxsWsJfDjH2OGIMfoWCIIghBERjDBQaGlWtHxH\nLqsyCzj76RVBx274MbBNaq3LTWJMBLERgf88noZIZH4Bjmi45TuIToao+OaZvCAIQgNIveNmps7l\n5ocD9Ql0Tkv0UzCW7zBKQDx+0Uh6p9ZHRSVGRxAd2cg/T+ZS6HMSJPUUsRAE4bgggtHM/PGzbTy5\nsL6keF5ZTaPjM/PKUQoum9CLFb+d5jVDJcY4iG2oT3ZJNuRth/6nN9u8BUEQjoSYpJqZFTvzfD7n\nHkEweuoDfBD5ELbHDOf4epsLHQWObQrHThvboswKtI9a/Bna3NZvWrPNWxAE4UiIYDQz0RF2y3ub\nd4Xx8s8mMHfBNjLzfCvNzrCtJVWVwYRfg83O+9/+SFmNk5P6pDGqZxKvrNgDwA0n+/U0SEyHrr5l\nzgVBEMJJSIKhlPoA+BewQOtQS4C2f5wuNzalfBoKxVgimxKjI7yCMbBLPL1TY72CYcfFnyJeYopt\nE3tsGfSb8RgA9y39DID/nXky9Epm7tLP6JEcww1niflJEISWJVQfxvPAlcAupdRcpdTgMM6pzTDg\nvgXc9e73PmU9rL2tE6Id1JpJfNERdkb0qO+FPVbt4mL7V+TrJD5NrM9YHtTVcGAPSzdyLhbfMYVP\nbzlOjXsEQRAaIaQVhtZ6CbBEKZUEXGG+3w+8DLymta5r9ATtkMpaw+fwwYYcVuzK4/XrJjO4WwKV\ntfVd7xItGd7RETb6da7v33CqfTMurbis9n4mpdT3W37tuhPILa0hwgyfHdgeqssKgtAuCDlKSimV\nBlwLXIfRWeFvwDiggQpw7ZNDJdVU17nIKarybssvr2XBFqOvQanZIe/6U/uSEG0VDDtTB3UhOdbY\nNsW2mczIwZQST+eE+ranXRKifVYigiAIrYWQBEMp9SHwFRALnK+1nqW1fltrfQvQYZIADpVUM/nx\nL7j5jQ1km4LRr3McSTERXt9ESVUdV53Qm/tmDiMxun4BF+WwkRIXycYHziKJckapTHbETQRgsKwi\nBEFoA4QaJfWM1npZsB1a6wnNOJ9Wy8b9xVzw3EoAlmw7TF6ZUf7jzesn87v3N5GZW86uw2UUVNR6\niw16VhhRDhtK1TvGL0rejb1as9w1CoAhZo0oQRCE1kyoJqlhSilviVSlVIpS6qYjHaSUmqGU2qGU\n2q2UuifI/tlKqU1KqY1KqXVKqVNCPfZ4s+twmc/n77NLAOgcH0X/zvH8cLCU8581OrJ1NcuSe1YY\nVkc4ddU8OCQHohKJ6D0eoH10wRMEod0TqmBcr7X2Fj3SWhcBjbYzU0rZgeeAc4BhwBVKqWF+w74A\nRmutxwC/AP7ZhGObHXcjZTwiHYG/qheuHo/Nppg+xGinWV3n5k8Xj+Kyib2Aeqe3N+y2shCe7A8b\nX4e+U3hw9hgW3j6F1LjIgHMLgiC0NkIVDLuy2FTMG/qR7nKTgN1a6z1a61rgLWC2dYDWulxr7blL\nxwE61GObm8Ol1fS7dz7vrtsfdL81+gngzjMHMWNENwBO7J/G7DHp3D9zKJdO7OVN3kswVxi1TjN1\nJXcb1JbDpDlw1qPERNoZ3E1WF4IgtA1CFYzPgbeVUtOVUtOBN81tjdEDsN59s81tPiilLlRKbQc+\nw1hlhHysefwc05y1Li8vL9iQkNhjOq3vfm8Tu3MN81NhRS3XvbKOA8VVrN1b6DO+a1J9NzylFH+7\nfCzXneqbje1po+oVm6K9xusJN0Bq36OeqyAIQksQqmD8DlgG3Gj+fAH8tjkmoLX+UGs9BLgA+MNR\nHP+S1nqC1npC586dj3oeFp80Z/zFKEW++IdDLNl2mJPmLuWDDTk+49NCMCN5kvC8FO4FZYfk3kc9\nT0EQhJYi1MQ9N/AP8ydUcoBels89zW0NXWOFUqqfUqpTU49tDjyJeFaiHPYgIw08+RSN0Ssl1ndD\n0V6jHLn9yMcKgiC0NkKtJTUQeBzDAe21xWit+zV4EKwFBiql+mLc7C/HKC9iPe8AIFNrrZVS44Ao\noAAoPtKxzU2wVqrFlkZIHp6/ahyVtS7G9U454jk9zm6vwzxnPXQJu+9eEAQhLISah/Fv4EHgr8A0\n4OccwZyltXYqpW4GFgJ2YJ7WeqtS6gZz/wvAxcDPlFJ1QBVwmekED3psk79diNS53Hy+5ZDPthlP\nryDRzKPY9sgMhj5guGzOHdm9Sedec990HDYbFO4xVhiTb2yeSQuCIBxnQhWMGK31F0oppbXeBzyk\nlPoOeKCxg7TW84H5fttesLx/Angi1GPDxd+W7GKBn2BsP2Q4vuMi7T4VaJtKlwRzQfaDmfcoTY8E\nQWijhCoYNUopG0a12psxzETtpiRIZl55g/uSYw3n9gtXj/MpJtj0iyyFpN6QNuDozyEIgtCChCoY\nt2HUkboVI5JpGnBNuCZ1vAmWlOfBIxIzRjTNFOWDqw72roDhF/qGYwmCILQhjigYZpLeZVrru4By\nDP9Fu6KRBG9vj+1jIuc7qCkVc5QgCG2aI+ZhaK1dQLvu4JNv6budNXcms0ane/MsdvrVkGoyn90J\nr14Aygb9Tju2cwmCILQgoZqkNiilPgbeBbxNqbXWH4RlVseZvHJDMCb1TQXgmSvGAvCnz7czPP0Y\ne1PsWGBkdU++EWKOHIorCILQWglVMKIx8iOsNhUNtA/BKKvhmhP78PDsET7bfztjyLGduK4aSg/A\nuJ8ZP4IgCG2YUDO9253fwoPWmovG9eCEvmnNf/LifYCGFKkbJQhC2yfUTO9/U19J1ovW+hdBhrcp\nlFI8eP7w8Jy80Cw2KIUGBUFoB4RqkvrU8j4auBA40PzTaWd4qtPKCkMQhHZAqCap962flVJvAl+H\nZUbticK9EBkPcZ1aeiaCIAjHTKjlzf0ZCHRpzom0S4r2GqsLSdYTBKEdEKoPowxfH8YhjB4ZQmMU\n7oUuxxhpJQiC0EoI1SQlfUSbirPWiJIafE5Lz0QQBKFZCMkkZbZRTbJ8TlZKXRC+abUDsteAqxZ6\nT27pmQiCIDQLofowHtRal3g+aK2LMfpjCMGoyIdXzgcUZJza0rMRBEFoFkIVjGDjQg3J7XjsXwPa\nDaMug+jElp6NIAhCsxCqYKxTSv1FKdXf/PkL8F04J9amKdxjvM54vGXnIQiC0IyEKhi3ALXA28Bb\nQDXw63BNqs1TtBeikqTYoCAI7YpQo6QqgHvCPJf2wZ7lsP9boxyI5F8IgtCOCDVKarFSKtnyOUUp\ntTB802qjlGTDq7Ph0GboPqqlZyMIgtCshOq47mRGRgGgtS5SSkmmtz+ZS43Xn34k0VGCILQ7QvVh\nuJVSvT0flFIZBKle2+HJXAoJ3aHfVLBLEJkgCO2LUO9q9wFfK6W+BBRwKjAnbLNqi7hdhv9i8Lni\nu2C+iW8AAA5iSURBVBAEoV0SqtP7c6XUBAyR2AB8BFSFc2JtjoMboaoI+p9+5LGCIAhtkFCLD14H\n3Ab0BDYCk4HV+LZs7dh4/Bf9prbkLARBEMJGqD6M24CJwD6t9TRgLFDc+CEdjMxl0H209L4QBKHd\nEqpgVGutqwGUUlFa6+3A4PBNqw2SvxPSx7X0LARBEMJGqE7vbDMP4yNgsVKqCNgXvmm1MbQ2/BeS\n2S0IQjsmVKf3hebbh5RSy4Ak4PMjHaeUmgH8DbAD/9Raz/XbfxVGIyYFlAE3aq2/N/dlmdtcgFNr\nPSGUubYIteXgdopgCILQrmlysoDW+stQximl7MBzwJlANrBWKfWx1voHy7C9wGlmIuA5wEvACZb9\n07TW+U2d43GnynTnxCQ3Pk4QBKENc7Q9vUNhErBba71Ha12LUbRwtnWA1nqV1rrI/PgNRhRW26PK\n/AqywhAEoR0TTsHoAey3fM42tzXEL4EFls8aWKKU+k4p1WCSoFJqjlJqnVJqXV5e3jFN+KipNlcY\n0bLCEASh/dIq6lcopaZhCMYpls2naK1zzJpVi5VS27XWK/yP1Vq/hGHKYsKECS1TrkRWGIIgdADC\nucLIAXpZPvc0t/mglBoF/BOYrbUu8GzXWueYr7nAhxgmrtaJ+DAEQegAhFMw1gIDlVJ9lVKRwOXA\nx9YBZkHDD4Cfaq13WrbHKaUSPO+Bs4AtYZzrsSErDEEQOgBhM0lprZ1KqZuBhRhhtfO01luVUjeY\n+18AHgDSgOeVUbDPEz7bFfjQ3OYA3tBaHzGMt8UozYHIBIiIbemZCIIghI2w+jC01vOB+X7bXrC8\nvw64Lshxe4DR4Zxbs1K4VzrsCYLQ7gmnSarjUGQKhiAIQjtGBONYcbugaB+kiGAIgtC+EcE4Vgp2\ng7sO0ga09EwEQRDCigjGsZK5zHjtKz28BUFo34hgHCuZSyG1P6RktPRMBEEQwooIxrHgrIGsr6Qt\nqyAIHQIRjGNh/7dQVymCIQhCh0AE41jIXAo2B2SccuSxgiAIbRwRjGMhcyn0nATRiS09E0EQhLAj\ngnG0uJxweCv0ntzSMxEEQTguiGAcLSX7jbasqf1aeiaCIAjHBRGMo6Vor/EqJUEEQeggiGAcLYV7\njFcpCSIIQgdBBONoKdwL9ihI6N7SMxEEQTguiGAcLUVZRna3TX6FgiB0DORud7QUSklzQRA6FiIY\nR4PWxgpDIqQEQehAiGAcDcseg7oKcXgLgtChEMFoKm4XrH3ZeD/wzJadiyAIwnFEBKOpHNwIVUVw\n0T/FhyEIQodCBKOpZC41XvtNbclZCIIgHHccLT2BNoPWsGcZ/PAxdB8N8Z1bekaCIAjHFVlhhMqP\nq+G/F8KhTTBoRkvPRhAE4bgjK4xQ2bUYlB2uXwpdR7T0bARBEI47IhihsncF9JwI6WNaeiaCIAgt\ngpikQqVgF3STlYUgCB0XEYxQqCyE6hJJ1BMEoUMjghEK0vtCEAQhvIKhlJqhlNqhlNqtlLonyP6r\nlFKblFKblVKrlFKjQz32uFJoCoasMARB6MCETTCUUnbgOeAcYBhwhVJqmN+wvcBpWuuRwB+Al5pw\n7PEjZz04oqXYoCAIHZpwrjAmAbu11nu01rXAW8Bs6wCt9SqtdZH58RugZ6jHHjcK98A3z0GfkyAi\nukWmIAiC0BoIp2D0APZbPmeb2xril8CCph6rlJqjlFqnlFqXl5d3DNNtgC8eMV6Hzmr+cwuCILQh\nWoXTWyk1DUMwftfUY7XWL2mtJ2itJ3TuHIZyHQW7ofdJMOHnzX9uQRCENkQ4BSMH6GX53NPc5oNS\nahTwT2C21rqgKceGHa2hMAu6jTzulxYEQWhthFMw1gIDlVJ9lVKRwOXAx9YBSqnewAfAT7XWO5ty\n7HGhsgBqyyScVhAEgTCWBtFaO5VSNwMLATswT2u9VSl1g7n/BeABIA14XikF4DTNS0GPDddcG6Rg\nt/Eq4bSCIAjhrSWltZ4PzPfb9oLl/XXAdaEee9zJ+tp47TG+RachCILQGmgVTu9WS+Yy6DZKel8I\ngiAggtEwNWWw/xvof3pLz0QQBKFVIILREFlfg9spgiEIgmAigtEQmUvBEQO9J7f0TARBEFoFIhgN\nkbkUMk4BR1RLz0QQBKFVIIIRjPJcI6S232ktPRNBEIRWgwhGMAoyjdfOQ1p2HoIgCK0IEYxgFEn/\nC0EQBH9EMIJRuBeUDZJ7t/RMBEEQWg0iGP7k74IVf4LEnuCIbOnZCIIgtBpEMPzZ8oHxevKtLTsP\nQRCEVoYIhj+ZSyF9HEz6//buNUaqs47j+PfndqErS0spa224FLA1Sk2LlaCxSFDT2lsEkxobbdMY\nIzGpUWKMQuol+k5fqG9IoNEmmFJrrN1Imkbl0tA0XljaLmWhYNmCCqFutVzEFGx3/744z4TjZpc9\nLMyc2TO/TzKZM885Mzy/SZb/POfMPM8Xy+6JmVlTccHIO30CDvf4191mZiNwwcg7+AzEoAuGmdkI\nXDDy+rfBpE6YvbjsnpiZNR0XjLz+bTBvKbS1l90TM7Om44JR869+OHbIp6PMzEbhglHTvy27d8Ew\nMxuRC0bNwe1w+RyYPr/snpiZNSUXjJoTR6Dr3SCV3RMzs6bkglHzxjG4dFrZvTAza1ouGDWnj0PH\nFWX3wsysablgAAwNwRvHocMjDDOz0bhgAJw5CYRHGGZm5+CCAdn1C/A1DDOzc3DBgOz6BXiEYWZ2\nDi4YcHaE4WsYZmajcsEAOPVadu8RhpnZqOpaMCTdJmm/pAOSVo+w/z2S/ijpjKSvD9t3SNJuSb2S\ndtazn/ztDzD5Mrjy2rr+M2ZmE9kl9XphSW3AWuAW4DDQI2lTROzNHfY68BVgxSgv89GI+Ge9+ghA\nBBzwLLVmZmOp5whjMXAgIl6JiP8CjwHL8wdExEBE9ABv1rEf5/bWaZi/FK7/VGldMDObCOo2wgBm\nAn/PPT4MfPA8nh/AFkmDwPqIeGikgyStBFYCzJkz5/x72d4By9ee//PMzFpMM1/0XhIRC4HbgQck\nLR3poIh4KCIWRcSirq6uxvbQzKyF1LNgHAFm5x7PSm2FRMSRdD8AdJOd4jIzs5LUs2D0ANdJmidp\nEnAPsKnIEyVNkTS1tg3cCvTVradmZjamul3DiIi3JH0Z+B3QBjwcEXskfSntXyfpncBO4DJgSNIq\nYAEwA+hWtjbFJcCjEfHbevXVzMzGVs+L3kTEU8BTw9rW5bZfJTtVNdxJ4MZ69s3MzM5PM1/0NjOz\nJuKCYWZmhbhgmJlZIYqIsvtw0Uh6DfjrOJ8+A6jvNCTNx5lbgzO3hvFmviYiCv2IrVIF40JI2hkR\ni8ruRyM5c2tw5tbQiMw+JWVmZoW4YJiZWSEuGGeNOLlhxTlza3Dm1lD3zL6GYWZmhXiEYWZmhbhg\nmJlZIS1fMMZad3yikvSwpAFJfbm26ZI2S3o53V+R27cmvQf7JX2inF5fGEmzJT0taa+kPZK+mtor\nm1vSpZJ2SNqVMn8vtVc2c42kNkkvSHoyPa50ZkmHJO2W1CtpZ2prbOaIaNkb2Sy6/cB8YBKwC1hQ\ndr8uUralwE1AX67th8DqtL0a+EHaXpCyTwbmpfekrewM48h8NXBT2p4K/CVlq2xuQEBn2m4H/gx8\nqMqZc9m/BjwKPJkeVzozcAiYMaytoZlbfYQx5rrjE1VEPAO8Pqx5ObAhbW8AVuTaH4uIMxFxEDjA\nBFywKiKORsTzafvfwEtkSwVXNndkTqWH7ekWVDgzgKRZwJ3AT3PNlc48ioZmbvWCMdK64zNL6ksj\nXBURR9P2q8BVabty74OkucD7yT5xVzp3OjXTCwwAmyOi8pmBnwDfAIZybVXPHMAWSc9JWpnaGpq5\nruthWPOKiJBUye9US+oEfg2sioiTaSEuoJq5I2IQWChpGtnCY+8btr9SmSXdBQxExHOSlo10TNUy\nJ0si4oikdwCbJe3L72xE5lYfYVzQuuMT0D8kXQ2Q7gdSe2XeB0ntZMViY0Q8kZornxsgIo4DTwO3\nUe3MNwOflHSI7DTyxyQ9QrUzExFH0v0A0E12iqmhmVu9YIx73fEJahNwf9q+H/hNrv0eSZMlzQOu\nA3aU0L8Lomwo8TPgpYj4UW5XZXNL6kojCyR1ALcA+6hw5ohYExGzImIu2d/stoi4lwpnljRF0tTa\nNnAr0EejM5d95b/sG3AH2bdp+oEHy+7PRcz1C+Ao8CbZ+csvAFcCW4GXgS3A9NzxD6b3YD9we9n9\nH2fmJWTneV8EetPtjirnBm4AXkiZ+4DvpPbKZh6WfxlnvyVV2cxk3+TclW57av9XNTqzpwYxM7NC\nWv2UlJmZFeSCYWZmhbhgmJlZIS4YZmZWiAuGmZkV4oJh1gQkLavNumrWrFwwzMysEBcMs/Mg6d60\n/kSvpPVp4r9Tkn6c1qPYKqkrHbtQ0p8kvSipu7ZWgaRrJW1Ja1g8L+ld6eU7JT0uaZ+kjcpPgmXW\nBFwwzAqS9F7gM8DNEbEQGAQ+B0wBdkbE9cB24LvpKT8HvhkRNwC7c+0bgbURcSPwYbJf5EM2u+4q\nsrUM5pPNmWTWNDxbrVlxHwc+APSkD/8dZJO9DQG/TMc8Ajwh6XJgWkRsT+0bgF+l+YBmRkQ3QESc\nBkivtyMiDqfHvcBc4Nn6xzIrxgXDrDgBGyJizf81St8edtx459s5k9sexH+f1mR8SsqsuK3A3Wk9\ngtp6yteQ/R3dnY75LPBsRJwAjkn6SGq/D9ge2UqAhyWtSK8xWdLbG5rCbJz8CcasoIjYK+lbwO8l\nvY1sJuAHgP8Ai9O+AbLrHJBNN70uFYRXgM+n9vuA9ZK+n17j0w2MYTZunq3W7AJJOhURnWX3w6ze\nfErKzMwK8QjDzMwK8QjDzMwKccEwM7NCXDDMzKwQFwwzMyvEBcPMzAr5H27vwYUfovN0AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17c0d6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model.history['acc'])\n",
    "plt.plot(zillow_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 1.4290 - acc: 0.3459 - val_loss: 1.2957 - val_acc: 0.4381\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3392 - acc: 0.3843 - val_loss: 1.2893 - val_acc: 0.4350\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3316 - acc: 0.3681 - val_loss: 1.2717 - val_acc: 0.4350\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3060 - acc: 0.4037 - val_loss: 1.2706 - val_acc: 0.4411\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.3118 - acc: 0.3949 - val_loss: 1.2661 - val_acc: 0.4864\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2875 - acc: 0.3942 - val_loss: 1.2614 - val_acc: 0.5166\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2731 - acc: 0.4068 - val_loss: 1.2410 - val_acc: 0.4018\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2716 - acc: 0.4047 - val_loss: 1.2427 - val_acc: 0.4894\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2657 - acc: 0.4241 - val_loss: 1.2363 - val_acc: 0.5015\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2592 - acc: 0.4269 - val_loss: 1.2303 - val_acc: 0.4713\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2625 - acc: 0.4213 - val_loss: 1.2359 - val_acc: 0.5196\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2423 - acc: 0.4163 - val_loss: 1.2153 - val_acc: 0.5227\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.2285 - acc: 0.4195 - val_loss: 1.2341 - val_acc: 0.5227\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2378 - acc: 0.4072 - val_loss: 1.2076 - val_acc: 0.5045\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2431 - acc: 0.4065 - val_loss: 1.2080 - val_acc: 0.4471\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2241 - acc: 0.4185 - val_loss: 1.1958 - val_acc: 0.4683\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2232 - acc: 0.4132 - val_loss: 1.2180 - val_acc: 0.5136\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.2126 - acc: 0.4188 - val_loss: 1.1926 - val_acc: 0.5015\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2043 - acc: 0.4213 - val_loss: 1.1837 - val_acc: 0.5076\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1982 - acc: 0.4280 - val_loss: 1.1901 - val_acc: 0.4592\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1889 - acc: 0.4392 - val_loss: 1.2270 - val_acc: 0.4411\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1843 - acc: 0.4498 - val_loss: 1.1640 - val_acc: 0.4622\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1797 - acc: 0.4639 - val_loss: 1.1630 - val_acc: 0.5257\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1791 - acc: 0.4540 - val_loss: 1.1815 - val_acc: 0.4804\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1549 - acc: 0.4621 - val_loss: 1.1522 - val_acc: 0.5166\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1626 - acc: 0.4671 - val_loss: 1.1691 - val_acc: 0.4350\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1474 - acc: 0.4734 - val_loss: 1.1342 - val_acc: 0.5257\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1472 - acc: 0.4787 - val_loss: 1.1322 - val_acc: 0.5196\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1413 - acc: 0.4794 - val_loss: 1.1575 - val_acc: 0.5287\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1394 - acc: 0.4815 - val_loss: 1.1492 - val_acc: 0.5227\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1208 - acc: 0.4889 - val_loss: 1.1440 - val_acc: 0.5136\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1127 - acc: 0.4988 - val_loss: 1.1183 - val_acc: 0.5438\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1235 - acc: 0.4949 - val_loss: 1.1276 - val_acc: 0.5498\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1185 - acc: 0.4991 - val_loss: 1.1272 - val_acc: 0.5076\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1070 - acc: 0.5143 - val_loss: 1.1408 - val_acc: 0.5378\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0986 - acc: 0.5055 - val_loss: 1.1178 - val_acc: 0.5196\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1013 - acc: 0.5041 - val_loss: 1.0913 - val_acc: 0.5529\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1006 - acc: 0.5051 - val_loss: 1.0926 - val_acc: 0.5378\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0886 - acc: 0.5192 - val_loss: 1.1120 - val_acc: 0.5257\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0731 - acc: 0.5259 - val_loss: 1.0873 - val_acc: 0.5559\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0777 - acc: 0.5231 - val_loss: 1.0920 - val_acc: 0.5408\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0678 - acc: 0.5301 - val_loss: 1.0796 - val_acc: 0.5559\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0680 - acc: 0.5174 - val_loss: 1.0810 - val_acc: 0.5619\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0652 - acc: 0.5227 - val_loss: 1.0724 - val_acc: 0.5680\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0454 - acc: 0.5389 - val_loss: 1.0819 - val_acc: 0.5196\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0729 - acc: 0.5174 - val_loss: 1.0766 - val_acc: 0.5680\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0453 - acc: 0.5435 - val_loss: 1.0722 - val_acc: 0.5740\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0520 - acc: 0.5372 - val_loss: 1.0831 - val_acc: 0.5045\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0407 - acc: 0.5340 - val_loss: 1.1010 - val_acc: 0.4985\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0227 - acc: 0.5389 - val_loss: 1.0926 - val_acc: 0.5589\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0560 - acc: 0.5280 - val_loss: 1.0784 - val_acc: 0.5559\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0270 - acc: 0.5463 - val_loss: 1.0680 - val_acc: 0.5650\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0350 - acc: 0.5322 - val_loss: 1.0857 - val_acc: 0.5559\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0085 - acc: 0.5572 - val_loss: 1.0564 - val_acc: 0.5378\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0168 - acc: 0.5548 - val_loss: 1.0757 - val_acc: 0.5317\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.9924 - acc: 0.5569 - val_loss: 1.0589 - val_acc: 0.5257\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0068 - acc: 0.5572 - val_loss: 1.0714 - val_acc: 0.5498\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0202 - acc: 0.5442 - val_loss: 1.0643 - val_acc: 0.5619\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0004 - acc: 0.5569 - val_loss: 1.0943 - val_acc: 0.5045\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9959 - acc: 0.5703 - val_loss: 1.0619 - val_acc: 0.5257\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9782 - acc: 0.5685 - val_loss: 1.0434 - val_acc: 0.5710\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9787 - acc: 0.5583 - val_loss: 1.0503 - val_acc: 0.5347\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9731 - acc: 0.5456 - val_loss: 1.0445 - val_acc: 0.5347\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9706 - acc: 0.5586 - val_loss: 1.0513 - val_acc: 0.5498\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9804 - acc: 0.5646 - val_loss: 1.1046 - val_acc: 0.5559\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9955 - acc: 0.5530 - val_loss: 1.0512 - val_acc: 0.5559\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9495 - acc: 0.5727 - val_loss: 1.0573 - val_acc: 0.5378\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9584 - acc: 0.5734 - val_loss: 1.0840 - val_acc: 0.5378\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9516 - acc: 0.5847 - val_loss: 1.0999 - val_acc: 0.5045\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9770 - acc: 0.5664 - val_loss: 1.0614 - val_acc: 0.5378\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9311 - acc: 0.5939 - val_loss: 1.0658 - val_acc: 0.5257\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9762 - acc: 0.5664 - val_loss: 1.0755 - val_acc: 0.5378\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.9434 - acc: 0.5886 - val_loss: 1.0431 - val_acc: 0.5498\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.9292 - acc: 0.5854 - val_loss: 1.0349 - val_acc: 0.5559\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 0.9606 - acc: 0.5851 - val_loss: 1.1258 - val_acc: 0.4804\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9248 - acc: 0.5900 - val_loss: 1.0483 - val_acc: 0.5438\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9536 - acc: 0.5710 - val_loss: 1.0613 - val_acc: 0.5559\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9242 - acc: 0.5907 - val_loss: 1.0818 - val_acc: 0.5287\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9039 - acc: 0.5974 - val_loss: 1.0856 - val_acc: 0.5015\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9308 - acc: 0.5903 - val_loss: 1.0504 - val_acc: 0.5559\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9016 - acc: 0.5999 - val_loss: 1.1065 - val_acc: 0.5045\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.9218 - acc: 0.5794 - val_loss: 1.0864 - val_acc: 0.5136\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.8992 - acc: 0.6041 - val_loss: 1.0710 - val_acc: 0.5227\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9180 - acc: 0.5851 - val_loss: 1.0523 - val_acc: 0.5589\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9030 - acc: 0.6027 - val_loss: 1.0647 - val_acc: 0.5378\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8874 - acc: 0.6122 - val_loss: 1.1044 - val_acc: 0.5287\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9197 - acc: 0.5956 - val_loss: 1.0674 - val_acc: 0.5408\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8907 - acc: 0.6097 - val_loss: 1.0720 - val_acc: 0.5378\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.8691 - acc: 0.6196 - val_loss: 1.0712 - val_acc: 0.5468\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9012 - acc: 0.5946 - val_loss: 1.0782 - val_acc: 0.5347\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8628 - acc: 0.6185 - val_loss: 1.0760 - val_acc: 0.5529\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8798 - acc: 0.6203 - val_loss: 1.0833 - val_acc: 0.5650\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8923 - acc: 0.6132 - val_loss: 1.0711 - val_acc: 0.5650\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8927 - acc: 0.6090 - val_loss: 1.0768 - val_acc: 0.5891\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8552 - acc: 0.6259 - val_loss: 1.1125 - val_acc: 0.5740\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8674 - acc: 0.6168 - val_loss: 1.0574 - val_acc: 0.5680\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8695 - acc: 0.6270 - val_loss: 1.1653 - val_acc: 0.5106\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8808 - acc: 0.5949 - val_loss: 1.1226 - val_acc: 0.5468\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8466 - acc: 0.6168 - val_loss: 1.0898 - val_acc: 0.5680\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8569 - acc: 0.6189 - val_loss: 1.1454 - val_acc: 0.5378\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8917 - acc: 0.6080 - val_loss: 1.1727 - val_acc: 0.5045\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8499 - acc: 0.6217 - val_loss: 1.1052 - val_acc: 0.5650\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8425 - acc: 0.6252 - val_loss: 1.1443 - val_acc: 0.5227\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8750 - acc: 0.6108 - val_loss: 1.1287 - val_acc: 0.5408\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8183 - acc: 0.6460 - val_loss: 1.0839 - val_acc: 0.5952\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8590 - acc: 0.6192 - val_loss: 1.1167 - val_acc: 0.5529\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8276 - acc: 0.6354 - val_loss: 1.2043 - val_acc: 0.5166\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8359 - acc: 0.6259 - val_loss: 1.1665 - val_acc: 0.4713\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8468 - acc: 0.6256 - val_loss: 1.1455 - val_acc: 0.5106\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8447 - acc: 0.6252 - val_loss: 1.1574 - val_acc: 0.5589\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8095 - acc: 0.6502 - val_loss: 1.2603 - val_acc: 0.4169\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8206 - acc: 0.6404 - val_loss: 1.1684 - val_acc: 0.5227\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8409 - acc: 0.6312 - val_loss: 1.1459 - val_acc: 0.5559\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7962 - acc: 0.6538 - val_loss: 1.1423 - val_acc: 0.5347\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8361 - acc: 0.6235 - val_loss: 1.1480 - val_acc: 0.5076\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8221 - acc: 0.6323 - val_loss: 1.1751 - val_acc: 0.4653\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8050 - acc: 0.6509 - val_loss: 1.2425 - val_acc: 0.4773\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8145 - acc: 0.6372 - val_loss: 1.1338 - val_acc: 0.5347\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7940 - acc: 0.6580 - val_loss: 1.1496 - val_acc: 0.5408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7869 - acc: 0.6573 - val_loss: 1.1423 - val_acc: 0.5287\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8142 - acc: 0.6407 - val_loss: 1.1733 - val_acc: 0.4804\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7968 - acc: 0.6527 - val_loss: 1.2293 - val_acc: 0.4955\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7976 - acc: 0.6432 - val_loss: 1.2256 - val_acc: 0.4713\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7901 - acc: 0.6467 - val_loss: 1.2517 - val_acc: 0.4773\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8121 - acc: 0.6365 - val_loss: 1.1806 - val_acc: 0.5227\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7822 - acc: 0.6562 - val_loss: 1.1929 - val_acc: 0.4683\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8001 - acc: 0.6442 - val_loss: 1.1531 - val_acc: 0.5408\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7858 - acc: 0.6594 - val_loss: 1.1452 - val_acc: 0.5408\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7712 - acc: 0.6611 - val_loss: 1.1735 - val_acc: 0.5166\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7618 - acc: 0.6675 - val_loss: 1.1612 - val_acc: 0.5317\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7976 - acc: 0.6548 - val_loss: 1.1722 - val_acc: 0.5468\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7840 - acc: 0.6552 - val_loss: 1.1864 - val_acc: 0.5106\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7784 - acc: 0.6580 - val_loss: 1.1944 - val_acc: 0.5227\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7731 - acc: 0.6597 - val_loss: 1.2683 - val_acc: 0.4592\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7543 - acc: 0.6714 - val_loss: 1.2412 - val_acc: 0.4924\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7974 - acc: 0.6418 - val_loss: 1.2714 - val_acc: 0.4924\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7411 - acc: 0.6819 - val_loss: 1.2286 - val_acc: 0.5227\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7528 - acc: 0.6833 - val_loss: 1.2886 - val_acc: 0.4894\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7479 - acc: 0.6847 - val_loss: 1.3206 - val_acc: 0.4894\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7633 - acc: 0.6689 - val_loss: 1.2451 - val_acc: 0.5196\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7607 - acc: 0.6752 - val_loss: 1.2139 - val_acc: 0.5378\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7295 - acc: 0.6858 - val_loss: 1.2906 - val_acc: 0.4502\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7730 - acc: 0.6566 - val_loss: 1.2498 - val_acc: 0.4773\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7701 - acc: 0.6619 - val_loss: 1.2359 - val_acc: 0.5378\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7219 - acc: 0.6851 - val_loss: 1.3065 - val_acc: 0.4411\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7360 - acc: 0.6886 - val_loss: 1.2671 - val_acc: 0.4985\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7276 - acc: 0.6907 - val_loss: 1.4485 - val_acc: 0.4502\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7666 - acc: 0.6685 - val_loss: 1.3194 - val_acc: 0.4773\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7578 - acc: 0.6721 - val_loss: 1.3124 - val_acc: 0.4532\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7328 - acc: 0.6777 - val_loss: 1.2218 - val_acc: 0.5287\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7200 - acc: 0.6872 - val_loss: 1.2403 - val_acc: 0.5136\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7363 - acc: 0.6890 - val_loss: 1.3131 - val_acc: 0.4864\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7620 - acc: 0.6569 - val_loss: 1.3836 - val_acc: 0.4441\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7419 - acc: 0.6766 - val_loss: 1.3176 - val_acc: 0.4653\n",
      "Epoch 155/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6933 - acc: 0.6967 - val_loss: 1.3462 - val_acc: 0.4653\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7643 - acc: 0.6717 - val_loss: 1.2608 - val_acc: 0.4955\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7038 - acc: 0.6925 - val_loss: 1.3292 - val_acc: 0.4502\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7201 - acc: 0.6995 - val_loss: 1.3375 - val_acc: 0.4532\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.7191 - acc: 0.6900 - val_loss: 1.3991 - val_acc: 0.4562\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7473 - acc: 0.6745 - val_loss: 1.3379 - val_acc: 0.4713\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6825 - acc: 0.7041 - val_loss: 1.2783 - val_acc: 0.5015\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.6983 - acc: 0.7052 - val_loss: 1.3320 - val_acc: 0.4562\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7400 - acc: 0.6886 - val_loss: 1.2859 - val_acc: 0.5136\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6932 - acc: 0.6992 - val_loss: 1.4175 - val_acc: 0.4622\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7390 - acc: 0.6805 - val_loss: 1.3419 - val_acc: 0.5015\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6880 - acc: 0.7055 - val_loss: 1.4157 - val_acc: 0.4562\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6898 - acc: 0.7020 - val_loss: 1.3961 - val_acc: 0.5015\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6847 - acc: 0.7076 - val_loss: 1.4165 - val_acc: 0.5015\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6866 - acc: 0.7066 - val_loss: 1.4002 - val_acc: 0.4773\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6784 - acc: 0.7133 - val_loss: 1.4567 - val_acc: 0.4350\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6924 - acc: 0.7006 - val_loss: 1.4826 - val_acc: 0.4562\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7081 - acc: 0.7006 - val_loss: 1.4077 - val_acc: 0.4743\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6832 - acc: 0.6946 - val_loss: 1.4839 - val_acc: 0.4562\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6758 - acc: 0.7098 - val_loss: 1.4797 - val_acc: 0.4924\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6983 - acc: 0.7034 - val_loss: 1.4390 - val_acc: 0.4834\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6629 - acc: 0.7249 - val_loss: 1.4514 - val_acc: 0.4683\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6472 - acc: 0.7182 - val_loss: 1.4088 - val_acc: 0.5498\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6917 - acc: 0.6971 - val_loss: 1.4196 - val_acc: 0.4743\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6512 - acc: 0.7365 - val_loss: 1.5082 - val_acc: 0.5166\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.701 - 0s 34us/step - loss: 0.6917 - acc: 0.7006 - val_loss: 1.4592 - val_acc: 0.4683\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6584 - acc: 0.7298 - val_loss: 1.5202 - val_acc: 0.4562\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6761 - acc: 0.7119 - val_loss: 1.5799 - val_acc: 0.4592\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.7262 - acc: 0.690 - 0s 35us/step - loss: 0.7111 - acc: 0.6950 - val_loss: 1.4676 - val_acc: 0.4653\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6418 - acc: 0.7337 - val_loss: 1.5826 - val_acc: 0.4532\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6877 - acc: 0.7038 - val_loss: 1.4993 - val_acc: 0.4592\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6754 - acc: 0.7059 - val_loss: 1.5410 - val_acc: 0.4562\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6538 - acc: 0.7217 - val_loss: 1.5325 - val_acc: 0.4894\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.6898 - acc: 0.699 - 0s 35us/step - loss: 0.6898 - acc: 0.6985 - val_loss: 1.4611 - val_acc: 0.5106\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6398 - acc: 0.7355 - val_loss: 1.6082 - val_acc: 0.4411\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6556 - acc: 0.7235 - val_loss: 1.5615 - val_acc: 0.4804\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6876 - acc: 0.7034 - val_loss: 1.5196 - val_acc: 0.4532\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6365 - acc: 0.7341 - val_loss: 1.4494 - val_acc: 0.5287\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.6288 - acc: 0.7369 - val_loss: 1.5105 - val_acc: 0.4834\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6349 - acc: 0.7298 - val_loss: 1.6095 - val_acc: 0.4622\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6823 - acc: 0.7048 - val_loss: 1.5747 - val_acc: 0.4320\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6209 - acc: 0.7323 - val_loss: 1.5292 - val_acc: 0.4683\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6706 - acc: 0.7112 - val_loss: 1.4638 - val_acc: 0.4713\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6316 - acc: 0.7295 - val_loss: 1.5329 - val_acc: 0.4471\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.6488 - acc: 0.7238 - val_loss: 1.5207 - val_acc: 0.4622\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5964 - acc: 0.7503 - val_loss: 1.5464 - val_acc: 0.5136\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6708 - acc: 0.7281 - val_loss: 1.5928 - val_acc: 0.4592\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6373 - acc: 0.7295 - val_loss: 1.6003 - val_acc: 0.4411\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6277 - acc: 0.7362 - val_loss: 1.6701 - val_acc: 0.4743\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6516 - acc: 0.7365 - val_loss: 1.5503 - val_acc: 0.4834\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5949 - acc: 0.7503 - val_loss: 1.5094 - val_acc: 0.5287\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6472 - acc: 0.7168 - val_loss: 1.6729 - val_acc: 0.4502\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6383 - acc: 0.7323 - val_loss: 1.6102 - val_acc: 0.4562\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6204 - acc: 0.7319 - val_loss: 1.6987 - val_acc: 0.4441\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6160 - acc: 0.7351 - val_loss: 1.6951 - val_acc: 0.4592\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6086 - acc: 0.7376 - val_loss: 1.5946 - val_acc: 0.4683\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5849 - acc: 0.760 - 0s 34us/step - loss: 0.5944 - acc: 0.7563 - val_loss: 1.6677 - val_acc: 0.4048\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.6717 - acc: 0.7129 - val_loss: 1.5170 - val_acc: 0.5166\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5894 - acc: 0.7496 - val_loss: 1.6681 - val_acc: 0.5045\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6229 - acc: 0.7323 - val_loss: 1.6888 - val_acc: 0.4804\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6208 - acc: 0.7429 - val_loss: 1.5767 - val_acc: 0.4683\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5863 - acc: 0.7555 - val_loss: 1.6449 - val_acc: 0.5045\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6428 - acc: 0.7305 - val_loss: 1.5396 - val_acc: 0.4804\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5636 - acc: 0.7689 - val_loss: 1.8371 - val_acc: 0.4350\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.6140 - acc: 0.7390 - val_loss: 1.7486 - val_acc: 0.4622\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6136 - acc: 0.7316 - val_loss: 1.6382 - val_acc: 0.4834\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.5976 - acc: 0.7499 - val_loss: 1.7149 - val_acc: 0.4109\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6008 - acc: 0.7467 - val_loss: 1.6788 - val_acc: 0.5076\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5879 - acc: 0.7594 - val_loss: 1.8374 - val_acc: 0.4350\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5895 - acc: 0.7510 - val_loss: 1.7239 - val_acc: 0.4290\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6081 - acc: 0.7503 - val_loss: 1.6190 - val_acc: 0.4955\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5778 - acc: 0.7563 - val_loss: 1.7627 - val_acc: 0.4502\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5672 - acc: 0.7626 - val_loss: 1.7296 - val_acc: 0.4804\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5627 - acc: 0.7827 - val_loss: 1.8082 - val_acc: 0.4622\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6048 - acc: 0.7330 - val_loss: 1.7725 - val_acc: 0.4532\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5771 - acc: 0.7661 - val_loss: 1.7666 - val_acc: 0.4532\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6000 - acc: 0.7450 - val_loss: 1.6741 - val_acc: 0.4924\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6161 - acc: 0.7506 - val_loss: 1.6121 - val_acc: 0.4713\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5507 - acc: 0.7714 - val_loss: 1.6842 - val_acc: 0.4713\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5585 - acc: 0.7675 - val_loss: 1.8218 - val_acc: 0.4471\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6308 - acc: 0.7319 - val_loss: 1.6287 - val_acc: 0.5106\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5768 - acc: 0.7580 - val_loss: 1.6437 - val_acc: 0.4411\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5731 - acc: 0.7710 - val_loss: 1.6678 - val_acc: 0.4743\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5790 - acc: 0.7534 - val_loss: 1.6972 - val_acc: 0.4864\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.5379 - acc: 0.7784 - val_loss: 1.7629 - val_acc: 0.4592\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6028 - acc: 0.7429 - val_loss: 1.6471 - val_acc: 0.4743\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5423 - acc: 0.7799 - val_loss: 1.7624 - val_acc: 0.4834\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5592 - acc: 0.7679 - val_loss: 1.8137 - val_acc: 0.4743\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5724 - acc: 0.7612 - val_loss: 1.9258 - val_acc: 0.4381\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5548 - acc: 0.7735 - val_loss: 1.7307 - val_acc: 0.4924\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5435 - acc: 0.7686 - val_loss: 1.8777 - val_acc: 0.5317\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6207 - acc: 0.7425 - val_loss: 1.7875 - val_acc: 0.4834\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5287 - acc: 0.7774 - val_loss: 1.7843 - val_acc: 0.4804\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5301 - acc: 0.7858 - val_loss: 1.7938 - val_acc: 0.4532\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5655 - acc: 0.7735 - val_loss: 1.7289 - val_acc: 0.4532\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5897 - acc: 0.7482 - val_loss: 1.7780 - val_acc: 0.4502\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5456 - acc: 0.7742 - val_loss: 1.8103 - val_acc: 0.5408\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5663 - acc: 0.7696 - val_loss: 1.8941 - val_acc: 0.4955\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.5429 - acc: 0.7728 - val_loss: 1.8903 - val_acc: 0.4592\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5334 - acc: 0.7837 - val_loss: 1.8804 - val_acc: 0.4743\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5605 - acc: 0.7689 - val_loss: 1.9126 - val_acc: 0.4290\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5192 - acc: 0.7865 - val_loss: 1.8063 - val_acc: 0.4713\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5341 - acc: 0.7774 - val_loss: 1.8341 - val_acc: 0.4199\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5808 - acc: 0.7626 - val_loss: 1.7663 - val_acc: 0.4834\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.5396 - acc: 0.7753 - val_loss: 1.7875 - val_acc: 0.4622\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5235 - acc: 0.7820 - val_loss: 1.7387 - val_acc: 0.5045\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5593 - acc: 0.7739 - val_loss: 1.7807 - val_acc: 0.4381\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5187 - acc: 0.7911 - val_loss: 1.7720 - val_acc: 0.4713\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5336 - acc: 0.7763 - val_loss: 1.8122 - val_acc: 0.5196\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5578 - acc: 0.7679 - val_loss: 1.7921 - val_acc: 0.4773\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5422 - acc: 0.775 - 0s 34us/step - loss: 0.5395 - acc: 0.7746 - val_loss: 1.8317 - val_acc: 0.4894\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5390 - acc: 0.780 - 0s 34us/step - loss: 0.5359 - acc: 0.7806 - val_loss: 1.7805 - val_acc: 0.4894\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4998 - acc: 0.800 - 0s 35us/step - loss: 0.4990 - acc: 0.7996 - val_loss: 1.8855 - val_acc: 0.4804\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5194 - acc: 0.7894 - val_loss: 1.9814 - val_acc: 0.4683\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.5686 - acc: 0.7580 - val_loss: 1.8893 - val_acc: 0.4381\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5171 - acc: 0.7904 - val_loss: 1.9232 - val_acc: 0.4048\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5045 - acc: 0.7915 - val_loss: 1.9509 - val_acc: 0.4471\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.5398 - acc: 0.7718 - val_loss: 1.8073 - val_acc: 0.4924\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.4994 - acc: 0.8024 - val_loss: 2.0008 - val_acc: 0.5227\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5382 - acc: 0.7802 - val_loss: 1.9747 - val_acc: 0.4592\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5058 - acc: 0.7897 - val_loss: 1.9475 - val_acc: 0.5015\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5142 - acc: 0.7904 - val_loss: 2.1149 - val_acc: 0.4441\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5497 - acc: 0.7760 - val_loss: 1.9381 - val_acc: 0.4834\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4881 - acc: 0.7985 - val_loss: 1.9350 - val_acc: 0.4804\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.5275 - acc: 0.7813 - val_loss: 1.9975 - val_acc: 0.4471\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5400 - acc: 0.7732 - val_loss: 1.9548 - val_acc: 0.4411\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4936 - acc: 0.8006 - val_loss: 1.8946 - val_acc: 0.4894\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5093 - acc: 0.7897 - val_loss: 1.8669 - val_acc: 0.5076\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5149 - acc: 0.7848 - val_loss: 1.8820 - val_acc: 0.5015\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5119 - acc: 0.7788 - val_loss: 1.9248 - val_acc: 0.4199\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5322 - acc: 0.7788 - val_loss: 1.9936 - val_acc: 0.4502\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4790 - acc: 0.8140 - val_loss: 2.1376 - val_acc: 0.4471\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5285 - acc: 0.7834 - val_loss: 2.0852 - val_acc: 0.4653\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4741 - acc: 0.813 - 0s 35us/step - loss: 0.4788 - acc: 0.8108 - val_loss: 2.0048 - val_acc: 0.4592\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4966 - acc: 0.7982 - val_loss: 2.0339 - val_acc: 0.4592\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5040 - acc: 0.7964 - val_loss: 1.9801 - val_acc: 0.4592\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4735 - acc: 0.8070 - val_loss: 2.2053 - val_acc: 0.4592\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5361 - acc: 0.7686 - val_loss: 2.0740 - val_acc: 0.4592\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4779 - acc: 0.8049 - val_loss: 1.9708 - val_acc: 0.5106\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5031 - acc: 0.7978 - val_loss: 2.0659 - val_acc: 0.4713\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5073 - acc: 0.7876 - val_loss: 2.1117 - val_acc: 0.4804\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4749 - acc: 0.8070 - val_loss: 1.9856 - val_acc: 0.4562\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5442 - acc: 0.7732 - val_loss: 1.9450 - val_acc: 0.4743\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4648 - acc: 0.8108 - val_loss: 2.2572 - val_acc: 0.4864\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4684 - acc: 0.8035 - val_loss: 1.9793 - val_acc: 0.4834\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4743 - acc: 0.8186 - val_loss: 1.9990 - val_acc: 0.4955\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4738 - acc: 0.8126 - val_loss: 1.9763 - val_acc: 0.4834\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4818 - acc: 0.7894 - val_loss: 1.9920 - val_acc: 0.4894\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5141 - acc: 0.7932 - val_loss: 2.1237 - val_acc: 0.4924\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4760 - acc: 0.8059 - val_loss: 2.2360 - val_acc: 0.4804\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4826 - acc: 0.8112 - val_loss: 2.0109 - val_acc: 0.4864\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4999 - acc: 0.7964 - val_loss: 1.9729 - val_acc: 0.4834\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4499 - acc: 0.8260 - val_loss: 2.2243 - val_acc: 0.4955\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4905 - acc: 0.7999 - val_loss: 2.0386 - val_acc: 0.5076\n",
      "Epoch 309/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4823 - acc: 0.8049 - val_loss: 2.0423 - val_acc: 0.5408\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5064 - acc: 0.7971 - val_loss: 2.0409 - val_acc: 0.4441\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4735 - acc: 0.8038 - val_loss: 2.0228 - val_acc: 0.4743\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4807 - acc: 0.8108 - val_loss: 2.0628 - val_acc: 0.4471\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4719 - acc: 0.8084 - val_loss: 2.0800 - val_acc: 0.4864\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4882 - acc: 0.8013 - val_loss: 2.0156 - val_acc: 0.4894\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4389 - acc: 0.8246 - val_loss: 2.3214 - val_acc: 0.4532\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4842 - acc: 0.8035 - val_loss: 2.2044 - val_acc: 0.4743\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4656 - acc: 0.8101 - val_loss: 2.1892 - val_acc: 0.4532\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4570 - acc: 0.8140 - val_loss: 2.4828 - val_acc: 0.4713\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5092 - acc: 0.7992 - val_loss: 2.1783 - val_acc: 0.4441\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4509 - acc: 0.8116 - val_loss: 2.1051 - val_acc: 0.4804\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4873 - acc: 0.7950 - val_loss: 1.9715 - val_acc: 0.4622\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4738 - acc: 0.8084 - val_loss: 2.1371 - val_acc: 0.4804\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4338 - acc: 0.8225 - val_loss: 2.1326 - val_acc: 0.5196\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4884 - acc: 0.8038 - val_loss: 2.1306 - val_acc: 0.5015\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4664 - acc: 0.8158 - val_loss: 2.2416 - val_acc: 0.4924\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4475 - acc: 0.8161 - val_loss: 2.3003 - val_acc: 0.4653\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4254 - acc: 0.8285 - val_loss: 2.2308 - val_acc: 0.4743\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4686 - acc: 0.811 - 0s 35us/step - loss: 0.4732 - acc: 0.8077 - val_loss: 2.3347 - val_acc: 0.4804\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.4345 - acc: 0.8330 - val_loss: 2.1777 - val_acc: 0.4683\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4739 - acc: 0.8024 - val_loss: 2.1460 - val_acc: 0.4804\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4327 - acc: 0.832 - 0s 36us/step - loss: 0.4361 - acc: 0.8316 - val_loss: 2.0884 - val_acc: 0.4683\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4593 - acc: 0.8112 - val_loss: 2.1365 - val_acc: 0.4713\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4167 - acc: 0.8341 - val_loss: 2.4731 - val_acc: 0.4562\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5249 - acc: 0.7855 - val_loss: 2.1008 - val_acc: 0.5076\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4363 - acc: 0.8278 - val_loss: 2.4284 - val_acc: 0.5076\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4609 - acc: 0.8140 - val_loss: 2.1165 - val_acc: 0.5106\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4361 - acc: 0.8285 - val_loss: 2.1428 - val_acc: 0.4985\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4646 - acc: 0.8154 - val_loss: 2.2318 - val_acc: 0.4713\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4172 - acc: 0.8355 - val_loss: 2.1991 - val_acc: 0.4441\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.4354 - acc: 0.8246 - val_loss: 2.3760 - val_acc: 0.4924\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4761 - acc: 0.8105 - val_loss: 2.2677 - val_acc: 0.4924\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4160 - acc: 0.8302 - val_loss: 2.3962 - val_acc: 0.5196\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4085 - acc: 0.8352 - val_loss: 2.5297 - val_acc: 0.4773\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4780 - acc: 0.800 - ETA: 0s - loss: 0.4281 - acc: 0.826 - 0s 35us/step - loss: 0.4198 - acc: 0.8306 - val_loss: 2.3695 - val_acc: 0.5166\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4170 - acc: 0.8313 - val_loss: 2.2025 - val_acc: 0.4955\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4645 - acc: 0.8017 - val_loss: 2.2362 - val_acc: 0.4079\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4371 - acc: 0.8256 - val_loss: 2.3606 - val_acc: 0.5076\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4339 - acc: 0.8221 - val_loss: 2.2657 - val_acc: 0.4260\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4490 - acc: 0.8080 - val_loss: 2.3849 - val_acc: 0.4683\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4435 - acc: 0.8225 - val_loss: 2.3364 - val_acc: 0.4804\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4049 - acc: 0.8306 - val_loss: 2.3574 - val_acc: 0.4653\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3971 - acc: 0.8485 - val_loss: 2.4462 - val_acc: 0.4502\n",
      "Epoch 353/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4690 - acc: 0.8035 - val_loss: 2.3934 - val_acc: 0.4532\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4403 - acc: 0.8253 - val_loss: 2.4045 - val_acc: 0.4955\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4113 - acc: 0.8380 - val_loss: 2.4842 - val_acc: 0.4743\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4458 - acc: 0.8147 - val_loss: 2.6003 - val_acc: 0.4350\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4368 - acc: 0.8242 - val_loss: 2.6003 - val_acc: 0.4894\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4215 - acc: 0.8309 - val_loss: 2.3758 - val_acc: 0.4592\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4430 - acc: 0.8207 - val_loss: 2.3059 - val_acc: 0.4502\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4105 - acc: 0.8281 - val_loss: 2.4370 - val_acc: 0.4743\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4245 - acc: 0.8288 - val_loss: 2.4099 - val_acc: 0.5015\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4099 - acc: 0.8457 - val_loss: 2.4701 - val_acc: 0.4411\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4137 - acc: 0.8383 - val_loss: 2.4588 - val_acc: 0.4562\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4133 - acc: 0.8299 - val_loss: 2.4810 - val_acc: 0.4683\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4342 - acc: 0.8193 - val_loss: 2.5168 - val_acc: 0.4441\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4438 - acc: 0.8235 - val_loss: 2.6591 - val_acc: 0.4350\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4382 - acc: 0.8232 - val_loss: 2.5129 - val_acc: 0.4471\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3809 - acc: 0.8542 - val_loss: 2.5710 - val_acc: 0.4471\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4313 - acc: 0.8320 - val_loss: 2.4612 - val_acc: 0.4290\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3985 - acc: 0.8411 - val_loss: 2.6608 - val_acc: 0.4834\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4535 - acc: 0.8161 - val_loss: 2.4001 - val_acc: 0.5106\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3928 - acc: 0.8411 - val_loss: 2.4985 - val_acc: 0.4713\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 48us/step - loss: 0.4084 - acc: 0.8394 - val_loss: 2.7401 - val_acc: 0.4683\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4532 - acc: 0.8091 - val_loss: 2.4412 - val_acc: 0.4713\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.3648 - acc: 0.8521 - val_loss: 2.6866 - val_acc: 0.4653\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4221 - acc: 0.8249 - val_loss: 2.5758 - val_acc: 0.4532\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3784 - acc: 0.8499 - val_loss: 2.5069 - val_acc: 0.4592\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3925 - acc: 0.8454 - val_loss: 2.5822 - val_acc: 0.4743\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4285 - acc: 0.8221 - val_loss: 2.3272 - val_acc: 0.4924\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4221 - acc: 0.8330 - val_loss: 2.6427 - val_acc: 0.4562\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3749 - acc: 0.8531 - val_loss: 2.6478 - val_acc: 0.4713\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4624 - acc: 0.8130 - val_loss: 2.5007 - val_acc: 0.4683\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3714 - acc: 0.8531 - val_loss: 2.5139 - val_acc: 0.4471\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3868 - acc: 0.8443 - val_loss: 2.5194 - val_acc: 0.4169\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3900 - acc: 0.8433 - val_loss: 2.5269 - val_acc: 0.4653\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4743 - acc: 0.8091 - val_loss: 2.4176 - val_acc: 0.4683\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3553 - acc: 0.8647 - val_loss: 2.5722 - val_acc: 0.4653\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4018 - acc: 0.8376 - val_loss: 2.5732 - val_acc: 0.4562\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3854 - acc: 0.8461 - val_loss: 2.7754 - val_acc: 0.4622\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4212 - acc: 0.8330 - val_loss: 2.6228 - val_acc: 0.4592\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.3583 - acc: 0.8570 - val_loss: 2.5493 - val_acc: 0.4924\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4089 - acc: 0.8316 - val_loss: 2.4833 - val_acc: 0.4743\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3644 - acc: 0.8507 - val_loss: 2.5111 - val_acc: 0.4713\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3881 - acc: 0.8415 - val_loss: 2.7480 - val_acc: 0.4924\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4386 - acc: 0.8330 - val_loss: 2.6334 - val_acc: 0.4532\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3896 - acc: 0.8461 - val_loss: 2.6703 - val_acc: 0.4683\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4060 - acc: 0.8383 - val_loss: 2.7508 - val_acc: 0.4562\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3770 - acc: 0.8471 - val_loss: 2.5305 - val_acc: 0.4804\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3953 - acc: 0.8478 - val_loss: 2.7949 - val_acc: 0.4653\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4187 - acc: 0.8281 - val_loss: 2.7368 - val_acc: 0.4653\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3694 - acc: 0.8496 - val_loss: 2.7839 - val_acc: 0.4622\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3735 - acc: 0.8447 - val_loss: 2.8262 - val_acc: 0.4834\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4199 - acc: 0.8334 - val_loss: 2.9199 - val_acc: 0.4411\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4070 - acc: 0.838 - 0s 34us/step - loss: 0.3921 - acc: 0.8461 - val_loss: 2.6206 - val_acc: 0.4834\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3521 - acc: 0.8591 - val_loss: 2.8164 - val_acc: 0.4864\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4210 - acc: 0.8274 - val_loss: 2.7196 - val_acc: 0.4532\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3694 - acc: 0.8535 - val_loss: 2.5715 - val_acc: 0.4320\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3760 - acc: 0.8510 - val_loss: 2.6789 - val_acc: 0.4864\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4293 - acc: 0.8274 - val_loss: 2.5861 - val_acc: 0.3958\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3626 - acc: 0.860 - 0s 35us/step - loss: 0.3682 - acc: 0.8549 - val_loss: 2.5676 - val_acc: 0.4804\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3688 - acc: 0.8612 - val_loss: 2.6437 - val_acc: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4424 - acc: 0.8309 - val_loss: 2.4440 - val_acc: 0.4471\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3412 - acc: 0.8640 - val_loss: 2.6911 - val_acc: 0.4502\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3358 - acc: 0.8725 - val_loss: 2.7396 - val_acc: 0.4683\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4088 - acc: 0.8341 - val_loss: 2.7003 - val_acc: 0.4562\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3758 - acc: 0.8521 - val_loss: 2.6908 - val_acc: 0.4743\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3728 - acc: 0.8499 - val_loss: 2.6238 - val_acc: 0.4924\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3354 - acc: 0.8679 - val_loss: 2.6340 - val_acc: 0.4532\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4522 - acc: 0.8172 - val_loss: 2.5600 - val_acc: 0.4743\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3426 - acc: 0.8588 - val_loss: 2.8346 - val_acc: 0.4350\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3749 - acc: 0.8507 - val_loss: 2.6649 - val_acc: 0.4894\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3446 - acc: 0.8686 - val_loss: 2.7041 - val_acc: 0.4955\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.3674 - acc: 0.8609 - val_loss: 2.7879 - val_acc: 0.4471\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3903 - acc: 0.8457 - val_loss: 2.4549 - val_acc: 0.4713\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3755 - acc: 0.8545 - val_loss: 2.7286 - val_acc: 0.4441\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3523 - acc: 0.8545 - val_loss: 2.8064 - val_acc: 0.4592\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3596 - acc: 0.8514 - val_loss: 3.0341 - val_acc: 0.4743\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3838 - acc: 0.8436 - val_loss: 3.0215 - val_acc: 0.4834\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3969 - acc: 0.8408 - val_loss: 2.8264 - val_acc: 0.4683\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3650 - acc: 0.8602 - val_loss: 2.7898 - val_acc: 0.4592\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3819 - acc: 0.8475 - val_loss: 2.9362 - val_acc: 0.4622\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4475 - acc: 0.8154 - val_loss: 2.6577 - val_acc: 0.4622\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3439 - acc: 0.8637 - val_loss: 2.8520 - val_acc: 0.4532\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3638 - acc: 0.8573 - val_loss: 2.5095 - val_acc: 0.4894\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3560 - acc: 0.8665 - val_loss: 2.9773 - val_acc: 0.4743\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3560 - acc: 0.8538 - val_loss: 2.9310 - val_acc: 0.4653\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3460 - acc: 0.8679 - val_loss: 2.8951 - val_acc: 0.4562\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3198 - acc: 0.8764 - val_loss: 3.0444 - val_acc: 0.4532\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3704 - acc: 0.8507 - val_loss: 2.7424 - val_acc: 0.4773\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3659 - acc: 0.8584 - val_loss: 3.0309 - val_acc: 0.4713\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3725 - acc: 0.8559 - val_loss: 2.7530 - val_acc: 0.4773\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3528 - acc: 0.8580 - val_loss: 2.8128 - val_acc: 0.4441\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3694 - acc: 0.8507 - val_loss: 2.7588 - val_acc: 0.4653\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3575 - acc: 0.8633 - val_loss: 2.6757 - val_acc: 0.4894\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3512 - acc: 0.8630 - val_loss: 2.8381 - val_acc: 0.4290\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3639 - acc: 0.8598 - val_loss: 2.9532 - val_acc: 0.4743\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3530 - acc: 0.8563 - val_loss: 2.9281 - val_acc: 0.4713\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3453 - acc: 0.8626 - val_loss: 2.8277 - val_acc: 0.4713\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3490 - acc: 0.8517 - val_loss: 3.0194 - val_acc: 0.4592\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3792 - acc: 0.8503 - val_loss: 2.8156 - val_acc: 0.4743\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3746 - acc: 0.8542 - val_loss: 2.7833 - val_acc: 0.4109\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3767 - acc: 0.8535 - val_loss: 2.7568 - val_acc: 0.4532\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3117 - acc: 0.8750 - val_loss: 2.7300 - val_acc: 0.4502\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3905 - acc: 0.8464 - val_loss: 2.7470 - val_acc: 0.5015\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3132 - acc: 0.8764 - val_loss: 2.9048 - val_acc: 0.4894\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4030 - acc: 0.8366 - val_loss: 2.5548 - val_acc: 0.4502\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3085 - acc: 0.8795 - val_loss: 3.0556 - val_acc: 0.4653\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3429 - acc: 0.8707 - val_loss: 2.9212 - val_acc: 0.4773\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3387 - acc: 0.8623 - val_loss: 2.9688 - val_acc: 0.4562\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3187 - acc: 0.8753 - val_loss: 2.8552 - val_acc: 0.4773\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3937 - acc: 0.8418 - val_loss: 2.7825 - val_acc: 0.4471\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3370 - acc: 0.8707 - val_loss: 3.0744 - val_acc: 0.4411\n",
      "Epoch 463/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3189 - acc: 0.8767 - val_loss: 3.0078 - val_acc: 0.4562\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3640 - acc: 0.8503 - val_loss: 2.9949 - val_acc: 0.4683\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3317 - acc: 0.8651 - val_loss: 3.1906 - val_acc: 0.4290\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3559 - acc: 0.8566 - val_loss: 3.0371 - val_acc: 0.4804\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3481 - acc: 0.8683 - val_loss: 3.0069 - val_acc: 0.4653\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3328 - acc: 0.8732 - val_loss: 2.9989 - val_acc: 0.4622\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3144 - acc: 0.8714 - val_loss: 2.9288 - val_acc: 0.4260\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3383 - acc: 0.8683 - val_loss: 3.1430 - val_acc: 0.4471\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3879 - acc: 0.8538 - val_loss: 3.0445 - val_acc: 0.4320\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3153 - acc: 0.8739 - val_loss: 3.0828 - val_acc: 0.4471\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3792 - acc: 0.8433 - val_loss: 2.8598 - val_acc: 0.4441\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3355 - acc: 0.8686 - val_loss: 3.0126 - val_acc: 0.4532\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3258 - acc: 0.8672 - val_loss: 2.9231 - val_acc: 0.4683\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2952 - acc: 0.8813 - val_loss: 3.1327 - val_acc: 0.4562\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3278 - acc: 0.8697 - val_loss: 3.1295 - val_acc: 0.4562\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3395 - acc: 0.8637 - val_loss: 3.0379 - val_acc: 0.4622\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3220 - acc: 0.8778 - val_loss: 2.9151 - val_acc: 0.4622\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3412 - acc: 0.8676 - val_loss: 3.1439 - val_acc: 0.4683\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3798 - acc: 0.8521 - val_loss: 2.8517 - val_acc: 0.4773\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3196 - acc: 0.8802 - val_loss: 3.1577 - val_acc: 0.4864\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3176 - acc: 0.8746 - val_loss: 3.0489 - val_acc: 0.4441\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3710 - acc: 0.8591 - val_loss: 2.8830 - val_acc: 0.4502\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3303 - acc: 0.866 - 0s 34us/step - loss: 0.3312 - acc: 0.8676 - val_loss: 2.9852 - val_acc: 0.4894\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3242 - acc: 0.8732 - val_loss: 3.1163 - val_acc: 0.4894\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2915 - acc: 0.8845 - val_loss: 3.2126 - val_acc: 0.4683\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3504 - acc: 0.8573 - val_loss: 2.9636 - val_acc: 0.4743\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3314 - acc: 0.8662 - val_loss: 2.9749 - val_acc: 0.4502\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3384 - acc: 0.8676 - val_loss: 3.3207 - val_acc: 0.4955\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3189 - acc: 0.878 - 0s 34us/step - loss: 0.3141 - acc: 0.8806 - val_loss: 3.2665 - val_acc: 0.4804\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.2912 - acc: 0.8859 - val_loss: 3.4283 - val_acc: 0.4773\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3657 - acc: 0.8559 - val_loss: 2.9351 - val_acc: 0.4471\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2953 - acc: 0.8820 - val_loss: 3.0049 - val_acc: 0.4562\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.2847 - acc: 0.8887 - val_loss: 3.3551 - val_acc: 0.4622\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3732 - acc: 0.8475 - val_loss: 3.1568 - val_acc: 0.4743\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.2912 - acc: 0.8838 - val_loss: 3.2842 - val_acc: 0.4804\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3304 - acc: 0.8697 - val_loss: 3.1547 - val_acc: 0.4864\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3035 - acc: 0.8788 - val_loss: 3.1581 - val_acc: 0.4924\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3506 - acc: 0.8577 - val_loss: 2.9453 - val_acc: 0.4502\n"
     ]
    }
   ],
   "source": [
    "business_model = model.fit(x=X_train_business, y=y_cat_train_business, \n",
    "          batch_size=500, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_cat_test_business),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "0.6666666666666666\n",
      "0.9351851851851852\n",
      "52\n",
      "0.6923076923076923\n",
      "0.9038461538461539\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_business)\n",
    "model_metrics(predictions, y_cat_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEXJ8P9v9Yh3tICXIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17c049c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(business_model.history['acc'])\n",
    "plt.plot(business_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 4s 2ms/step - loss: 1.4900 - acc: 0.3484 - val_loss: 1.3558 - val_acc: 0.4169\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.3637 - acc: 0.3801 - val_loss: 1.3214 - val_acc: 0.4139\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.3493 - acc: 0.3829 - val_loss: 1.2997 - val_acc: 0.4230\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.3231 - acc: 0.3949 - val_loss: 1.2724 - val_acc: 0.4441\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.3106 - acc: 0.4061 - val_loss: 1.2684 - val_acc: 0.4743\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.2948 - acc: 0.4111 - val_loss: 1.2590 - val_acc: 0.4048\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2798 - acc: 0.4139 - val_loss: 1.2230 - val_acc: 0.5045\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.2657 - acc: 0.4269 - val_loss: 1.2255 - val_acc: 0.4834\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2564 - acc: 0.4237 - val_loss: 1.2538 - val_acc: 0.3807\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2423 - acc: 0.4509 - val_loss: 1.2112 - val_acc: 0.4985\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.2487 - acc: 0.4209 - val_loss: 1.2110 - val_acc: 0.4230\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2315 - acc: 0.4311 - val_loss: 1.1950 - val_acc: 0.4713\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.2035 - acc: 0.4502 - val_loss: 1.2239 - val_acc: 0.4864\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.2191 - acc: 0.4340 - val_loss: 1.1761 - val_acc: 0.5257\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1999 - acc: 0.4392 - val_loss: 1.2035 - val_acc: 0.4260\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2061 - acc: 0.4628 - val_loss: 1.1622 - val_acc: 0.5136\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2000 - acc: 0.4456 - val_loss: 1.2155 - val_acc: 0.4350\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1894 - acc: 0.4551 - val_loss: 1.1813 - val_acc: 0.4894\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1872 - acc: 0.4526 - val_loss: 1.1606 - val_acc: 0.4864\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1911 - acc: 0.4470 - val_loss: 1.1850 - val_acc: 0.4109\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1737 - acc: 0.4607 - val_loss: 1.1907 - val_acc: 0.4230\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.1682 - acc: 0.4593 - val_loss: 1.1974 - val_acc: 0.4230\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1695 - acc: 0.4583 - val_loss: 1.1411 - val_acc: 0.5196\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.1530 - acc: 0.4685 - val_loss: 1.1476 - val_acc: 0.4955\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.1413 - acc: 0.4805 - val_loss: 1.1660 - val_acc: 0.5076\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1564 - acc: 0.4702 - val_loss: 1.2079 - val_acc: 0.4079\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1401 - acc: 0.4907 - val_loss: 1.1815 - val_acc: 0.4290\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 1.1194 - acc: 0.4924 - val_loss: 1.1701 - val_acc: 0.4350\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 1.1557 - acc: 0.4815 - val_loss: 1.1860 - val_acc: 0.4320\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.1280 - acc: 0.4878 - val_loss: 1.1476 - val_acc: 0.4894\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1361 - acc: 0.4808 - val_loss: 1.1449 - val_acc: 0.4955\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 1.1172 - acc: 0.5023 - val_loss: 1.1553 - val_acc: 0.4683\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.1149 - acc: 0.4991 - val_loss: 1.1615 - val_acc: 0.4924\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.1208 - acc: 0.4945 - val_loss: 1.1527 - val_acc: 0.4834\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 1.1276 - acc: 0.4942 - val_loss: 1.1540 - val_acc: 0.4985\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.1089 - acc: 0.4935 - val_loss: 1.1341 - val_acc: 0.5106\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0916 - acc: 0.5079 - val_loss: 1.1442 - val_acc: 0.4894\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.1109 - acc: 0.5012 - val_loss: 1.1521 - val_acc: 0.4924\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 1.1108 - acc: 0.4974 - val_loss: 1.1986 - val_acc: 0.4260\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 1.0968 - acc: 0.5100 - val_loss: 1.1234 - val_acc: 0.4924\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.1087 - acc: 0.4868 - val_loss: 1.1437 - val_acc: 0.5076\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1013 - acc: 0.5150 - val_loss: 1.1070 - val_acc: 0.5227\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0674 - acc: 0.5217 - val_loss: 1.1313 - val_acc: 0.4864\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0563 - acc: 0.5199 - val_loss: 1.2697 - val_acc: 0.4502\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0837 - acc: 0.5203 - val_loss: 1.1167 - val_acc: 0.5166\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0736 - acc: 0.5139 - val_loss: 1.1198 - val_acc: 0.5076\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0737 - acc: 0.5118 - val_loss: 1.1368 - val_acc: 0.5166\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0433 - acc: 0.5284 - val_loss: 1.1859 - val_acc: 0.4955\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0847 - acc: 0.5097 - val_loss: 1.1542 - val_acc: 0.4834\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0603 - acc: 0.5319 - val_loss: 1.1055 - val_acc: 0.5227\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0575 - acc: 0.5206 - val_loss: 1.1265 - val_acc: 0.5468\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0633 - acc: 0.5220 - val_loss: 1.1540 - val_acc: 0.4653\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.0568 - acc: 0.5171 - val_loss: 1.1350 - val_acc: 0.5015\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0638 - acc: 0.5379 - val_loss: 1.1095 - val_acc: 0.5015\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0286 - acc: 0.5269 - val_loss: 1.1077 - val_acc: 0.4834\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0539 - acc: 0.5238 - val_loss: 1.1480 - val_acc: 0.5045\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0363 - acc: 0.5262 - val_loss: 1.1401 - val_acc: 0.5015\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0250 - acc: 0.5386 - val_loss: 1.1534 - val_acc: 0.4985\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0449 - acc: 0.5333 - val_loss: 1.1206 - val_acc: 0.5468\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0500 - acc: 0.5382 - val_loss: 1.1189 - val_acc: 0.5227\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0330 - acc: 0.5410 - val_loss: 1.1342 - val_acc: 0.5166\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0060 - acc: 0.5488 - val_loss: 1.1736 - val_acc: 0.4713\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0310 - acc: 0.5245 - val_loss: 1.1167 - val_acc: 0.4924\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0152 - acc: 0.5576 - val_loss: 1.1135 - val_acc: 0.4924\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0306 - acc: 0.5410 - val_loss: 1.1326 - val_acc: 0.4471\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0012 - acc: 0.5509 - val_loss: 1.1571 - val_acc: 0.5106\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0209 - acc: 0.5294 - val_loss: 1.1212 - val_acc: 0.5257\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9833 - acc: 0.5710 - val_loss: 1.1125 - val_acc: 0.4924\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0200 - acc: 0.5456 - val_loss: 1.1094 - val_acc: 0.5347\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0252 - acc: 0.5495 - val_loss: 1.1942 - val_acc: 0.4985\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0151 - acc: 0.5594 - val_loss: 1.1227 - val_acc: 0.5347\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0115 - acc: 0.5403 - val_loss: 1.1100 - val_acc: 0.5498\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9890 - acc: 0.5664 - val_loss: 1.1205 - val_acc: 0.4834\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9786 - acc: 0.5601 - val_loss: 1.1301 - val_acc: 0.4924\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 1.0196 - acc: 0.5453 - val_loss: 1.1601 - val_acc: 0.5076\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9773 - acc: 0.5622 - val_loss: 1.1847 - val_acc: 0.4985\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9966 - acc: 0.5646 - val_loss: 1.1230 - val_acc: 0.5196\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9980 - acc: 0.5562 - val_loss: 1.0969 - val_acc: 0.5559\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9946 - acc: 0.5523 - val_loss: 1.1128 - val_acc: 0.5498\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9761 - acc: 0.5749 - val_loss: 1.1206 - val_acc: 0.5347\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9625 - acc: 0.5678 - val_loss: 1.1771 - val_acc: 0.5136\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9951 - acc: 0.5495 - val_loss: 1.1638 - val_acc: 0.5257\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.0033 - acc: 0.5653 - val_loss: 1.1262 - val_acc: 0.4955\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9406 - acc: 0.5939 - val_loss: 1.1272 - val_acc: 0.5347\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.9653 - acc: 0.5710 - val_loss: 1.1029 - val_acc: 0.5227\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9938 - acc: 0.5484 - val_loss: 1.1217 - val_acc: 0.5166\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9555 - acc: 0.5812 - val_loss: 1.1124 - val_acc: 0.5106\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9462 - acc: 0.5893 - val_loss: 1.1221 - val_acc: 0.5650\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9691 - acc: 0.5773 - val_loss: 1.1139 - val_acc: 0.5740\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9682 - acc: 0.5727 - val_loss: 1.1615 - val_acc: 0.4622\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9431 - acc: 0.5819 - val_loss: 1.1434 - val_acc: 0.5619\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9555 - acc: 0.5720 - val_loss: 1.1580 - val_acc: 0.5166\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9488 - acc: 0.5847 - val_loss: 1.1358 - val_acc: 0.5076\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9314 - acc: 0.5868 - val_loss: 1.1299 - val_acc: 0.5347\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9205 - acc: 0.5844 - val_loss: 1.1803 - val_acc: 0.5408\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9494 - acc: 0.5749 - val_loss: 1.1401 - val_acc: 0.5498\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9454 - acc: 0.5791 - val_loss: 1.1585 - val_acc: 0.4894\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9201 - acc: 0.5896 - val_loss: 1.1535 - val_acc: 0.4804\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.9483 - acc: 0.5763 - val_loss: 1.1754 - val_acc: 0.5015\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9271 - acc: 0.5844 - val_loss: 1.1373 - val_acc: 0.5287\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9215 - acc: 0.5956 - val_loss: 1.2264 - val_acc: 0.4713\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9299 - acc: 0.5879 - val_loss: 1.1520 - val_acc: 0.4864\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9107 - acc: 0.5946 - val_loss: 1.1468 - val_acc: 0.5287\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9621 - acc: 0.5724 - val_loss: 1.1286 - val_acc: 0.5468\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9029 - acc: 0.6069 - val_loss: 1.1320 - val_acc: 0.5347\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9066 - acc: 0.5963 - val_loss: 1.1269 - val_acc: 0.5619\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9325 - acc: 0.5794 - val_loss: 1.1749 - val_acc: 0.5106\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9169 - acc: 0.5988 - val_loss: 1.1652 - val_acc: 0.5106\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9278 - acc: 0.5932 - val_loss: 1.1690 - val_acc: 0.5166\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9075 - acc: 0.6154 - val_loss: 1.1696 - val_acc: 0.5287\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9053 - acc: 0.6016 - val_loss: 1.1440 - val_acc: 0.5468\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9077 - acc: 0.6016 - val_loss: 1.1496 - val_acc: 0.5559\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8835 - acc: 0.6175 - val_loss: 1.1912 - val_acc: 0.5015\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8916 - acc: 0.6073 - val_loss: 1.2761 - val_acc: 0.4653\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9018 - acc: 0.6027 - val_loss: 1.2036 - val_acc: 0.4834\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8989 - acc: 0.5932 - val_loss: 1.1897 - val_acc: 0.4924\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9025 - acc: 0.5985 - val_loss: 1.1796 - val_acc: 0.5287\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8888 - acc: 0.6189 - val_loss: 1.1738 - val_acc: 0.5136\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8939 - acc: 0.6016 - val_loss: 1.1721 - val_acc: 0.5468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9055 - acc: 0.6083 - val_loss: 1.2029 - val_acc: 0.5045\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8680 - acc: 0.6101 - val_loss: 1.2128 - val_acc: 0.5045\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8707 - acc: 0.6069 - val_loss: 1.2050 - val_acc: 0.5076\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8583 - acc: 0.6284 - val_loss: 1.2322 - val_acc: 0.4773\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8960 - acc: 0.5960 - val_loss: 1.2216 - val_acc: 0.4985\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8625 - acc: 0.6277 - val_loss: 1.1760 - val_acc: 0.5559\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8553 - acc: 0.6224 - val_loss: 1.2139 - val_acc: 0.5106\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9145 - acc: 0.5837 - val_loss: 1.2758 - val_acc: 0.4502\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8567 - acc: 0.6143 - val_loss: 1.2018 - val_acc: 0.5801\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8562 - acc: 0.6235 - val_loss: 1.2003 - val_acc: 0.5045\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8452 - acc: 0.6199 - val_loss: 1.1913 - val_acc: 0.5378\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8716 - acc: 0.6196 - val_loss: 1.2861 - val_acc: 0.4743\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8593 - acc: 0.6171 - val_loss: 1.2010 - val_acc: 0.5438\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8678 - acc: 0.6118 - val_loss: 1.2028 - val_acc: 0.5408\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8550 - acc: 0.6280 - val_loss: 1.2214 - val_acc: 0.5468\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8437 - acc: 0.6291 - val_loss: 1.2454 - val_acc: 0.5136\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8377 - acc: 0.6252 - val_loss: 1.2346 - val_acc: 0.5076\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8456 - acc: 0.6400 - val_loss: 1.2191 - val_acc: 0.5921\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8003 - acc: 0.6471 - val_loss: 1.2785 - val_acc: 0.5317\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8340 - acc: 0.6256 - val_loss: 1.3409 - val_acc: 0.4683\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8652 - acc: 0.5970 - val_loss: 1.2770 - val_acc: 0.4773\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.8124 - acc: 0.648 - 0s 70us/step - loss: 0.8144 - acc: 0.6467 - val_loss: 1.2703 - val_acc: 0.5166\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8444 - acc: 0.6273 - val_loss: 1.2451 - val_acc: 0.5378\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8471 - acc: 0.6259 - val_loss: 1.2163 - val_acc: 0.5710\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8313 - acc: 0.6263 - val_loss: 1.2474 - val_acc: 0.5408\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8129 - acc: 0.6421 - val_loss: 1.2357 - val_acc: 0.5166\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8455 - acc: 0.6379 - val_loss: 1.2688 - val_acc: 0.5076\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8153 - acc: 0.6393 - val_loss: 1.3273 - val_acc: 0.4804\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8030 - acc: 0.6520 - val_loss: 1.3639 - val_acc: 0.4532\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8119 - acc: 0.6425 - val_loss: 1.2684 - val_acc: 0.5076\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8383 - acc: 0.6231 - val_loss: 1.2489 - val_acc: 0.5347\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8149 - acc: 0.6365 - val_loss: 1.2815 - val_acc: 0.5227\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8327 - acc: 0.6383 - val_loss: 1.3243 - val_acc: 0.5196\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8039 - acc: 0.6664 - val_loss: 1.3138 - val_acc: 0.4773\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7899 - acc: 0.6643 - val_loss: 1.2833 - val_acc: 0.5317\n",
      "Epoch 155/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7837 - acc: 0.6534 - val_loss: 1.2660 - val_acc: 0.5076\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8240 - acc: 0.6249 - val_loss: 1.3481 - val_acc: 0.5529\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8190 - acc: 0.6411 - val_loss: 1.2883 - val_acc: 0.5498\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7588 - acc: 0.6615 - val_loss: 1.3602 - val_acc: 0.5710\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8241 - acc: 0.6361 - val_loss: 1.3465 - val_acc: 0.5015\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7883 - acc: 0.6499 - val_loss: 1.3157 - val_acc: 0.5317\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8120 - acc: 0.6488 - val_loss: 1.3971 - val_acc: 0.4592\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.7893 - acc: 0.6492 - val_loss: 1.3047 - val_acc: 0.5378\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7940 - acc: 0.6400 - val_loss: 1.3311 - val_acc: 0.5559\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7696 - acc: 0.6643 - val_loss: 1.3425 - val_acc: 0.5347\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8065 - acc: 0.6467 - val_loss: 1.4610 - val_acc: 0.4622\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7986 - acc: 0.6545 - val_loss: 1.4366 - val_acc: 0.4622\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7676 - acc: 0.6576 - val_loss: 1.4180 - val_acc: 0.4834\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7914 - acc: 0.6502 - val_loss: 1.5058 - val_acc: 0.4350\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.7757 - acc: 0.6590 - val_loss: 1.3587 - val_acc: 0.5529\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7234 - acc: 0.6904 - val_loss: 1.4490 - val_acc: 0.4834\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7581 - acc: 0.6661 - val_loss: 1.4845 - val_acc: 0.4743\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7712 - acc: 0.6650 - val_loss: 1.4685 - val_acc: 0.5076\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7745 - acc: 0.6664 - val_loss: 1.5016 - val_acc: 0.4653\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7728 - acc: 0.6569 - val_loss: 1.3776 - val_acc: 0.5559\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7542 - acc: 0.6724 - val_loss: 1.4314 - val_acc: 0.5529\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7481 - acc: 0.6791 - val_loss: 1.4237 - val_acc: 0.5559\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7924 - acc: 0.6393 - val_loss: 1.4236 - val_acc: 0.5196\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7378 - acc: 0.6826 - val_loss: 1.3806 - val_acc: 0.5498\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7411 - acc: 0.6749 - val_loss: 1.4293 - val_acc: 0.5498\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7413 - acc: 0.6862 - val_loss: 1.4886 - val_acc: 0.4985\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7600 - acc: 0.6671 - val_loss: 1.4867 - val_acc: 0.5196\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7473 - acc: 0.6604 - val_loss: 1.4155 - val_acc: 0.5166\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7573 - acc: 0.6728 - val_loss: 1.3731 - val_acc: 0.5015\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.7643 - acc: 0.6647 - val_loss: 1.4148 - val_acc: 0.5287\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7013 - acc: 0.7006 - val_loss: 1.4755 - val_acc: 0.5347\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.7441 - acc: 0.6781 - val_loss: 1.5085 - val_acc: 0.4743\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.7501 - acc: 0.6615 - val_loss: 1.4769 - val_acc: 0.4773\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.7494 - acc: 0.684 - 0s 84us/step - loss: 0.7406 - acc: 0.6851 - val_loss: 1.4329 - val_acc: 0.5408\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7408 - acc: 0.6710 - val_loss: 1.5301 - val_acc: 0.5045\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7041 - acc: 0.6890 - val_loss: 1.6320 - val_acc: 0.5076\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8090 - acc: 0.6449 - val_loss: 1.4531 - val_acc: 0.5227\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6992 - acc: 0.6978 - val_loss: 1.5071 - val_acc: 0.4864\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7121 - acc: 0.6876 - val_loss: 1.5826 - val_acc: 0.4864\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7364 - acc: 0.6830 - val_loss: 1.5605 - val_acc: 0.4713\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7180 - acc: 0.6788 - val_loss: 1.4907 - val_acc: 0.5045\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6984 - acc: 0.6953 - val_loss: 1.6331 - val_acc: 0.4773\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7407 - acc: 0.6707 - val_loss: 1.6021 - val_acc: 0.4834\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6998 - acc: 0.6855 - val_loss: 1.6238 - val_acc: 0.4743\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7288 - acc: 0.6893 - val_loss: 1.4889 - val_acc: 0.5136\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7140 - acc: 0.7031 - val_loss: 1.5303 - val_acc: 0.4773\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7184 - acc: 0.6981 - val_loss: 1.4326 - val_acc: 0.5347\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6840 - acc: 0.7027 - val_loss: 1.4827 - val_acc: 0.5468\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7076 - acc: 0.6925 - val_loss: 1.6235 - val_acc: 0.4502\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7167 - acc: 0.6872 - val_loss: 1.4663 - val_acc: 0.4924\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7043 - acc: 0.6886 - val_loss: 1.5096 - val_acc: 0.5589\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6814 - acc: 0.6999 - val_loss: 1.4682 - val_acc: 0.5498\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7290 - acc: 0.6904 - val_loss: 1.4722 - val_acc: 0.5076\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6703 - acc: 0.7038 - val_loss: 1.5837 - val_acc: 0.4864\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7265 - acc: 0.6816 - val_loss: 1.5457 - val_acc: 0.4955\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6554 - acc: 0.7249 - val_loss: 1.6118 - val_acc: 0.4350\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6967 - acc: 0.7045 - val_loss: 1.5900 - val_acc: 0.4653\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.6529 - acc: 0.7168 - val_loss: 1.9571 - val_acc: 0.4683\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7180 - acc: 0.6862 - val_loss: 1.6614 - val_acc: 0.4985\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7054 - acc: 0.7038 - val_loss: 1.5952 - val_acc: 0.4773\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6880 - acc: 0.7010 - val_loss: 1.5483 - val_acc: 0.4864\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6946 - acc: 0.7038 - val_loss: 1.6312 - val_acc: 0.4834\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6634 - acc: 0.7126 - val_loss: 1.7303 - val_acc: 0.4562\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6715 - acc: 0.7055 - val_loss: 1.5920 - val_acc: 0.5408\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6690 - acc: 0.7094 - val_loss: 1.5755 - val_acc: 0.5438\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6697 - acc: 0.7041 - val_loss: 1.5558 - val_acc: 0.5589\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6639 - acc: 0.7024 - val_loss: 1.5294 - val_acc: 0.5559\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6929 - acc: 0.6992 - val_loss: 1.5536 - val_acc: 0.5408\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6133 - acc: 0.7464 - val_loss: 1.7990 - val_acc: 0.4471\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7264 - acc: 0.6851 - val_loss: 1.5936 - val_acc: 0.5347\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6418 - acc: 0.7256 - val_loss: 1.7609 - val_acc: 0.4834\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6213 - acc: 0.7267 - val_loss: 1.7321 - val_acc: 0.4562\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6694 - acc: 0.7150 - val_loss: 1.6757 - val_acc: 0.4683\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6612 - acc: 0.7207 - val_loss: 1.6196 - val_acc: 0.5589\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6158 - acc: 0.7362 - val_loss: 1.6040 - val_acc: 0.4743\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6887 - acc: 0.7122 - val_loss: 1.6223 - val_acc: 0.5227\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6021 - acc: 0.7471 - val_loss: 1.6679 - val_acc: 0.5408\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6486 - acc: 0.7122 - val_loss: 1.6884 - val_acc: 0.5438\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6416 - acc: 0.7281 - val_loss: 1.6409 - val_acc: 0.4864\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6793 - acc: 0.7235 - val_loss: 1.8071 - val_acc: 0.4834\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6778 - acc: 0.7105 - val_loss: 1.7062 - val_acc: 0.5136\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6061 - acc: 0.7513 - val_loss: 1.6123 - val_acc: 0.5196\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6998 - acc: 0.6904 - val_loss: 1.5889 - val_acc: 0.5287\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6679 - acc: 0.7161 - val_loss: 1.8156 - val_acc: 0.4864\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6586 - acc: 0.7154 - val_loss: 1.6347 - val_acc: 0.4955\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6197 - acc: 0.7541 - val_loss: 1.6579 - val_acc: 0.5498\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6249 - acc: 0.7369 - val_loss: 1.6015 - val_acc: 0.5317\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6740 - acc: 0.7052 - val_loss: 1.6809 - val_acc: 0.5106\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5970 - acc: 0.7369 - val_loss: 1.8392 - val_acc: 0.5015\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6431 - acc: 0.7253 - val_loss: 1.7081 - val_acc: 0.4834\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.6129 - acc: 0.730 - 0s 84us/step - loss: 0.6101 - acc: 0.7334 - val_loss: 1.8464 - val_acc: 0.4955\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6182 - acc: 0.7327 - val_loss: 1.7484 - val_acc: 0.5196\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6179 - acc: 0.7429 - val_loss: 1.7155 - val_acc: 0.4350\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6427 - acc: 0.7059 - val_loss: 1.8222 - val_acc: 0.4743\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6818 - acc: 0.7080 - val_loss: 1.6900 - val_acc: 0.4773\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6069 - acc: 0.7534 - val_loss: 1.7314 - val_acc: 0.5136\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6031 - acc: 0.7404 - val_loss: 1.7167 - val_acc: 0.5347\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6374 - acc: 0.7298 - val_loss: 1.8607 - val_acc: 0.4713\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6349 - acc: 0.7291 - val_loss: 1.6785 - val_acc: 0.5378\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6024 - acc: 0.7591 - val_loss: 1.8579 - val_acc: 0.5015\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6441 - acc: 0.7179 - val_loss: 1.8393 - val_acc: 0.4773\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6001 - acc: 0.7383 - val_loss: 1.7674 - val_acc: 0.5408\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6403 - acc: 0.7319 - val_loss: 1.7850 - val_acc: 0.4924\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5639 - acc: 0.7563 - val_loss: 1.6468 - val_acc: 0.5227\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6103 - acc: 0.7362 - val_loss: 1.7957 - val_acc: 0.5408\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6678 - acc: 0.7179 - val_loss: 1.6871 - val_acc: 0.4864\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6375 - acc: 0.7274 - val_loss: 1.8870 - val_acc: 0.4955\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5724 - acc: 0.7601 - val_loss: 1.8213 - val_acc: 0.4653\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6370 - acc: 0.7154 - val_loss: 1.7867 - val_acc: 0.4804\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6070 - acc: 0.7446 - val_loss: 1.7555 - val_acc: 0.5408\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6050 - acc: 0.7457 - val_loss: 1.8647 - val_acc: 0.5106\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5845 - acc: 0.7517 - val_loss: 1.8098 - val_acc: 0.5015\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5756 - acc: 0.7584 - val_loss: 2.2433 - val_acc: 0.4622\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6009 - acc: 0.7400 - val_loss: 1.8322 - val_acc: 0.4804\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6323 - acc: 0.7281 - val_loss: 1.7286 - val_acc: 0.5166\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5480 - acc: 0.7721 - val_loss: 1.7628 - val_acc: 0.4894\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6165 - acc: 0.7330 - val_loss: 1.8381 - val_acc: 0.5347\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5847 - acc: 0.748 - 0s 71us/step - loss: 0.5858 - acc: 0.7474 - val_loss: 1.7146 - val_acc: 0.5589\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5917 - acc: 0.7552 - val_loss: 1.7172 - val_acc: 0.5589\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6054 - acc: 0.7376 - val_loss: 1.6910 - val_acc: 0.5015\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5620 - acc: 0.7594 - val_loss: 1.9499 - val_acc: 0.4985\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5481 - acc: 0.7668 - val_loss: 2.0398 - val_acc: 0.4441\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6164 - acc: 0.7429 - val_loss: 1.9082 - val_acc: 0.4894\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5760 - acc: 0.7626 - val_loss: 2.1503 - val_acc: 0.4834\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5970 - acc: 0.7457 - val_loss: 1.9889 - val_acc: 0.4924\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.5892 - acc: 0.7492 - val_loss: 1.9331 - val_acc: 0.4924\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5306 - acc: 0.7739 - val_loss: 1.9932 - val_acc: 0.4683\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5525 - acc: 0.7700 - val_loss: 1.9919 - val_acc: 0.5347\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6004 - acc: 0.7348 - val_loss: 1.7562 - val_acc: 0.4955\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5418 - acc: 0.7746 - val_loss: 1.8631 - val_acc: 0.5378\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5716 - acc: 0.7520 - val_loss: 1.7634 - val_acc: 0.5589\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5526 - acc: 0.7721 - val_loss: 1.8196 - val_acc: 0.5196\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5739 - acc: 0.7432 - val_loss: 1.7566 - val_acc: 0.5408\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5530 - acc: 0.7654 - val_loss: 2.0784 - val_acc: 0.3988\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5621 - acc: 0.7700 - val_loss: 1.8206 - val_acc: 0.5347\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5950 - acc: 0.7457 - val_loss: 1.8613 - val_acc: 0.5378\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5829 - acc: 0.7492 - val_loss: 1.9037 - val_acc: 0.5076\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5278 - acc: 0.7823 - val_loss: 2.0187 - val_acc: 0.5498\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5341 - acc: 0.7806 - val_loss: 2.4033 - val_acc: 0.4592\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6909 - acc: 0.7161 - val_loss: 1.8626 - val_acc: 0.5227\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5209 - acc: 0.7799 - val_loss: 1.7760 - val_acc: 0.4985\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5327 - acc: 0.7763 - val_loss: 1.8222 - val_acc: 0.5529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5983 - acc: 0.7467 - val_loss: 1.8349 - val_acc: 0.4834\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5333 - acc: 0.7791 - val_loss: 1.8698 - val_acc: 0.5045\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5110 - acc: 0.7876 - val_loss: 1.8136 - val_acc: 0.5650\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5634 - acc: 0.7742 - val_loss: 1.7689 - val_acc: 0.5438\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7946 - val_loss: 2.1944 - val_acc: 0.4924\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5790 - acc: 0.7587 - val_loss: 1.9536 - val_acc: 0.4955\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5270 - acc: 0.7908 - val_loss: 2.2067 - val_acc: 0.4622\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5581 - acc: 0.7718 - val_loss: 1.9649 - val_acc: 0.5076\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4736 - acc: 0.8066 - val_loss: 2.2146 - val_acc: 0.4955\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6044 - acc: 0.7379 - val_loss: 1.7893 - val_acc: 0.5680\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5125 - acc: 0.7929 - val_loss: 1.9021 - val_acc: 0.5378\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5262 - acc: 0.7876 - val_loss: 1.7661 - val_acc: 0.5287\n",
      "Epoch 309/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5291 - acc: 0.7799 - val_loss: 2.0633 - val_acc: 0.4955\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4884 - acc: 0.7901 - val_loss: 1.9953 - val_acc: 0.5438\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6046 - acc: 0.7453 - val_loss: 1.9787 - val_acc: 0.4985\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5017 - acc: 0.8010 - val_loss: 2.0928 - val_acc: 0.4713\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5168 - acc: 0.7876 - val_loss: 2.1718 - val_acc: 0.4411\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5413 - acc: 0.7707 - val_loss: 2.4210 - val_acc: 0.4894\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5386 - acc: 0.7732 - val_loss: 2.2278 - val_acc: 0.4713\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5725 - acc: 0.7619 - val_loss: 1.9881 - val_acc: 0.5257\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4650 - acc: 0.8087 - val_loss: 2.2470 - val_acc: 0.4894\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5888 - acc: 0.7615 - val_loss: 2.1396 - val_acc: 0.4773\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5015 - acc: 0.7855 - val_loss: 2.2674 - val_acc: 0.4592\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4954 - acc: 0.7894 - val_loss: 2.4992 - val_acc: 0.4622\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5281 - acc: 0.776 - 0s 70us/step - loss: 0.5102 - acc: 0.7862 - val_loss: 2.1774 - val_acc: 0.4985\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5390 - acc: 0.7728 - val_loss: 2.1187 - val_acc: 0.4834\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4889 - acc: 0.7911 - val_loss: 1.8986 - val_acc: 0.5317\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5338 - acc: 0.7756 - val_loss: 2.0720 - val_acc: 0.5589\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5506 - acc: 0.7725 - val_loss: 2.2284 - val_acc: 0.4653\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4755 - acc: 0.8059 - val_loss: 2.0425 - val_acc: 0.5498\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5744 - acc: 0.7467 - val_loss: 2.0817 - val_acc: 0.4955\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.5357 - acc: 0.7784 - val_loss: 1.8756 - val_acc: 0.5015\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4697 - acc: 0.8070 - val_loss: 2.0375 - val_acc: 0.5136\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4676 - acc: 0.8144 - val_loss: 2.0249 - val_acc: 0.5378\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4851 - acc: 0.7992 - val_loss: 2.4710 - val_acc: 0.4683\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5411 - acc: 0.7746 - val_loss: 2.4029 - val_acc: 0.4592\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5342 - acc: 0.7816 - val_loss: 2.1130 - val_acc: 0.5287\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4738 - acc: 0.7996 - val_loss: 2.4829 - val_acc: 0.4622\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5141 - acc: 0.7830 - val_loss: 2.3416 - val_acc: 0.4894\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4909 - acc: 0.7978 - val_loss: 2.5355 - val_acc: 0.4924\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5220 - acc: 0.7894 - val_loss: 1.9983 - val_acc: 0.5257\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.8105 - val_loss: 2.1462 - val_acc: 0.4411\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5647 - acc: 0.7689 - val_loss: 1.8753 - val_acc: 0.4773\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5294 - acc: 0.7813 - val_loss: 2.0406 - val_acc: 0.4985\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4500 - acc: 0.8168 - val_loss: 2.0094 - val_acc: 0.5227\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5316 - acc: 0.7844 - val_loss: 2.1790 - val_acc: 0.4804\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4685 - acc: 0.8038 - val_loss: 2.2484 - val_acc: 0.4924\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4775 - acc: 0.8052 - val_loss: 1.9422 - val_acc: 0.5257\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5015 - acc: 0.7894 - val_loss: 1.9561 - val_acc: 0.4985\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4754 - acc: 0.8094 - val_loss: 2.1518 - val_acc: 0.4804\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5116 - acc: 0.7918 - val_loss: 1.9404 - val_acc: 0.5076\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5176 - acc: 0.7816 - val_loss: 2.3989 - val_acc: 0.4743\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5021 - acc: 0.7862 - val_loss: 2.3790 - val_acc: 0.4653\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4713 - acc: 0.8133 - val_loss: 2.1786 - val_acc: 0.4924\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4510 - acc: 0.8165 - val_loss: 2.3087 - val_acc: 0.4743\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4521 - acc: 0.8168 - val_loss: 1.9655 - val_acc: 0.5257\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5364 - acc: 0.7806 - val_loss: 2.0919 - val_acc: 0.4804\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5114 - acc: 0.7911 - val_loss: 1.9910 - val_acc: 0.5468\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4663 - acc: 0.8158 - val_loss: 1.9639 - val_acc: 0.5106\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4760 - acc: 0.8063 - val_loss: 2.0319 - val_acc: 0.5136\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4645 - acc: 0.8221 - val_loss: 2.1530 - val_acc: 0.5408\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5203 - acc: 0.7872 - val_loss: 2.1432 - val_acc: 0.5710\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4674 - acc: 0.8101 - val_loss: 2.1494 - val_acc: 0.4683\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4485 - acc: 0.8119 - val_loss: 2.4122 - val_acc: 0.4683\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4938 - acc: 0.7925 - val_loss: 2.2895 - val_acc: 0.5045\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4775 - acc: 0.8045 - val_loss: 2.0289 - val_acc: 0.4924\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4384 - acc: 0.8256 - val_loss: 2.0191 - val_acc: 0.4985\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4374 - acc: 0.8200 - val_loss: 2.5102 - val_acc: 0.4985\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4979 - acc: 0.7929 - val_loss: 2.4204 - val_acc: 0.4834\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4101 - acc: 0.8302 - val_loss: 2.2027 - val_acc: 0.5468\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5338 - acc: 0.7827 - val_loss: 2.0993 - val_acc: 0.4894\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4657 - acc: 0.8094 - val_loss: 2.1770 - val_acc: 0.4653\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4625 - acc: 0.8154 - val_loss: 2.1908 - val_acc: 0.5166\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4802 - acc: 0.8070 - val_loss: 2.1631 - val_acc: 0.4411\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4597 - acc: 0.8130 - val_loss: 2.3700 - val_acc: 0.4502\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4286 - acc: 0.8281 - val_loss: 2.5603 - val_acc: 0.4713\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5083 - acc: 0.7876 - val_loss: 2.2054 - val_acc: 0.4743\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4154 - acc: 0.8341 - val_loss: 2.7126 - val_acc: 0.4622\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4449 - acc: 0.8193 - val_loss: 2.3664 - val_acc: 0.4773\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4686 - acc: 0.8070 - val_loss: 2.2800 - val_acc: 0.4683\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4528 - acc: 0.8151 - val_loss: 2.5103 - val_acc: 0.4683\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4677 - acc: 0.8084 - val_loss: 2.3641 - val_acc: 0.4924\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.4248 - acc: 0.8383 - val_loss: 2.4425 - val_acc: 0.4834\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5017 - acc: 0.8073 - val_loss: 2.2243 - val_acc: 0.4864\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4676 - acc: 0.8101 - val_loss: 2.1661 - val_acc: 0.5347\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4015 - acc: 0.8348 - val_loss: 2.1970 - val_acc: 0.4653\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4494 - acc: 0.8197 - val_loss: 2.1241 - val_acc: 0.5196\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4438 - acc: 0.8211 - val_loss: 2.4002 - val_acc: 0.5227\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4228 - acc: 0.8394 - val_loss: 2.1372 - val_acc: 0.4381\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4985 - acc: 0.7975 - val_loss: 2.1911 - val_acc: 0.4924\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4632 - acc: 0.8101 - val_loss: 2.8752 - val_acc: 0.4502\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4390 - acc: 0.8218 - val_loss: 2.4211 - val_acc: 0.5257\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3750 - acc: 0.8517 - val_loss: 2.5712 - val_acc: 0.5196\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4401 - acc: 0.8070 - val_loss: 2.5201 - val_acc: 0.4592\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4821 - acc: 0.8091 - val_loss: 2.3815 - val_acc: 0.4985\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4187 - acc: 0.8376 - val_loss: 2.4772 - val_acc: 0.4653\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4134 - acc: 0.8352 - val_loss: 2.4926 - val_acc: 0.5287\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4403 - acc: 0.823 - 0s 82us/step - loss: 0.4344 - acc: 0.8263 - val_loss: 2.5021 - val_acc: 0.5287\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4794 - acc: 0.8084 - val_loss: 2.4608 - val_acc: 0.4532\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4347 - acc: 0.8281 - val_loss: 2.3481 - val_acc: 0.5076\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.4207 - acc: 0.8327 - val_loss: 2.7923 - val_acc: 0.4532\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4416 - acc: 0.8172 - val_loss: 2.2830 - val_acc: 0.5166\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3882 - acc: 0.8492 - val_loss: 2.2055 - val_acc: 0.4804\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4666 - acc: 0.8052 - val_loss: 2.4077 - val_acc: 0.4894\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4891 - acc: 0.8059 - val_loss: 2.3105 - val_acc: 0.4894\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4434 - acc: 0.8285 - val_loss: 2.2444 - val_acc: 0.4985\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3774 - acc: 0.8496 - val_loss: 2.6168 - val_acc: 0.4743\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3919 - acc: 0.8457 - val_loss: 2.3831 - val_acc: 0.5166\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 115us/step - loss: 0.4701 - acc: 0.8140 - val_loss: 2.6648 - val_acc: 0.4773\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.4402 - acc: 0.8249 - val_loss: 2.4477 - val_acc: 0.4864\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.4264 - acc: 0.8249 - val_loss: 2.1139 - val_acc: 0.5136\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3794 - acc: 0.8433 - val_loss: 2.4817 - val_acc: 0.5015\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.4635 - acc: 0.8175 - val_loss: 2.2774 - val_acc: 0.5317\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3967 - acc: 0.8478 - val_loss: 2.2034 - val_acc: 0.4804\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3893 - acc: 0.8447 - val_loss: 2.4989 - val_acc: 0.5136\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.4836 - acc: 0.8193 - val_loss: 2.3154 - val_acc: 0.4924\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.4231 - acc: 0.8193 - val_loss: 2.1477 - val_acc: 0.4985\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3834 - acc: 0.8510 - val_loss: 2.3238 - val_acc: 0.5196\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4124 - acc: 0.8327 - val_loss: 2.3039 - val_acc: 0.5468\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3980 - acc: 0.8422 - val_loss: 2.5782 - val_acc: 0.5166\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4245 - acc: 0.8278 - val_loss: 2.4838 - val_acc: 0.4592\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4000 - acc: 0.8401 - val_loss: 2.7290 - val_acc: 0.4653\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.3858 - acc: 0.8503 - val_loss: 2.4096 - val_acc: 0.4773\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.3795 - acc: 0.8447 - val_loss: 2.7505 - val_acc: 0.4713\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4492 - acc: 0.8116 - val_loss: 2.7145 - val_acc: 0.4955\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.4002 - acc: 0.8426 - val_loss: 2.3931 - val_acc: 0.5227\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 93us/step - loss: 0.3857 - acc: 0.8447 - val_loss: 2.8084 - val_acc: 0.4864\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4777 - acc: 0.8084 - val_loss: 2.5479 - val_acc: 0.4894\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3635 - acc: 0.8637 - val_loss: 2.5591 - val_acc: 0.5136\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3965 - acc: 0.8464 - val_loss: 2.5711 - val_acc: 0.5045\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3781 - acc: 0.8514 - val_loss: 2.3737 - val_acc: 0.5468\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.4544 - acc: 0.8225 - val_loss: 2.2660 - val_acc: 0.4773\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3696 - acc: 0.8556 - val_loss: 2.7619 - val_acc: 0.4743\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4521 - acc: 0.8179 - val_loss: 2.6293 - val_acc: 0.4773\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4143 - acc: 0.8302 - val_loss: 2.6979 - val_acc: 0.4894\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3639 - acc: 0.8619 - val_loss: 2.6163 - val_acc: 0.4985\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4388 - acc: 0.8337 - val_loss: 2.2048 - val_acc: 0.5106\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4270 - acc: 0.8267 - val_loss: 2.4952 - val_acc: 0.4683\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3446 - acc: 0.8644 - val_loss: 2.7651 - val_acc: 0.4924\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 94us/step - loss: 0.4102 - acc: 0.8369 - val_loss: 2.7076 - val_acc: 0.4955\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3518 - acc: 0.8566 - val_loss: 2.6711 - val_acc: 0.5196\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3927 - acc: 0.8535 - val_loss: 2.9262 - val_acc: 0.5045\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4662 - acc: 0.8116 - val_loss: 2.5213 - val_acc: 0.4894\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3603 - acc: 0.8566 - val_loss: 2.4112 - val_acc: 0.5287\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4257 - acc: 0.8228 - val_loss: 2.2890 - val_acc: 0.5045\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3906 - acc: 0.8429 - val_loss: 2.3892 - val_acc: 0.4985\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3532 - acc: 0.8573 - val_loss: 2.5065 - val_acc: 0.5378\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 98us/step - loss: 0.3562 - acc: 0.8633 - val_loss: 2.4780 - val_acc: 0.5347\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 104us/step - loss: 0.4606 - acc: 0.8147 - val_loss: 2.4963 - val_acc: 0.5227\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3766 - acc: 0.8485 - val_loss: 2.6646 - val_acc: 0.4743\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4195 - acc: 0.8426 - val_loss: 2.5920 - val_acc: 0.5045\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3627 - acc: 0.8538 - val_loss: 3.0329 - val_acc: 0.4713\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3949 - acc: 0.8397 - val_loss: 2.7210 - val_acc: 0.5196\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3309 - acc: 0.8711 - val_loss: 2.5426 - val_acc: 0.5196\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4603 - acc: 0.8182 - val_loss: 3.0496 - val_acc: 0.4804\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4169 - acc: 0.8302 - val_loss: 2.5334 - val_acc: 0.4924\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4474 - acc: 0.8278 - val_loss: 2.3823 - val_acc: 0.5106\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3096 - acc: 0.8834 - val_loss: 2.8566 - val_acc: 0.4622\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3699 - acc: 0.8602 - val_loss: 2.6674 - val_acc: 0.5196\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4089 - acc: 0.8366 - val_loss: 2.6905 - val_acc: 0.4834\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3741 - acc: 0.8524 - val_loss: 2.7789 - val_acc: 0.4713\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3420 - acc: 0.8616 - val_loss: 2.6065 - val_acc: 0.5136\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4230 - acc: 0.8256 - val_loss: 2.4644 - val_acc: 0.5166\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3353 - acc: 0.8767 - val_loss: 2.7102 - val_acc: 0.5015\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3814 - acc: 0.8503 - val_loss: 2.4862 - val_acc: 0.5076\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4007 - acc: 0.8411 - val_loss: 2.4819 - val_acc: 0.4864\n",
      "Epoch 463/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3547 - acc: 0.8700 - val_loss: 2.7619 - val_acc: 0.4622\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3522 - acc: 0.8598 - val_loss: 3.1003 - val_acc: 0.4713\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 104us/step - loss: 0.4222 - acc: 0.8341 - val_loss: 2.6924 - val_acc: 0.4773\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3283 - acc: 0.8788 - val_loss: 2.7067 - val_acc: 0.5227\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3872 - acc: 0.8471 - val_loss: 2.5312 - val_acc: 0.5287\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3479 - acc: 0.8598 - val_loss: 2.8184 - val_acc: 0.5106\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3682 - acc: 0.8612 - val_loss: 2.5003 - val_acc: 0.5468\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3954 - acc: 0.8471 - val_loss: 3.2649 - val_acc: 0.4622\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3803 - acc: 0.8584 - val_loss: 2.8656 - val_acc: 0.4653\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3602 - acc: 0.8563 - val_loss: 2.8786 - val_acc: 0.4864\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3925 - acc: 0.8454 - val_loss: 2.7361 - val_acc: 0.4773\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3385 - acc: 0.8714 - val_loss: 2.7577 - val_acc: 0.5136\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3308 - acc: 0.8732 - val_loss: 2.8214 - val_acc: 0.5196\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4349 - acc: 0.8260 - val_loss: 2.8483 - val_acc: 0.4864\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3310 - acc: 0.8771 - val_loss: 2.9889 - val_acc: 0.5287\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3426 - acc: 0.8640 - val_loss: 2.5117 - val_acc: 0.4713\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3918 - acc: 0.8426 - val_loss: 3.0774 - val_acc: 0.5045\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4170 - acc: 0.8341 - val_loss: 3.0932 - val_acc: 0.4562\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3976 - acc: 0.8418 - val_loss: 2.8453 - val_acc: 0.4622\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3101 - acc: 0.8816 - val_loss: 2.9595 - val_acc: 0.4804\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3084 - acc: 0.8764 - val_loss: 2.6774 - val_acc: 0.4622\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4727 - acc: 0.8179 - val_loss: 2.6061 - val_acc: 0.5227\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3143 - acc: 0.8848 - val_loss: 2.9227 - val_acc: 0.4653\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3705 - acc: 0.8626 - val_loss: 3.1333 - val_acc: 0.4622\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4112 - acc: 0.8288 - val_loss: 2.7012 - val_acc: 0.5045\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2889 - acc: 0.8901 - val_loss: 2.5076 - val_acc: 0.4955\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3559 - acc: 0.8573 - val_loss: 2.6502 - val_acc: 0.4683\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3911 - acc: 0.8366 - val_loss: 2.7546 - val_acc: 0.5227\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3044 - acc: 0.8820 - val_loss: 2.7799 - val_acc: 0.5136\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4098 - acc: 0.8330 - val_loss: 2.7032 - val_acc: 0.5408\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3522 - acc: 0.8693 - val_loss: 2.7153 - val_acc: 0.4864\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3695 - acc: 0.8521 - val_loss: 2.6520 - val_acc: 0.4804\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3640 - acc: 0.8573 - val_loss: 2.7315 - val_acc: 0.5106\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3029 - acc: 0.8831 - val_loss: 2.8591 - val_acc: 0.5076\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3801 - acc: 0.8619 - val_loss: 3.1533 - val_acc: 0.5378\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.8151 - val_loss: 2.4951 - val_acc: 0.4955\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.2931 - acc: 0.8912 - val_loss: 3.0927 - val_acc: 0.5408\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3170 - acc: 0.8764 - val_loss: 2.5558 - val_acc: 0.4985\n"
     ]
    }
   ],
   "source": [
    "w2v_model = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=500, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "0.625\n",
      "0.9652777777777778\n",
      "47\n",
      "0.7446808510638298\n",
      "0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_w2v)\n",
    "model_metrics(predictions, y_cat_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e6c3748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model.history['acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1825f5da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model.history['val_acc'])\n",
    "plt.plot(business_model.history['val_acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['zillow', 'business', 'w2v'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {0 : 2,\n",
    "    1: 1,\n",
    "    2: .5,\n",
    "    3: 1,\n",
    "    4: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>loss</th>\n",
       "      <th>gain</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>gain_true_true</th>\n",
       "      <th>gain_stay</th>\n",
       "      <th>loss_true_true</th>\n",
       "      <th>loss_stay</th>\n",
       "      <th>gain_large</th>\n",
       "      <th>loss_large</th>\n",
       "      <th>gain_large_true</th>\n",
       "      <th>loss_large_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.386394e-03</td>\n",
       "      <td>1.050091e-01</td>\n",
       "      <td>1.591386e-01</td>\n",
       "      <td>0.356899</td>\n",
       "      <td>3.745667e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.575360e-10</td>\n",
       "      <td>2.015372e-06</td>\n",
       "      <td>9.907100e-01</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>5.487662e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.422529e-10</td>\n",
       "      <td>2.247291e-07</td>\n",
       "      <td>9.999537e-01</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>4.702748e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.420212e-11</td>\n",
       "      <td>1.134737e-06</td>\n",
       "      <td>1.622263e-06</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>9.164789e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.406993e-33</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.781700e-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2         3             4  loss  \\\n",
       "0  4.386394e-03  1.050091e-01  1.591386e-01  0.356899  3.745667e-01     0   \n",
       "1  2.575360e-10  2.015372e-06  9.907100e-01  0.009283  5.487662e-06     0   \n",
       "2  1.422529e-10  2.247291e-07  9.999537e-01  0.000046  4.702748e-07     0   \n",
       "3  2.420212e-11  1.134737e-06  1.622263e-06  0.083518  9.164789e-01     0   \n",
       "4  5.406993e-33  1.000000e+00  7.781700e-19  0.000000  0.000000e+00     1   \n",
       "\n",
       "   gain  1  2  3  4  5  gain_true_true  gain_stay  loss_true_true  loss_stay  \\\n",
       "0     1  0  0  0  1  0               1          0               0          0   \n",
       "1     1  0  0  0  1  0               1          0               0          0   \n",
       "2     1  0  0  1  0  0               0          1               0          0   \n",
       "3     1  0  0  1  0  0               0          1               0          0   \n",
       "4     0  0  0  0  1  0               0          0               0          0   \n",
       "\n",
       "   gain_large  loss_large  gain_large_true  loss_large_true  \n",
       "0           1           0                0                0  \n",
       "1           0           0                0                0  \n",
       "2           0           0                0                0  \n",
       "3           1           0                0                0  \n",
       "4           0           0                0                0  "
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.00001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 1.5175 - acc: 0.1955 - val_loss: 1.6007 - val_acc: 0.3323\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5223 - acc: 0.1944 - val_loss: 1.6000 - val_acc: 0.3353\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.5247 - acc: 0.1948 - val_loss: 1.5993 - val_acc: 0.3353\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.5229 - acc: 0.1874 - val_loss: 1.5987 - val_acc: 0.3353\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5271 - acc: 0.1948 - val_loss: 1.5982 - val_acc: 0.3353\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5183 - acc: 0.2018 - val_loss: 1.5978 - val_acc: 0.3384\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5186 - acc: 0.2015 - val_loss: 1.5974 - val_acc: 0.3384\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5225 - acc: 0.2018 - val_loss: 1.5969 - val_acc: 0.3353\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5123 - acc: 0.1965 - val_loss: 1.5964 - val_acc: 0.3353\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5160 - acc: 0.2036 - val_loss: 1.5960 - val_acc: 0.3353\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5179 - acc: 0.1990 - val_loss: 1.5954 - val_acc: 0.3353\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5217 - acc: 0.1976 - val_loss: 1.5949 - val_acc: 0.3353\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5094 - acc: 0.2036 - val_loss: 1.5945 - val_acc: 0.3353\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5065 - acc: 0.2124 - val_loss: 1.5941 - val_acc: 0.3353\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5174 - acc: 0.1983 - val_loss: 1.5936 - val_acc: 0.3353\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5123 - acc: 0.1983 - val_loss: 1.5932 - val_acc: 0.3353\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5049 - acc: 0.2029 - val_loss: 1.5926 - val_acc: 0.3353\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5171 - acc: 0.1930 - val_loss: 1.5923 - val_acc: 0.3353\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5100 - acc: 0.1902 - val_loss: 1.5920 - val_acc: 0.3353\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5065 - acc: 0.2082 - val_loss: 1.5916 - val_acc: 0.3323\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5221 - acc: 0.1997 - val_loss: 1.5913 - val_acc: 0.3323\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5154 - acc: 0.2018 - val_loss: 1.5909 - val_acc: 0.3323\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5086 - acc: 0.2082 - val_loss: 1.5906 - val_acc: 0.3323\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5144 - acc: 0.2011 - val_loss: 1.5903 - val_acc: 0.3323\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5075 - acc: 0.2120 - val_loss: 1.5899 - val_acc: 0.3353\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5096 - acc: 0.2032 - val_loss: 1.5895 - val_acc: 0.3353\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5093 - acc: 0.2064 - val_loss: 1.5891 - val_acc: 0.3353\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4992 - acc: 0.2110 - val_loss: 1.5888 - val_acc: 0.3353\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5020 - acc: 0.2106 - val_loss: 1.5884 - val_acc: 0.3353\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5035 - acc: 0.2096 - val_loss: 1.5880 - val_acc: 0.3323\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5094 - acc: 0.2082 - val_loss: 1.5878 - val_acc: 0.3323\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5081 - acc: 0.2008 - val_loss: 1.5874 - val_acc: 0.3323\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5078 - acc: 0.1980 - val_loss: 1.5871 - val_acc: 0.3323\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5016 - acc: 0.2085 - val_loss: 1.5867 - val_acc: 0.3323\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.5096 - acc: 0.2022 - val_loss: 1.5864 - val_acc: 0.3323\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5069 - acc: 0.2050 - val_loss: 1.5860 - val_acc: 0.3323\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5065 - acc: 0.1958 - val_loss: 1.5856 - val_acc: 0.3323\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4982 - acc: 0.2117 - val_loss: 1.5854 - val_acc: 0.3323\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5021 - acc: 0.2004 - val_loss: 1.5850 - val_acc: 0.3323\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5000 - acc: 0.2131 - val_loss: 1.5847 - val_acc: 0.3323\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5027 - acc: 0.2032 - val_loss: 1.5844 - val_acc: 0.3323\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5079 - acc: 0.2135 - val_loss: 1.5841 - val_acc: 0.3323\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5022 - acc: 0.2149 - val_loss: 1.5838 - val_acc: 0.3323\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5092 - acc: 0.2057 - val_loss: 1.5834 - val_acc: 0.3353\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4902 - acc: 0.2120 - val_loss: 1.5830 - val_acc: 0.3353\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4959 - acc: 0.2233 - val_loss: 1.5826 - val_acc: 0.3353\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5045 - acc: 0.2029 - val_loss: 1.5822 - val_acc: 0.3353\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4949 - acc: 0.2092 - val_loss: 1.5818 - val_acc: 0.3353\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4985 - acc: 0.2124 - val_loss: 1.5814 - val_acc: 0.3353\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.5059 - acc: 0.1965 - val_loss: 1.5811 - val_acc: 0.3353\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5056 - acc: 0.1962 - val_loss: 1.5808 - val_acc: 0.3353\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4958 - acc: 0.2170 - val_loss: 1.5805 - val_acc: 0.3353\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4952 - acc: 0.2180 - val_loss: 1.5801 - val_acc: 0.3384\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.5032 - acc: 0.2099 - val_loss: 1.5798 - val_acc: 0.3414\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4926 - acc: 0.2244 - val_loss: 1.5795 - val_acc: 0.3414\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4917 - acc: 0.2124 - val_loss: 1.5791 - val_acc: 0.3414\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4877 - acc: 0.2230 - val_loss: 1.5786 - val_acc: 0.3384\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.5043 - acc: 0.2054 - val_loss: 1.5783 - val_acc: 0.3384\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4943 - acc: 0.2128 - val_loss: 1.5781 - val_acc: 0.3384\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4955 - acc: 0.2071 - val_loss: 1.5778 - val_acc: 0.3384\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4858 - acc: 0.2226 - val_loss: 1.5775 - val_acc: 0.3384\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4985 - acc: 0.2032 - val_loss: 1.5771 - val_acc: 0.3384\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4947 - acc: 0.2089 - val_loss: 1.5768 - val_acc: 0.3384\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4914 - acc: 0.2068 - val_loss: 1.5764 - val_acc: 0.3384\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4945 - acc: 0.2138 - val_loss: 1.5761 - val_acc: 0.3384\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4926 - acc: 0.2223 - val_loss: 1.5757 - val_acc: 0.3384\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4913 - acc: 0.2261 - val_loss: 1.5753 - val_acc: 0.3384\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4885 - acc: 0.2064 - val_loss: 1.5751 - val_acc: 0.3384\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4813 - acc: 0.2300 - val_loss: 1.5747 - val_acc: 0.3384\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4986 - acc: 0.2068 - val_loss: 1.5744 - val_acc: 0.3384\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4833 - acc: 0.2240 - val_loss: 1.5739 - val_acc: 0.3384\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4867 - acc: 0.2201 - val_loss: 1.5736 - val_acc: 0.3353\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4956 - acc: 0.1937 - val_loss: 1.5733 - val_acc: 0.3353\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4887 - acc: 0.2180 - val_loss: 1.5730 - val_acc: 0.3353\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4853 - acc: 0.2240 - val_loss: 1.5725 - val_acc: 0.3384\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4935 - acc: 0.2173 - val_loss: 1.5722 - val_acc: 0.3384\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.5001 - acc: 0.2156 - val_loss: 1.5719 - val_acc: 0.3384\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4914 - acc: 0.2191 - val_loss: 1.5716 - val_acc: 0.3323\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4925 - acc: 0.2159 - val_loss: 1.5712 - val_acc: 0.3293\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4941 - acc: 0.2180 - val_loss: 1.5709 - val_acc: 0.3323\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4916 - acc: 0.2166 - val_loss: 1.5705 - val_acc: 0.3323\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4796 - acc: 0.2212 - val_loss: 1.5701 - val_acc: 0.3323\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4814 - acc: 0.2251 - val_loss: 1.5697 - val_acc: 0.3353\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4865 - acc: 0.2258 - val_loss: 1.5693 - val_acc: 0.3323\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4917 - acc: 0.2138 - val_loss: 1.5690 - val_acc: 0.3293\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4855 - acc: 0.2194 - val_loss: 1.5686 - val_acc: 0.3293\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4805 - acc: 0.2177 - val_loss: 1.5681 - val_acc: 0.3323\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4807 - acc: 0.2219 - val_loss: 1.5677 - val_acc: 0.3323\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4880 - acc: 0.2113 - val_loss: 1.5675 - val_acc: 0.3263\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4883 - acc: 0.2282 - val_loss: 1.5672 - val_acc: 0.3293\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4904 - acc: 0.2293 - val_loss: 1.5668 - val_acc: 0.3293\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4863 - acc: 0.2106 - val_loss: 1.5665 - val_acc: 0.3263\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4835 - acc: 0.2314 - val_loss: 1.5661 - val_acc: 0.3263\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4839 - acc: 0.2293 - val_loss: 1.5658 - val_acc: 0.3263\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4847 - acc: 0.2209 - val_loss: 1.5655 - val_acc: 0.3263\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4807 - acc: 0.2282 - val_loss: 1.5652 - val_acc: 0.3263\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4862 - acc: 0.2219 - val_loss: 1.5649 - val_acc: 0.3263\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4785 - acc: 0.2184 - val_loss: 1.5645 - val_acc: 0.3233\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4806 - acc: 0.2223 - val_loss: 1.5641 - val_acc: 0.3263\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4875 - acc: 0.2191 - val_loss: 1.5637 - val_acc: 0.3233\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4816 - acc: 0.2290 - val_loss: 1.5633 - val_acc: 0.3233\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4742 - acc: 0.2406 - val_loss: 1.5631 - val_acc: 0.3233\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4822 - acc: 0.2180 - val_loss: 1.5627 - val_acc: 0.3233\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4795 - acc: 0.2240 - val_loss: 1.5623 - val_acc: 0.3202\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4772 - acc: 0.2226 - val_loss: 1.5620 - val_acc: 0.3202\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4751 - acc: 0.2219 - val_loss: 1.5616 - val_acc: 0.3202\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4766 - acc: 0.2335 - val_loss: 1.5613 - val_acc: 0.3202\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4759 - acc: 0.2349 - val_loss: 1.5610 - val_acc: 0.3202\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4787 - acc: 0.2311 - val_loss: 1.5606 - val_acc: 0.3202\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4727 - acc: 0.2332 - val_loss: 1.5604 - val_acc: 0.3172\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4770 - acc: 0.2314 - val_loss: 1.5600 - val_acc: 0.3172\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4773 - acc: 0.2261 - val_loss: 1.5597 - val_acc: 0.3172\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4711 - acc: 0.2201 - val_loss: 1.5593 - val_acc: 0.3233\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4711 - acc: 0.2297 - val_loss: 1.5589 - val_acc: 0.3202\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4783 - acc: 0.2159 - val_loss: 1.5585 - val_acc: 0.3172\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4692 - acc: 0.2265 - val_loss: 1.5581 - val_acc: 0.3172\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4732 - acc: 0.2385 - val_loss: 1.5578 - val_acc: 0.3172\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4736 - acc: 0.2367 - val_loss: 1.5575 - val_acc: 0.3172\n",
      "Epoch 119/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4735 - acc: 0.2364 - val_loss: 1.5572 - val_acc: 0.3172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4659 - acc: 0.2353 - val_loss: 1.5567 - val_acc: 0.3202\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4793 - acc: 0.2237 - val_loss: 1.5565 - val_acc: 0.3112\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4711 - acc: 0.2353 - val_loss: 1.5560 - val_acc: 0.3051\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4738 - acc: 0.2290 - val_loss: 1.5556 - val_acc: 0.3112\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4747 - acc: 0.2110 - val_loss: 1.5553 - val_acc: 0.3142\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4743 - acc: 0.2321 - val_loss: 1.5549 - val_acc: 0.3142\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4651 - acc: 0.2332 - val_loss: 1.5545 - val_acc: 0.3172\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4705 - acc: 0.2219 - val_loss: 1.5541 - val_acc: 0.3142\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4700 - acc: 0.2219 - val_loss: 1.5539 - val_acc: 0.3112\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4788 - acc: 0.2170 - val_loss: 1.5535 - val_acc: 0.3202\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4697 - acc: 0.2328 - val_loss: 1.5530 - val_acc: 0.3202\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4750 - acc: 0.2290 - val_loss: 1.5527 - val_acc: 0.3202\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4765 - acc: 0.2286 - val_loss: 1.5524 - val_acc: 0.3233\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4652 - acc: 0.2307 - val_loss: 1.5520 - val_acc: 0.3202\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4619 - acc: 0.2360 - val_loss: 1.5517 - val_acc: 0.3142\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4696 - acc: 0.2332 - val_loss: 1.5514 - val_acc: 0.3112\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4614 - acc: 0.2374 - val_loss: 1.5510 - val_acc: 0.3172\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4632 - acc: 0.2427 - val_loss: 1.5507 - val_acc: 0.3172\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4673 - acc: 0.2392 - val_loss: 1.5502 - val_acc: 0.3263\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4683 - acc: 0.2349 - val_loss: 1.5499 - val_acc: 0.3233\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4599 - acc: 0.2511 - val_loss: 1.5495 - val_acc: 0.3172\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4623 - acc: 0.2399 - val_loss: 1.5492 - val_acc: 0.3202\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4664 - acc: 0.2441 - val_loss: 1.5489 - val_acc: 0.3263\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4658 - acc: 0.2402 - val_loss: 1.5485 - val_acc: 0.3233\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4654 - acc: 0.2335 - val_loss: 1.5481 - val_acc: 0.3323\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4667 - acc: 0.2335 - val_loss: 1.5478 - val_acc: 0.3293\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4673 - acc: 0.2240 - val_loss: 1.5474 - val_acc: 0.3263\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4730 - acc: 0.2339 - val_loss: 1.5470 - val_acc: 0.3263\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4583 - acc: 0.2469 - val_loss: 1.5466 - val_acc: 0.3353\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4695 - acc: 0.2240 - val_loss: 1.5463 - val_acc: 0.3414\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4556 - acc: 0.2459 - val_loss: 1.5461 - val_acc: 0.3474\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4615 - acc: 0.2448 - val_loss: 1.5457 - val_acc: 0.3505\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4553 - acc: 0.2490 - val_loss: 1.5453 - val_acc: 0.3565\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4576 - acc: 0.2430 - val_loss: 1.5449 - val_acc: 0.3595\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4668 - acc: 0.2402 - val_loss: 1.5446 - val_acc: 0.3686\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4583 - acc: 0.2536 - val_loss: 1.5441 - val_acc: 0.3686\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4650 - acc: 0.2367 - val_loss: 1.5438 - val_acc: 0.3716\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4627 - acc: 0.2448 - val_loss: 1.5434 - val_acc: 0.3807\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4580 - acc: 0.2328 - val_loss: 1.5431 - val_acc: 0.3746\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4616 - acc: 0.2395 - val_loss: 1.5428 - val_acc: 0.3776\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4565 - acc: 0.2469 - val_loss: 1.5424 - val_acc: 0.3716\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4633 - acc: 0.2360 - val_loss: 1.5420 - val_acc: 0.3686\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4616 - acc: 0.2374 - val_loss: 1.5417 - val_acc: 0.3656\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4601 - acc: 0.2487 - val_loss: 1.5413 - val_acc: 0.3656\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4580 - acc: 0.2476 - val_loss: 1.5410 - val_acc: 0.3686\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4570 - acc: 0.2466 - val_loss: 1.5408 - val_acc: 0.3656\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4524 - acc: 0.2515 - val_loss: 1.5403 - val_acc: 0.3686\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4609 - acc: 0.2307 - val_loss: 1.5397 - val_acc: 0.3625\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4513 - acc: 0.2652 - val_loss: 1.5394 - val_acc: 0.3656\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4580 - acc: 0.2346 - val_loss: 1.5390 - val_acc: 0.3686\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4539 - acc: 0.2395 - val_loss: 1.5387 - val_acc: 0.3625\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4539 - acc: 0.2526 - val_loss: 1.5383 - val_acc: 0.3656\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4526 - acc: 0.2561 - val_loss: 1.5379 - val_acc: 0.3565\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4588 - acc: 0.2402 - val_loss: 1.5375 - val_acc: 0.3565\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4654 - acc: 0.2364 - val_loss: 1.5373 - val_acc: 0.3595\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4641 - acc: 0.2335 - val_loss: 1.5371 - val_acc: 0.3595\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4572 - acc: 0.2314 - val_loss: 1.5368 - val_acc: 0.3535\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4544 - acc: 0.2480 - val_loss: 1.5365 - val_acc: 0.3595\n",
      "Epoch 178/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4531 - acc: 0.2448 - val_loss: 1.5361 - val_acc: 0.3595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4508 - acc: 0.2466 - val_loss: 1.5359 - val_acc: 0.3595\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4465 - acc: 0.2526 - val_loss: 1.5356 - val_acc: 0.3505\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4488 - acc: 0.2515 - val_loss: 1.5352 - val_acc: 0.3535\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4495 - acc: 0.2575 - val_loss: 1.5350 - val_acc: 0.3535\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4577 - acc: 0.2466 - val_loss: 1.5346 - val_acc: 0.3505\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4585 - acc: 0.2508 - val_loss: 1.5344 - val_acc: 0.3505\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4532 - acc: 0.2603 - val_loss: 1.5341 - val_acc: 0.3505\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4473 - acc: 0.2462 - val_loss: 1.5337 - val_acc: 0.3505\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4536 - acc: 0.2452 - val_loss: 1.5334 - val_acc: 0.3535\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4444 - acc: 0.2533 - val_loss: 1.5330 - val_acc: 0.3505\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4459 - acc: 0.2487 - val_loss: 1.5326 - val_acc: 0.3505\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4486 - acc: 0.2607 - val_loss: 1.5323 - val_acc: 0.3535\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4331 - acc: 0.2582 - val_loss: 1.5319 - val_acc: 0.3505\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4485 - acc: 0.2656 - val_loss: 1.5315 - val_acc: 0.3565\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4472 - acc: 0.2642 - val_loss: 1.5312 - val_acc: 0.3535\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4531 - acc: 0.2452 - val_loss: 1.5309 - val_acc: 0.3535\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4400 - acc: 0.2652 - val_loss: 1.5305 - val_acc: 0.3535\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4507 - acc: 0.2413 - val_loss: 1.5302 - val_acc: 0.3505\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4446 - acc: 0.2515 - val_loss: 1.5299 - val_acc: 0.3474\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4409 - acc: 0.2600 - val_loss: 1.5296 - val_acc: 0.3474\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4500 - acc: 0.2642 - val_loss: 1.5292 - val_acc: 0.3474\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4432 - acc: 0.2543 - val_loss: 1.5288 - val_acc: 0.3535\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4434 - acc: 0.2684 - val_loss: 1.5285 - val_acc: 0.3505\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4535 - acc: 0.2392 - val_loss: 1.5283 - val_acc: 0.3474\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4480 - acc: 0.2624 - val_loss: 1.5279 - val_acc: 0.3474\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4444 - acc: 0.2603 - val_loss: 1.5275 - val_acc: 0.3474\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4448 - acc: 0.2621 - val_loss: 1.5271 - val_acc: 0.3474\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4466 - acc: 0.2487 - val_loss: 1.5268 - val_acc: 0.3474\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4454 - acc: 0.2469 - val_loss: 1.5266 - val_acc: 0.3444\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4370 - acc: 0.2596 - val_loss: 1.5263 - val_acc: 0.3474\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4418 - acc: 0.2631 - val_loss: 1.5260 - val_acc: 0.3535\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4364 - acc: 0.2526 - val_loss: 1.5256 - val_acc: 0.3505\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4450 - acc: 0.2663 - val_loss: 1.5253 - val_acc: 0.3474\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4469 - acc: 0.2561 - val_loss: 1.5250 - val_acc: 0.3505\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4385 - acc: 0.2688 - val_loss: 1.5246 - val_acc: 0.3505\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4363 - acc: 0.2681 - val_loss: 1.5243 - val_acc: 0.3505\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4371 - acc: 0.2526 - val_loss: 1.5241 - val_acc: 0.3474\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4384 - acc: 0.2575 - val_loss: 1.5238 - val_acc: 0.3474\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4430 - acc: 0.2631 - val_loss: 1.5235 - val_acc: 0.3444\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4363 - acc: 0.2681 - val_loss: 1.5232 - val_acc: 0.3474\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4382 - acc: 0.2684 - val_loss: 1.5228 - val_acc: 0.3474\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4358 - acc: 0.2716 - val_loss: 1.5224 - val_acc: 0.3474\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4289 - acc: 0.2730 - val_loss: 1.5219 - val_acc: 0.3505\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4275 - acc: 0.2719 - val_loss: 1.5215 - val_acc: 0.3474\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4352 - acc: 0.2737 - val_loss: 1.5211 - val_acc: 0.3444\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4388 - acc: 0.2564 - val_loss: 1.5208 - val_acc: 0.3444\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4472 - acc: 0.2607 - val_loss: 1.5205 - val_acc: 0.3444\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4385 - acc: 0.2540 - val_loss: 1.5202 - val_acc: 0.3444\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4332 - acc: 0.2754 - val_loss: 1.5198 - val_acc: 0.3474\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4335 - acc: 0.2716 - val_loss: 1.5194 - val_acc: 0.3474\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4377 - acc: 0.2635 - val_loss: 1.5190 - val_acc: 0.3474\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4379 - acc: 0.2578 - val_loss: 1.5187 - val_acc: 0.3414\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4425 - acc: 0.2508 - val_loss: 1.5183 - val_acc: 0.3414\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4383 - acc: 0.2557 - val_loss: 1.5180 - val_acc: 0.3414\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4335 - acc: 0.2638 - val_loss: 1.5177 - val_acc: 0.3414\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4308 - acc: 0.2758 - val_loss: 1.5174 - val_acc: 0.3384\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4269 - acc: 0.2614 - val_loss: 1.5170 - val_acc: 0.3384\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4353 - acc: 0.2628 - val_loss: 1.5168 - val_acc: 0.3384\n",
      "Epoch 237/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4398 - acc: 0.2585 - val_loss: 1.5165 - val_acc: 0.3384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4421 - acc: 0.2614 - val_loss: 1.5162 - val_acc: 0.3384\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4289 - acc: 0.2681 - val_loss: 1.5158 - val_acc: 0.3384\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4311 - acc: 0.2589 - val_loss: 1.5155 - val_acc: 0.3384\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4355 - acc: 0.2695 - val_loss: 1.5153 - val_acc: 0.3384\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4314 - acc: 0.2603 - val_loss: 1.5149 - val_acc: 0.3414\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4302 - acc: 0.2790 - val_loss: 1.5147 - val_acc: 0.3414\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4356 - acc: 0.2621 - val_loss: 1.5144 - val_acc: 0.3414\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4244 - acc: 0.2621 - val_loss: 1.5141 - val_acc: 0.3414\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4269 - acc: 0.2800 - val_loss: 1.5137 - val_acc: 0.3414\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4225 - acc: 0.2751 - val_loss: 1.5134 - val_acc: 0.3414\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4186 - acc: 0.2719 - val_loss: 1.5132 - val_acc: 0.3414\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4263 - acc: 0.2751 - val_loss: 1.5128 - val_acc: 0.3414\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4328 - acc: 0.2754 - val_loss: 1.5125 - val_acc: 0.3414\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4214 - acc: 0.2776 - val_loss: 1.5122 - val_acc: 0.3384\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4273 - acc: 0.2723 - val_loss: 1.5119 - val_acc: 0.3353\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4205 - acc: 0.2652 - val_loss: 1.5116 - val_acc: 0.3353\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4263 - acc: 0.2769 - val_loss: 1.5112 - val_acc: 0.3353\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4247 - acc: 0.2772 - val_loss: 1.5110 - val_acc: 0.3353\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4192 - acc: 0.2793 - val_loss: 1.5107 - val_acc: 0.3353\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4228 - acc: 0.2769 - val_loss: 1.5103 - val_acc: 0.3323\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4211 - acc: 0.2769 - val_loss: 1.5100 - val_acc: 0.3323\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4227 - acc: 0.2807 - val_loss: 1.5097 - val_acc: 0.3323\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4249 - acc: 0.2786 - val_loss: 1.5094 - val_acc: 0.3293\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4260 - acc: 0.2684 - val_loss: 1.5090 - val_acc: 0.3293\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4256 - acc: 0.2797 - val_loss: 1.5087 - val_acc: 0.3293\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4347 - acc: 0.2677 - val_loss: 1.5084 - val_acc: 0.3293\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4253 - acc: 0.2747 - val_loss: 1.5081 - val_acc: 0.3293\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4234 - acc: 0.2730 - val_loss: 1.5077 - val_acc: 0.3293\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4287 - acc: 0.2723 - val_loss: 1.5074 - val_acc: 0.3293\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4252 - acc: 0.2776 - val_loss: 1.5070 - val_acc: 0.3263\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4187 - acc: 0.2797 - val_loss: 1.5067 - val_acc: 0.3263\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4192 - acc: 0.2705 - val_loss: 1.5064 - val_acc: 0.3263\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4257 - acc: 0.2702 - val_loss: 1.5061 - val_acc: 0.3263\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4215 - acc: 0.2744 - val_loss: 1.5057 - val_acc: 0.3263\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4092 - acc: 0.2783 - val_loss: 1.5055 - val_acc: 0.3263\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4257 - acc: 0.2754 - val_loss: 1.5052 - val_acc: 0.3263\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4222 - acc: 0.2726 - val_loss: 1.5050 - val_acc: 0.3263\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4280 - acc: 0.2635 - val_loss: 1.5047 - val_acc: 0.3263\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4125 - acc: 0.2864 - val_loss: 1.5044 - val_acc: 0.3263\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4205 - acc: 0.2744 - val_loss: 1.5042 - val_acc: 0.3263\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4158 - acc: 0.2857 - val_loss: 1.5040 - val_acc: 0.3263\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4147 - acc: 0.2705 - val_loss: 1.5038 - val_acc: 0.3263\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4151 - acc: 0.2871 - val_loss: 1.5034 - val_acc: 0.3263\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4088 - acc: 0.2909 - val_loss: 1.5031 - val_acc: 0.3263\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4239 - acc: 0.2828 - val_loss: 1.5029 - val_acc: 0.3263\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4133 - acc: 0.2772 - val_loss: 1.5025 - val_acc: 0.3263\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4112 - acc: 0.2839 - val_loss: 1.5023 - val_acc: 0.3263\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4205 - acc: 0.2695 - val_loss: 1.5020 - val_acc: 0.3263\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4182 - acc: 0.2691 - val_loss: 1.5018 - val_acc: 0.3263\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4219 - acc: 0.2691 - val_loss: 1.5016 - val_acc: 0.3263\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4159 - acc: 0.2885 - val_loss: 1.5013 - val_acc: 0.3263\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4105 - acc: 0.2772 - val_loss: 1.5012 - val_acc: 0.3263\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4147 - acc: 0.2846 - val_loss: 1.5008 - val_acc: 0.3263\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4150 - acc: 0.2786 - val_loss: 1.5005 - val_acc: 0.3263\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4135 - acc: 0.2878 - val_loss: 1.5002 - val_acc: 0.3263\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4203 - acc: 0.2762 - val_loss: 1.5000 - val_acc: 0.3263\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4168 - acc: 0.2758 - val_loss: 1.4998 - val_acc: 0.3263\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4217 - acc: 0.2941 - val_loss: 1.4996 - val_acc: 0.3263\n",
      "Epoch 296/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4230 - acc: 0.2726 - val_loss: 1.4994 - val_acc: 0.3263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4219 - acc: 0.2828 - val_loss: 1.4991 - val_acc: 0.3263\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4122 - acc: 0.3033 - val_loss: 1.4987 - val_acc: 0.3263\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4051 - acc: 0.2807 - val_loss: 1.4983 - val_acc: 0.3263\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4069 - acc: 0.2934 - val_loss: 1.4980 - val_acc: 0.3263\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4152 - acc: 0.2783 - val_loss: 1.4977 - val_acc: 0.3263\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4100 - acc: 0.2931 - val_loss: 1.4975 - val_acc: 0.3263\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4202 - acc: 0.2811 - val_loss: 1.4972 - val_acc: 0.3263\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4097 - acc: 0.2857 - val_loss: 1.4970 - val_acc: 0.3263\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4073 - acc: 0.2814 - val_loss: 1.4967 - val_acc: 0.3263\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4092 - acc: 0.2811 - val_loss: 1.4964 - val_acc: 0.3263\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4128 - acc: 0.2860 - val_loss: 1.4962 - val_acc: 0.3263\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4172 - acc: 0.2853 - val_loss: 1.4960 - val_acc: 0.3263\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4107 - acc: 0.2814 - val_loss: 1.4958 - val_acc: 0.3263\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4140 - acc: 0.2776 - val_loss: 1.4956 - val_acc: 0.3263\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4046 - acc: 0.2909 - val_loss: 1.4953 - val_acc: 0.3263\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4102 - acc: 0.2860 - val_loss: 1.4950 - val_acc: 0.3263\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4124 - acc: 0.2913 - val_loss: 1.4948 - val_acc: 0.3263\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4116 - acc: 0.2899 - val_loss: 1.4945 - val_acc: 0.3263\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4080 - acc: 0.2941 - val_loss: 1.4942 - val_acc: 0.3263\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4099 - acc: 0.2980 - val_loss: 1.4940 - val_acc: 0.3263\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3980 - acc: 0.2990 - val_loss: 1.4937 - val_acc: 0.3263\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4093 - acc: 0.3033 - val_loss: 1.4934 - val_acc: 0.3263\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3990 - acc: 0.2793 - val_loss: 1.4932 - val_acc: 0.3263\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4084 - acc: 0.2839 - val_loss: 1.4929 - val_acc: 0.3263\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4022 - acc: 0.2899 - val_loss: 1.4927 - val_acc: 0.3263\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4139 - acc: 0.2902 - val_loss: 1.4925 - val_acc: 0.3263\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4126 - acc: 0.2800 - val_loss: 1.4922 - val_acc: 0.3263\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4046 - acc: 0.2825 - val_loss: 1.4921 - val_acc: 0.3263\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4020 - acc: 0.2864 - val_loss: 1.4918 - val_acc: 0.3263\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3987 - acc: 0.2885 - val_loss: 1.4915 - val_acc: 0.3263\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.4037 - acc: 0.2864 - val_loss: 1.4912 - val_acc: 0.3263\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4009 - acc: 0.2927 - val_loss: 1.4910 - val_acc: 0.3263\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4042 - acc: 0.2945 - val_loss: 1.4908 - val_acc: 0.3263\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3985 - acc: 0.2892 - val_loss: 1.4904 - val_acc: 0.3263\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4017 - acc: 0.2832 - val_loss: 1.4902 - val_acc: 0.3263\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4081 - acc: 0.2804 - val_loss: 1.4900 - val_acc: 0.3263\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3983 - acc: 0.2934 - val_loss: 1.4897 - val_acc: 0.3263\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3985 - acc: 0.2938 - val_loss: 1.4895 - val_acc: 0.3263\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3955 - acc: 0.2941 - val_loss: 1.4893 - val_acc: 0.3263\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4053 - acc: 0.2818 - val_loss: 1.4890 - val_acc: 0.3263\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4127 - acc: 0.2899 - val_loss: 1.4888 - val_acc: 0.3263\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4053 - acc: 0.2895 - val_loss: 1.4887 - val_acc: 0.3263\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4053 - acc: 0.2909 - val_loss: 1.4884 - val_acc: 0.3263\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4015 - acc: 0.2892 - val_loss: 1.4882 - val_acc: 0.3263\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3939 - acc: 0.2983 - val_loss: 1.4879 - val_acc: 0.3263\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3951 - acc: 0.2902 - val_loss: 1.4877 - val_acc: 0.3263\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3921 - acc: 0.2959 - val_loss: 1.4875 - val_acc: 0.3263\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4036 - acc: 0.2832 - val_loss: 1.4873 - val_acc: 0.3263\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4071 - acc: 0.2906 - val_loss: 1.4871 - val_acc: 0.3263\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4034 - acc: 0.2924 - val_loss: 1.4870 - val_acc: 0.3263\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.4035 - acc: 0.2980 - val_loss: 1.4868 - val_acc: 0.3263\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3987 - acc: 0.2825 - val_loss: 1.4866 - val_acc: 0.3263\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3939 - acc: 0.2931 - val_loss: 1.4863 - val_acc: 0.3263\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4034 - acc: 0.2909 - val_loss: 1.4862 - val_acc: 0.3263\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.4009 - acc: 0.3019 - val_loss: 1.4859 - val_acc: 0.3263\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3920 - acc: 0.3156 - val_loss: 1.4857 - val_acc: 0.3263\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3977 - acc: 0.3005 - val_loss: 1.4854 - val_acc: 0.3263\n",
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3942 - acc: 0.2980 - val_loss: 1.4852 - val_acc: 0.3263\n",
      "Epoch 355/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3978 - acc: 0.2909 - val_loss: 1.4851 - val_acc: 0.3263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3951 - acc: 0.2864 - val_loss: 1.4849 - val_acc: 0.3263\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3963 - acc: 0.2874 - val_loss: 1.4846 - val_acc: 0.3263\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3926 - acc: 0.2888 - val_loss: 1.4844 - val_acc: 0.3263\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.4026 - acc: 0.2821 - val_loss: 1.4843 - val_acc: 0.3263\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4066 - acc: 0.2850 - val_loss: 1.4841 - val_acc: 0.3263\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3934 - acc: 0.2864 - val_loss: 1.4839 - val_acc: 0.3263\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3996 - acc: 0.2924 - val_loss: 1.4838 - val_acc: 0.3263\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3909 - acc: 0.2966 - val_loss: 1.4836 - val_acc: 0.3263\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3954 - acc: 0.2952 - val_loss: 1.4832 - val_acc: 0.3263\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3898 - acc: 0.2998 - val_loss: 1.4831 - val_acc: 0.3263\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3882 - acc: 0.2962 - val_loss: 1.4828 - val_acc: 0.3263\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3819 - acc: 0.3110 - val_loss: 1.4826 - val_acc: 0.3263\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3930 - acc: 0.3012 - val_loss: 1.4824 - val_acc: 0.3293\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4020 - acc: 0.2969 - val_loss: 1.4822 - val_acc: 0.3293\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3938 - acc: 0.3061 - val_loss: 1.4821 - val_acc: 0.3293\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.4035 - acc: 0.2832 - val_loss: 1.4821 - val_acc: 0.3293\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3966 - acc: 0.3019 - val_loss: 1.4819 - val_acc: 0.3293\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3924 - acc: 0.2850 - val_loss: 1.4816 - val_acc: 0.3293\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3948 - acc: 0.2941 - val_loss: 1.4813 - val_acc: 0.3293\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3925 - acc: 0.2941 - val_loss: 1.4813 - val_acc: 0.3293\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3918 - acc: 0.2983 - val_loss: 1.4810 - val_acc: 0.3293\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3893 - acc: 0.3022 - val_loss: 1.4809 - val_acc: 0.3293\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3885 - acc: 0.2980 - val_loss: 1.4808 - val_acc: 0.3293\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3860 - acc: 0.3050 - val_loss: 1.4806 - val_acc: 0.3293\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3908 - acc: 0.3082 - val_loss: 1.4805 - val_acc: 0.3293\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3973 - acc: 0.2976 - val_loss: 1.4802 - val_acc: 0.3293\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3916 - acc: 0.3086 - val_loss: 1.4801 - val_acc: 0.3293\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3979 - acc: 0.2843 - val_loss: 1.4800 - val_acc: 0.3293\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3934 - acc: 0.2969 - val_loss: 1.4798 - val_acc: 0.3293\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3958 - acc: 0.2924 - val_loss: 1.4796 - val_acc: 0.3293\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3943 - acc: 0.2913 - val_loss: 1.4796 - val_acc: 0.3293\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.4017 - acc: 0.2864 - val_loss: 1.4794 - val_acc: 0.3293\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3874 - acc: 0.2973 - val_loss: 1.4792 - val_acc: 0.3293\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3918 - acc: 0.2920 - val_loss: 1.4791 - val_acc: 0.3293\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3803 - acc: 0.3191 - val_loss: 1.4789 - val_acc: 0.3293\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3874 - acc: 0.3082 - val_loss: 1.4786 - val_acc: 0.3293\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3810 - acc: 0.2969 - val_loss: 1.4785 - val_acc: 0.3293\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3869 - acc: 0.2955 - val_loss: 1.4782 - val_acc: 0.3293\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3780 - acc: 0.3198 - val_loss: 1.4780 - val_acc: 0.3293\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3925 - acc: 0.3005 - val_loss: 1.4778 - val_acc: 0.3293\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3895 - acc: 0.3033 - val_loss: 1.4777 - val_acc: 0.3293\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3905 - acc: 0.3093 - val_loss: 1.4775 - val_acc: 0.3293\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3863 - acc: 0.2969 - val_loss: 1.4775 - val_acc: 0.3293\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3914 - acc: 0.2909 - val_loss: 1.4773 - val_acc: 0.3293\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3950 - acc: 0.2987 - val_loss: 1.4772 - val_acc: 0.3293\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3918 - acc: 0.2980 - val_loss: 1.4771 - val_acc: 0.3293\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3895 - acc: 0.2934 - val_loss: 1.4769 - val_acc: 0.3293\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3820 - acc: 0.3131 - val_loss: 1.4768 - val_acc: 0.3293\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3912 - acc: 0.2980 - val_loss: 1.4766 - val_acc: 0.3293\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3826 - acc: 0.3047 - val_loss: 1.4764 - val_acc: 0.3293\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3811 - acc: 0.3064 - val_loss: 1.4763 - val_acc: 0.3293\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3754 - acc: 0.3082 - val_loss: 1.4762 - val_acc: 0.3293\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3918 - acc: 0.2998 - val_loss: 1.4760 - val_acc: 0.3293\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3747 - acc: 0.3064 - val_loss: 1.4759 - val_acc: 0.3293\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3727 - acc: 0.3082 - val_loss: 1.4758 - val_acc: 0.3293\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3835 - acc: 0.3050 - val_loss: 1.4756 - val_acc: 0.3293\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3767 - acc: 0.3100 - val_loss: 1.4755 - val_acc: 0.3293\n",
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3839 - acc: 0.3043 - val_loss: 1.4753 - val_acc: 0.3293\n",
      "Epoch 414/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3809 - acc: 0.3019 - val_loss: 1.4752 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3840 - acc: 0.3033 - val_loss: 1.4751 - val_acc: 0.3293\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3885 - acc: 0.3093 - val_loss: 1.4749 - val_acc: 0.3293\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3773 - acc: 0.2983 - val_loss: 1.4748 - val_acc: 0.3293\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 23us/step - loss: 1.3846 - acc: 0.3057 - val_loss: 1.4746 - val_acc: 0.3293\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3788 - acc: 0.2906 - val_loss: 1.4745 - val_acc: 0.3293\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3806 - acc: 0.3047 - val_loss: 1.4743 - val_acc: 0.3293\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3848 - acc: 0.2962 - val_loss: 1.4742 - val_acc: 0.3293\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3837 - acc: 0.3082 - val_loss: 1.4741 - val_acc: 0.3293\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3737 - acc: 0.3138 - val_loss: 1.4739 - val_acc: 0.3293\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3874 - acc: 0.3072 - val_loss: 1.4738 - val_acc: 0.3293\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3798 - acc: 0.3086 - val_loss: 1.4736 - val_acc: 0.3293\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3936 - acc: 0.3036 - val_loss: 1.4735 - val_acc: 0.3293\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3808 - acc: 0.2973 - val_loss: 1.4734 - val_acc: 0.3293\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3880 - acc: 0.3057 - val_loss: 1.4733 - val_acc: 0.3293\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3783 - acc: 0.2973 - val_loss: 1.4732 - val_acc: 0.3293\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3841 - acc: 0.3064 - val_loss: 1.4731 - val_acc: 0.3293\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3822 - acc: 0.3040 - val_loss: 1.4729 - val_acc: 0.3293\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3846 - acc: 0.3029 - val_loss: 1.4728 - val_acc: 0.3293\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3760 - acc: 0.3121 - val_loss: 1.4726 - val_acc: 0.3293\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3784 - acc: 0.3072 - val_loss: 1.4726 - val_acc: 0.3293\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3910 - acc: 0.3054 - val_loss: 1.4724 - val_acc: 0.3293\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3719 - acc: 0.3064 - val_loss: 1.4722 - val_acc: 0.3293\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3803 - acc: 0.3036 - val_loss: 1.4721 - val_acc: 0.3293\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3834 - acc: 0.3019 - val_loss: 1.4722 - val_acc: 0.3293\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3693 - acc: 0.3064 - val_loss: 1.4721 - val_acc: 0.3293\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3850 - acc: 0.3050 - val_loss: 1.4721 - val_acc: 0.3293\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3781 - acc: 0.3100 - val_loss: 1.4719 - val_acc: 0.3293\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3659 - acc: 0.3198 - val_loss: 1.4718 - val_acc: 0.3293\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3834 - acc: 0.3050 - val_loss: 1.4717 - val_acc: 0.3293\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3745 - acc: 0.3047 - val_loss: 1.4716 - val_acc: 0.3293\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3719 - acc: 0.3114 - val_loss: 1.4716 - val_acc: 0.3293\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3783 - acc: 0.3089 - val_loss: 1.4715 - val_acc: 0.3293\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3753 - acc: 0.3124 - val_loss: 1.4714 - val_acc: 0.3293\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3886 - acc: 0.2969 - val_loss: 1.4712 - val_acc: 0.3293\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3772 - acc: 0.3054 - val_loss: 1.4711 - val_acc: 0.3293\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3687 - acc: 0.3170 - val_loss: 1.4710 - val_acc: 0.3293\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3831 - acc: 0.2867 - val_loss: 1.4708 - val_acc: 0.3293\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3680 - acc: 0.3096 - val_loss: 1.4707 - val_acc: 0.3293\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3679 - acc: 0.3131 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3737 - acc: 0.3138 - val_loss: 1.4704 - val_acc: 0.3293\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3859 - acc: 0.3117 - val_loss: 1.4702 - val_acc: 0.3293\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3849 - acc: 0.2938 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3681 - acc: 0.3008 - val_loss: 1.4700 - val_acc: 0.3293\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3715 - acc: 0.3170 - val_loss: 1.4698 - val_acc: 0.3293\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3688 - acc: 0.3209 - val_loss: 1.4698 - val_acc: 0.3293\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3710 - acc: 0.3145 - val_loss: 1.4698 - val_acc: 0.3293\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3785 - acc: 0.3072 - val_loss: 1.4696 - val_acc: 0.3293\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3746 - acc: 0.3174 - val_loss: 1.4695 - val_acc: 0.3293\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3739 - acc: 0.3110 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3740 - acc: 0.3093 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3703 - acc: 0.3072 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3710 - acc: 0.3107 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3748 - acc: 0.3026 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3678 - acc: 0.3124 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3656 - acc: 0.3177 - val_loss: 1.4689 - val_acc: 0.3293\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3674 - acc: 0.3131 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3604 - acc: 0.3121 - val_loss: 1.4685 - val_acc: 0.3293\n",
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3685 - acc: 0.3121 - val_loss: 1.4685 - val_acc: 0.3293\n",
      "Epoch 473/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3593 - acc: 0.3308 - val_loss: 1.4684 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3730 - acc: 0.3110 - val_loss: 1.4683 - val_acc: 0.3293\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3704 - acc: 0.3100 - val_loss: 1.4681 - val_acc: 0.3293\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3704 - acc: 0.3114 - val_loss: 1.4682 - val_acc: 0.3293\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3718 - acc: 0.3138 - val_loss: 1.4680 - val_acc: 0.3293\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3773 - acc: 0.3103 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3746 - acc: 0.3103 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3720 - acc: 0.3121 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3719 - acc: 0.3121 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3678 - acc: 0.3036 - val_loss: 1.4676 - val_acc: 0.3293\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3733 - acc: 0.3050 - val_loss: 1.4676 - val_acc: 0.3293\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3706 - acc: 0.3117 - val_loss: 1.4676 - val_acc: 0.3293\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3633 - acc: 0.3226 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3640 - acc: 0.3212 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3752 - acc: 0.3131 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3659 - acc: 0.3191 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3658 - acc: 0.3138 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3695 - acc: 0.3050 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3607 - acc: 0.3145 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3549 - acc: 0.3276 - val_loss: 1.4668 - val_acc: 0.3293\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3569 - acc: 0.3279 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3634 - acc: 0.3156 - val_loss: 1.4665 - val_acc: 0.3293\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3604 - acc: 0.3086 - val_loss: 1.4665 - val_acc: 0.3293\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3577 - acc: 0.3251 - val_loss: 1.4664 - val_acc: 0.3293\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3655 - acc: 0.3110 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3721 - acc: 0.3110 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3634 - acc: 0.3138 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3694 - acc: 0.3124 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3813 - acc: 0.3015 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3711 - acc: 0.3036 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3606 - acc: 0.3248 - val_loss: 1.4660 - val_acc: 0.3293\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3612 - acc: 0.3202 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3710 - acc: 0.3064 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3595 - acc: 0.3234 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3627 - acc: 0.3244 - val_loss: 1.4657 - val_acc: 0.3293\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3638 - acc: 0.3188 - val_loss: 1.4655 - val_acc: 0.3293\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3791 - acc: 0.3135 - val_loss: 1.4655 - val_acc: 0.3293\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3693 - acc: 0.2962 - val_loss: 1.4655 - val_acc: 0.3293\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3533 - acc: 0.3297 - val_loss: 1.4654 - val_acc: 0.3293\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3582 - acc: 0.3262 - val_loss: 1.4654 - val_acc: 0.3293\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3463 - acc: 0.3315 - val_loss: 1.4652 - val_acc: 0.3293\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3657 - acc: 0.3131 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3690 - acc: 0.3022 - val_loss: 1.4650 - val_acc: 0.3293\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3560 - acc: 0.3283 - val_loss: 1.4649 - val_acc: 0.3293\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3578 - acc: 0.3145 - val_loss: 1.4648 - val_acc: 0.3293\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3578 - acc: 0.3279 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3556 - acc: 0.3177 - val_loss: 1.4648 - val_acc: 0.3293\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3535 - acc: 0.3272 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3701 - acc: 0.3096 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3664 - acc: 0.3079 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3629 - acc: 0.3033 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3526 - acc: 0.3251 - val_loss: 1.4645 - val_acc: 0.3293\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3774 - acc: 0.3177 - val_loss: 1.4646 - val_acc: 0.3293\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3596 - acc: 0.3131 - val_loss: 1.4644 - val_acc: 0.3293\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3491 - acc: 0.3237 - val_loss: 1.4644 - val_acc: 0.3293\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3615 - acc: 0.3237 - val_loss: 1.4645 - val_acc: 0.3293\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3560 - acc: 0.3163 - val_loss: 1.4644 - val_acc: 0.3293\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3593 - acc: 0.3198 - val_loss: 1.4643 - val_acc: 0.3293\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3556 - acc: 0.3283 - val_loss: 1.4644 - val_acc: 0.3293\n",
      "Epoch 532/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3523 - acc: 0.3364 - val_loss: 1.4642 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3589 - acc: 0.3234 - val_loss: 1.4643 - val_acc: 0.3293\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3555 - acc: 0.3272 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3479 - acc: 0.3241 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3637 - acc: 0.3170 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3618 - acc: 0.3047 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3574 - acc: 0.3170 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3540 - acc: 0.3110 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3583 - acc: 0.3163 - val_loss: 1.4642 - val_acc: 0.3293\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3568 - acc: 0.3191 - val_loss: 1.4641 - val_acc: 0.3293\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3554 - acc: 0.3075 - val_loss: 1.4641 - val_acc: 0.3293\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3482 - acc: 0.3297 - val_loss: 1.4639 - val_acc: 0.3293\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3529 - acc: 0.3212 - val_loss: 1.4639 - val_acc: 0.3293\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3517 - acc: 0.3234 - val_loss: 1.4638 - val_acc: 0.3293\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3572 - acc: 0.3230 - val_loss: 1.4638 - val_acc: 0.3293\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3563 - acc: 0.3145 - val_loss: 1.4637 - val_acc: 0.3293\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3648 - acc: 0.3142 - val_loss: 1.4636 - val_acc: 0.3293\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3494 - acc: 0.3241 - val_loss: 1.4636 - val_acc: 0.3293\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3535 - acc: 0.3276 - val_loss: 1.4637 - val_acc: 0.3293\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3576 - acc: 0.3195 - val_loss: 1.4636 - val_acc: 0.3293\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3672 - acc: 0.3131 - val_loss: 1.4636 - val_acc: 0.3293\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3438 - acc: 0.3329 - val_loss: 1.4635 - val_acc: 0.3293\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3550 - acc: 0.3255 - val_loss: 1.4634 - val_acc: 0.3293\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3686 - acc: 0.3212 - val_loss: 1.4634 - val_acc: 0.3293\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3556 - acc: 0.3142 - val_loss: 1.4634 - val_acc: 0.3293\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3544 - acc: 0.3255 - val_loss: 1.4634 - val_acc: 0.3293\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3572 - acc: 0.3131 - val_loss: 1.4635 - val_acc: 0.3293\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3536 - acc: 0.3163 - val_loss: 1.4634 - val_acc: 0.3293\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3556 - acc: 0.3272 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3604 - acc: 0.3174 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3598 - acc: 0.3128 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3562 - acc: 0.3181 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3513 - acc: 0.3434 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3572 - acc: 0.3241 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3471 - acc: 0.3420 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3562 - acc: 0.3131 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3552 - acc: 0.3188 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3508 - acc: 0.3212 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3559 - acc: 0.3230 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3587 - acc: 0.3142 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3530 - acc: 0.3188 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3575 - acc: 0.3216 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3613 - acc: 0.3135 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3515 - acc: 0.3251 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3618 - acc: 0.3167 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3374 - acc: 0.3308 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3515 - acc: 0.3205 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3541 - acc: 0.3234 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3554 - acc: 0.3198 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3575 - acc: 0.3177 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3576 - acc: 0.3219 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3465 - acc: 0.3251 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3465 - acc: 0.3329 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3628 - acc: 0.3142 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3549 - acc: 0.3269 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3603 - acc: 0.3061 - val_loss: 1.4633 - val_acc: 0.3293\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3468 - acc: 0.3308 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3496 - acc: 0.3304 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 590/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3580 - acc: 0.3163 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3498 - acc: 0.3262 - val_loss: 1.4631 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3547 - acc: 0.3170 - val_loss: 1.4631 - val_acc: 0.3293\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3507 - acc: 0.3332 - val_loss: 1.4632 - val_acc: 0.3293\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3336 - acc: 0.3332 - val_loss: 1.4630 - val_acc: 0.3293\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3614 - acc: 0.3156 - val_loss: 1.4630 - val_acc: 0.3293\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3525 - acc: 0.3325 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3446 - acc: 0.3128 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3581 - acc: 0.3202 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3527 - acc: 0.3216 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3384 - acc: 0.3230 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3624 - acc: 0.3212 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3599 - acc: 0.3248 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3560 - acc: 0.3093 - val_loss: 1.4627 - val_acc: 0.3293\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3483 - acc: 0.3248 - val_loss: 1.4627 - val_acc: 0.3293\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3519 - acc: 0.3272 - val_loss: 1.4627 - val_acc: 0.3293\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3549 - acc: 0.3269 - val_loss: 1.4626 - val_acc: 0.3293\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3460 - acc: 0.3410 - val_loss: 1.4627 - val_acc: 0.3293\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3503 - acc: 0.3241 - val_loss: 1.4627 - val_acc: 0.3293\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3537 - acc: 0.3160 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3377 - acc: 0.3265 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3489 - acc: 0.3138 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3394 - acc: 0.3325 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3402 - acc: 0.3336 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3543 - acc: 0.3226 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3478 - acc: 0.3248 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3428 - acc: 0.3205 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3494 - acc: 0.3300 - val_loss: 1.4628 - val_acc: 0.3293\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3560 - acc: 0.3174 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3471 - acc: 0.3308 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3477 - acc: 0.3212 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3435 - acc: 0.3223 - val_loss: 1.4629 - val_acc: 0.3293\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3495 - acc: 0.3258 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3356 - acc: 0.3360 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3341 - acc: 0.3297 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3605 - acc: 0.3283 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3532 - acc: 0.3188 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3364 - acc: 0.3251 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3484 - acc: 0.3343 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3485 - acc: 0.3297 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3416 - acc: 0.3248 - val_loss: 1.4628 - val_acc: 0.3323\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3384 - acc: 0.3248 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3508 - acc: 0.3209 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.3434 - acc: 0.3188 - val_loss: 1.4627 - val_acc: 0.3323\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3430 - acc: 0.3251 - val_loss: 1.4629 - val_acc: 0.3323\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3431 - acc: 0.3364 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3445 - acc: 0.3297 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3479 - acc: 0.3248 - val_loss: 1.4629 - val_acc: 0.3323\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3328 - acc: 0.3350 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3400 - acc: 0.3241 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3357 - acc: 0.3378 - val_loss: 1.4629 - val_acc: 0.3323\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3434 - acc: 0.3265 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3519 - acc: 0.3315 - val_loss: 1.4632 - val_acc: 0.3323\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3356 - acc: 0.3297 - val_loss: 1.4631 - val_acc: 0.3323\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3487 - acc: 0.3237 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3450 - acc: 0.3167 - val_loss: 1.4631 - val_acc: 0.3323\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3496 - acc: 0.3364 - val_loss: 1.4632 - val_acc: 0.3323\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3298 - acc: 0.3420 - val_loss: 1.4630 - val_acc: 0.3323\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3397 - acc: 0.3332 - val_loss: 1.4632 - val_acc: 0.3323\n",
      "Epoch 649/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3509 - acc: 0.3064 - val_loss: 1.4633 - val_acc: 0.3323\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3360 - acc: 0.3311 - val_loss: 1.4632 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3495 - acc: 0.3174 - val_loss: 1.4633 - val_acc: 0.3323\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3475 - acc: 0.3269 - val_loss: 1.4634 - val_acc: 0.3323\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3340 - acc: 0.3318 - val_loss: 1.4635 - val_acc: 0.3323\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3405 - acc: 0.3262 - val_loss: 1.4636 - val_acc: 0.3323\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3357 - acc: 0.3339 - val_loss: 1.4637 - val_acc: 0.3323\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3427 - acc: 0.3308 - val_loss: 1.4637 - val_acc: 0.3323\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3313 - acc: 0.3477 - val_loss: 1.4636 - val_acc: 0.3323\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3474 - acc: 0.3258 - val_loss: 1.4637 - val_acc: 0.3323\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3437 - acc: 0.3293 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3471 - acc: 0.3223 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3337 - acc: 0.3329 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3477 - acc: 0.3251 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3454 - acc: 0.3209 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3458 - acc: 0.3255 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3425 - acc: 0.3209 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3394 - acc: 0.3272 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3380 - acc: 0.3406 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3379 - acc: 0.3234 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3516 - acc: 0.3177 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3411 - acc: 0.3272 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3429 - acc: 0.3209 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3484 - acc: 0.3315 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3484 - acc: 0.3191 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3433 - acc: 0.3237 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3432 - acc: 0.3329 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3338 - acc: 0.3353 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3385 - acc: 0.3392 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3351 - acc: 0.3304 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3416 - acc: 0.3322 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3496 - acc: 0.3205 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3329 - acc: 0.3473 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3347 - acc: 0.3438 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3269 - acc: 0.3389 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3310 - acc: 0.3308 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3336 - acc: 0.3452 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3360 - acc: 0.3371 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3388 - acc: 0.3149 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3457 - acc: 0.3212 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3321 - acc: 0.3255 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3411 - acc: 0.3177 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3443 - acc: 0.3163 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3315 - acc: 0.3258 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3394 - acc: 0.3286 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3428 - acc: 0.3406 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3466 - acc: 0.3226 - val_loss: 1.4642 - val_acc: 0.3323\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3305 - acc: 0.3367 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3430 - acc: 0.3244 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3400 - acc: 0.3269 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3293 - acc: 0.3293 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3330 - acc: 0.3269 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3280 - acc: 0.3427 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3373 - acc: 0.3290 - val_loss: 1.4642 - val_acc: 0.3323\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3376 - acc: 0.3293 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3316 - acc: 0.3251 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3377 - acc: 0.3269 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3308 - acc: 0.3329 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3378 - acc: 0.3406 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3221 - acc: 0.3357 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3353 - acc: 0.3300 - val_loss: 1.4639 - val_acc: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3311 - acc: 0.3251 - val_loss: 1.4637 - val_acc: 0.3323\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3441 - acc: 0.3212 - val_loss: 1.4637 - val_acc: 0.3323\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3377 - acc: 0.3455 - val_loss: 1.4638 - val_acc: 0.3323\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3330 - acc: 0.3279 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3399 - acc: 0.3262 - val_loss: 1.4639 - val_acc: 0.3323\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3291 - acc: 0.3434 - val_loss: 1.4640 - val_acc: 0.3323\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3414 - acc: 0.3297 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3254 - acc: 0.3399 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3305 - acc: 0.3346 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3405 - acc: 0.3336 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3484 - acc: 0.3283 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3448 - acc: 0.3276 - val_loss: 1.4641 - val_acc: 0.3323\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3339 - acc: 0.3258 - val_loss: 1.4642 - val_acc: 0.3323\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3349 - acc: 0.3226 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3442 - acc: 0.3248 - val_loss: 1.4644 - val_acc: 0.3323\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3288 - acc: 0.3283 - val_loss: 1.4645 - val_acc: 0.3323\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3363 - acc: 0.3269 - val_loss: 1.4645 - val_acc: 0.3323\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3310 - acc: 0.3332 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3336 - acc: 0.3311 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3329 - acc: 0.3360 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3244 - acc: 0.3353 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3237 - acc: 0.3279 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3176 - acc: 0.3431 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3246 - acc: 0.3399 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3190 - acc: 0.3470 - val_loss: 1.4648 - val_acc: 0.3293\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3285 - acc: 0.3212 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3347 - acc: 0.3279 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3352 - acc: 0.3315 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3203 - acc: 0.3403 - val_loss: 1.4646 - val_acc: 0.3323\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3337 - acc: 0.3336 - val_loss: 1.4646 - val_acc: 0.3323\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3350 - acc: 0.3279 - val_loss: 1.4646 - val_acc: 0.3323\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3413 - acc: 0.3237 - val_loss: 1.4646 - val_acc: 0.3293\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3370 - acc: 0.3290 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3248 - acc: 0.3431 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3246 - acc: 0.3396 - val_loss: 1.4647 - val_acc: 0.3293\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3231 - acc: 0.3378 - val_loss: 1.4648 - val_acc: 0.3293\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3283 - acc: 0.3389 - val_loss: 1.4649 - val_acc: 0.3293\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3481 - acc: 0.3212 - val_loss: 1.4650 - val_acc: 0.3293\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3231 - acc: 0.3374 - val_loss: 1.4650 - val_acc: 0.3293\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3374 - acc: 0.3290 - val_loss: 1.4650 - val_acc: 0.3293\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3359 - acc: 0.3234 - val_loss: 1.4649 - val_acc: 0.3293\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3309 - acc: 0.3258 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3290 - acc: 0.3441 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3410 - acc: 0.3325 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3365 - acc: 0.3420 - val_loss: 1.4652 - val_acc: 0.3293\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3286 - acc: 0.3389 - val_loss: 1.4652 - val_acc: 0.3293\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3379 - acc: 0.3336 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3137 - acc: 0.3410 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3309 - acc: 0.3230 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3313 - acc: 0.3417 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3304 - acc: 0.3424 - val_loss: 1.4651 - val_acc: 0.3293\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3283 - acc: 0.3286 - val_loss: 1.4652 - val_acc: 0.3293\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3229 - acc: 0.3399 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3257 - acc: 0.3462 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3294 - acc: 0.3360 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3346 - acc: 0.3360 - val_loss: 1.4652 - val_acc: 0.3293\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3225 - acc: 0.3336 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3314 - acc: 0.3392 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3390 - acc: 0.3293 - val_loss: 1.4654 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3257 - acc: 0.3339 - val_loss: 1.4654 - val_acc: 0.3293\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3318 - acc: 0.3374 - val_loss: 1.4654 - val_acc: 0.3293\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3298 - acc: 0.3329 - val_loss: 1.4654 - val_acc: 0.3293\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3254 - acc: 0.3378 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3292 - acc: 0.3371 - val_loss: 1.4652 - val_acc: 0.3293\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3214 - acc: 0.3445 - val_loss: 1.4653 - val_acc: 0.3293\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3152 - acc: 0.3417 - val_loss: 1.4654 - val_acc: 0.3293\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3164 - acc: 0.3396 - val_loss: 1.4655 - val_acc: 0.3293\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3260 - acc: 0.3399 - val_loss: 1.4656 - val_acc: 0.3293\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3222 - acc: 0.3480 - val_loss: 1.4655 - val_acc: 0.3293\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3369 - acc: 0.3251 - val_loss: 1.4656 - val_acc: 0.3293\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3273 - acc: 0.3434 - val_loss: 1.4657 - val_acc: 0.3293\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3388 - acc: 0.3329 - val_loss: 1.4657 - val_acc: 0.3293\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3265 - acc: 0.3346 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3294 - acc: 0.3332 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3196 - acc: 0.3396 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3349 - acc: 0.3315 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3384 - acc: 0.3311 - val_loss: 1.4657 - val_acc: 0.3293\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3295 - acc: 0.3339 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3398 - acc: 0.3357 - val_loss: 1.4657 - val_acc: 0.3293\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3154 - acc: 0.3480 - val_loss: 1.4658 - val_acc: 0.3293\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3275 - acc: 0.3269 - val_loss: 1.4659 - val_acc: 0.3293\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3252 - acc: 0.3269 - val_loss: 1.4659 - val_acc: 0.3293\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3235 - acc: 0.3325 - val_loss: 1.4661 - val_acc: 0.3293\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3379 - acc: 0.3244 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3266 - acc: 0.3392 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3232 - acc: 0.3276 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3287 - acc: 0.3297 - val_loss: 1.4661 - val_acc: 0.3293\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3198 - acc: 0.3494 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3423 - acc: 0.3389 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3402 - acc: 0.3202 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3251 - acc: 0.3336 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3166 - acc: 0.3346 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3190 - acc: 0.3332 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3184 - acc: 0.3441 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3170 - acc: 0.3431 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3172 - acc: 0.3420 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3256 - acc: 0.3343 - val_loss: 1.4662 - val_acc: 0.3293\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3227 - acc: 0.3392 - val_loss: 1.4661 - val_acc: 0.3293\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3337 - acc: 0.3202 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3186 - acc: 0.3385 - val_loss: 1.4664 - val_acc: 0.3293\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3189 - acc: 0.3329 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3320 - acc: 0.3318 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3333 - acc: 0.3448 - val_loss: 1.4663 - val_acc: 0.3293\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3249 - acc: 0.3311 - val_loss: 1.4664 - val_acc: 0.3293\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3199 - acc: 0.3445 - val_loss: 1.4666 - val_acc: 0.3293\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3250 - acc: 0.3315 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3156 - acc: 0.3498 - val_loss: 1.4666 - val_acc: 0.3293\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3197 - acc: 0.3381 - val_loss: 1.4668 - val_acc: 0.3293\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3246 - acc: 0.3367 - val_loss: 1.4668 - val_acc: 0.3293\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3372 - acc: 0.3350 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3110 - acc: 0.3452 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3216 - acc: 0.3332 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3256 - acc: 0.3322 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3235 - acc: 0.3396 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3258 - acc: 0.3283 - val_loss: 1.4667 - val_acc: 0.3293\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3300 - acc: 0.3381 - val_loss: 1.4669 - val_acc: 0.3293\n",
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3265 - acc: 0.3308 - val_loss: 1.4669 - val_acc: 0.3293\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3300 - acc: 0.3308 - val_loss: 1.4670 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3208 - acc: 0.3378 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3237 - acc: 0.3385 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3129 - acc: 0.3480 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3251 - acc: 0.3462 - val_loss: 1.4668 - val_acc: 0.3293\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3114 - acc: 0.3357 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3227 - acc: 0.3343 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3101 - acc: 0.3487 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3227 - acc: 0.3297 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3309 - acc: 0.3209 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3080 - acc: 0.3501 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3202 - acc: 0.3346 - val_loss: 1.4673 - val_acc: 0.3293\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3271 - acc: 0.3293 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3138 - acc: 0.3385 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3167 - acc: 0.3470 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3192 - acc: 0.3410 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3097 - acc: 0.3424 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3141 - acc: 0.3441 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3228 - acc: 0.3403 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3231 - acc: 0.3332 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3103 - acc: 0.3529 - val_loss: 1.4671 - val_acc: 0.3293\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3174 - acc: 0.3293 - val_loss: 1.4670 - val_acc: 0.3293\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3202 - acc: 0.3357 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3167 - acc: 0.3322 - val_loss: 1.4672 - val_acc: 0.3293\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3303 - acc: 0.3332 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3299 - acc: 0.3381 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3213 - acc: 0.3441 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3149 - acc: 0.3378 - val_loss: 1.4673 - val_acc: 0.3293\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3291 - acc: 0.3420 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3324 - acc: 0.3336 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3286 - acc: 0.3392 - val_loss: 1.4674 - val_acc: 0.3293\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3142 - acc: 0.3459 - val_loss: 1.4675 - val_acc: 0.3293\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3103 - acc: 0.3385 - val_loss: 1.4675 - val_acc: 0.3293\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3171 - acc: 0.3367 - val_loss: 1.4676 - val_acc: 0.3293\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3256 - acc: 0.3381 - val_loss: 1.4675 - val_acc: 0.3293\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3163 - acc: 0.3441 - val_loss: 1.4675 - val_acc: 0.3293\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3188 - acc: 0.3427 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3318 - acc: 0.3385 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3242 - acc: 0.3480 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3171 - acc: 0.3389 - val_loss: 1.4676 - val_acc: 0.3293\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3272 - acc: 0.3336 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3180 - acc: 0.3385 - val_loss: 1.4679 - val_acc: 0.3293\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3104 - acc: 0.3389 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3315 - acc: 0.3441 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3170 - acc: 0.3417 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 24us/step - loss: 1.3147 - acc: 0.3396 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3126 - acc: 0.3399 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3198 - acc: 0.3241 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3185 - acc: 0.3438 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3292 - acc: 0.3230 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3160 - acc: 0.3381 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3222 - acc: 0.3325 - val_loss: 1.4677 - val_acc: 0.3293\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3211 - acc: 0.3505 - val_loss: 1.4679 - val_acc: 0.3293\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3266 - acc: 0.3434 - val_loss: 1.4679 - val_acc: 0.3293\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3033 - acc: 0.3434 - val_loss: 1.4679 - val_acc: 0.3293\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3121 - acc: 0.3431 - val_loss: 1.4679 - val_acc: 0.3293\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3253 - acc: 0.3353 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3156 - acc: 0.3484 - val_loss: 1.4678 - val_acc: 0.3293\n",
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3046 - acc: 0.3572 - val_loss: 1.4679 - val_acc: 0.3293\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3243 - acc: 0.3381 - val_loss: 1.4679 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3203 - acc: 0.3357 - val_loss: 1.4681 - val_acc: 0.3293\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3151 - acc: 0.3473 - val_loss: 1.4680 - val_acc: 0.3293\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3119 - acc: 0.3505 - val_loss: 1.4680 - val_acc: 0.3293\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3269 - acc: 0.3346 - val_loss: 1.4680 - val_acc: 0.3293\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3285 - acc: 0.3371 - val_loss: 1.4680 - val_acc: 0.3293\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3027 - acc: 0.3462 - val_loss: 1.4681 - val_acc: 0.3293\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3141 - acc: 0.3491 - val_loss: 1.4682 - val_acc: 0.3293\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3172 - acc: 0.3417 - val_loss: 1.4684 - val_acc: 0.3293\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3229 - acc: 0.3477 - val_loss: 1.4683 - val_acc: 0.3293\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3131 - acc: 0.3480 - val_loss: 1.4684 - val_acc: 0.3293\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3283 - acc: 0.3297 - val_loss: 1.4685 - val_acc: 0.3293\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3232 - acc: 0.3410 - val_loss: 1.4685 - val_acc: 0.3293\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3211 - acc: 0.3223 - val_loss: 1.4686 - val_acc: 0.3293\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3197 - acc: 0.3329 - val_loss: 1.4686 - val_acc: 0.3293\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3106 - acc: 0.3357 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3189 - acc: 0.3381 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3173 - acc: 0.3462 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3024 - acc: 0.3522 - val_loss: 1.4689 - val_acc: 0.3293\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3128 - acc: 0.3536 - val_loss: 1.4689 - val_acc: 0.3293\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3111 - acc: 0.3501 - val_loss: 1.4689 - val_acc: 0.3293\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3115 - acc: 0.3381 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3095 - acc: 0.3466 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3082 - acc: 0.3473 - val_loss: 1.4689 - val_acc: 0.3293\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3238 - acc: 0.3381 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3173 - acc: 0.3251 - val_loss: 1.4686 - val_acc: 0.3293\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3149 - acc: 0.3389 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3079 - acc: 0.3346 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3223 - acc: 0.3315 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3068 - acc: 0.3519 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3273 - acc: 0.3350 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3269 - acc: 0.3329 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3232 - acc: 0.3357 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3229 - acc: 0.3322 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3067 - acc: 0.3459 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3159 - acc: 0.3410 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3098 - acc: 0.3290 - val_loss: 1.4687 - val_acc: 0.3293\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3108 - acc: 0.3445 - val_loss: 1.4688 - val_acc: 0.3293\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3161 - acc: 0.3441 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3146 - acc: 0.3448 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3129 - acc: 0.3385 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3176 - acc: 0.3487 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3174 - acc: 0.3515 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3178 - acc: 0.3269 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3120 - acc: 0.3308 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.3039 - acc: 0.3462 - val_loss: 1.4691 - val_acc: 0.3293\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3212 - acc: 0.3470 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3269 - acc: 0.3308 - val_loss: 1.4690 - val_acc: 0.3293\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3180 - acc: 0.3498 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3156 - acc: 0.3462 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3285 - acc: 0.3424 - val_loss: 1.4691 - val_acc: 0.3293\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3071 - acc: 0.3332 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3164 - acc: 0.3434 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3123 - acc: 0.3304 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3106 - acc: 0.3389 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3082 - acc: 0.3434 - val_loss: 1.4692 - val_acc: 0.3293\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3252 - acc: 0.3389 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3150 - acc: 0.3536 - val_loss: 1.4691 - val_acc: 0.3293\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3067 - acc: 0.3448 - val_loss: 1.4691 - val_acc: 0.3293\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3126 - acc: 0.3413 - val_loss: 1.4693 - val_acc: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3142 - acc: 0.3392 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3199 - acc: 0.3417 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3173 - acc: 0.3470 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.2991 - acc: 0.3533 - val_loss: 1.4695 - val_acc: 0.3293\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3052 - acc: 0.3547 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3143 - acc: 0.3455 - val_loss: 1.4694 - val_acc: 0.3293\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3254 - acc: 0.3329 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3162 - acc: 0.3357 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3022 - acc: 0.3424 - val_loss: 1.4693 - val_acc: 0.3293\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3120 - acc: 0.3403 - val_loss: 1.4695 - val_acc: 0.3293\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3177 - acc: 0.3385 - val_loss: 1.4696 - val_acc: 0.3293\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3134 - acc: 0.3427 - val_loss: 1.4697 - val_acc: 0.3293\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3302 - acc: 0.3343 - val_loss: 1.4696 - val_acc: 0.3293\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3077 - acc: 0.3526 - val_loss: 1.4697 - val_acc: 0.3293\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3101 - acc: 0.3420 - val_loss: 1.4697 - val_acc: 0.3293\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3153 - acc: 0.3413 - val_loss: 1.4697 - val_acc: 0.3293\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3120 - acc: 0.3452 - val_loss: 1.4699 - val_acc: 0.3293\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3080 - acc: 0.3438 - val_loss: 1.4698 - val_acc: 0.3293\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.2996 - acc: 0.3424 - val_loss: 1.4699 - val_acc: 0.3293\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3115 - acc: 0.3480 - val_loss: 1.4699 - val_acc: 0.3293\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3086 - acc: 0.3406 - val_loss: 1.4700 - val_acc: 0.3293\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3076 - acc: 0.3403 - val_loss: 1.4699 - val_acc: 0.3293\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3104 - acc: 0.3406 - val_loss: 1.4700 - val_acc: 0.3293\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3171 - acc: 0.3357 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3180 - acc: 0.3378 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3103 - acc: 0.3484 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3012 - acc: 0.3381 - val_loss: 1.4703 - val_acc: 0.3293\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3037 - acc: 0.3462 - val_loss: 1.4704 - val_acc: 0.3293\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.2937 - acc: 0.3434 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3180 - acc: 0.3392 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3122 - acc: 0.3399 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3159 - acc: 0.3371 - val_loss: 1.4704 - val_acc: 0.3293\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3038 - acc: 0.3477 - val_loss: 1.4703 - val_acc: 0.3293\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3288 - acc: 0.3399 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3136 - acc: 0.3353 - val_loss: 1.4703 - val_acc: 0.3293\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3077 - acc: 0.3501 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3066 - acc: 0.3508 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3144 - acc: 0.3389 - val_loss: 1.4703 - val_acc: 0.3293\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3041 - acc: 0.3491 - val_loss: 1.4703 - val_acc: 0.3293\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3073 - acc: 0.3329 - val_loss: 1.4704 - val_acc: 0.3293\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3172 - acc: 0.3381 - val_loss: 1.4701 - val_acc: 0.3293\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3216 - acc: 0.3431 - val_loss: 1.4700 - val_acc: 0.3293\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2990 - acc: 0.3455 - val_loss: 1.4702 - val_acc: 0.3293\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.2966 - acc: 0.3434 - val_loss: 1.4703 - val_acc: 0.3293\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.3060 - acc: 0.3441 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.2973 - acc: 0.3519 - val_loss: 1.4706 - val_acc: 0.3293\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3097 - acc: 0.3410 - val_loss: 1.4707 - val_acc: 0.3293\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3127 - acc: 0.3332 - val_loss: 1.4707 - val_acc: 0.3293\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3070 - acc: 0.3579 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 26us/step - loss: 1.2940 - acc: 0.3424 - val_loss: 1.4706 - val_acc: 0.3293\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3078 - acc: 0.3498 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.2997 - acc: 0.3484 - val_loss: 1.4705 - val_acc: 0.3293\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 1.3036 - acc: 0.3424 - val_loss: 1.4707 - val_acc: 0.3293\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3159 - acc: 0.3459 - val_loss: 1.4707 - val_acc: 0.3293\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 25us/step - loss: 1.3193 - acc: 0.3339 - val_loss: 1.4706 - val_acc: 0.3293\n"
     ]
    }
   ],
   "source": [
    "zillow_model_2 = model.fit(x=X_train, y=y_cat_train, \n",
    "          batch_size=20000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_cat_test),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-767-5bac093a14be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-730-9d1a245b8a9e>\u001b[0m in \u001b[0;36mmodel_metrics\u001b[0;34m(predictions, y_test)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mgain_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mloss_stay_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_true_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mgain_stay_large_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large_stay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain_large'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model_metrics(predictions, y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTiRmZpaLE4mZmeXiRGJmZrn8H8Dh/YTdt7KbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1830e6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model_2.history['acc'])\n",
    "plt.plot(zillow_model_2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 4s 2ms/step - loss: 1.6218 - acc: 0.2998 - val_loss: 1.5722 - val_acc: 0.3323\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4104 - acc: 0.3519 - val_loss: 1.6386 - val_acc: 0.3323\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4149 - acc: 0.3452 - val_loss: 1.5748 - val_acc: 0.3323\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3846 - acc: 0.3667 - val_loss: 1.5040 - val_acc: 0.3323\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3682 - acc: 0.3610 - val_loss: 1.5195 - val_acc: 0.3323\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3570 - acc: 0.3868 - val_loss: 1.4774 - val_acc: 0.3323\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3649 - acc: 0.3607 - val_loss: 1.4647 - val_acc: 0.3323\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 1.3477 - acc: 0.3688 - val_loss: 1.4935 - val_acc: 0.3323\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3350 - acc: 0.3825 - val_loss: 1.4558 - val_acc: 0.3323\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3268 - acc: 0.3889 - val_loss: 1.4643 - val_acc: 0.3323\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3265 - acc: 0.3945 - val_loss: 1.4644 - val_acc: 0.3323\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3264 - acc: 0.3927 - val_loss: 1.4776 - val_acc: 0.3323\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3217 - acc: 0.3864 - val_loss: 1.4539 - val_acc: 0.3323\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3161 - acc: 0.3970 - val_loss: 1.4491 - val_acc: 0.3323\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3053 - acc: 0.4019 - val_loss: 1.4571 - val_acc: 0.3323\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.3042 - acc: 0.404 - 0s 34us/step - loss: 1.2921 - acc: 0.4023 - val_loss: 1.4151 - val_acc: 0.3293\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2942 - acc: 0.3998 - val_loss: 1.4364 - val_acc: 0.3263\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2813 - acc: 0.3861 - val_loss: 1.4148 - val_acc: 0.3293\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2822 - acc: 0.3924 - val_loss: 1.4818 - val_acc: 0.3263\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2847 - acc: 0.3994 - val_loss: 1.4369 - val_acc: 0.3414\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2808 - acc: 0.4012 - val_loss: 1.4026 - val_acc: 0.3444\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.2795 - acc: 0.4079 - val_loss: 1.4183 - val_acc: 0.3384\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2577 - acc: 0.4230 - val_loss: 1.4377 - val_acc: 0.3444\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2579 - acc: 0.4093 - val_loss: 1.4015 - val_acc: 0.3474\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2567 - acc: 0.4192 - val_loss: 1.4362 - val_acc: 0.3384\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2592 - acc: 0.4146 - val_loss: 1.4911 - val_acc: 0.3323\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2536 - acc: 0.4086 - val_loss: 1.4265 - val_acc: 0.3353\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2561 - acc: 0.4121 - val_loss: 1.4286 - val_acc: 0.3414\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2525 - acc: 0.4065 - val_loss: 1.4183 - val_acc: 0.3414\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2340 - acc: 0.4121 - val_loss: 1.4041 - val_acc: 0.3414\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2182 - acc: 0.4301 - val_loss: 1.4590 - val_acc: 0.3384\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2346 - acc: 0.4178 - val_loss: 1.3807 - val_acc: 0.3565\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2135 - acc: 0.4192 - val_loss: 1.4199 - val_acc: 0.3384\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2267 - acc: 0.4269 - val_loss: 1.4094 - val_acc: 0.3686\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2025 - acc: 0.4276 - val_loss: 1.4231 - val_acc: 0.3656\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2240 - acc: 0.4178 - val_loss: 1.4701 - val_acc: 0.3384\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2266 - acc: 0.4202 - val_loss: 1.3964 - val_acc: 0.3625\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1993 - acc: 0.4304 - val_loss: 1.3822 - val_acc: 0.3535\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1926 - acc: 0.4396 - val_loss: 1.3352 - val_acc: 0.3897\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1853 - acc: 0.4512 - val_loss: 1.2807 - val_acc: 0.4471\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1941 - acc: 0.4572 - val_loss: 1.3619 - val_acc: 0.3867\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1882 - acc: 0.4294 - val_loss: 1.3219 - val_acc: 0.3867\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1821 - acc: 0.4516 - val_loss: 1.3256 - val_acc: 0.4230\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1699 - acc: 0.4466 - val_loss: 1.3269 - val_acc: 0.4260\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1765 - acc: 0.4537 - val_loss: 1.3074 - val_acc: 0.4320\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1752 - acc: 0.4466 - val_loss: 1.2613 - val_acc: 0.4653\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1741 - acc: 0.4431 - val_loss: 1.2938 - val_acc: 0.4834\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1699 - acc: 0.4635 - val_loss: 1.2886 - val_acc: 0.4320\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1645 - acc: 0.4565 - val_loss: 1.2728 - val_acc: 0.4683\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1438 - acc: 0.4569 - val_loss: 1.2934 - val_acc: 0.4169\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1489 - acc: 0.4523 - val_loss: 1.3069 - val_acc: 0.4199\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1559 - acc: 0.4456 - val_loss: 1.2977 - val_acc: 0.4320\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1359 - acc: 0.4600 - val_loss: 1.2523 - val_acc: 0.4713\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1370 - acc: 0.4773 - val_loss: 1.2151 - val_acc: 0.4834\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1572 - acc: 0.4685 - val_loss: 1.2788 - val_acc: 0.4350\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1315 - acc: 0.4576 - val_loss: 1.3018 - val_acc: 0.4199\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1265 - acc: 0.4537 - val_loss: 1.2832 - val_acc: 0.4653\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1317 - acc: 0.4646 - val_loss: 1.2365 - val_acc: 0.4864\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1308 - acc: 0.4738 - val_loss: 1.2790 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1253 - acc: 0.4597 - val_loss: 1.2731 - val_acc: 0.4773\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1159 - acc: 0.4600 - val_loss: 1.2432 - val_acc: 0.4864\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1137 - acc: 0.4794 - val_loss: 1.2280 - val_acc: 0.4924\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1072 - acc: 0.4709 - val_loss: 1.2507 - val_acc: 0.4955\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1117 - acc: 0.4678 - val_loss: 1.2970 - val_acc: 0.4562\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1148 - acc: 0.4618 - val_loss: 1.2380 - val_acc: 0.5015\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0901 - acc: 0.4762 - val_loss: 1.2609 - val_acc: 0.4894\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1001 - acc: 0.4579 - val_loss: 1.2206 - val_acc: 0.4985\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0845 - acc: 0.4847 - val_loss: 1.2238 - val_acc: 0.4804\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1054 - acc: 0.4561 - val_loss: 1.2213 - val_acc: 0.4804\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0865 - acc: 0.4745 - val_loss: 1.2908 - val_acc: 0.4320\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0964 - acc: 0.4692 - val_loss: 1.3267 - val_acc: 0.3927\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0856 - acc: 0.4625 - val_loss: 1.3523 - val_acc: 0.3746\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1002 - acc: 0.4523 - val_loss: 1.3717 - val_acc: 0.3505\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0928 - acc: 0.4445 - val_loss: 1.3135 - val_acc: 0.3716\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0883 - acc: 0.4551 - val_loss: 1.2482 - val_acc: 0.4350\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0665 - acc: 0.4685 - val_loss: 1.3117 - val_acc: 0.4109\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0943 - acc: 0.4653 - val_loss: 1.2861 - val_acc: 0.4139\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0646 - acc: 0.4776 - val_loss: 1.3039 - val_acc: 0.4048\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0642 - acc: 0.4706 - val_loss: 1.3158 - val_acc: 0.3958\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0900 - acc: 0.4586 - val_loss: 1.3457 - val_acc: 0.3535\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0799 - acc: 0.4498 - val_loss: 1.2735 - val_acc: 0.4169\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0549 - acc: 0.4805 - val_loss: 1.2483 - val_acc: 0.4562\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0442 - acc: 0.4815 - val_loss: 1.3379 - val_acc: 0.3686\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0760 - acc: 0.4537 - val_loss: 1.2902 - val_acc: 0.4199\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0460 - acc: 0.4611 - val_loss: 1.2730 - val_acc: 0.4320\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0532 - acc: 0.4723 - val_loss: 1.2786 - val_acc: 0.4320\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0602 - acc: 0.4752 - val_loss: 1.3174 - val_acc: 0.3807\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0603 - acc: 0.4569 - val_loss: 1.2836 - val_acc: 0.3988\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0460 - acc: 0.4738 - val_loss: 1.2955 - val_acc: 0.4260\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0602 - acc: 0.4695 - val_loss: 1.3007 - val_acc: 0.3958\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0467 - acc: 0.4776 - val_loss: 1.2945 - val_acc: 0.4169\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0349 - acc: 0.4748 - val_loss: 1.2375 - val_acc: 0.4622\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0275 - acc: 0.4917 - val_loss: 1.2306 - val_acc: 0.4683\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0209 - acc: 0.4924 - val_loss: 1.2271 - val_acc: 0.4713\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0110 - acc: 0.4907 - val_loss: 1.1941 - val_acc: 0.4894\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0097 - acc: 0.4949 - val_loss: 1.1797 - val_acc: 0.5136\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9972 - acc: 0.4991 - val_loss: 1.1321 - val_acc: 0.5589\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9984 - acc: 0.4977 - val_loss: 1.1201 - val_acc: 0.5559\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0610 - acc: 0.4991 - val_loss: 1.1344 - val_acc: 0.5468\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0257 - acc: 0.5072 - val_loss: 1.2124 - val_acc: 0.4713\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0110 - acc: 0.5023 - val_loss: 1.2554 - val_acc: 0.4199\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0137 - acc: 0.4755 - val_loss: 1.2304 - val_acc: 0.4411\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9912 - acc: 0.4974 - val_loss: 1.1456 - val_acc: 0.5227\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9931 - acc: 0.5178 - val_loss: 1.2307 - val_acc: 0.4532\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9967 - acc: 0.5009 - val_loss: 1.2372 - val_acc: 0.4441\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0103 - acc: 0.4875 - val_loss: 1.2161 - val_acc: 0.4622\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9798 - acc: 0.5086 - val_loss: 1.2238 - val_acc: 0.4592\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0072 - acc: 0.4875 - val_loss: 1.3134 - val_acc: 0.3867\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0205 - acc: 0.4843 - val_loss: 1.2185 - val_acc: 0.4683\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9842 - acc: 0.4974 - val_loss: 1.1675 - val_acc: 0.5196\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9901 - acc: 0.5164 - val_loss: 1.1827 - val_acc: 0.5196\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9879 - acc: 0.5005 - val_loss: 1.2010 - val_acc: 0.4894\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9935 - acc: 0.5012 - val_loss: 1.2226 - val_acc: 0.4653\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9787 - acc: 0.4977 - val_loss: 1.2450 - val_acc: 0.4502\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0007 - acc: 0.4970 - val_loss: 1.2861 - val_acc: 0.4230\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9799 - acc: 0.4850 - val_loss: 1.1750 - val_acc: 0.5076\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9531 - acc: 0.5188 - val_loss: 1.1544 - val_acc: 0.5408\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9632 - acc: 0.5185 - val_loss: 1.1482 - val_acc: 0.5196\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9987 - acc: 0.4995 - val_loss: 1.1464 - val_acc: 0.5227\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9523 - acc: 0.5277 - val_loss: 1.1296 - val_acc: 0.5196\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9589 - acc: 0.5262 - val_loss: 1.1128 - val_acc: 0.5378\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9603 - acc: 0.5231 - val_loss: 1.1171 - val_acc: 0.5196\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9882 - acc: 0.5157 - val_loss: 1.1400 - val_acc: 0.4985\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9756 - acc: 0.5262 - val_loss: 1.1498 - val_acc: 0.5136\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9532 - acc: 0.5241 - val_loss: 1.1209 - val_acc: 0.5227\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9622 - acc: 0.5234 - val_loss: 1.1237 - val_acc: 0.5317\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9496 - acc: 0.5227 - val_loss: 1.1038 - val_acc: 0.5317\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9514 - acc: 0.5164 - val_loss: 1.1240 - val_acc: 0.5045\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9665 - acc: 0.5241 - val_loss: 1.1446 - val_acc: 0.4955\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9458 - acc: 0.5372 - val_loss: 1.1715 - val_acc: 0.4804\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9178 - acc: 0.5350 - val_loss: 1.1870 - val_acc: 0.4713\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9420 - acc: 0.5305 - val_loss: 1.2067 - val_acc: 0.4592\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.9238 - acc: 0.5294 - val_loss: 1.2594 - val_acc: 0.4350\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9525 - acc: 0.5012 - val_loss: 1.2351 - val_acc: 0.4532\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9538 - acc: 0.5055 - val_loss: 1.2072 - val_acc: 0.4773\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9188 - acc: 0.5206 - val_loss: 1.1366 - val_acc: 0.5076\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9072 - acc: 0.5308 - val_loss: 1.1219 - val_acc: 0.5106\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9256 - acc: 0.5287 - val_loss: 1.0960 - val_acc: 0.5438\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9430 - acc: 0.5368 - val_loss: 1.1353 - val_acc: 0.4955\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9518 - acc: 0.5298 - val_loss: 1.1473 - val_acc: 0.4804\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9047 - acc: 0.5523 - val_loss: 1.1428 - val_acc: 0.4955\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9052 - acc: 0.5622 - val_loss: 1.1812 - val_acc: 0.4834\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9090 - acc: 0.5312 - val_loss: 1.2681 - val_acc: 0.4471\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9682 - acc: 0.5009 - val_loss: 1.2408 - val_acc: 0.4653\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9101 - acc: 0.5129 - val_loss: 1.1932 - val_acc: 0.4834\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9142 - acc: 0.5273 - val_loss: 1.1894 - val_acc: 0.4804\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8847 - acc: 0.5333 - val_loss: 1.1338 - val_acc: 0.5227\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9105 - acc: 0.5308 - val_loss: 1.1041 - val_acc: 0.5347\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9237 - acc: 0.5315 - val_loss: 1.1333 - val_acc: 0.5076\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9076 - acc: 0.5389 - val_loss: 1.1965 - val_acc: 0.4743\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.9145 - acc: 0.5213 - val_loss: 1.2426 - val_acc: 0.4683\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9329 - acc: 0.5019 - val_loss: 1.2672 - val_acc: 0.4350\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8957 - acc: 0.5277 - val_loss: 1.2023 - val_acc: 0.4532\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8729 - acc: 0.5484 - val_loss: 1.1418 - val_acc: 0.4955\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8804 - acc: 0.5527 - val_loss: 1.1646 - val_acc: 0.4804\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9015 - acc: 0.5548 - val_loss: 1.1990 - val_acc: 0.4653\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9517 - acc: 0.5343 - val_loss: 1.1128 - val_acc: 0.5317\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9203 - acc: 0.5491 - val_loss: 1.1260 - val_acc: 0.5196\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8913 - acc: 0.5601 - val_loss: 1.1313 - val_acc: 0.5045\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8912 - acc: 0.5502 - val_loss: 1.1636 - val_acc: 0.4773\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8670 - acc: 0.5586 - val_loss: 1.1642 - val_acc: 0.4773\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8505 - acc: 0.5636 - val_loss: 1.2382 - val_acc: 0.4320\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8868 - acc: 0.5386 - val_loss: 1.2880 - val_acc: 0.4079\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8893 - acc: 0.5446 - val_loss: 1.2033 - val_acc: 0.4592\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8590 - acc: 0.5594 - val_loss: 1.1731 - val_acc: 0.4804\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8526 - acc: 0.5594 - val_loss: 1.2868 - val_acc: 0.4622\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9562 - acc: 0.5083 - val_loss: 1.2728 - val_acc: 0.4441\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8858 - acc: 0.5273 - val_loss: 1.1865 - val_acc: 0.4683\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8448 - acc: 0.5576 - val_loss: 1.1874 - val_acc: 0.4773\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8575 - acc: 0.5460 - val_loss: 1.1572 - val_acc: 0.4955\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8662 - acc: 0.5618 - val_loss: 1.1365 - val_acc: 0.5227\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8915 - acc: 0.5386 - val_loss: 1.1357 - val_acc: 0.5317\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8316 - acc: 0.5720 - val_loss: 1.1796 - val_acc: 0.4985\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8374 - acc: 0.5625 - val_loss: 1.1953 - val_acc: 0.4804\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8707 - acc: 0.5583 - val_loss: 1.4007 - val_acc: 0.4048\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0082 - acc: 0.4678 - val_loss: 1.2198 - val_acc: 0.4713\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8426 - acc: 0.5558 - val_loss: 1.1875 - val_acc: 0.4864\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8324 - acc: 0.5745 - val_loss: 1.2077 - val_acc: 0.4864\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.8546 - acc: 0.5555 - val_loss: 1.1684 - val_acc: 0.5106\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8400 - acc: 0.5601 - val_loss: 1.1801 - val_acc: 0.4924\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8408 - acc: 0.5653 - val_loss: 1.1570 - val_acc: 0.5106\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8423 - acc: 0.5632 - val_loss: 1.1770 - val_acc: 0.4985\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8320 - acc: 0.5611 - val_loss: 1.1892 - val_acc: 0.4924\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8336 - acc: 0.5646 - val_loss: 1.2114 - val_acc: 0.4804\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8533 - acc: 0.5562 - val_loss: 1.3131 - val_acc: 0.4381\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.9054 - acc: 0.5174 - val_loss: 1.2925 - val_acc: 0.4109\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8510 - acc: 0.5403 - val_loss: 1.2370 - val_acc: 0.4502\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8126 - acc: 0.5667 - val_loss: 1.2241 - val_acc: 0.4743\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8356 - acc: 0.5586 - val_loss: 1.2525 - val_acc: 0.4562\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.8301 - acc: 0.5646 - val_loss: 1.2637 - val_acc: 0.4381\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8212 - acc: 0.5685 - val_loss: 1.3060 - val_acc: 0.4199\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8643 - acc: 0.5421 - val_loss: 1.2879 - val_acc: 0.4230\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8431 - acc: 0.5520 - val_loss: 1.2691 - val_acc: 0.4350\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8076 - acc: 0.5801 - val_loss: 1.2695 - val_acc: 0.4471\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8101 - acc: 0.5653 - val_loss: 1.2158 - val_acc: 0.4864\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8460 - acc: 0.5530 - val_loss: 1.2675 - val_acc: 0.4864\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8604 - acc: 0.5375 - val_loss: 1.2233 - val_acc: 0.4804\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.8162 - acc: 0.5555 - val_loss: 1.1936 - val_acc: 0.4894\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8046 - acc: 0.5822 - val_loss: 1.1475 - val_acc: 0.5045\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8386 - acc: 0.5639 - val_loss: 1.1475 - val_acc: 0.5287\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8518 - acc: 0.5777 - val_loss: 1.1766 - val_acc: 0.5106\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8433 - acc: 0.5720 - val_loss: 1.1692 - val_acc: 0.4955\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8022 - acc: 0.5854 - val_loss: 1.1903 - val_acc: 0.4955\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8215 - acc: 0.5738 - val_loss: 1.2135 - val_acc: 0.4955\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8393 - acc: 0.5502 - val_loss: 1.1781 - val_acc: 0.5045\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8000 - acc: 0.5734 - val_loss: 1.1913 - val_acc: 0.5015\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7894 - acc: 0.5801 - val_loss: 1.1685 - val_acc: 0.5317\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8348 - acc: 0.5830 - val_loss: 1.1697 - val_acc: 0.5227\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8105 - acc: 0.5875 - val_loss: 1.2131 - val_acc: 0.4955\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7952 - acc: 0.5872 - val_loss: 1.1990 - val_acc: 0.5106\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.8056 - acc: 0.5963 - val_loss: 1.2572 - val_acc: 0.4683\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.8147 - acc: 0.610 - 0s 33us/step - loss: 0.8025 - acc: 0.6009 - val_loss: 1.2355 - val_acc: 0.5076\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7973 - acc: 0.5872 - val_loss: 1.1736 - val_acc: 0.5287\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8199 - acc: 0.5830 - val_loss: 1.1561 - val_acc: 0.5196\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8193 - acc: 0.5791 - val_loss: 1.1997 - val_acc: 0.4924\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7804 - acc: 0.5847 - val_loss: 1.1954 - val_acc: 0.5227\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8049 - acc: 0.5682 - val_loss: 1.1691 - val_acc: 0.5196\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8017 - acc: 0.5689 - val_loss: 1.1792 - val_acc: 0.5287\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8109 - acc: 0.5787 - val_loss: 1.2284 - val_acc: 0.4924\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7984 - acc: 0.5939 - val_loss: 1.3074 - val_acc: 0.4532\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7815 - acc: 0.6030 - val_loss: 1.2741 - val_acc: 0.4773\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7752 - acc: 0.5921 - val_loss: 1.2766 - val_acc: 0.4743\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7617 - acc: 0.5935 - val_loss: 1.3104 - val_acc: 0.4622\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7585 - acc: 0.6027 - val_loss: 1.3647 - val_acc: 0.4230\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7968 - acc: 0.5854 - val_loss: 1.4256 - val_acc: 0.4079\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8931 - acc: 0.5238 - val_loss: 1.2843 - val_acc: 0.4532\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7684 - acc: 0.5914 - val_loss: 1.2347 - val_acc: 0.4834\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7634 - acc: 0.6055 - val_loss: 1.2117 - val_acc: 0.5196\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7526 - acc: 0.5939 - val_loss: 1.2720 - val_acc: 0.4773\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7864 - acc: 0.5763 - val_loss: 1.3422 - val_acc: 0.4562\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8175 - acc: 0.5572 - val_loss: 1.3157 - val_acc: 0.4532\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7789 - acc: 0.5756 - val_loss: 1.3416 - val_acc: 0.4290\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7607 - acc: 0.5858 - val_loss: 1.2991 - val_acc: 0.4622\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7512 - acc: 0.6041 - val_loss: 1.2877 - val_acc: 0.4894\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7486 - acc: 0.6143 - val_loss: 1.4031 - val_acc: 0.4169\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7656 - acc: 0.5992 - val_loss: 1.4073 - val_acc: 0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7892 - acc: 0.5794 - val_loss: 1.3249 - val_acc: 0.4592\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7584 - acc: 0.5872 - val_loss: 1.4036 - val_acc: 0.4109\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7951 - acc: 0.5597 - val_loss: 1.3416 - val_acc: 0.4320\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7542 - acc: 0.5886 - val_loss: 1.2986 - val_acc: 0.4683\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7551 - acc: 0.6041 - val_loss: 1.2773 - val_acc: 0.4834\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7533 - acc: 0.5868 - val_loss: 1.2759 - val_acc: 0.4834\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7410 - acc: 0.5970 - val_loss: 1.2909 - val_acc: 0.4622\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7299 - acc: 0.6101 - val_loss: 1.3282 - val_acc: 0.4532\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7772 - acc: 0.5928 - val_loss: 1.4252 - val_acc: 0.4411\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8632 - acc: 0.5343 - val_loss: 1.3301 - val_acc: 0.4350\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7319 - acc: 0.5889 - val_loss: 1.3307 - val_acc: 0.4713\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7279 - acc: 0.6182 - val_loss: 1.3800 - val_acc: 0.4381\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7161 - acc: 0.6129 - val_loss: 1.3963 - val_acc: 0.4381\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7331 - acc: 0.6147 - val_loss: 1.4504 - val_acc: 0.4079\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7731 - acc: 0.5893 - val_loss: 1.3732 - val_acc: 0.4320\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7476 - acc: 0.5988 - val_loss: 1.4260 - val_acc: 0.4199\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7970 - acc: 0.5773 - val_loss: 1.3295 - val_acc: 0.4562\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.7350 - acc: 0.5967 - val_loss: 1.2796 - val_acc: 0.4894\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.7446 - acc: 0.588 - 0s 34us/step - loss: 0.7214 - acc: 0.6048 - val_loss: 1.2857 - val_acc: 0.4894\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7166 - acc: 0.6125 - val_loss: 1.3050 - val_acc: 0.4653\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7137 - acc: 0.6132 - val_loss: 1.2948 - val_acc: 0.4834\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.7346 - acc: 0.5985 - val_loss: 1.4088 - val_acc: 0.4350\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.8111 - acc: 0.5590 - val_loss: 1.4172 - val_acc: 0.4139\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7448 - acc: 0.5826 - val_loss: 1.3836 - val_acc: 0.4381\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7061 - acc: 0.6185 - val_loss: 1.3516 - val_acc: 0.4743\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7175 - acc: 0.6196 - val_loss: 1.3962 - val_acc: 0.4411\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7308 - acc: 0.6136 - val_loss: 1.4418 - val_acc: 0.4260\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7647 - acc: 0.6013 - val_loss: 1.4740 - val_acc: 0.3988\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.8204 - acc: 0.5562 - val_loss: 1.3159 - val_acc: 0.4562\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7161 - acc: 0.6055 - val_loss: 1.2795 - val_acc: 0.4894\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7156 - acc: 0.6136 - val_loss: 1.2935 - val_acc: 0.4924\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7057 - acc: 0.6122 - val_loss: 1.2721 - val_acc: 0.5106\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7256 - acc: 0.5942 - val_loss: 1.2882 - val_acc: 0.4894\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6993 - acc: 0.6340 - val_loss: 1.3035 - val_acc: 0.4894\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7021 - acc: 0.6164 - val_loss: 1.2728 - val_acc: 0.5076\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7219 - acc: 0.6055 - val_loss: 1.2432 - val_acc: 0.5287\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7064 - acc: 0.6199 - val_loss: 1.2201 - val_acc: 0.5317\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.8462 - acc: 0.5868 - val_loss: 1.2833 - val_acc: 0.5045\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7957 - acc: 0.6097 - val_loss: 1.2965 - val_acc: 0.4834\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6900 - acc: 0.6354 - val_loss: 1.3314 - val_acc: 0.5015\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6744 - acc: 0.6474 - val_loss: 1.3501 - val_acc: 0.5015\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6877 - acc: 0.6347 - val_loss: 1.3782 - val_acc: 0.4743\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6723 - acc: 0.6309 - val_loss: 1.4151 - val_acc: 0.4350\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6879 - acc: 0.6252 - val_loss: 1.4873 - val_acc: 0.4169\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7273 - acc: 0.6062 - val_loss: 1.4139 - val_acc: 0.4532\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7026 - acc: 0.6294 - val_loss: 1.3613 - val_acc: 0.4773\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6727 - acc: 0.6545 - val_loss: 1.3737 - val_acc: 0.4864\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6770 - acc: 0.6407 - val_loss: 1.4482 - val_acc: 0.4350\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7065 - acc: 0.6210 - val_loss: 1.4848 - val_acc: 0.4260\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7556 - acc: 0.6027 - val_loss: 1.4505 - val_acc: 0.4441\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7518 - acc: 0.5738 - val_loss: 1.3842 - val_acc: 0.4502\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7182 - acc: 0.5995 - val_loss: 1.3945 - val_acc: 0.4441\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6658 - acc: 0.6238 - val_loss: 1.3803 - val_acc: 0.4713\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6517 - acc: 0.6432 - val_loss: 1.3684 - val_acc: 0.4804\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6771 - acc: 0.6383 - val_loss: 1.3546 - val_acc: 0.4924\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7001 - acc: 0.6129 - val_loss: 1.4390 - val_acc: 0.4381\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7615 - acc: 0.5865 - val_loss: 1.4725 - val_acc: 0.4290\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6906 - acc: 0.6203 - val_loss: 1.3912 - val_acc: 0.4622\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.6540 - acc: 0.6414 - val_loss: 1.3995 - val_acc: 0.4773\n",
      "Epoch 296/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6622 - acc: 0.6411 - val_loss: 1.4727 - val_acc: 0.4441\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6973 - acc: 0.6132 - val_loss: 1.4935 - val_acc: 0.4139\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.7155 - acc: 0.5974 - val_loss: 1.4446 - val_acc: 0.4683\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6679 - acc: 0.6375 - val_loss: 1.5201 - val_acc: 0.4169\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7119 - acc: 0.6217 - val_loss: 1.4707 - val_acc: 0.4441\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6800 - acc: 0.6291 - val_loss: 1.4617 - val_acc: 0.4622\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6927 - acc: 0.6287 - val_loss: 1.4516 - val_acc: 0.4592\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6759 - acc: 0.6456 - val_loss: 1.4689 - val_acc: 0.4562\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6846 - acc: 0.6474 - val_loss: 1.3769 - val_acc: 0.4894\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7472 - acc: 0.6192 - val_loss: 1.3098 - val_acc: 0.5106\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7134 - acc: 0.6425 - val_loss: 1.3481 - val_acc: 0.4834\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6413 - acc: 0.6425 - val_loss: 1.3300 - val_acc: 0.5045\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6658 - acc: 0.6495 - val_loss: 1.3453 - val_acc: 0.5076\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6373 - acc: 0.6601 - val_loss: 1.3679 - val_acc: 0.5015\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6586 - acc: 0.6456 - val_loss: 1.3385 - val_acc: 0.5015\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7061 - acc: 0.6453 - val_loss: 1.3594 - val_acc: 0.4955\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6858 - acc: 0.6365 - val_loss: 1.3820 - val_acc: 0.5015\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6481 - acc: 0.6502 - val_loss: 1.3768 - val_acc: 0.4864\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6454 - acc: 0.6481 - val_loss: 1.3691 - val_acc: 0.5076\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6552 - acc: 0.6509 - val_loss: 1.3482 - val_acc: 0.5076\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6824 - acc: 0.6414 - val_loss: 1.3868 - val_acc: 0.5045\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7171 - acc: 0.6305 - val_loss: 1.4270 - val_acc: 0.4924\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6840 - acc: 0.6333 - val_loss: 1.5129 - val_acc: 0.4320\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.7044 - acc: 0.6361 - val_loss: 1.5476 - val_acc: 0.4290\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6737 - acc: 0.6379 - val_loss: 1.4155 - val_acc: 0.4743\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6448 - acc: 0.6411 - val_loss: 1.4819 - val_acc: 0.4622\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6608 - acc: 0.6280 - val_loss: 1.4980 - val_acc: 0.4381\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6567 - acc: 0.6340 - val_loss: 1.4665 - val_acc: 0.4622\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6453 - acc: 0.6435 - val_loss: 1.6098 - val_acc: 0.3958\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6913 - acc: 0.6249 - val_loss: 1.4852 - val_acc: 0.4562\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6372 - acc: 0.6464 - val_loss: 1.4364 - val_acc: 0.4834\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6260 - acc: 0.6559 - val_loss: 1.4659 - val_acc: 0.4562\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6696 - acc: 0.6337 - val_loss: 1.5197 - val_acc: 0.4381\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.7261 - acc: 0.5872 - val_loss: 1.3688 - val_acc: 0.5076\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6471 - acc: 0.6316 - val_loss: 1.3347 - val_acc: 0.5136\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6476 - acc: 0.6390 - val_loss: 1.3476 - val_acc: 0.5257\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6275 - acc: 0.6513 - val_loss: 1.3871 - val_acc: 0.4985\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6082 - acc: 0.6608 - val_loss: 1.4165 - val_acc: 0.4834\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6215 - acc: 0.6636 - val_loss: 1.3470 - val_acc: 0.5076\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.7094 - acc: 0.6242 - val_loss: 1.3372 - val_acc: 0.5378\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.7454 - acc: 0.6326 - val_loss: 1.4446 - val_acc: 0.4743\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6344 - acc: 0.6675 - val_loss: 1.4515 - val_acc: 0.4622\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6132 - acc: 0.6788 - val_loss: 1.5311 - val_acc: 0.4441\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6275 - acc: 0.6650 - val_loss: 1.5507 - val_acc: 0.4350\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6340 - acc: 0.6562 - val_loss: 1.5104 - val_acc: 0.4562\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6376 - acc: 0.6372 - val_loss: 1.5210 - val_acc: 0.4562\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6655 - acc: 0.6316 - val_loss: 1.5203 - val_acc: 0.4471\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6418 - acc: 0.6464 - val_loss: 1.4820 - val_acc: 0.4713\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6304 - acc: 0.6456 - val_loss: 1.5020 - val_acc: 0.4653\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6192 - acc: 0.6633 - val_loss: 1.4645 - val_acc: 0.4804\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6007 - acc: 0.6731 - val_loss: 1.4588 - val_acc: 0.4894\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5898 - acc: 0.6745 - val_loss: 1.4450 - val_acc: 0.4955\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6676 - acc: 0.6375 - val_loss: 1.3745 - val_acc: 0.5136\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6958 - acc: 0.6104 - val_loss: 1.3109 - val_acc: 0.5378\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6887 - acc: 0.6316 - val_loss: 1.4000 - val_acc: 0.5076\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6745 - acc: 0.6678 - val_loss: 1.3710 - val_acc: 0.4985\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6096 - acc: 0.6802 - val_loss: 1.4072 - val_acc: 0.5076\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6098 - acc: 0.6608 - val_loss: 1.4516 - val_acc: 0.4804\n",
      "Epoch 354/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5756 - acc: 0.6809 - val_loss: 1.4422 - val_acc: 0.4894\n",
      "Epoch 355/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5797 - acc: 0.6826 - val_loss: 1.4323 - val_acc: 0.5106\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6147 - acc: 0.6615 - val_loss: 1.4141 - val_acc: 0.5076\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6464 - acc: 0.6601 - val_loss: 1.4993 - val_acc: 0.4713\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6891 - acc: 0.6365 - val_loss: 1.5588 - val_acc: 0.4441\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6480 - acc: 0.6714 - val_loss: 1.5473 - val_acc: 0.4653\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6023 - acc: 0.6696 - val_loss: 1.5231 - val_acc: 0.4592\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5822 - acc: 0.6890 - val_loss: 1.5558 - val_acc: 0.4562\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5934 - acc: 0.6692 - val_loss: 1.6149 - val_acc: 0.4350\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6430 - acc: 0.6562 - val_loss: 1.6768 - val_acc: 0.3958\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6656 - acc: 0.6097 - val_loss: 1.4853 - val_acc: 0.4804\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6003 - acc: 0.6566 - val_loss: 1.4334 - val_acc: 0.5076\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5826 - acc: 0.6675 - val_loss: 1.3989 - val_acc: 0.5166\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.6356 - acc: 0.6495 - val_loss: 1.3535 - val_acc: 0.5529\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6474 - acc: 0.6538 - val_loss: 1.3845 - val_acc: 0.5227\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.6241 - acc: 0.6742 - val_loss: 1.4737 - val_acc: 0.4955\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6208 - acc: 0.6735 - val_loss: 1.4496 - val_acc: 0.4985\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5744 - acc: 0.6879 - val_loss: 1.5289 - val_acc: 0.4683\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5737 - acc: 0.6826 - val_loss: 1.6235 - val_acc: 0.4502\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6160 - acc: 0.6714 - val_loss: 1.6688 - val_acc: 0.4260\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.6188 - acc: 0.6714 - val_loss: 1.5826 - val_acc: 0.4622\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.5931 - acc: 0.6763 - val_loss: 1.6250 - val_acc: 0.4441\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.6331 - acc: 0.6587 - val_loss: 1.6648 - val_acc: 0.4139\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6897 - acc: 0.6048 - val_loss: 1.4923 - val_acc: 0.4834\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5672 - acc: 0.6759 - val_loss: 1.5540 - val_acc: 0.4743\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5563 - acc: 0.6819 - val_loss: 1.5417 - val_acc: 0.4773\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5598 - acc: 0.6858 - val_loss: 1.5940 - val_acc: 0.4773\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5574 - acc: 0.6869 - val_loss: 1.6876 - val_acc: 0.4139\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6318 - acc: 0.6594 - val_loss: 1.7164 - val_acc: 0.3927\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6325 - acc: 0.6587 - val_loss: 1.5873 - val_acc: 0.4683\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6010 - acc: 0.6601 - val_loss: 1.6578 - val_acc: 0.4441\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6492 - acc: 0.6407 - val_loss: 1.5635 - val_acc: 0.4622\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5657 - acc: 0.6640 - val_loss: 1.5108 - val_acc: 0.5015\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5546 - acc: 0.6946 - val_loss: 1.4429 - val_acc: 0.4955\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5739 - acc: 0.6893 - val_loss: 1.4391 - val_acc: 0.5196\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6546 - acc: 0.6569 - val_loss: 1.4213 - val_acc: 0.5045\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5663 - acc: 0.6911 - val_loss: 1.5324 - val_acc: 0.4955\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5573 - acc: 0.6943 - val_loss: 1.6358 - val_acc: 0.4441\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5876 - acc: 0.6837 - val_loss: 1.6454 - val_acc: 0.4471\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5868 - acc: 0.6862 - val_loss: 1.6159 - val_acc: 0.4562\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5544 - acc: 0.6862 - val_loss: 1.6683 - val_acc: 0.4502\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5759 - acc: 0.6897 - val_loss: 1.6987 - val_acc: 0.4290\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5927 - acc: 0.6724 - val_loss: 1.6260 - val_acc: 0.4441\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5593 - acc: 0.6911 - val_loss: 1.6819 - val_acc: 0.4471\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6547 - acc: 0.6442 - val_loss: 1.6248 - val_acc: 0.4411\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5954 - acc: 0.6622 - val_loss: 1.5311 - val_acc: 0.4894\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5388 - acc: 0.7006 - val_loss: 1.5815 - val_acc: 0.4834\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5478 - acc: 0.6819 - val_loss: 1.5492 - val_acc: 0.4924\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5416 - acc: 0.7034 - val_loss: 1.5214 - val_acc: 0.4955\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5694 - acc: 0.6802 - val_loss: 1.4489 - val_acc: 0.5136\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.6419 - acc: 0.6309 - val_loss: 1.3937 - val_acc: 0.5378\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6462 - acc: 0.6640 - val_loss: 1.5192 - val_acc: 0.5106\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6366 - acc: 0.6749 - val_loss: 1.5232 - val_acc: 0.4864\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5337 - acc: 0.7147 - val_loss: 1.5345 - val_acc: 0.4864\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5301 - acc: 0.7080 - val_loss: 1.5729 - val_acc: 0.4773\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5238 - acc: 0.7038 - val_loss: 1.6271 - val_acc: 0.4683\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5509 - acc: 0.6985 - val_loss: 1.7750 - val_acc: 0.4230\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6271 - acc: 0.6464 - val_loss: 1.5664 - val_acc: 0.4864\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5367 - acc: 0.7087 - val_loss: 1.5768 - val_acc: 0.4743\n",
      "Epoch 413/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5611 - acc: 0.6707 - val_loss: 1.5924 - val_acc: 0.4834\n",
      "Epoch 414/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5681 - acc: 0.6763 - val_loss: 1.6197 - val_acc: 0.4562\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5714 - acc: 0.6721 - val_loss: 1.5604 - val_acc: 0.4622\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5397 - acc: 0.6932 - val_loss: 1.5701 - val_acc: 0.4864\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5337 - acc: 0.6900 - val_loss: 1.6070 - val_acc: 0.4683\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5387 - acc: 0.6918 - val_loss: 1.7844 - val_acc: 0.4471\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5905 - acc: 0.6696 - val_loss: 1.9311 - val_acc: 0.3807\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6741 - acc: 0.6298 - val_loss: 1.6462 - val_acc: 0.4683\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.5349 - acc: 0.7020 - val_loss: 1.6156 - val_acc: 0.4683\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5347 - acc: 0.6865 - val_loss: 1.5540 - val_acc: 0.4834\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5264 - acc: 0.7010 - val_loss: 1.5189 - val_acc: 0.4894\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5189 - acc: 0.7002 - val_loss: 1.5709 - val_acc: 0.4985\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5287 - acc: 0.7048 - val_loss: 1.5451 - val_acc: 0.4955\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5495 - acc: 0.7034 - val_loss: 1.4659 - val_acc: 0.5136\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.6790 - acc: 0.6559 - val_loss: 1.5610 - val_acc: 0.4955\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5837 - acc: 0.6904 - val_loss: 1.5829 - val_acc: 0.4834\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5400 - acc: 0.7256 - val_loss: 1.6407 - val_acc: 0.4773\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5365 - acc: 0.6967 - val_loss: 1.7605 - val_acc: 0.4260\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5418 - acc: 0.6992 - val_loss: 1.5674 - val_acc: 0.4894\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5070 - acc: 0.7249 - val_loss: 1.6210 - val_acc: 0.4834\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5336 - acc: 0.7080 - val_loss: 1.6696 - val_acc: 0.4532\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5952 - acc: 0.6914 - val_loss: 1.6444 - val_acc: 0.4834\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5896 - acc: 0.6886 - val_loss: 1.4960 - val_acc: 0.5136\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5548 - acc: 0.6964 - val_loss: 1.4695 - val_acc: 0.5166\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5733 - acc: 0.6914 - val_loss: 1.4758 - val_acc: 0.5045\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5426 - acc: 0.6971 - val_loss: 1.5012 - val_acc: 0.4924\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5332 - acc: 0.7076 - val_loss: 1.5471 - val_acc: 0.5015\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5167 - acc: 0.7157 - val_loss: 1.6073 - val_acc: 0.4894\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5248 - acc: 0.7133 - val_loss: 1.6165 - val_acc: 0.4955\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5641 - acc: 0.6911 - val_loss: 1.6122 - val_acc: 0.4864\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5710 - acc: 0.6981 - val_loss: 1.6310 - val_acc: 0.4713\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5211 - acc: 0.7186 - val_loss: 1.5914 - val_acc: 0.4955\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5033 - acc: 0.7312 - val_loss: 1.6141 - val_acc: 0.5015\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4934 - acc: 0.7288 - val_loss: 1.5247 - val_acc: 0.5076\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5678 - acc: 0.6847 - val_loss: 1.4588 - val_acc: 0.5196\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.6112 - acc: 0.6682 - val_loss: 1.5006 - val_acc: 0.5257\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5421 - acc: 0.7122 - val_loss: 1.6037 - val_acc: 0.4864\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5213 - acc: 0.7091 - val_loss: 1.7505 - val_acc: 0.4350\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5761 - acc: 0.6928 - val_loss: 1.6956 - val_acc: 0.4471\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5655 - acc: 0.7027 - val_loss: 1.5415 - val_acc: 0.5045\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5295 - acc: 0.7140 - val_loss: 1.5205 - val_acc: 0.5136\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5432 - acc: 0.6971 - val_loss: 1.4962 - val_acc: 0.5166\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5611 - acc: 0.6914 - val_loss: 1.5121 - val_acc: 0.5287\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5206 - acc: 0.7143 - val_loss: 1.5619 - val_acc: 0.5136\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5167 - acc: 0.7284 - val_loss: 1.5827 - val_acc: 0.5166\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5366 - acc: 0.7031 - val_loss: 1.5497 - val_acc: 0.5015\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5521 - acc: 0.7179 - val_loss: 1.5301 - val_acc: 0.5106\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5360 - acc: 0.7164 - val_loss: 1.5256 - val_acc: 0.5045\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5161 - acc: 0.7076 - val_loss: 1.5272 - val_acc: 0.5076\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4905 - acc: 0.7267 - val_loss: 1.5725 - val_acc: 0.4924\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5254 - acc: 0.7059 - val_loss: 1.5642 - val_acc: 0.5136\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5204 - acc: 0.7083 - val_loss: 1.5945 - val_acc: 0.4924\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5216 - acc: 0.6992 - val_loss: 1.6085 - val_acc: 0.4924\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4874 - acc: 0.7189 - val_loss: 1.6512 - val_acc: 0.4864\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5174 - acc: 0.7105 - val_loss: 1.6624 - val_acc: 0.4773\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5452 - acc: 0.6872 - val_loss: 1.8615 - val_acc: 0.4290\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.6282 - acc: 0.6548 - val_loss: 1.7410 - val_acc: 0.4502\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5180 - acc: 0.7034 - val_loss: 1.6193 - val_acc: 0.4924\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4774 - acc: 0.7376 - val_loss: 1.6012 - val_acc: 0.4955\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5093 - acc: 0.7143 - val_loss: 1.5461 - val_acc: 0.5196\n",
      "Epoch 473/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5525 - acc: 0.6883 - val_loss: 1.5191 - val_acc: 0.5166\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5150 - acc: 0.7098 - val_loss: 1.5683 - val_acc: 0.4985\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5170 - acc: 0.7179 - val_loss: 1.6034 - val_acc: 0.4924\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5197 - acc: 0.7231 - val_loss: 1.5960 - val_acc: 0.4985\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5092 - acc: 0.7235 - val_loss: 1.6252 - val_acc: 0.4864\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4869 - acc: 0.7344 - val_loss: 1.5920 - val_acc: 0.4955\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4897 - acc: 0.7284 - val_loss: 1.5653 - val_acc: 0.5196\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5085 - acc: 0.7186 - val_loss: 1.5413 - val_acc: 0.5166\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5025 - acc: 0.7129 - val_loss: 1.5276 - val_acc: 0.5166\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5440 - acc: 0.6911 - val_loss: 1.5371 - val_acc: 0.5257\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5020 - acc: 0.7309 - val_loss: 1.6086 - val_acc: 0.4924\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5073 - acc: 0.7235 - val_loss: 1.6868 - val_acc: 0.4743\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5489 - acc: 0.7186 - val_loss: 1.6353 - val_acc: 0.4773\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5131 - acc: 0.7319 - val_loss: 1.6664 - val_acc: 0.4713\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4834 - acc: 0.7302 - val_loss: 1.7323 - val_acc: 0.4683\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5008 - acc: 0.7316 - val_loss: 1.8281 - val_acc: 0.4290\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5154 - acc: 0.7168 - val_loss: 1.7402 - val_acc: 0.4441\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5181 - acc: 0.7080 - val_loss: 1.6414 - val_acc: 0.4955\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5001 - acc: 0.7408 - val_loss: 1.6379 - val_acc: 0.4834\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5002 - acc: 0.7344 - val_loss: 1.5894 - val_acc: 0.5076\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5566 - acc: 0.7126 - val_loss: 1.5566 - val_acc: 0.5136\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5124 - acc: 0.7284 - val_loss: 1.5890 - val_acc: 0.5106\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4921 - acc: 0.7200 - val_loss: 1.6015 - val_acc: 0.5106\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4995 - acc: 0.7172 - val_loss: 1.5825 - val_acc: 0.5106\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4952 - acc: 0.7041 - val_loss: 1.5751 - val_acc: 0.5045\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4658 - acc: 0.7330 - val_loss: 1.5794 - val_acc: 0.5106\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4771 - acc: 0.7358 - val_loss: 1.6313 - val_acc: 0.4804\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5447 - acc: 0.7108 - val_loss: 1.6270 - val_acc: 0.4894\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5233 - acc: 0.7150 - val_loss: 1.6554 - val_acc: 0.4622\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4759 - acc: 0.7450 - val_loss: 1.6467 - val_acc: 0.4804\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4437 - acc: 0.7397 - val_loss: 1.6653 - val_acc: 0.4985\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4538 - acc: 0.7418 - val_loss: 1.6025 - val_acc: 0.5257\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5141 - acc: 0.7217 - val_loss: 1.5688 - val_acc: 0.5529\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.5491 - acc: 0.7020 - val_loss: 1.5497 - val_acc: 0.5317\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4543 - acc: 0.7439 - val_loss: 1.6414 - val_acc: 0.4985\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4502 - acc: 0.7489 - val_loss: 1.6473 - val_acc: 0.4924\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4493 - acc: 0.7517 - val_loss: 1.7513 - val_acc: 0.4713\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4434 - acc: 0.7538 - val_loss: 1.7867 - val_acc: 0.4804\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4462 - acc: 0.7506 - val_loss: 1.7174 - val_acc: 0.4804\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.5013 - acc: 0.7214 - val_loss: 1.9254 - val_acc: 0.4350\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.6380 - acc: 0.6823 - val_loss: 1.6440 - val_acc: 0.4834\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5398 - acc: 0.7256 - val_loss: 1.5636 - val_acc: 0.5196\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4738 - acc: 0.7330 - val_loss: 1.6136 - val_acc: 0.5106\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4574 - acc: 0.7524 - val_loss: 1.6198 - val_acc: 0.5136\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5002 - acc: 0.7355 - val_loss: 1.6185 - val_acc: 0.5106\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4498 - acc: 0.7418 - val_loss: 1.6467 - val_acc: 0.5076\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4554 - acc: 0.7464 - val_loss: 1.6895 - val_acc: 0.4985\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4539 - acc: 0.7485 - val_loss: 1.6562 - val_acc: 0.5317\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4998 - acc: 0.7231 - val_loss: 1.6619 - val_acc: 0.4924\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5210 - acc: 0.7143 - val_loss: 1.7200 - val_acc: 0.4592\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5005 - acc: 0.7284 - val_loss: 1.8411 - val_acc: 0.4350\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4669 - acc: 0.7453 - val_loss: 1.7869 - val_acc: 0.4653\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4222 - acc: 0.7513 - val_loss: 1.7988 - val_acc: 0.4773\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4435 - acc: 0.7559 - val_loss: 1.8711 - val_acc: 0.4381\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4744 - acc: 0.7351 - val_loss: 2.0653 - val_acc: 0.4109\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5707 - acc: 0.6918 - val_loss: 1.8066 - val_acc: 0.4653\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4597 - acc: 0.7386 - val_loss: 1.7212 - val_acc: 0.4804\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4382 - acc: 0.7534 - val_loss: 1.7671 - val_acc: 0.4713\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4833 - acc: 0.7182 - val_loss: 1.9485 - val_acc: 0.4139\n",
      "Epoch 532/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5998 - acc: 0.6559 - val_loss: 1.8272 - val_acc: 0.4411\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4903 - acc: 0.7129 - val_loss: 1.7700 - val_acc: 0.4683\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4395 - acc: 0.7478 - val_loss: 1.7491 - val_acc: 0.4864\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4405 - acc: 0.7510 - val_loss: 1.7926 - val_acc: 0.4502\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4589 - acc: 0.7291 - val_loss: 1.9791 - val_acc: 0.4230\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5022 - acc: 0.7175 - val_loss: 1.8158 - val_acc: 0.4562\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4560 - acc: 0.7587 - val_loss: 1.7875 - val_acc: 0.4773\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4406 - acc: 0.7594 - val_loss: 1.8449 - val_acc: 0.4683\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4670 - acc: 0.7436 - val_loss: 1.8254 - val_acc: 0.4653\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4848 - acc: 0.7334 - val_loss: 1.7629 - val_acc: 0.4743\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4588 - acc: 0.7351 - val_loss: 1.8274 - val_acc: 0.4713\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4766 - acc: 0.7277 - val_loss: 1.8250 - val_acc: 0.4683\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4588 - acc: 0.7429 - val_loss: 1.9322 - val_acc: 0.4169\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4758 - acc: 0.7210 - val_loss: 1.8876 - val_acc: 0.4532\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4772 - acc: 0.7337 - val_loss: 1.8977 - val_acc: 0.4411\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4644 - acc: 0.7390 - val_loss: 1.8322 - val_acc: 0.4441\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4846 - acc: 0.7499 - val_loss: 1.8020 - val_acc: 0.4683\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4590 - acc: 0.7510 - val_loss: 1.7826 - val_acc: 0.4350\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4570 - acc: 0.7672 - val_loss: 1.7891 - val_acc: 0.4713\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4324 - acc: 0.7591 - val_loss: 1.7863 - val_acc: 0.4683\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4174 - acc: 0.7644 - val_loss: 1.7691 - val_acc: 0.4834\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4322 - acc: 0.7735 - val_loss: 1.9418 - val_acc: 0.4532\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5662 - acc: 0.6936 - val_loss: 1.9354 - val_acc: 0.4109\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4938 - acc: 0.6928 - val_loss: 1.7650 - val_acc: 0.4622\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4461 - acc: 0.7474 - val_loss: 1.8887 - val_acc: 0.4290\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4580 - acc: 0.7379 - val_loss: 1.9689 - val_acc: 0.4169\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4921 - acc: 0.7284 - val_loss: 1.8386 - val_acc: 0.4532\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4389 - acc: 0.7598 - val_loss: 1.7520 - val_acc: 0.4743\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4183 - acc: 0.7608 - val_loss: 1.7835 - val_acc: 0.4653\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4179 - acc: 0.7591 - val_loss: 1.7715 - val_acc: 0.4804\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4063 - acc: 0.7728 - val_loss: 1.7779 - val_acc: 0.4955\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5398 - acc: 0.7150 - val_loss: 1.7202 - val_acc: 0.5076\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5254 - acc: 0.7334 - val_loss: 1.7875 - val_acc: 0.4592\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4351 - acc: 0.7573 - val_loss: 1.8583 - val_acc: 0.4532\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4446 - acc: 0.7566 - val_loss: 1.8749 - val_acc: 0.4350\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4391 - acc: 0.7661 - val_loss: 1.8743 - val_acc: 0.4441\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4171 - acc: 0.7679 - val_loss: 1.8845 - val_acc: 0.4532\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4047 - acc: 0.7742 - val_loss: 1.9255 - val_acc: 0.4381\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4523 - acc: 0.7510 - val_loss: 1.9972 - val_acc: 0.4411\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5010 - acc: 0.7355 - val_loss: 1.9798 - val_acc: 0.4260\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5279 - acc: 0.7048 - val_loss: 1.7662 - val_acc: 0.5045\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4387 - acc: 0.7386 - val_loss: 1.7510 - val_acc: 0.4924\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4133 - acc: 0.7563 - val_loss: 1.8242 - val_acc: 0.4773\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4485 - acc: 0.7355 - val_loss: 1.8146 - val_acc: 0.4622\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4349 - acc: 0.7369 - val_loss: 1.7991 - val_acc: 0.4985\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4378 - acc: 0.7369 - val_loss: 1.7828 - val_acc: 0.5076\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4295 - acc: 0.7457 - val_loss: 1.7822 - val_acc: 0.5136\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4257 - acc: 0.7513 - val_loss: 1.7622 - val_acc: 0.5257\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4574 - acc: 0.7390 - val_loss: 1.7017 - val_acc: 0.5227\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4543 - acc: 0.7323 - val_loss: 1.7413 - val_acc: 0.4864\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4043 - acc: 0.7714 - val_loss: 1.7674 - val_acc: 0.4985\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3989 - acc: 0.7777 - val_loss: 1.8521 - val_acc: 0.4653\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 0.3998 - acc: 0.7728 - val_loss: 1.8758 - val_acc: 0.4713\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.4869 - acc: 0.7443 - val_loss: 1.8753 - val_acc: 0.4653\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5363 - acc: 0.7319 - val_loss: 1.7859 - val_acc: 0.4562\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4137 - acc: 0.7781 - val_loss: 1.7993 - val_acc: 0.4924\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4249 - acc: 0.7499 - val_loss: 1.7949 - val_acc: 0.5015\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4570 - acc: 0.7309 - val_loss: 1.7717 - val_acc: 0.5287\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4317 - acc: 0.7457 - val_loss: 1.7721 - val_acc: 0.5408\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4393 - acc: 0.7527 - val_loss: 1.8185 - val_acc: 0.5015\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4480 - acc: 0.7408 - val_loss: 1.8415 - val_acc: 0.4713\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4276 - acc: 0.7450 - val_loss: 1.8960 - val_acc: 0.4562\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4498 - acc: 0.7369 - val_loss: 2.1037 - val_acc: 0.4109\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5453 - acc: 0.7034 - val_loss: 1.9379 - val_acc: 0.4320\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4273 - acc: 0.7439 - val_loss: 1.8596 - val_acc: 0.4653\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3952 - acc: 0.7799 - val_loss: 1.8459 - val_acc: 0.4653\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3932 - acc: 0.7753 - val_loss: 1.8741 - val_acc: 0.4622\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3871 - acc: 0.7746 - val_loss: 1.8841 - val_acc: 0.4622\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3930 - acc: 0.7837 - val_loss: 1.9544 - val_acc: 0.4441\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4295 - acc: 0.7651 - val_loss: 2.0143 - val_acc: 0.4411\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4285 - acc: 0.7682 - val_loss: 1.9048 - val_acc: 0.4471\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4070 - acc: 0.7746 - val_loss: 1.8973 - val_acc: 0.4683\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4699 - acc: 0.7552 - val_loss: 1.8824 - val_acc: 0.4864\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5415 - acc: 0.7334 - val_loss: 1.7725 - val_acc: 0.4713\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4078 - acc: 0.7721 - val_loss: 1.7852 - val_acc: 0.4834\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4172 - acc: 0.7626 - val_loss: 1.8122 - val_acc: 0.5045\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4105 - acc: 0.7489 - val_loss: 1.8288 - val_acc: 0.4864\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3956 - acc: 0.7570 - val_loss: 1.8624 - val_acc: 0.4713\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4222 - acc: 0.7453 - val_loss: 1.8469 - val_acc: 0.4894\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3936 - acc: 0.7598 - val_loss: 1.8888 - val_acc: 0.4864\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3891 - acc: 0.7777 - val_loss: 1.8964 - val_acc: 0.4804\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4215 - acc: 0.7510 - val_loss: 1.9269 - val_acc: 0.4653\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.4312 - acc: 0.7253 - val_loss: 1.8375 - val_acc: 0.5015\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4050 - acc: 0.7460 - val_loss: 1.8320 - val_acc: 0.4985\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3807 - acc: 0.7813 - val_loss: 1.8336 - val_acc: 0.5196\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4287 - acc: 0.7555 - val_loss: 1.8142 - val_acc: 0.5257\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4607 - acc: 0.7485 - val_loss: 1.7641 - val_acc: 0.5136\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4566 - acc: 0.7485 - val_loss: 1.8318 - val_acc: 0.4924\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4472 - acc: 0.7665 - val_loss: 1.8622 - val_acc: 0.4743\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4095 - acc: 0.7767 - val_loss: 1.8434 - val_acc: 0.4894\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3940 - acc: 0.7816 - val_loss: 1.8340 - val_acc: 0.5076\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4204 - acc: 0.7809 - val_loss: 1.8766 - val_acc: 0.4834\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4145 - acc: 0.7809 - val_loss: 1.9592 - val_acc: 0.4502\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4298 - acc: 0.7636 - val_loss: 2.0410 - val_acc: 0.4471\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4358 - acc: 0.7640 - val_loss: 1.9440 - val_acc: 0.4471\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4210 - acc: 0.7806 - val_loss: 1.9472 - val_acc: 0.4441\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3954 - acc: 0.7732 - val_loss: 2.0098 - val_acc: 0.4592\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4091 - acc: 0.7809 - val_loss: 2.0102 - val_acc: 0.4683\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3999 - acc: 0.7739 - val_loss: 2.0146 - val_acc: 0.4743\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4123 - acc: 0.7644 - val_loss: 2.0089 - val_acc: 0.4532\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4391 - acc: 0.7397 - val_loss: 1.9650 - val_acc: 0.4804\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3936 - acc: 0.7696 - val_loss: 1.9260 - val_acc: 0.4985\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3798 - acc: 0.7714 - val_loss: 1.8969 - val_acc: 0.4894\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3833 - acc: 0.7753 - val_loss: 1.8800 - val_acc: 0.5045\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4224 - acc: 0.7503 - val_loss: 1.8189 - val_acc: 0.5438\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4705 - acc: 0.7284 - val_loss: 1.8372 - val_acc: 0.5045\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3775 - acc: 0.7763 - val_loss: 1.9182 - val_acc: 0.4773\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3795 - acc: 0.7922 - val_loss: 1.9325 - val_acc: 0.4804\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3789 - acc: 0.7749 - val_loss: 1.9508 - val_acc: 0.4653\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4076 - acc: 0.7728 - val_loss: 1.8995 - val_acc: 0.4955\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.5471 - acc: 0.7298 - val_loss: 1.8928 - val_acc: 0.4713\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4637 - acc: 0.7672 - val_loss: 1.9021 - val_acc: 0.4713\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3797 - acc: 0.7939 - val_loss: 2.0267 - val_acc: 0.4532\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4059 - acc: 0.7841 - val_loss: 2.3423 - val_acc: 0.3897\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.5095 - acc: 0.7309 - val_loss: 1.9452 - val_acc: 0.4683\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3905 - acc: 0.7880 - val_loss: 1.9022 - val_acc: 0.4804\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3667 - acc: 0.7887 - val_loss: 2.0079 - val_acc: 0.4773\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3764 - acc: 0.7865 - val_loss: 2.0198 - val_acc: 0.4864\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4135 - acc: 0.7721 - val_loss: 2.0355 - val_acc: 0.4622\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4555 - acc: 0.7411 - val_loss: 1.9568 - val_acc: 0.4773\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4180 - acc: 0.7570 - val_loss: 1.9449 - val_acc: 0.4834\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3770 - acc: 0.7784 - val_loss: 1.8947 - val_acc: 0.5015\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4030 - acc: 0.7622 - val_loss: 1.8772 - val_acc: 0.5136\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4080 - acc: 0.7619 - val_loss: 1.9304 - val_acc: 0.4804\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3663 - acc: 0.7929 - val_loss: 1.9420 - val_acc: 0.4743\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3778 - acc: 0.7837 - val_loss: 1.9463 - val_acc: 0.4985\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4092 - acc: 0.7601 - val_loss: 1.8828 - val_acc: 0.5015\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4952 - acc: 0.7429 - val_loss: 1.8773 - val_acc: 0.4804\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4770 - acc: 0.7626 - val_loss: 1.9695 - val_acc: 0.4532\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3947 - acc: 0.7862 - val_loss: 2.0381 - val_acc: 0.4532\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3765 - acc: 0.7922 - val_loss: 1.9892 - val_acc: 0.4592\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3834 - acc: 0.7915 - val_loss: 2.0466 - val_acc: 0.4471\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3752 - acc: 0.7932 - val_loss: 2.0566 - val_acc: 0.4471\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3889 - acc: 0.7813 - val_loss: 2.1400 - val_acc: 0.4471\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4048 - acc: 0.7682 - val_loss: 2.1278 - val_acc: 0.4230\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4013 - acc: 0.7795 - val_loss: 2.0542 - val_acc: 0.4683\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3581 - acc: 0.7961 - val_loss: 2.0720 - val_acc: 0.4713\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3875 - acc: 0.7929 - val_loss: 2.1034 - val_acc: 0.4622\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4284 - acc: 0.7552 - val_loss: 2.1436 - val_acc: 0.4411\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4291 - acc: 0.7443 - val_loss: 2.0003 - val_acc: 0.4592\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3906 - acc: 0.7781 - val_loss: 1.9909 - val_acc: 0.4773\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3623 - acc: 0.7876 - val_loss: 2.0781 - val_acc: 0.4804\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4174 - acc: 0.7566 - val_loss: 2.0728 - val_acc: 0.4622\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3713 - acc: 0.7802 - val_loss: 2.0748 - val_acc: 0.4592\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3700 - acc: 0.7883 - val_loss: 2.1039 - val_acc: 0.4804\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3691 - acc: 0.7865 - val_loss: 2.0445 - val_acc: 0.4804\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.4476 - acc: 0.7256 - val_loss: 2.0244 - val_acc: 0.4894\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.5217 - acc: 0.6946 - val_loss: 1.9109 - val_acc: 0.5106\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.3635 - acc: 0.7756 - val_loss: 1.9713 - val_acc: 0.4713\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3581 - acc: 0.7869 - val_loss: 2.0186 - val_acc: 0.4773\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3559 - acc: 0.8035 - val_loss: 2.0004 - val_acc: 0.4804\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3668 - acc: 0.7975 - val_loss: 1.9988 - val_acc: 0.4864\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3990 - acc: 0.7774 - val_loss: 1.9981 - val_acc: 0.4955\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4544 - acc: 0.7672 - val_loss: 1.9834 - val_acc: 0.4773\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4068 - acc: 0.7908 - val_loss: 1.9358 - val_acc: 0.4894\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3611 - acc: 0.7957 - val_loss: 1.9655 - val_acc: 0.4804\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3562 - acc: 0.8017 - val_loss: 1.9691 - val_acc: 0.4924\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4177 - acc: 0.7538 - val_loss: 1.9626 - val_acc: 0.5076\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4068 - acc: 0.7503 - val_loss: 1.9980 - val_acc: 0.4834\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3717 - acc: 0.7813 - val_loss: 1.9997 - val_acc: 0.4834\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 51us/step - loss: 0.3478 - acc: 0.8027 - val_loss: 1.9905 - val_acc: 0.4924\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.3353 - acc: 0.8130 - val_loss: 2.0261 - val_acc: 0.4864\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3511 - acc: 0.7820 - val_loss: 1.9712 - val_acc: 0.4955\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3542 - acc: 0.7880 - val_loss: 2.0147 - val_acc: 0.4804\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4098 - acc: 0.7728 - val_loss: 2.0384 - val_acc: 0.5015\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.5212 - acc: 0.7485 - val_loss: 2.0184 - val_acc: 0.4834\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3920 - acc: 0.7851 - val_loss: 2.0470 - val_acc: 0.4532\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3601 - acc: 0.8027 - val_loss: 2.1042 - val_acc: 0.4471\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3811 - acc: 0.7968 - val_loss: 2.1580 - val_acc: 0.4441\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3639 - acc: 0.7999 - val_loss: 2.0899 - val_acc: 0.4592\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3421 - acc: 0.7992 - val_loss: 2.1847 - val_acc: 0.4592\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3473 - acc: 0.8024 - val_loss: 2.1488 - val_acc: 0.4532\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3433 - acc: 0.8038 - val_loss: 2.1781 - val_acc: 0.4562\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3564 - acc: 0.7904 - val_loss: 2.1492 - val_acc: 0.4441\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3672 - acc: 0.7915 - val_loss: 2.2231 - val_acc: 0.4320\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4295 - acc: 0.7636 - val_loss: 2.1492 - val_acc: 0.4471\n",
      "Epoch 708/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4593 - acc: 0.7675 - val_loss: 2.0254 - val_acc: 0.4743\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4742 - acc: 0.7672 - val_loss: 1.9186 - val_acc: 0.4834\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4174 - acc: 0.7806 - val_loss: 1.9461 - val_acc: 0.4743\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3342 - acc: 0.8052 - val_loss: 2.0130 - val_acc: 0.4804\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3297 - acc: 0.8144 - val_loss: 2.0166 - val_acc: 0.4894\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3269 - acc: 0.8101 - val_loss: 2.0778 - val_acc: 0.4562\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3267 - acc: 0.8091 - val_loss: 2.0878 - val_acc: 0.4743\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3433 - acc: 0.7992 - val_loss: 2.0977 - val_acc: 0.4743\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3902 - acc: 0.7707 - val_loss: 2.1056 - val_acc: 0.4834\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4504 - acc: 0.7418 - val_loss: 2.1126 - val_acc: 0.4834\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3973 - acc: 0.7619 - val_loss: 2.1180 - val_acc: 0.4713\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3557 - acc: 0.7957 - val_loss: 2.1705 - val_acc: 0.4532\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3344 - acc: 0.7968 - val_loss: 2.1423 - val_acc: 0.4713\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3510 - acc: 0.7978 - val_loss: 2.1619 - val_acc: 0.4713\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3771 - acc: 0.7932 - val_loss: 2.2466 - val_acc: 0.4592\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3846 - acc: 0.7830 - val_loss: 2.1922 - val_acc: 0.4320\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3809 - acc: 0.7929 - val_loss: 2.1061 - val_acc: 0.4773\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3562 - acc: 0.7943 - val_loss: 2.1174 - val_acc: 0.4653\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3404 - acc: 0.8042 - val_loss: 2.1251 - val_acc: 0.4804\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3312 - acc: 0.8182 - val_loss: 2.1803 - val_acc: 0.4713\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3778 - acc: 0.7872 - val_loss: 2.3148 - val_acc: 0.4441\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4336 - acc: 0.7661 - val_loss: 2.1758 - val_acc: 0.4411\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3669 - acc: 0.7975 - val_loss: 2.1146 - val_acc: 0.4562\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3370 - acc: 0.8228 - val_loss: 2.2305 - val_acc: 0.4502\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3542 - acc: 0.7992 - val_loss: 2.1441 - val_acc: 0.4653\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3471 - acc: 0.8084 - val_loss: 2.1971 - val_acc: 0.4592\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3498 - acc: 0.8038 - val_loss: 2.2845 - val_acc: 0.4381\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3750 - acc: 0.7862 - val_loss: 2.3024 - val_acc: 0.4471\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4568 - acc: 0.7679 - val_loss: 2.2135 - val_acc: 0.4502\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3915 - acc: 0.7665 - val_loss: 2.0750 - val_acc: 0.4834\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3621 - acc: 0.7890 - val_loss: 2.0944 - val_acc: 0.4713\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3609 - acc: 0.7865 - val_loss: 2.1039 - val_acc: 0.4864\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3534 - acc: 0.7855 - val_loss: 2.0848 - val_acc: 0.4713\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3235 - acc: 0.8158 - val_loss: 2.1457 - val_acc: 0.4683\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3256 - acc: 0.8101 - val_loss: 2.1805 - val_acc: 0.4622\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3195 - acc: 0.8179 - val_loss: 2.1099 - val_acc: 0.4924\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3430 - acc: 0.7929 - val_loss: 2.1021 - val_acc: 0.4985\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4466 - acc: 0.7415 - val_loss: 2.0130 - val_acc: 0.5408\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3930 - acc: 0.7629 - val_loss: 2.0833 - val_acc: 0.4683\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3792 - acc: 0.7975 - val_loss: 2.1131 - val_acc: 0.4683\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3906 - acc: 0.7996 - val_loss: 2.1326 - val_acc: 0.4622\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3637 - acc: 0.8154 - val_loss: 2.1122 - val_acc: 0.4713\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3033 - acc: 0.8263 - val_loss: 2.1391 - val_acc: 0.4653\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3172 - acc: 0.8204 - val_loss: 2.1778 - val_acc: 0.4713\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3181 - acc: 0.8154 - val_loss: 2.1321 - val_acc: 0.5015\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3366 - acc: 0.8091 - val_loss: 2.1398 - val_acc: 0.5166\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.4251 - acc: 0.7584 - val_loss: 2.1208 - val_acc: 0.5045\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3765 - acc: 0.7718 - val_loss: 2.1371 - val_acc: 0.4713\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3271 - acc: 0.8010 - val_loss: 2.2040 - val_acc: 0.4773\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3292 - acc: 0.8027 - val_loss: 2.2219 - val_acc: 0.4532\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.3307 - acc: 0.8070 - val_loss: 2.3374 - val_acc: 0.4411\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.4324 - acc: 0.7700 - val_loss: 2.3351 - val_acc: 0.4502\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.4064 - acc: 0.7651 - val_loss: 2.1200 - val_acc: 0.4894\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3221 - acc: 0.8239 - val_loss: 2.2067 - val_acc: 0.4653\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3255 - acc: 0.8140 - val_loss: 2.3585 - val_acc: 0.4441\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.3458 - acc: 0.8070 - val_loss: 2.2681 - val_acc: 0.4471\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3392 - acc: 0.8218 - val_loss: 2.3278 - val_acc: 0.4713\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4061 - acc: 0.7872 - val_loss: 2.2497 - val_acc: 0.4592\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4353 - acc: 0.7869 - val_loss: 2.1331 - val_acc: 0.4653\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3093 - acc: 0.8249 - val_loss: 2.1904 - val_acc: 0.4653\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3075 - acc: 0.8207 - val_loss: 2.2085 - val_acc: 0.4924\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3127 - acc: 0.8221 - val_loss: 2.3771 - val_acc: 0.4502\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3518 - acc: 0.7999 - val_loss: 2.3950 - val_acc: 0.4411\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3851 - acc: 0.7915 - val_loss: 2.2933 - val_acc: 0.4683\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3323 - acc: 0.8168 - val_loss: 2.2767 - val_acc: 0.4653\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3017 - acc: 0.8323 - val_loss: 2.2727 - val_acc: 0.4502\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3392 - acc: 0.8256 - val_loss: 2.3863 - val_acc: 0.4320\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.4055 - acc: 0.7763 - val_loss: 2.2689 - val_acc: 0.4592\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3539 - acc: 0.8045 - val_loss: 2.2509 - val_acc: 0.4532\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3530 - acc: 0.8017 - val_loss: 2.3019 - val_acc: 0.4713\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3298 - acc: 0.8161 - val_loss: 2.3727 - val_acc: 0.4683\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3499 - acc: 0.8161 - val_loss: 2.2273 - val_acc: 0.4773\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3242 - acc: 0.8168 - val_loss: 2.2675 - val_acc: 0.4592\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3490 - acc: 0.8070 - val_loss: 2.2376 - val_acc: 0.4864\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3667 - acc: 0.8020 - val_loss: 2.2153 - val_acc: 0.4894\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.4024 - acc: 0.7950 - val_loss: 2.1077 - val_acc: 0.5045\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3738 - acc: 0.8031 - val_loss: 2.1470 - val_acc: 0.4743\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3245 - acc: 0.8186 - val_loss: 2.2874 - val_acc: 0.4653\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3051 - acc: 0.8418 - val_loss: 2.3692 - val_acc: 0.4562\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3358 - acc: 0.8137 - val_loss: 2.4637 - val_acc: 0.4381\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3452 - acc: 0.8006 - val_loss: 2.4344 - val_acc: 0.4441\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3399 - acc: 0.8101 - val_loss: 2.3357 - val_acc: 0.4622\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3458 - acc: 0.8098 - val_loss: 2.3321 - val_acc: 0.4411\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3298 - acc: 0.8200 - val_loss: 2.2825 - val_acc: 0.4592\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.3199 - acc: 0.8309 - val_loss: 2.2922 - val_acc: 0.4653\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3245 - acc: 0.8200 - val_loss: 2.3505 - val_acc: 0.4773\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3545 - acc: 0.8084 - val_loss: 2.2747 - val_acc: 0.4804\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4200 - acc: 0.8013 - val_loss: 2.1613 - val_acc: 0.5045\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3813 - acc: 0.8105 - val_loss: 2.1384 - val_acc: 0.5076\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3459 - acc: 0.8080 - val_loss: 2.1093 - val_acc: 0.5076\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3095 - acc: 0.8091 - val_loss: 2.2115 - val_acc: 0.4804\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3162 - acc: 0.8225 - val_loss: 2.2272 - val_acc: 0.4924\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3094 - acc: 0.8133 - val_loss: 2.2352 - val_acc: 0.4955\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3068 - acc: 0.8077 - val_loss: 2.2154 - val_acc: 0.4834\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3211 - acc: 0.8052 - val_loss: 2.2081 - val_acc: 0.5196\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3522 - acc: 0.7820 - val_loss: 2.1730 - val_acc: 0.5045\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3663 - acc: 0.7816 - val_loss: 2.1642 - val_acc: 0.5378\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3674 - acc: 0.7820 - val_loss: 2.2266 - val_acc: 0.4773\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3194 - acc: 0.8161 - val_loss: 2.2794 - val_acc: 0.4653\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3445 - acc: 0.8035 - val_loss: 2.3030 - val_acc: 0.4381\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4159 - acc: 0.7890 - val_loss: 2.3946 - val_acc: 0.4199\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3975 - acc: 0.7806 - val_loss: 2.1716 - val_acc: 0.4683\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3216 - acc: 0.8147 - val_loss: 2.1981 - val_acc: 0.4773\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2824 - acc: 0.8390 - val_loss: 2.2809 - val_acc: 0.4804\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2982 - acc: 0.8271 - val_loss: 2.3125 - val_acc: 0.4743\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3167 - acc: 0.8320 - val_loss: 2.3009 - val_acc: 0.4804\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3376 - acc: 0.8292 - val_loss: 2.2649 - val_acc: 0.4985\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3202 - acc: 0.8179 - val_loss: 2.2484 - val_acc: 0.4985\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3085 - acc: 0.8281 - val_loss: 2.3161 - val_acc: 0.4653\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3169 - acc: 0.8260 - val_loss: 2.4875 - val_acc: 0.4471\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3834 - acc: 0.7918 - val_loss: 2.5968 - val_acc: 0.4169\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4065 - acc: 0.7742 - val_loss: 2.3324 - val_acc: 0.4622\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3417 - acc: 0.8204 - val_loss: 2.3010 - val_acc: 0.4773\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2888 - acc: 0.8337 - val_loss: 2.3297 - val_acc: 0.4864\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2880 - acc: 0.8426 - val_loss: 2.3518 - val_acc: 0.4743\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2952 - acc: 0.8313 - val_loss: 2.3684 - val_acc: 0.4773\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3399 - acc: 0.8232 - val_loss: 2.2845 - val_acc: 0.4985\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3674 - acc: 0.8084 - val_loss: 2.2412 - val_acc: 0.4834\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3097 - acc: 0.8369 - val_loss: 2.2644 - val_acc: 0.4955\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3268 - acc: 0.8344 - val_loss: 2.3361 - val_acc: 0.4713\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2924 - acc: 0.8355 - val_loss: 2.3124 - val_acc: 0.4955\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2998 - acc: 0.8295 - val_loss: 2.3831 - val_acc: 0.4683\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3455 - acc: 0.8161 - val_loss: 2.4718 - val_acc: 0.4502\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3879 - acc: 0.7943 - val_loss: 2.4282 - val_acc: 0.4411\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3509 - acc: 0.8024 - val_loss: 2.2824 - val_acc: 0.4834\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2847 - acc: 0.8390 - val_loss: 2.3315 - val_acc: 0.4864\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2827 - acc: 0.8397 - val_loss: 2.3185 - val_acc: 0.5076\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2964 - acc: 0.8433 - val_loss: 2.2926 - val_acc: 0.4955\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2965 - acc: 0.8323 - val_loss: 2.1893 - val_acc: 0.5196\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3216 - acc: 0.8108 - val_loss: 2.2565 - val_acc: 0.5196\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3847 - acc: 0.7971 - val_loss: 2.1698 - val_acc: 0.5196\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.4297 - acc: 0.7732 - val_loss: 2.2618 - val_acc: 0.5076\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3223 - acc: 0.8295 - val_loss: 2.3673 - val_acc: 0.4804\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3065 - acc: 0.8344 - val_loss: 2.3738 - val_acc: 0.4622\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2894 - acc: 0.8401 - val_loss: 2.3272 - val_acc: 0.4713\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2942 - acc: 0.8341 - val_loss: 2.4531 - val_acc: 0.4471\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3155 - acc: 0.8207 - val_loss: 2.5755 - val_acc: 0.4381\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3744 - acc: 0.8020 - val_loss: 2.4715 - val_acc: 0.4471\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3679 - acc: 0.8010 - val_loss: 2.3504 - val_acc: 0.4622\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3386 - acc: 0.8337 - val_loss: 2.3013 - val_acc: 0.4985\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3257 - acc: 0.8249 - val_loss: 2.3031 - val_acc: 0.4894\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3095 - acc: 0.8330 - val_loss: 2.3382 - val_acc: 0.4834\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2916 - acc: 0.8355 - val_loss: 2.3081 - val_acc: 0.5015\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3204 - acc: 0.8327 - val_loss: 2.3684 - val_acc: 0.4713\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3605 - acc: 0.8172 - val_loss: 2.2516 - val_acc: 0.4955\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3525 - acc: 0.8098 - val_loss: 2.2683 - val_acc: 0.5045\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2861 - acc: 0.8320 - val_loss: 2.3051 - val_acc: 0.4804\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2671 - acc: 0.8549 - val_loss: 2.4515 - val_acc: 0.4592\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3245 - acc: 0.8232 - val_loss: 2.5633 - val_acc: 0.4441\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4310 - acc: 0.7830 - val_loss: 2.4037 - val_acc: 0.4441\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3478 - acc: 0.8214 - val_loss: 2.2773 - val_acc: 0.4834\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3033 - acc: 0.8288 - val_loss: 2.3122 - val_acc: 0.4834\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2741 - acc: 0.8514 - val_loss: 2.3668 - val_acc: 0.4653\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2672 - acc: 0.8454 - val_loss: 2.3868 - val_acc: 0.4622\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3073 - acc: 0.8274 - val_loss: 2.4008 - val_acc: 0.4743\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3060 - acc: 0.8197 - val_loss: 2.4606 - val_acc: 0.4532\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3552 - acc: 0.7904 - val_loss: 2.5897 - val_acc: 0.4260\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4130 - acc: 0.7742 - val_loss: 2.3648 - val_acc: 0.4743\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3525 - acc: 0.8101 - val_loss: 2.3780 - val_acc: 0.4713\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2787 - acc: 0.8408 - val_loss: 2.4383 - val_acc: 0.4653\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2891 - acc: 0.8316 - val_loss: 2.5767 - val_acc: 0.4471\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2990 - acc: 0.8366 - val_loss: 2.5266 - val_acc: 0.4471\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3457 - acc: 0.8123 - val_loss: 2.5247 - val_acc: 0.4350\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3341 - acc: 0.8232 - val_loss: 2.4040 - val_acc: 0.4804\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2836 - acc: 0.8426 - val_loss: 2.4382 - val_acc: 0.4924\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2977 - acc: 0.8415 - val_loss: 2.4265 - val_acc: 0.4834\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3464 - acc: 0.8285 - val_loss: 2.4139 - val_acc: 0.4955\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3118 - acc: 0.8355 - val_loss: 2.4642 - val_acc: 0.4713\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2919 - acc: 0.8390 - val_loss: 2.4809 - val_acc: 0.4773\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3250 - acc: 0.8207 - val_loss: 2.5382 - val_acc: 0.4411\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3338 - acc: 0.8172 - val_loss: 2.4406 - val_acc: 0.4773\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3145 - acc: 0.8288 - val_loss: 2.5136 - val_acc: 0.4562\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3109 - acc: 0.8341 - val_loss: 2.4737 - val_acc: 0.4773\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2825 - acc: 0.8380 - val_loss: 2.4729 - val_acc: 0.4562\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2753 - acc: 0.8482 - val_loss: 2.5255 - val_acc: 0.4864\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3142 - acc: 0.8299 - val_loss: 2.5651 - val_acc: 0.4411\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3312 - acc: 0.8235 - val_loss: 2.5062 - val_acc: 0.4713\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3745 - acc: 0.8207 - val_loss: 2.3377 - val_acc: 0.4985\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3128 - acc: 0.8320 - val_loss: 2.3241 - val_acc: 0.4894\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3421 - acc: 0.8253 - val_loss: 2.3239 - val_acc: 0.5045\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3146 - acc: 0.8309 - val_loss: 2.3437 - val_acc: 0.5106\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3210 - acc: 0.8320 - val_loss: 2.3449 - val_acc: 0.5045\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2601 - acc: 0.8524 - val_loss: 2.4241 - val_acc: 0.5136\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2690 - acc: 0.8482 - val_loss: 2.5053 - val_acc: 0.5015\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2834 - acc: 0.8362 - val_loss: 2.5479 - val_acc: 0.4683\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.3297 - acc: 0.8249 - val_loss: 2.6068 - val_acc: 0.4532\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3528 - acc: 0.8020 - val_loss: 2.5544 - val_acc: 0.4562\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3091 - acc: 0.8327 - val_loss: 2.6588 - val_acc: 0.4532\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3026 - acc: 0.8242 - val_loss: 2.5133 - val_acc: 0.4562\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2910 - acc: 0.8387 - val_loss: 2.5008 - val_acc: 0.4683\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2941 - acc: 0.8380 - val_loss: 2.5252 - val_acc: 0.4532\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2832 - acc: 0.8366 - val_loss: 2.4734 - val_acc: 0.4713\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3078 - acc: 0.8256 - val_loss: 2.5290 - val_acc: 0.4713\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2836 - acc: 0.8411 - val_loss: 2.6041 - val_acc: 0.4502\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.3433 - acc: 0.8091 - val_loss: 2.7088 - val_acc: 0.4169\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3823 - acc: 0.8049 - val_loss: 2.5046 - val_acc: 0.4532\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3084 - acc: 0.8285 - val_loss: 2.4250 - val_acc: 0.5015\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3056 - acc: 0.8337 - val_loss: 2.4298 - val_acc: 0.5045\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2946 - acc: 0.8418 - val_loss: 2.4856 - val_acc: 0.4924\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.2983 - acc: 0.8422 - val_loss: 2.4836 - val_acc: 0.4834\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.3293 - acc: 0.8271 - val_loss: 2.3042 - val_acc: 0.4985\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.3178 - acc: 0.8246 - val_loss: 2.3569 - val_acc: 0.4985\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.2829 - acc: 0.8352 - val_loss: 2.4603 - val_acc: 0.4804\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2997 - acc: 0.8140 - val_loss: 2.3754 - val_acc: 0.5136\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2761 - acc: 0.8306 - val_loss: 2.4352 - val_acc: 0.4894\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2718 - acc: 0.8362 - val_loss: 2.3524 - val_acc: 0.5227\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3007 - acc: 0.8218 - val_loss: 2.3403 - val_acc: 0.5287\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3196 - acc: 0.8137 - val_loss: 2.3908 - val_acc: 0.5227\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2790 - acc: 0.8337 - val_loss: 2.5035 - val_acc: 0.5045\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2865 - acc: 0.8376 - val_loss: 2.6125 - val_acc: 0.4713\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3018 - acc: 0.8461 - val_loss: 2.5129 - val_acc: 0.4683\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2887 - acc: 0.8524 - val_loss: 2.4802 - val_acc: 0.4804\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2750 - acc: 0.8496 - val_loss: 2.5170 - val_acc: 0.4622\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2785 - acc: 0.8299 - val_loss: 2.5433 - val_acc: 0.4622\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2824 - acc: 0.8348 - val_loss: 2.6111 - val_acc: 0.4592\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2838 - acc: 0.8457 - val_loss: 2.4937 - val_acc: 0.4743\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3426 - acc: 0.8042 - val_loss: 2.5595 - val_acc: 0.4653\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4041 - acc: 0.7700 - val_loss: 2.4520 - val_acc: 0.4924\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3231 - acc: 0.8010 - val_loss: 2.5175 - val_acc: 0.4743\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2757 - acc: 0.8433 - val_loss: 2.6132 - val_acc: 0.4532\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2830 - acc: 0.8418 - val_loss: 2.5575 - val_acc: 0.4562\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2728 - acc: 0.8461 - val_loss: 2.5161 - val_acc: 0.4773\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2703 - acc: 0.8443 - val_loss: 2.4636 - val_acc: 0.5136\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3133 - acc: 0.8249 - val_loss: 2.4581 - val_acc: 0.5196\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3907 - acc: 0.7718 - val_loss: 2.3560 - val_acc: 0.5347\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3228 - acc: 0.8035 - val_loss: 2.4824 - val_acc: 0.4955\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2523 - acc: 0.8542 - val_loss: 2.5464 - val_acc: 0.4773\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2609 - acc: 0.8573 - val_loss: 2.5738 - val_acc: 0.4683\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2608 - acc: 0.8514 - val_loss: 2.5005 - val_acc: 0.4924\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2700 - acc: 0.8397 - val_loss: 2.5558 - val_acc: 0.4653\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2880 - acc: 0.8411 - val_loss: 2.4944 - val_acc: 0.5076\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3651 - acc: 0.8161 - val_loss: 2.5676 - val_acc: 0.4683\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3770 - acc: 0.8091 - val_loss: 2.5358 - val_acc: 0.4743\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.2845 - acc: 0.8510 - val_loss: 2.5507 - val_acc: 0.4804\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2541 - acc: 0.8521 - val_loss: 2.6603 - val_acc: 0.4683\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2761 - acc: 0.8545 - val_loss: 2.6639 - val_acc: 0.4864\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2662 - acc: 0.8510 - val_loss: 2.6738 - val_acc: 0.4743\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2673 - acc: 0.8514 - val_loss: 2.6615 - val_acc: 0.4683\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2650 - acc: 0.8559 - val_loss: 2.8272 - val_acc: 0.4502\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3603 - acc: 0.8087 - val_loss: 2.7838 - val_acc: 0.4320\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3383 - acc: 0.8175 - val_loss: 2.5438 - val_acc: 0.4924\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2788 - acc: 0.8489 - val_loss: 2.5466 - val_acc: 0.4743\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2646 - acc: 0.8591 - val_loss: 2.4638 - val_acc: 0.4773\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2720 - acc: 0.8390 - val_loss: 2.5800 - val_acc: 0.4381\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2655 - acc: 0.8334 - val_loss: 2.5852 - val_acc: 0.4532\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2540 - acc: 0.8489 - val_loss: 2.5739 - val_acc: 0.4773\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.3080 - acc: 0.8161 - val_loss: 2.5246 - val_acc: 0.4864\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3391 - acc: 0.7932 - val_loss: 2.4670 - val_acc: 0.4955\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2660 - acc: 0.8376 - val_loss: 2.5061 - val_acc: 0.5076\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2677 - acc: 0.8492 - val_loss: 2.4793 - val_acc: 0.5045\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2956 - acc: 0.8366 - val_loss: 2.5754 - val_acc: 0.4924\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2985 - acc: 0.8524 - val_loss: 2.5879 - val_acc: 0.4985\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3224 - acc: 0.8447 - val_loss: 2.6153 - val_acc: 0.4773\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2841 - acc: 0.8489 - val_loss: 2.6701 - val_acc: 0.4773\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2512 - acc: 0.8559 - val_loss: 2.7014 - val_acc: 0.4683\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2568 - acc: 0.8588 - val_loss: 2.7063 - val_acc: 0.4502\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2897 - acc: 0.8278 - val_loss: 2.6574 - val_acc: 0.4683\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2727 - acc: 0.8507 - val_loss: 2.6333 - val_acc: 0.4562\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2531 - acc: 0.8573 - val_loss: 2.6723 - val_acc: 0.4532\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2771 - acc: 0.8450 - val_loss: 2.6258 - val_acc: 0.4592\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2677 - acc: 0.8492 - val_loss: 2.6195 - val_acc: 0.4653\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3653 - acc: 0.7883 - val_loss: 2.5791 - val_acc: 0.4773\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3651 - acc: 0.7756 - val_loss: 2.4601 - val_acc: 0.4834\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2635 - acc: 0.8443 - val_loss: 2.5795 - val_acc: 0.4743\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2739 - acc: 0.8499 - val_loss: 2.4844 - val_acc: 0.5076\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2624 - acc: 0.8461 - val_loss: 2.5795 - val_acc: 0.4924\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2411 - acc: 0.8662 - val_loss: 2.6032 - val_acc: 0.4834\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2490 - acc: 0.8651 - val_loss: 2.6169 - val_acc: 0.4743\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2579 - acc: 0.8623 - val_loss: 2.6151 - val_acc: 0.4834\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2748 - acc: 0.8542 - val_loss: 2.6185 - val_acc: 0.5015\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3829 - acc: 0.8137 - val_loss: 2.4911 - val_acc: 0.4864\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3009 - acc: 0.8376 - val_loss: 2.5143 - val_acc: 0.4894\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2772 - acc: 0.8471 - val_loss: 2.5508 - val_acc: 0.4773\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2809 - acc: 0.8274 - val_loss: 2.4939 - val_acc: 0.5166\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3143 - acc: 0.8070 - val_loss: 2.4792 - val_acc: 0.5045\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2765 - acc: 0.8260 - val_loss: 2.5369 - val_acc: 0.4804\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2430 - acc: 0.8644 - val_loss: 2.6171 - val_acc: 0.4864\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2500 - acc: 0.8644 - val_loss: 2.5732 - val_acc: 0.4773\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.2519 - acc: 0.8580 - val_loss: 2.5631 - val_acc: 0.5045\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2942 - acc: 0.8334 - val_loss: 2.5270 - val_acc: 0.4773\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.3119 - acc: 0.8112 - val_loss: 2.4245 - val_acc: 0.5196\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2918 - acc: 0.8285 - val_loss: 2.5649 - val_acc: 0.4683\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.3130 - acc: 0.8017 - val_loss: 2.5516 - val_acc: 0.4834\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2788 - acc: 0.8366 - val_loss: 2.7193 - val_acc: 0.4381\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2999 - acc: 0.8313 - val_loss: 2.6665 - val_acc: 0.4592\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.3134 - acc: 0.8323 - val_loss: 2.6353 - val_acc: 0.4713\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2808 - acc: 0.8454 - val_loss: 2.5920 - val_acc: 0.5015\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2543 - acc: 0.8623 - val_loss: 2.5568 - val_acc: 0.4924\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2339 - acc: 0.8623 - val_loss: 2.5485 - val_acc: 0.4955\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2981 - acc: 0.8306 - val_loss: 2.6192 - val_acc: 0.4622\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.4045 - acc: 0.7665 - val_loss: 2.4774 - val_acc: 0.4955\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.2882 - acc: 0.8218 - val_loss: 2.5212 - val_acc: 0.4955\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2381 - acc: 0.8475 - val_loss: 2.5785 - val_acc: 0.4834\n"
     ]
    }
   ],
   "source": [
    "business_model_2 = model.fit(x=X_train_business, y=y_cat_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_cat_test_business),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "0.7313432835820896\n",
      "0.9402985074626866\n",
      "26\n",
      "0.7692307692307693\n",
      "0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_business)\n",
    "model_metrics(predictions, y_cat_test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMLKYUDAMwzCymFAwDMMwsvw/3bY0CV0QOG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838c35c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(business_model_2.history['acc'])\n",
    "plt.plot(business_model_2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 4s 2ms/step - loss: 1.9334 - acc: 0.1599 - val_loss: 1.5912 - val_acc: 0.0695\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 1.4178 - acc: 0.2434 - val_loss: 1.5054 - val_acc: 0.3082\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.3628 - acc: 0.3057 - val_loss: 1.4886 - val_acc: 0.3263\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.3520 - acc: 0.3145 - val_loss: 1.4878 - val_acc: 0.3051\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.3197 - acc: 0.3396 - val_loss: 1.4820 - val_acc: 0.3021\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.3304 - acc: 0.3279 - val_loss: 1.4832 - val_acc: 0.3293\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.3283 - acc: 0.3258 - val_loss: 1.4875 - val_acc: 0.2719\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.3197 - acc: 0.3343 - val_loss: 1.5097 - val_acc: 0.2145\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.3220 - acc: 0.3117 - val_loss: 1.4544 - val_acc: 0.3051\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.2885 - acc: 0.3572 - val_loss: 1.4625 - val_acc: 0.3233\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 1.2931 - acc: 0.3455 - val_loss: 1.4220 - val_acc: 0.3263\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.2757 - acc: 0.3688 - val_loss: 1.4477 - val_acc: 0.3293\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.2859 - acc: 0.3635 - val_loss: 1.4089 - val_acc: 0.3293\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2947 - acc: 0.3667 - val_loss: 1.3930 - val_acc: 0.3233\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.2626 - acc: 0.3706 - val_loss: 1.3756 - val_acc: 0.3293\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.2522 - acc: 0.3783 - val_loss: 1.4548 - val_acc: 0.3233\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 1.2567 - acc: 0.3586 - val_loss: 1.3914 - val_acc: 0.3263\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.2465 - acc: 0.3741 - val_loss: 1.3482 - val_acc: 0.3263\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.2589 - acc: 0.3670 - val_loss: 1.3511 - val_acc: 0.3293\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.2322 - acc: 0.3963 - val_loss: 1.3585 - val_acc: 0.3082\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.2417 - acc: 0.3850 - val_loss: 1.3520 - val_acc: 0.3202\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.2293 - acc: 0.3839 - val_loss: 1.3506 - val_acc: 0.3021\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.2193 - acc: 0.3843 - val_loss: 1.3308 - val_acc: 0.3263\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.2761 - acc: 0.3600 - val_loss: 1.3799 - val_acc: 0.3263\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.2049 - acc: 0.3970 - val_loss: 1.3775 - val_acc: 0.3082\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2050 - acc: 0.3861 - val_loss: 1.3936 - val_acc: 0.2628\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.2134 - acc: 0.3720 - val_loss: 1.3986 - val_acc: 0.2659\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.2328 - acc: 0.3625 - val_loss: 1.4782 - val_acc: 0.2054\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.2223 - acc: 0.3237 - val_loss: 1.4139 - val_acc: 0.3021\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.2024 - acc: 0.3776 - val_loss: 1.4234 - val_acc: 0.2659\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1897 - acc: 0.3607 - val_loss: 1.4240 - val_acc: 0.3082\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1776 - acc: 0.4008 - val_loss: 1.4270 - val_acc: 0.2840\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.1771 - acc: 0.3741 - val_loss: 1.3562 - val_acc: 0.3021\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 1.1914 - acc: 0.3959 - val_loss: 1.4763 - val_acc: 0.1813\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.2297 - acc: 0.3153 - val_loss: 1.3466 - val_acc: 0.2991\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1593 - acc: 0.3938 - val_loss: 1.4258 - val_acc: 0.2508\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.1643 - acc: 0.3765 - val_loss: 1.4182 - val_acc: 0.2749\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.1714 - acc: 0.3896 - val_loss: 1.4011 - val_acc: 0.2538\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1715 - acc: 0.3730 - val_loss: 1.5126 - val_acc: 0.1903\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1963 - acc: 0.3318 - val_loss: 1.3735 - val_acc: 0.2870\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.1459 - acc: 0.3977 - val_loss: 1.3935 - val_acc: 0.2900\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.1615 - acc: 0.3991 - val_loss: 1.4431 - val_acc: 0.2538\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1471 - acc: 0.3751 - val_loss: 1.4143 - val_acc: 0.2779\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1446 - acc: 0.3846 - val_loss: 1.4262 - val_acc: 0.2779\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1519 - acc: 0.3945 - val_loss: 1.4778 - val_acc: 0.2628\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.1485 - acc: 0.3815 - val_loss: 1.3959 - val_acc: 0.3202\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.2050 - acc: 0.3772 - val_loss: 1.3699 - val_acc: 0.3051\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.1395 - acc: 0.4072 - val_loss: 1.4028 - val_acc: 0.2779\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1326 - acc: 0.3927 - val_loss: 1.3836 - val_acc: 0.2840\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.1233 - acc: 0.3913 - val_loss: 1.4160 - val_acc: 0.2266\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.1436 - acc: 0.3540 - val_loss: 1.4318 - val_acc: 0.2689\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1192 - acc: 0.3861 - val_loss: 1.3587 - val_acc: 0.3051\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.1079 - acc: 0.4142 - val_loss: 1.4530 - val_acc: 0.2810\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1394 - acc: 0.4015 - val_loss: 1.4945 - val_acc: 0.2477\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.1223 - acc: 0.3720 - val_loss: 1.3561 - val_acc: 0.2870\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1356 - acc: 0.4015 - val_loss: 1.3924 - val_acc: 0.2508\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1307 - acc: 0.3839 - val_loss: 1.3128 - val_acc: 0.3021\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0992 - acc: 0.4079 - val_loss: 1.3002 - val_acc: 0.3082\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.1015 - acc: 0.4107 - val_loss: 1.2420 - val_acc: 0.3263\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 60us/step - loss: 1.1470 - acc: 0.4111 - val_loss: 1.3128 - val_acc: 0.3112\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.0802 - acc: 0.4251 - val_loss: 1.3074 - val_acc: 0.3051\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0650 - acc: 0.4170 - val_loss: 1.3458 - val_acc: 0.3233\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 1.1162 - acc: 0.4068 - val_loss: 1.3006 - val_acc: 0.3172\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 1.0862 - acc: 0.4343 - val_loss: 1.2513 - val_acc: 0.3353\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.1017 - acc: 0.4058 - val_loss: 1.2398 - val_acc: 0.3474\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 1.1302 - acc: 0.4399 - val_loss: 1.3537 - val_acc: 0.2961\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0991 - acc: 0.4146 - val_loss: 1.3222 - val_acc: 0.3082\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0818 - acc: 0.4336 - val_loss: 1.2623 - val_acc: 0.3323\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0728 - acc: 0.4354 - val_loss: 1.2231 - val_acc: 0.3384\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.1008 - acc: 0.4290 - val_loss: 1.2572 - val_acc: 0.3353\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 1.0740 - acc: 0.4424 - val_loss: 1.2693 - val_acc: 0.3384\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 1.0432 - acc: 0.4399 - val_loss: 1.2621 - val_acc: 0.3323\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0417 - acc: 0.4325 - val_loss: 1.2705 - val_acc: 0.3353\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0666 - acc: 0.4343 - val_loss: 1.3476 - val_acc: 0.3172\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 1.0742 - acc: 0.4442 - val_loss: 1.5185 - val_acc: 0.2719\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.1173 - acc: 0.4146 - val_loss: 1.4421 - val_acc: 0.2749\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0688 - acc: 0.4132 - val_loss: 1.3798 - val_acc: 0.3142\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.0525 - acc: 0.4227 - val_loss: 1.4259 - val_acc: 0.2991\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0568 - acc: 0.4354 - val_loss: 1.3644 - val_acc: 0.3202\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.0380 - acc: 0.441 - 0s 70us/step - loss: 1.0436 - acc: 0.4403 - val_loss: 1.3080 - val_acc: 0.3323\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.0801 - acc: 0.4234 - val_loss: 1.2223 - val_acc: 0.3656\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.0902 - acc: 0.4502 - val_loss: 1.2832 - val_acc: 0.3474\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0432 - acc: 0.4399 - val_loss: 1.2834 - val_acc: 0.3565\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0162 - acc: 0.4505 - val_loss: 1.2681 - val_acc: 0.3807\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 1.0364 - acc: 0.4505 - val_loss: 1.2136 - val_acc: 0.4381\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1183 - acc: 0.4406 - val_loss: 1.2381 - val_acc: 0.3444\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 1.0862 - acc: 0.4410 - val_loss: 1.3234 - val_acc: 0.3293\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 1.0605 - acc: 0.4456 - val_loss: 1.3335 - val_acc: 0.3353\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0242 - acc: 0.4477 - val_loss: 1.2653 - val_acc: 0.3474\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0217 - acc: 0.4470 - val_loss: 1.1875 - val_acc: 0.3927\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0875 - acc: 0.4512 - val_loss: 1.2550 - val_acc: 0.3716\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0274 - acc: 0.4554 - val_loss: 1.2993 - val_acc: 0.3776\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0442 - acc: 0.4491 - val_loss: 1.2509 - val_acc: 0.3867\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0330 - acc: 0.4639 - val_loss: 1.1983 - val_acc: 0.4139\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0661 - acc: 0.4459 - val_loss: 1.2061 - val_acc: 0.3656\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0864 - acc: 0.4452 - val_loss: 1.2733 - val_acc: 0.3474\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9920 - acc: 0.4650 - val_loss: 1.2350 - val_acc: 0.3746\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0119 - acc: 0.4512 - val_loss: 1.2349 - val_acc: 0.3927\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0302 - acc: 0.4547 - val_loss: 1.2221 - val_acc: 0.3716\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0250 - acc: 0.4558 - val_loss: 1.2123 - val_acc: 0.3776\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0122 - acc: 0.4706 - val_loss: 1.2151 - val_acc: 0.4199\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0572 - acc: 0.4738 - val_loss: 1.2973 - val_acc: 0.4320\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 1.0566 - acc: 0.4646 - val_loss: 1.2903 - val_acc: 0.3686\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9733 - acc: 0.4688 - val_loss: 1.2303 - val_acc: 0.4532\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9870 - acc: 0.4787 - val_loss: 1.2124 - val_acc: 0.4532\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0047 - acc: 0.4727 - val_loss: 1.1968 - val_acc: 0.4018\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0522 - acc: 0.4509 - val_loss: 1.2548 - val_acc: 0.3625\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0104 - acc: 0.4752 - val_loss: 1.3518 - val_acc: 0.3595\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0083 - acc: 0.4642 - val_loss: 1.4797 - val_acc: 0.2991\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0413 - acc: 0.4308 - val_loss: 1.3489 - val_acc: 0.3505\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9709 - acc: 0.4678 - val_loss: 1.4155 - val_acc: 0.3384\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9885 - acc: 0.4604 - val_loss: 1.3777 - val_acc: 0.3444\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9868 - acc: 0.4533 - val_loss: 1.3319 - val_acc: 0.3263\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9922 - acc: 0.4614 - val_loss: 1.3038 - val_acc: 0.3656\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.9644 - acc: 0.4759 - val_loss: 1.2730 - val_acc: 0.3807\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.0091 - acc: 0.4614 - val_loss: 1.2063 - val_acc: 0.4079\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 98us/step - loss: 1.0160 - acc: 0.4593 - val_loss: 1.2206 - val_acc: 0.4109\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.9782 - acc: 0.4780 - val_loss: 1.1876 - val_acc: 0.4532\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 66us/step - loss: 1.0419 - acc: 0.4780 - val_loss: 1.2323 - val_acc: 0.3988\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 1.0080 - acc: 0.4822 - val_loss: 1.3174 - val_acc: 0.3746\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9680 - acc: 0.4642 - val_loss: 1.3483 - val_acc: 0.3625\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9519 - acc: 0.4699 - val_loss: 1.3738 - val_acc: 0.3535\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.9759 - acc: 0.4537 - val_loss: 1.3980 - val_acc: 0.3414\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9705 - acc: 0.4699 - val_loss: 1.4251 - val_acc: 0.3474\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.0154 - acc: 0.4621 - val_loss: 1.2888 - val_acc: 0.3444\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9700 - acc: 0.4674 - val_loss: 1.2444 - val_acc: 0.3958\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9765 - acc: 0.4565 - val_loss: 1.2319 - val_acc: 0.4109\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9417 - acc: 0.4938 - val_loss: 1.2306 - val_acc: 0.4411\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9502 - acc: 0.4681 - val_loss: 1.1683 - val_acc: 0.4592\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 1.0676 - acc: 0.4653 - val_loss: 1.2196 - val_acc: 0.4018\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.9779 - acc: 0.4889 - val_loss: 1.2473 - val_acc: 0.3958\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 101us/step - loss: 0.9284 - acc: 0.4921 - val_loss: 1.2329 - val_acc: 0.4502\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 1.0124 - acc: 0.4871 - val_loss: 1.2204 - val_acc: 0.4320\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9666 - acc: 0.4956 - val_loss: 1.2319 - val_acc: 0.4079\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9395 - acc: 0.4833 - val_loss: 1.2310 - val_acc: 0.4169\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.9670 - acc: 0.4783 - val_loss: 1.2242 - val_acc: 0.3958\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9847 - acc: 0.4878 - val_loss: 1.2509 - val_acc: 0.4411\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9160 - acc: 0.5072 - val_loss: 1.2106 - val_acc: 0.4290\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9555 - acc: 0.4843 - val_loss: 1.1801 - val_acc: 0.4471\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 1.0379 - acc: 0.4963 - val_loss: 1.2926 - val_acc: 0.3656\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9436 - acc: 0.4812 - val_loss: 1.2418 - val_acc: 0.4441\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9681 - acc: 0.5069 - val_loss: 1.2173 - val_acc: 0.4230\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.9240 - acc: 0.4988 - val_loss: 1.2102 - val_acc: 0.4199\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.9609 - acc: 0.4709 - val_loss: 1.1930 - val_acc: 0.4290\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9598 - acc: 0.4945 - val_loss: 1.1835 - val_acc: 0.4683\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9765 - acc: 0.4882 - val_loss: 1.2696 - val_acc: 0.4199\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9737 - acc: 0.4921 - val_loss: 1.2580 - val_acc: 0.3958\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9047 - acc: 0.4945 - val_loss: 1.3292 - val_acc: 0.3807\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9113 - acc: 0.4762 - val_loss: 1.3524 - val_acc: 0.3625\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9294 - acc: 0.4840 - val_loss: 1.3288 - val_acc: 0.3897\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9226 - acc: 0.4988 - val_loss: 1.4180 - val_acc: 0.3656\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9816 - acc: 0.4653 - val_loss: 1.3397 - val_acc: 0.3505\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9598 - acc: 0.4755 - val_loss: 1.2448 - val_acc: 0.3958\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.9078 - acc: 0.5114 - val_loss: 1.1787 - val_acc: 0.4471\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9487 - acc: 0.4907 - val_loss: 1.1854 - val_acc: 0.4290\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9579 - acc: 0.5079 - val_loss: 1.2433 - val_acc: 0.4350\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9640 - acc: 0.5090 - val_loss: 1.2828 - val_acc: 0.4260\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9009 - acc: 0.5026 - val_loss: 1.3055 - val_acc: 0.4048\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9089 - acc: 0.4942 - val_loss: 1.3613 - val_acc: 0.3505\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9035 - acc: 0.4984 - val_loss: 1.3770 - val_acc: 0.3505\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9323 - acc: 0.4780 - val_loss: 1.3817 - val_acc: 0.3565\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9533 - acc: 0.4766 - val_loss: 1.3874 - val_acc: 0.3535\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9736 - acc: 0.4801 - val_loss: 1.2923 - val_acc: 0.3867\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8978 - acc: 0.4850 - val_loss: 1.2458 - val_acc: 0.4199\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.9078 - acc: 0.4963 - val_loss: 1.1782 - val_acc: 0.4743\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9472 - acc: 0.4945 - val_loss: 1.2032 - val_acc: 0.4320\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9121 - acc: 0.5319 - val_loss: 1.2568 - val_acc: 0.4199\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9419 - acc: 0.5083 - val_loss: 1.2669 - val_acc: 0.4471\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.9216 - acc: 0.5114 - val_loss: 1.2936 - val_acc: 0.4018\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8853 - acc: 0.5055 - val_loss: 1.4382 - val_acc: 0.3202\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9678 - acc: 0.4590 - val_loss: 1.3501 - val_acc: 0.3505\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9040 - acc: 0.4942 - val_loss: 1.2991 - val_acc: 0.3837\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8552 - acc: 0.5150 - val_loss: 1.4048 - val_acc: 0.3746\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9514 - acc: 0.4759 - val_loss: 1.3331 - val_acc: 0.3656\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8826 - acc: 0.5079 - val_loss: 1.3157 - val_acc: 0.4048\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.9478 - acc: 0.4833 - val_loss: 1.2439 - val_acc: 0.4471\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8589 - acc: 0.5333 - val_loss: 1.2476 - val_acc: 0.4199\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8500 - acc: 0.5195 - val_loss: 1.1832 - val_acc: 0.4653\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8892 - acc: 0.5090 - val_loss: 1.1691 - val_acc: 0.4502\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9608 - acc: 0.5248 - val_loss: 1.2741 - val_acc: 0.4109\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8794 - acc: 0.5234 - val_loss: 1.2825 - val_acc: 0.4350\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9287 - acc: 0.5048 - val_loss: 1.2268 - val_acc: 0.4381\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8896 - acc: 0.5294 - val_loss: 1.1960 - val_acc: 0.4532\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9262 - acc: 0.5284 - val_loss: 1.1836 - val_acc: 0.4653\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8992 - acc: 0.5308 - val_loss: 1.2335 - val_acc: 0.4230\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8352 - acc: 0.5255 - val_loss: 1.2341 - val_acc: 0.4441\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8358 - acc: 0.5213 - val_loss: 1.1880 - val_acc: 0.4894\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9370 - acc: 0.4893 - val_loss: 1.1638 - val_acc: 0.4350\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9516 - acc: 0.5259 - val_loss: 1.2448 - val_acc: 0.4350\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.8288 - acc: 0.5551 - val_loss: 1.3030 - val_acc: 0.4260\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9300 - acc: 0.5129 - val_loss: 1.2531 - val_acc: 0.4441\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8585 - acc: 0.5375 - val_loss: 1.2498 - val_acc: 0.4199\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8248 - acc: 0.5368 - val_loss: 1.2574 - val_acc: 0.4441\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8206 - acc: 0.5403 - val_loss: 1.2642 - val_acc: 0.4381\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8110 - acc: 0.5537 - val_loss: 1.3763 - val_acc: 0.3897\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9130 - acc: 0.5037 - val_loss: 1.4774 - val_acc: 0.3142\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9190 - acc: 0.4660 - val_loss: 1.2919 - val_acc: 0.4018\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8246 - acc: 0.5298 - val_loss: 1.3179 - val_acc: 0.4048\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8338 - acc: 0.5375 - val_loss: 1.5743 - val_acc: 0.3202\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0207 - acc: 0.4414 - val_loss: 1.2901 - val_acc: 0.3625\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9570 - acc: 0.4857 - val_loss: 1.2246 - val_acc: 0.4411\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8219 - acc: 0.5354 - val_loss: 1.2571 - val_acc: 0.4290\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8123 - acc: 0.5417 - val_loss: 1.3009 - val_acc: 0.3988\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8101 - acc: 0.5389 - val_loss: 1.3807 - val_acc: 0.3746\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9371 - acc: 0.5012 - val_loss: 1.4712 - val_acc: 0.3263\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9212 - acc: 0.4572 - val_loss: 1.3336 - val_acc: 0.4018\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8869 - acc: 0.5083 - val_loss: 1.2583 - val_acc: 0.4109\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8162 - acc: 0.5315 - val_loss: 1.2634 - val_acc: 0.4230\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8006 - acc: 0.5379 - val_loss: 1.2830 - val_acc: 0.4230\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8324 - acc: 0.5248 - val_loss: 1.3094 - val_acc: 0.4199\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8922 - acc: 0.5132 - val_loss: 1.2639 - val_acc: 0.4290\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8301 - acc: 0.5234 - val_loss: 1.2993 - val_acc: 0.4048\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7876 - acc: 0.5467 - val_loss: 1.4252 - val_acc: 0.3897\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9536 - acc: 0.5019 - val_loss: 1.3424 - val_acc: 0.3565\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8384 - acc: 0.5069 - val_loss: 1.2620 - val_acc: 0.4018\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.8166 - acc: 0.5354 - val_loss: 1.2162 - val_acc: 0.4441\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8587 - acc: 0.5305 - val_loss: 1.2342 - val_acc: 0.4441\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8215 - acc: 0.5372 - val_loss: 1.3259 - val_acc: 0.4079\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8672 - acc: 0.5203 - val_loss: 1.4665 - val_acc: 0.3384\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9270 - acc: 0.4706 - val_loss: 1.3181 - val_acc: 0.3807\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8047 - acc: 0.5474 - val_loss: 1.3806 - val_acc: 0.3837\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8162 - acc: 0.5343 - val_loss: 1.5201 - val_acc: 0.3625\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8638 - acc: 0.5030 - val_loss: 1.3155 - val_acc: 0.4109\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7872 - acc: 0.5583 - val_loss: 1.3146 - val_acc: 0.4169\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7813 - acc: 0.5667 - val_loss: 1.3953 - val_acc: 0.3988\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9122 - acc: 0.5231 - val_loss: 1.3032 - val_acc: 0.4411\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8505 - acc: 0.5403 - val_loss: 1.2357 - val_acc: 0.4471\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8139 - acc: 0.5326 - val_loss: 1.2264 - val_acc: 0.4502\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9025 - acc: 0.5343 - val_loss: 1.2775 - val_acc: 0.4109\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7838 - acc: 0.5675 - val_loss: 1.3661 - val_acc: 0.4169\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8042 - acc: 0.5491 - val_loss: 1.3553 - val_acc: 0.4109\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8383 - acc: 0.5389 - val_loss: 1.3611 - val_acc: 0.4169\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8212 - acc: 0.5414 - val_loss: 1.4056 - val_acc: 0.3807\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.8662 - acc: 0.5157 - val_loss: 1.3868 - val_acc: 0.3927\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8274 - acc: 0.5234 - val_loss: 1.2981 - val_acc: 0.4471\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7760 - acc: 0.5717 - val_loss: 1.3799 - val_acc: 0.3927\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8204 - acc: 0.5231 - val_loss: 1.3535 - val_acc: 0.4169\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8665 - acc: 0.5224 - val_loss: 1.4098 - val_acc: 0.3716\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8545 - acc: 0.4970 - val_loss: 1.3783 - val_acc: 0.4048\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7913 - acc: 0.5312 - val_loss: 1.3778 - val_acc: 0.4109\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7681 - acc: 0.5583 - val_loss: 1.4609 - val_acc: 0.3867\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.8408 - acc: 0.501 - 0s 70us/step - loss: 0.8387 - acc: 0.5262 - val_loss: 1.3860 - val_acc: 0.4048\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7936 - acc: 0.5548 - val_loss: 1.4246 - val_acc: 0.3897\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7878 - acc: 0.5463 - val_loss: 1.4309 - val_acc: 0.4018\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7997 - acc: 0.5467 - val_loss: 1.3731 - val_acc: 0.4502\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8087 - acc: 0.5491 - val_loss: 1.4651 - val_acc: 0.4018\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.9271 - acc: 0.5019 - val_loss: 1.2376 - val_acc: 0.4622\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8177 - acc: 0.5657 - val_loss: 1.2808 - val_acc: 0.4290\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7592 - acc: 0.5689 - val_loss: 1.2810 - val_acc: 0.4381\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7815 - acc: 0.5541 - val_loss: 1.2207 - val_acc: 0.4441\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8445 - acc: 0.5516 - val_loss: 1.2762 - val_acc: 0.4048\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7833 - acc: 0.5639 - val_loss: 1.2905 - val_acc: 0.4381\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7579 - acc: 0.5851 - val_loss: 1.3593 - val_acc: 0.4260\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8286 - acc: 0.5675 - val_loss: 1.3788 - val_acc: 0.4199\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9069 - acc: 0.5266 - val_loss: 1.3371 - val_acc: 0.4381\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7713 - acc: 0.5579 - val_loss: 1.4978 - val_acc: 0.3927\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8591 - acc: 0.5167 - val_loss: 1.4362 - val_acc: 0.4048\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7907 - acc: 0.5407 - val_loss: 1.3445 - val_acc: 0.4079\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7314 - acc: 0.5882 - val_loss: 1.4038 - val_acc: 0.4199\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7557 - acc: 0.5678 - val_loss: 1.4689 - val_acc: 0.3897\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8189 - acc: 0.5379 - val_loss: 1.4406 - val_acc: 0.3867\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7991 - acc: 0.5361 - val_loss: 1.3917 - val_acc: 0.4018\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7523 - acc: 0.5629 - val_loss: 1.3657 - val_acc: 0.4109\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7932 - acc: 0.5428 - val_loss: 1.4335 - val_acc: 0.3837\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8868 - acc: 0.5107 - val_loss: 1.2636 - val_acc: 0.4502\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7569 - acc: 0.5749 - val_loss: 1.2790 - val_acc: 0.4683\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7859 - acc: 0.5537 - val_loss: 1.2676 - val_acc: 0.4502\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8393 - acc: 0.5558 - val_loss: 1.3099 - val_acc: 0.4350\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7729 - acc: 0.5914 - val_loss: 1.3401 - val_acc: 0.4320\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7077 - acc: 0.6002 - val_loss: 1.4026 - val_acc: 0.4381\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7192 - acc: 0.5907 - val_loss: 1.4353 - val_acc: 0.4199\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7939 - acc: 0.5498 - val_loss: 1.5964 - val_acc: 0.3686\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8726 - acc: 0.5062 - val_loss: 1.3647 - val_acc: 0.4079\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7740 - acc: 0.5615 - val_loss: 1.4294 - val_acc: 0.3958\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7813 - acc: 0.5336 - val_loss: 1.4012 - val_acc: 0.4109\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7463 - acc: 0.5601 - val_loss: 1.4871 - val_acc: 0.4018\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7737 - acc: 0.5505 - val_loss: 1.4778 - val_acc: 0.4018\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7599 - acc: 0.5590 - val_loss: 1.5308 - val_acc: 0.4109\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7770 - acc: 0.5513 - val_loss: 1.3681 - val_acc: 0.4502\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7044 - acc: 0.5942 - val_loss: 1.4312 - val_acc: 0.4230\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7850 - acc: 0.5548 - val_loss: 1.5379 - val_acc: 0.3807\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9103 - acc: 0.5076 - val_loss: 1.3355 - val_acc: 0.4169\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7179 - acc: 0.5731 - val_loss: 1.3252 - val_acc: 0.4320\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7336 - acc: 0.5787 - val_loss: 1.2718 - val_acc: 0.4502\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8185 - acc: 0.5664 - val_loss: 1.2959 - val_acc: 0.4381\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7131 - acc: 0.6104 - val_loss: 1.3709 - val_acc: 0.4411\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6825 - acc: 0.6058 - val_loss: 1.4405 - val_acc: 0.4411\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7148 - acc: 0.5985 - val_loss: 1.4192 - val_acc: 0.4260\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7772 - acc: 0.5710 - val_loss: 1.3764 - val_acc: 0.4532\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8101 - acc: 0.5798 - val_loss: 1.2979 - val_acc: 0.4230\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8401 - acc: 0.5308 - val_loss: 1.2745 - val_acc: 0.4320\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7371 - acc: 0.5925 - val_loss: 1.3498 - val_acc: 0.4381\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6993 - acc: 0.6231 - val_loss: 1.3985 - val_acc: 0.4471\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6959 - acc: 0.6097 - val_loss: 1.3829 - val_acc: 0.4502\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7784 - acc: 0.5787 - val_loss: 1.3318 - val_acc: 0.4471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7347 - acc: 0.5882 - val_loss: 1.3465 - val_acc: 0.4502\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6843 - acc: 0.6002 - val_loss: 1.3338 - val_acc: 0.4532\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7757 - acc: 0.5724 - val_loss: 1.3233 - val_acc: 0.4199\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7980 - acc: 0.5579 - val_loss: 1.3769 - val_acc: 0.4532\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7423 - acc: 0.5808 - val_loss: 1.5390 - val_acc: 0.3746\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8119 - acc: 0.5368 - val_loss: 1.4805 - val_acc: 0.3897\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7223 - acc: 0.5692 - val_loss: 1.4438 - val_acc: 0.4290\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6812 - acc: 0.6083 - val_loss: 1.5129 - val_acc: 0.4199\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7072 - acc: 0.6048 - val_loss: 1.6113 - val_acc: 0.3897\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7990 - acc: 0.5435 - val_loss: 1.4244 - val_acc: 0.4562\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.6919 - acc: 0.6080 - val_loss: 1.4125 - val_acc: 0.4592\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7762 - acc: 0.5777 - val_loss: 1.4337 - val_acc: 0.4441\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8193 - acc: 0.5822 - val_loss: 1.3658 - val_acc: 0.4169\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.6831 - acc: 0.6048 - val_loss: 1.3594 - val_acc: 0.4320\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7163 - acc: 0.5974 - val_loss: 1.3459 - val_acc: 0.4260\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7573 - acc: 0.5594 - val_loss: 1.3348 - val_acc: 0.4411\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7094 - acc: 0.6027 - val_loss: 1.3637 - val_acc: 0.4562\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6709 - acc: 0.6073 - val_loss: 1.3729 - val_acc: 0.4290\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7105 - acc: 0.5963 - val_loss: 1.3402 - val_acc: 0.4230\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7421 - acc: 0.5798 - val_loss: 1.3571 - val_acc: 0.4562\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7252 - acc: 0.5826 - val_loss: 1.3967 - val_acc: 0.4411\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6962 - acc: 0.5847 - val_loss: 1.4268 - val_acc: 0.4169\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6876 - acc: 0.5826 - val_loss: 1.5783 - val_acc: 0.3716\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8922 - acc: 0.5262 - val_loss: 1.6811 - val_acc: 0.3414\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7871 - acc: 0.5245 - val_loss: 1.4667 - val_acc: 0.4230\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6807 - acc: 0.6196 - val_loss: 1.5784 - val_acc: 0.4109\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.7072 - acc: 0.5932 - val_loss: 1.5425 - val_acc: 0.4320\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7437 - acc: 0.5801 - val_loss: 1.5446 - val_acc: 0.4139\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7497 - acc: 0.5801 - val_loss: 1.5056 - val_acc: 0.4018\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7197 - acc: 0.5868 - val_loss: 1.4573 - val_acc: 0.4169\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6958 - acc: 0.5868 - val_loss: 1.4482 - val_acc: 0.4199\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6796 - acc: 0.5851 - val_loss: 1.4253 - val_acc: 0.4199\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.6516 - acc: 0.596 - 0s 70us/step - loss: 0.6508 - acc: 0.6143 - val_loss: 1.4957 - val_acc: 0.4199\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6448 - acc: 0.6175 - val_loss: 1.6065 - val_acc: 0.3988\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7291 - acc: 0.5798 - val_loss: 1.6738 - val_acc: 0.3837\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7679 - acc: 0.5520 - val_loss: 1.5468 - val_acc: 0.4230\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6920 - acc: 0.6090 - val_loss: 1.6348 - val_acc: 0.4230\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.7382 - acc: 0.5868 - val_loss: 1.4367 - val_acc: 0.4562\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7033 - acc: 0.6154 - val_loss: 1.4316 - val_acc: 0.4441\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6666 - acc: 0.6217 - val_loss: 1.4431 - val_acc: 0.4502\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7003 - acc: 0.6164 - val_loss: 1.3855 - val_acc: 0.4502\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7252 - acc: 0.6066 - val_loss: 1.3590 - val_acc: 0.4411\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7050 - acc: 0.6090 - val_loss: 1.4213 - val_acc: 0.4320\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6484 - acc: 0.6164 - val_loss: 1.4328 - val_acc: 0.4471\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6831 - acc: 0.6185 - val_loss: 1.4405 - val_acc: 0.4320\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7337 - acc: 0.6020 - val_loss: 1.6274 - val_acc: 0.4048\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8798 - acc: 0.5646 - val_loss: 1.5539 - val_acc: 0.3958\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7177 - acc: 0.5889 - val_loss: 1.5008 - val_acc: 0.4260\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6655 - acc: 0.6150 - val_loss: 1.5756 - val_acc: 0.4079\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6896 - acc: 0.6009 - val_loss: 1.5831 - val_acc: 0.4260\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6589 - acc: 0.6090 - val_loss: 1.5197 - val_acc: 0.4290\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6326 - acc: 0.6217 - val_loss: 1.5073 - val_acc: 0.4320\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6344 - acc: 0.6302 - val_loss: 1.5592 - val_acc: 0.3988\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7567 - acc: 0.5618 - val_loss: 1.4022 - val_acc: 0.4592\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6928 - acc: 0.5830 - val_loss: 1.3780 - val_acc: 0.4502\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6666 - acc: 0.6076 - val_loss: 1.4205 - val_acc: 0.4562\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6641 - acc: 0.6242 - val_loss: 1.4207 - val_acc: 0.4502\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.7400 - acc: 0.6101 - val_loss: 1.4281 - val_acc: 0.4350\n",
      "Epoch 354/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6291 - acc: 0.6456 - val_loss: 1.5369 - val_acc: 0.4350\n",
      "Epoch 355/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6690 - acc: 0.6242 - val_loss: 1.5783 - val_acc: 0.4199\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7165 - acc: 0.6143 - val_loss: 1.6055 - val_acc: 0.4109\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6996 - acc: 0.6020 - val_loss: 1.5202 - val_acc: 0.4532\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6339 - acc: 0.6245 - val_loss: 1.6372 - val_acc: 0.4230\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.7353 - acc: 0.5900 - val_loss: 1.6883 - val_acc: 0.3988\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7392 - acc: 0.5692 - val_loss: 1.5172 - val_acc: 0.4381\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6375 - acc: 0.6213 - val_loss: 1.4690 - val_acc: 0.4441\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6135 - acc: 0.6383 - val_loss: 1.5236 - val_acc: 0.4230\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7328 - acc: 0.5724 - val_loss: 1.5349 - val_acc: 0.3988\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 97us/step - loss: 0.7387 - acc: 0.5710 - val_loss: 1.4945 - val_acc: 0.4169\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6223 - acc: 0.6273 - val_loss: 1.5311 - val_acc: 0.4381\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5924 - acc: 0.6449 - val_loss: 1.6501 - val_acc: 0.4350\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6752 - acc: 0.6217 - val_loss: 1.9773 - val_acc: 0.3263\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.8751 - acc: 0.5037 - val_loss: 1.4434 - val_acc: 0.4290\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7086 - acc: 0.5977 - val_loss: 1.4383 - val_acc: 0.4381\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6289 - acc: 0.6228 - val_loss: 1.4989 - val_acc: 0.4230\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5948 - acc: 0.6390 - val_loss: 1.5301 - val_acc: 0.4411\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6014 - acc: 0.6280 - val_loss: 1.4947 - val_acc: 0.4532\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6003 - acc: 0.6414 - val_loss: 1.5208 - val_acc: 0.4290\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6059 - acc: 0.6263 - val_loss: 1.5123 - val_acc: 0.4109\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6729 - acc: 0.5914 - val_loss: 1.4044 - val_acc: 0.4924\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7493 - acc: 0.5837 - val_loss: 1.4661 - val_acc: 0.4381\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7324 - acc: 0.6196 - val_loss: 1.5964 - val_acc: 0.4230\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6637 - acc: 0.6488 - val_loss: 1.5644 - val_acc: 0.4441\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6055 - acc: 0.6597 - val_loss: 1.7449 - val_acc: 0.4260\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7035 - acc: 0.6051 - val_loss: 1.6282 - val_acc: 0.4169\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7040 - acc: 0.5949 - val_loss: 1.6203 - val_acc: 0.4048\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6388 - acc: 0.6090 - val_loss: 1.6685 - val_acc: 0.4199\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6406 - acc: 0.6213 - val_loss: 1.6431 - val_acc: 0.4018\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6453 - acc: 0.6252 - val_loss: 1.5698 - val_acc: 0.4290\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6111 - acc: 0.6316 - val_loss: 1.5305 - val_acc: 0.4109\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6642 - acc: 0.5935 - val_loss: 1.5420 - val_acc: 0.4441\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.7190 - acc: 0.5907 - val_loss: 1.5689 - val_acc: 0.4018\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6362 - acc: 0.6150 - val_loss: 1.6701 - val_acc: 0.4139\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6739 - acc: 0.6034 - val_loss: 1.8890 - val_acc: 0.3776\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7099 - acc: 0.5868 - val_loss: 1.5917 - val_acc: 0.4290\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5928 - acc: 0.6587 - val_loss: 1.6514 - val_acc: 0.4381\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6143 - acc: 0.6474 - val_loss: 1.6302 - val_acc: 0.4199\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6272 - acc: 0.6545 - val_loss: 1.5826 - val_acc: 0.4381\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6325 - acc: 0.6594 - val_loss: 1.5066 - val_acc: 0.4592\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7480 - acc: 0.6108 - val_loss: 1.3968 - val_acc: 0.4441\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6563 - acc: 0.6520 - val_loss: 1.5262 - val_acc: 0.4320\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5850 - acc: 0.6552 - val_loss: 1.5436 - val_acc: 0.4079\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5807 - acc: 0.6545 - val_loss: 1.5499 - val_acc: 0.4290\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6350 - acc: 0.6284 - val_loss: 1.6415 - val_acc: 0.4139\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6724 - acc: 0.6016 - val_loss: 1.5274 - val_acc: 0.4230\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5900 - acc: 0.6319 - val_loss: 1.5391 - val_acc: 0.4441\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5864 - acc: 0.6351 - val_loss: 1.5043 - val_acc: 0.4622\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7475 - acc: 0.5759 - val_loss: 1.4263 - val_acc: 0.4502\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6772 - acc: 0.6252 - val_loss: 1.5559 - val_acc: 0.4381\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5896 - acc: 0.6731 - val_loss: 1.6398 - val_acc: 0.4320\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6170 - acc: 0.6471 - val_loss: 1.6646 - val_acc: 0.4381\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6687 - acc: 0.6400 - val_loss: 1.6038 - val_acc: 0.4350\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5681 - acc: 0.6742 - val_loss: 1.6314 - val_acc: 0.4471\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5802 - acc: 0.6714 - val_loss: 1.7026 - val_acc: 0.4320\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5885 - acc: 0.6520 - val_loss: 1.7678 - val_acc: 0.4320\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6325 - acc: 0.6407 - val_loss: 2.0093 - val_acc: 0.3565\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.9120 - acc: 0.5051 - val_loss: 1.5138 - val_acc: 0.4230\n",
      "Epoch 413/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6594 - acc: 0.6189 - val_loss: 1.5286 - val_acc: 0.4199\n",
      "Epoch 414/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5831 - acc: 0.6383 - val_loss: 1.5755 - val_acc: 0.4381\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5490 - acc: 0.6728 - val_loss: 1.5713 - val_acc: 0.4592\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5773 - acc: 0.6481 - val_loss: 1.5423 - val_acc: 0.4653\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6063 - acc: 0.6456 - val_loss: 1.4981 - val_acc: 0.4924\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7344 - acc: 0.6044 - val_loss: 1.6302 - val_acc: 0.4441\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6689 - acc: 0.6400 - val_loss: 1.5776 - val_acc: 0.4592\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5622 - acc: 0.6819 - val_loss: 1.6133 - val_acc: 0.4381\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 106us/step - loss: 0.5401 - acc: 0.6953 - val_loss: 1.6363 - val_acc: 0.4502\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.5383 - acc: 0.6911 - val_loss: 1.6136 - val_acc: 0.4622\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5806 - acc: 0.6569 - val_loss: 1.5411 - val_acc: 0.4562\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6818 - acc: 0.6298 - val_loss: 1.5076 - val_acc: 0.4713\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6795 - acc: 0.6474 - val_loss: 1.6588 - val_acc: 0.4320\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5672 - acc: 0.6661 - val_loss: 1.8418 - val_acc: 0.4079\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6590 - acc: 0.6467 - val_loss: 1.8204 - val_acc: 0.4139\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6561 - acc: 0.6358 - val_loss: 1.6115 - val_acc: 0.4381\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5335 - acc: 0.6795 - val_loss: 1.6263 - val_acc: 0.4532\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5423 - acc: 0.6756 - val_loss: 1.6937 - val_acc: 0.4350\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5659 - acc: 0.6661 - val_loss: 1.8738 - val_acc: 0.4139\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6916 - acc: 0.6030 - val_loss: 1.7466 - val_acc: 0.4260\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6488 - acc: 0.6199 - val_loss: 1.6324 - val_acc: 0.4048\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5701 - acc: 0.6456 - val_loss: 1.6367 - val_acc: 0.4169\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6627 - acc: 0.6323 - val_loss: 1.6276 - val_acc: 0.3958\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6686 - acc: 0.5914 - val_loss: 1.5156 - val_acc: 0.4592\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5786 - acc: 0.6530 - val_loss: 1.5623 - val_acc: 0.4471\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5816 - acc: 0.6555 - val_loss: 1.5640 - val_acc: 0.4653\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6239 - acc: 0.6411 - val_loss: 1.5746 - val_acc: 0.4562\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6331 - acc: 0.6626 - val_loss: 1.6635 - val_acc: 0.4320\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5567 - acc: 0.6763 - val_loss: 1.7725 - val_acc: 0.4199\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5949 - acc: 0.6619 - val_loss: 1.7396 - val_acc: 0.4411\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5587 - acc: 0.6847 - val_loss: 1.8419 - val_acc: 0.4079\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6066 - acc: 0.6414 - val_loss: 1.7417 - val_acc: 0.4320\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6004 - acc: 0.6615 - val_loss: 1.8332 - val_acc: 0.3897\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7389 - acc: 0.5942 - val_loss: 1.6609 - val_acc: 0.4350\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6480 - acc: 0.6203 - val_loss: 1.5407 - val_acc: 0.4441\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5669 - acc: 0.6365 - val_loss: 1.6397 - val_acc: 0.4320\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5183 - acc: 0.6904 - val_loss: 1.6401 - val_acc: 0.4532\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5366 - acc: 0.6763 - val_loss: 1.7016 - val_acc: 0.4411\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5591 - acc: 0.6576 - val_loss: 1.7330 - val_acc: 0.4230\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7058 - acc: 0.6213 - val_loss: 1.8564 - val_acc: 0.3565\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6457 - acc: 0.5999 - val_loss: 1.7160 - val_acc: 0.4290\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5328 - acc: 0.6798 - val_loss: 1.8470 - val_acc: 0.4048\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5504 - acc: 0.6742 - val_loss: 1.8713 - val_acc: 0.4169\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5825 - acc: 0.6675 - val_loss: 1.9409 - val_acc: 0.4350\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5958 - acc: 0.6774 - val_loss: 1.8544 - val_acc: 0.4441\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.5907 - acc: 0.6604 - val_loss: 1.7756 - val_acc: 0.4260\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.5429 - acc: 0.6664 - val_loss: 1.7050 - val_acc: 0.4562\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5288 - acc: 0.6865 - val_loss: 1.6686 - val_acc: 0.4290\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5632 - acc: 0.6622 - val_loss: 1.7993 - val_acc: 0.3897\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6995 - acc: 0.5918 - val_loss: 1.6435 - val_acc: 0.4411\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5668 - acc: 0.6710 - val_loss: 1.8305 - val_acc: 0.4502\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5805 - acc: 0.6724 - val_loss: 2.0321 - val_acc: 0.3897\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6595 - acc: 0.6252 - val_loss: 1.8740 - val_acc: 0.4260\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6570 - acc: 0.6305 - val_loss: 1.6958 - val_acc: 0.4079\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6108 - acc: 0.6375 - val_loss: 1.5947 - val_acc: 0.4230\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 93us/step - loss: 0.6028 - acc: 0.6319 - val_loss: 1.5534 - val_acc: 0.4894\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5509 - acc: 0.6587 - val_loss: 1.6870 - val_acc: 0.4290\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5102 - acc: 0.6872 - val_loss: 1.6987 - val_acc: 0.4441\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5015 - acc: 0.6946 - val_loss: 1.7993 - val_acc: 0.4260\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5883 - acc: 0.6657 - val_loss: 1.8566 - val_acc: 0.3625\n",
      "Epoch 473/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7366 - acc: 0.5706 - val_loss: 1.7075 - val_acc: 0.4260\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5711 - acc: 0.6513 - val_loss: 1.6487 - val_acc: 0.4532\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5239 - acc: 0.6925 - val_loss: 1.6370 - val_acc: 0.4381\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5498 - acc: 0.6661 - val_loss: 1.6016 - val_acc: 0.4834\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5960 - acc: 0.6552 - val_loss: 1.5790 - val_acc: 0.4502\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5351 - acc: 0.6566 - val_loss: 1.6604 - val_acc: 0.4532\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5232 - acc: 0.6855 - val_loss: 1.6166 - val_acc: 0.4683\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6080 - acc: 0.6495 - val_loss: 1.6304 - val_acc: 0.4592\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6090 - acc: 0.6545 - val_loss: 1.7478 - val_acc: 0.4562\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5938 - acc: 0.6781 - val_loss: 1.8213 - val_acc: 0.4139\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5229 - acc: 0.6978 - val_loss: 1.8530 - val_acc: 0.4411\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5334 - acc: 0.6943 - val_loss: 2.0493 - val_acc: 0.3988\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5902 - acc: 0.6559 - val_loss: 1.7529 - val_acc: 0.4411\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5231 - acc: 0.7017 - val_loss: 1.7618 - val_acc: 0.4441\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5203 - acc: 0.7094 - val_loss: 1.8344 - val_acc: 0.4260\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5877 - acc: 0.6749 - val_loss: 1.7262 - val_acc: 0.4713\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8047 - acc: 0.6157 - val_loss: 1.6592 - val_acc: 0.4169\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5366 - acc: 0.6837 - val_loss: 1.7377 - val_acc: 0.4381\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4868 - acc: 0.7045 - val_loss: 1.9719 - val_acc: 0.3958\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5888 - acc: 0.6689 - val_loss: 1.9173 - val_acc: 0.4230\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5696 - acc: 0.6583 - val_loss: 1.7964 - val_acc: 0.4350\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5098 - acc: 0.6936 - val_loss: 1.8351 - val_acc: 0.4411\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5016 - acc: 0.7027 - val_loss: 1.8754 - val_acc: 0.4199\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5054 - acc: 0.7041 - val_loss: 1.8734 - val_acc: 0.4139\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5167 - acc: 0.7101 - val_loss: 1.9318 - val_acc: 0.4139\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5332 - acc: 0.6974 - val_loss: 1.9940 - val_acc: 0.4411\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5680 - acc: 0.6869 - val_loss: 1.9596 - val_acc: 0.4381\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5339 - acc: 0.7059 - val_loss: 1.9135 - val_acc: 0.4230\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.5229 - acc: 0.6897 - val_loss: 1.9147 - val_acc: 0.4230\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5913 - acc: 0.6742 - val_loss: 2.4064 - val_acc: 0.3082\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 1.0171 - acc: 0.5076 - val_loss: 1.6436 - val_acc: 0.4048\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6029 - acc: 0.6400 - val_loss: 1.6728 - val_acc: 0.4441\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5054 - acc: 0.7006 - val_loss: 1.7505 - val_acc: 0.4290\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4987 - acc: 0.6995 - val_loss: 1.7348 - val_acc: 0.4199\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4835 - acc: 0.7020 - val_loss: 1.6973 - val_acc: 0.4441\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5275 - acc: 0.6791 - val_loss: 1.6633 - val_acc: 0.4411\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5303 - acc: 0.6668 - val_loss: 1.6772 - val_acc: 0.4502\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5484 - acc: 0.6629 - val_loss: 1.8127 - val_acc: 0.3988\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5275 - acc: 0.6629 - val_loss: 1.7306 - val_acc: 0.4290\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5326 - acc: 0.6700 - val_loss: 2.1893 - val_acc: 0.3776\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6604 - acc: 0.6199 - val_loss: 2.0227 - val_acc: 0.4079\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5814 - acc: 0.6654 - val_loss: 1.7685 - val_acc: 0.4381\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4979 - acc: 0.7048 - val_loss: 1.7860 - val_acc: 0.4381\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4704 - acc: 0.7150 - val_loss: 1.9103 - val_acc: 0.4411\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4994 - acc: 0.7101 - val_loss: 2.1039 - val_acc: 0.3988\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6282 - acc: 0.6562 - val_loss: 1.9457 - val_acc: 0.4199\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5901 - acc: 0.6692 - val_loss: 1.6917 - val_acc: 0.4743\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5421 - acc: 0.6960 - val_loss: 1.7726 - val_acc: 0.4471\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4795 - acc: 0.7200 - val_loss: 1.8322 - val_acc: 0.4471\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4882 - acc: 0.7059 - val_loss: 1.7632 - val_acc: 0.4471\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5501 - acc: 0.6833 - val_loss: 1.6853 - val_acc: 0.4894\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6025 - acc: 0.6678 - val_loss: 1.8550 - val_acc: 0.4230\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5388 - acc: 0.6971 - val_loss: 1.9062 - val_acc: 0.4350\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4727 - acc: 0.7319 - val_loss: 1.9634 - val_acc: 0.4260\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4703 - acc: 0.7193 - val_loss: 1.9591 - val_acc: 0.4320\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5016 - acc: 0.6992 - val_loss: 2.0054 - val_acc: 0.4320\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 101us/step - loss: 0.5580 - acc: 0.6826 - val_loss: 1.9414 - val_acc: 0.4169\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.5192 - acc: 0.6936 - val_loss: 1.8096 - val_acc: 0.4532\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4688 - acc: 0.7281 - val_loss: 1.8828 - val_acc: 0.4350\n",
      "Epoch 532/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5263 - acc: 0.7031 - val_loss: 1.7442 - val_acc: 0.4683\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7155 - acc: 0.6471 - val_loss: 1.6730 - val_acc: 0.4713\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5522 - acc: 0.6964 - val_loss: 1.7427 - val_acc: 0.4562\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.4663 - acc: 0.7246 - val_loss: 1.8025 - val_acc: 0.4411\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4635 - acc: 0.7298 - val_loss: 1.7692 - val_acc: 0.4381\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5138 - acc: 0.7041 - val_loss: 1.7538 - val_acc: 0.4320\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6559 - acc: 0.6104 - val_loss: 1.6215 - val_acc: 0.5076\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5709 - acc: 0.6590 - val_loss: 1.8081 - val_acc: 0.4653\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5156 - acc: 0.7052 - val_loss: 1.7846 - val_acc: 0.4562\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4743 - acc: 0.7274 - val_loss: 1.8479 - val_acc: 0.4622\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4777 - acc: 0.7386 - val_loss: 1.8599 - val_acc: 0.4290\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4543 - acc: 0.7355 - val_loss: 1.9289 - val_acc: 0.4381\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4820 - acc: 0.7147 - val_loss: 2.1207 - val_acc: 0.3958\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6344 - acc: 0.6626 - val_loss: 2.0189 - val_acc: 0.4350\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6688 - acc: 0.6573 - val_loss: 1.7312 - val_acc: 0.4743\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4730 - acc: 0.7196 - val_loss: 1.8594 - val_acc: 0.4653\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4594 - acc: 0.7179 - val_loss: 1.9064 - val_acc: 0.4441\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4414 - acc: 0.7457 - val_loss: 1.9801 - val_acc: 0.4411\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4357 - acc: 0.7309 - val_loss: 2.0308 - val_acc: 0.4350\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4915 - acc: 0.7020 - val_loss: 2.4397 - val_acc: 0.3746\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7190 - acc: 0.5960 - val_loss: 1.9481 - val_acc: 0.4139\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6220 - acc: 0.6583 - val_loss: 1.8690 - val_acc: 0.4139\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5422 - acc: 0.6615 - val_loss: 1.8660 - val_acc: 0.4592\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4774 - acc: 0.7164 - val_loss: 1.8575 - val_acc: 0.4320\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4582 - acc: 0.7231 - val_loss: 1.8797 - val_acc: 0.4350\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4435 - acc: 0.7193 - val_loss: 1.9799 - val_acc: 0.4320\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4520 - acc: 0.7161 - val_loss: 2.0212 - val_acc: 0.4532\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4909 - acc: 0.7224 - val_loss: 2.0812 - val_acc: 0.3988\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6665 - acc: 0.6397 - val_loss: 2.2615 - val_acc: 0.3625\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6444 - acc: 0.6157 - val_loss: 1.9692 - val_acc: 0.4109\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4890 - acc: 0.7214 - val_loss: 2.1311 - val_acc: 0.4169\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4970 - acc: 0.7182 - val_loss: 1.9896 - val_acc: 0.4350\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4649 - acc: 0.7267 - val_loss: 1.9219 - val_acc: 0.4592\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4311 - acc: 0.7527 - val_loss: 2.0456 - val_acc: 0.4562\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4587 - acc: 0.7284 - val_loss: 2.1627 - val_acc: 0.4290\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5023 - acc: 0.7080 - val_loss: 2.2567 - val_acc: 0.3927\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5773 - acc: 0.6678 - val_loss: 1.8489 - val_acc: 0.4592\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5131 - acc: 0.7140 - val_loss: 1.8499 - val_acc: 0.4683\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5096 - acc: 0.7196 - val_loss: 1.8128 - val_acc: 0.4773\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.6028 - acc: 0.6802 - val_loss: 1.8828 - val_acc: 0.4411\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5078 - acc: 0.7129 - val_loss: 1.9038 - val_acc: 0.4502\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4464 - acc: 0.7319 - val_loss: 1.9246 - val_acc: 0.4441\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4393 - acc: 0.7393 - val_loss: 1.9854 - val_acc: 0.4411\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4116 - acc: 0.7570 - val_loss: 2.0784 - val_acc: 0.4441\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4348 - acc: 0.7453 - val_loss: 2.1253 - val_acc: 0.4048\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.5212 - acc: 0.7002 - val_loss: 1.9844 - val_acc: 0.4381\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5413 - acc: 0.6992 - val_loss: 1.9063 - val_acc: 0.4683\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6442 - acc: 0.6756 - val_loss: 1.7161 - val_acc: 0.4471\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5603 - acc: 0.6777 - val_loss: 1.7660 - val_acc: 0.4320\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4531 - acc: 0.7073 - val_loss: 1.7929 - val_acc: 0.4502\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4577 - acc: 0.7168 - val_loss: 1.8159 - val_acc: 0.4713\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4447 - acc: 0.7277 - val_loss: 1.8319 - val_acc: 0.4955\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4745 - acc: 0.7235 - val_loss: 1.8405 - val_acc: 0.4471\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4883 - acc: 0.6904 - val_loss: 1.7637 - val_acc: 0.4441\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4736 - acc: 0.6921 - val_loss: 1.8052 - val_acc: 0.4562\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4524 - acc: 0.7161 - val_loss: 1.8910 - val_acc: 0.4562\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4605 - acc: 0.7098 - val_loss: 1.8085 - val_acc: 0.4804\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5389 - acc: 0.7062 - val_loss: 1.8332 - val_acc: 0.4924\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6344 - acc: 0.6774 - val_loss: 1.9581 - val_acc: 0.4260\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5053 - acc: 0.7147 - val_loss: 1.9682 - val_acc: 0.4592\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4343 - acc: 0.7369 - val_loss: 2.2244 - val_acc: 0.4079\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5065 - acc: 0.7157 - val_loss: 2.2412 - val_acc: 0.4109\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5432 - acc: 0.6974 - val_loss: 2.0043 - val_acc: 0.4502\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4643 - acc: 0.7425 - val_loss: 1.9685 - val_acc: 0.4532\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4334 - acc: 0.7415 - val_loss: 2.0056 - val_acc: 0.4502\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 111us/step - loss: 0.3907 - acc: 0.7651 - val_loss: 2.0408 - val_acc: 0.4441\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4372 - acc: 0.7415 - val_loss: 2.0207 - val_acc: 0.4834\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6819 - acc: 0.6724 - val_loss: 1.8907 - val_acc: 0.4683\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6401 - acc: 0.6847 - val_loss: 1.8869 - val_acc: 0.4955\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4400 - acc: 0.7467 - val_loss: 1.9749 - val_acc: 0.4622\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4131 - acc: 0.7524 - val_loss: 1.9425 - val_acc: 0.4592\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3980 - acc: 0.7696 - val_loss: 1.9713 - val_acc: 0.4622\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4133 - acc: 0.7453 - val_loss: 1.9193 - val_acc: 0.4713\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4776 - acc: 0.7147 - val_loss: 1.8480 - val_acc: 0.4411\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6358 - acc: 0.6136 - val_loss: 1.7511 - val_acc: 0.4622\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4555 - acc: 0.7136 - val_loss: 1.8982 - val_acc: 0.4743\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4279 - acc: 0.7425 - val_loss: 1.9558 - val_acc: 0.4713\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4159 - acc: 0.7534 - val_loss: 2.0427 - val_acc: 0.4502\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.4141 - acc: 0.7520 - val_loss: 2.0955 - val_acc: 0.4562\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5300 - acc: 0.7105 - val_loss: 1.9008 - val_acc: 0.4864\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8404 - acc: 0.6404 - val_loss: 1.6684 - val_acc: 0.4441\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5004 - acc: 0.7055 - val_loss: 1.7869 - val_acc: 0.4381\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4511 - acc: 0.7189 - val_loss: 1.8876 - val_acc: 0.4471\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3970 - acc: 0.7499 - val_loss: 2.0310 - val_acc: 0.4381\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3963 - acc: 0.7594 - val_loss: 1.9835 - val_acc: 0.4381\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4125 - acc: 0.7400 - val_loss: 1.9086 - val_acc: 0.4441\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4696 - acc: 0.7263 - val_loss: 1.8967 - val_acc: 0.4502\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.7043 - acc: 0.6132 - val_loss: 1.7563 - val_acc: 0.4683\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4743 - acc: 0.6876 - val_loss: 1.8798 - val_acc: 0.4471\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4054 - acc: 0.7489 - val_loss: 1.9591 - val_acc: 0.4350\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4033 - acc: 0.7422 - val_loss: 2.0730 - val_acc: 0.4773\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4109 - acc: 0.7527 - val_loss: 2.0319 - val_acc: 0.4562\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4008 - acc: 0.7636 - val_loss: 2.0143 - val_acc: 0.4683\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5066 - acc: 0.7140 - val_loss: 2.0144 - val_acc: 0.4864\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.7218 - acc: 0.6661 - val_loss: 1.7745 - val_acc: 0.4804\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4546 - acc: 0.7418 - val_loss: 1.8471 - val_acc: 0.4502\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4354 - acc: 0.7365 - val_loss: 1.8736 - val_acc: 0.4471\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4452 - acc: 0.7108 - val_loss: 1.9541 - val_acc: 0.4411\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3959 - acc: 0.7541 - val_loss: 2.0318 - val_acc: 0.4260\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.4141 - acc: 0.7291 - val_loss: 2.0135 - val_acc: 0.4199\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4158 - acc: 0.7235 - val_loss: 1.9443 - val_acc: 0.4562\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5431 - acc: 0.6791 - val_loss: 1.8605 - val_acc: 0.4653\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5075 - acc: 0.6710 - val_loss: 1.8713 - val_acc: 0.4683\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.5011 - acc: 0.7164 - val_loss: 1.9825 - val_acc: 0.4592\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6079 - acc: 0.7115 - val_loss: 1.9984 - val_acc: 0.4894\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4138 - acc: 0.7739 - val_loss: 2.1479 - val_acc: 0.4381\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4225 - acc: 0.7598 - val_loss: 2.2341 - val_acc: 0.4441\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4368 - acc: 0.7443 - val_loss: 2.0864 - val_acc: 0.4411\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4238 - acc: 0.7460 - val_loss: 2.1830 - val_acc: 0.4350\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4369 - acc: 0.7485 - val_loss: 2.3273 - val_acc: 0.3867\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5012 - acc: 0.7101 - val_loss: 2.2025 - val_acc: 0.4199\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4479 - acc: 0.7446 - val_loss: 2.1399 - val_acc: 0.4320\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4122 - acc: 0.7552 - val_loss: 2.1660 - val_acc: 0.4320\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4423 - acc: 0.7400 - val_loss: 2.0877 - val_acc: 0.4743\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6492 - acc: 0.6928 - val_loss: 1.9088 - val_acc: 0.4441\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.5573 - acc: 0.7055 - val_loss: 1.8625 - val_acc: 0.4592\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4335 - acc: 0.7323 - val_loss: 1.9326 - val_acc: 0.4139\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4100 - acc: 0.7386 - val_loss: 1.9785 - val_acc: 0.4532\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3984 - acc: 0.7482 - val_loss: 2.1394 - val_acc: 0.4622\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3880 - acc: 0.7675 - val_loss: 2.0597 - val_acc: 0.4834\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4060 - acc: 0.7598 - val_loss: 2.0590 - val_acc: 0.4562\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4534 - acc: 0.7379 - val_loss: 1.9507 - val_acc: 0.4562\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5747 - acc: 0.6759 - val_loss: 1.8933 - val_acc: 0.4804\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4854 - acc: 0.7358 - val_loss: 2.0764 - val_acc: 0.4502\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4241 - acc: 0.7577 - val_loss: 2.3468 - val_acc: 0.4199\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4807 - acc: 0.7450 - val_loss: 2.6018 - val_acc: 0.3625\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5724 - acc: 0.6943 - val_loss: 1.9877 - val_acc: 0.4562\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4063 - acc: 0.7668 - val_loss: 2.0335 - val_acc: 0.4864\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3776 - acc: 0.7781 - val_loss: 2.1052 - val_acc: 0.4834\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3780 - acc: 0.7700 - val_loss: 2.1419 - val_acc: 0.4713\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3895 - acc: 0.7640 - val_loss: 2.4883 - val_acc: 0.4381\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5865 - acc: 0.7020 - val_loss: 2.0729 - val_acc: 0.4079\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6452 - acc: 0.6534 - val_loss: 1.7995 - val_acc: 0.4773\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4399 - acc: 0.7383 - val_loss: 2.0054 - val_acc: 0.4743\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3784 - acc: 0.7774 - val_loss: 2.0366 - val_acc: 0.4471\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.3869 - acc: 0.7573 - val_loss: 2.0219 - val_acc: 0.4532\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3942 - acc: 0.7499 - val_loss: 2.0078 - val_acc: 0.4441\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4508 - acc: 0.7122 - val_loss: 1.9547 - val_acc: 0.4773\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4398 - acc: 0.7217 - val_loss: 2.0079 - val_acc: 0.4653\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3921 - acc: 0.7651 - val_loss: 2.1154 - val_acc: 0.4411\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4241 - acc: 0.7418 - val_loss: 1.9630 - val_acc: 0.4713\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4376 - acc: 0.7372 - val_loss: 2.0782 - val_acc: 0.4985\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5656 - acc: 0.7147 - val_loss: 1.9887 - val_acc: 0.4834\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6937 - acc: 0.6918 - val_loss: 2.1100 - val_acc: 0.4562\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4196 - acc: 0.7654 - val_loss: 2.1543 - val_acc: 0.4290\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3879 - acc: 0.7735 - val_loss: 2.2077 - val_acc: 0.4502\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3836 - acc: 0.7749 - val_loss: 2.2089 - val_acc: 0.4471\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3668 - acc: 0.7809 - val_loss: 2.5152 - val_acc: 0.4139\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4807 - acc: 0.7443 - val_loss: 2.3664 - val_acc: 0.3776\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 107us/step - loss: 0.4979 - acc: 0.7140 - val_loss: 2.0327 - val_acc: 0.4502\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3811 - acc: 0.7742 - val_loss: 2.1563 - val_acc: 0.4562\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3813 - acc: 0.7725 - val_loss: 2.2637 - val_acc: 0.4320\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.3977 - acc: 0.7707 - val_loss: 2.3017 - val_acc: 0.4230\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4679 - acc: 0.7453 - val_loss: 2.1493 - val_acc: 0.4683\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6727 - acc: 0.6900 - val_loss: 1.9067 - val_acc: 0.4743\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5286 - acc: 0.7179 - val_loss: 2.0797 - val_acc: 0.4532\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3711 - acc: 0.7791 - val_loss: 2.1150 - val_acc: 0.4743\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3648 - acc: 0.7858 - val_loss: 2.1487 - val_acc: 0.4502\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3626 - acc: 0.7813 - val_loss: 2.4394 - val_acc: 0.4018\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4399 - acc: 0.7524 - val_loss: 2.4270 - val_acc: 0.3746\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4808 - acc: 0.7411 - val_loss: 2.2234 - val_acc: 0.4411\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3986 - acc: 0.7654 - val_loss: 2.2725 - val_acc: 0.4562\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4048 - acc: 0.7675 - val_loss: 2.2916 - val_acc: 0.4411\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3792 - acc: 0.7703 - val_loss: 2.2226 - val_acc: 0.4320\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3990 - acc: 0.7682 - val_loss: 2.2880 - val_acc: 0.4320\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4078 - acc: 0.7555 - val_loss: 2.4466 - val_acc: 0.4018\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5317 - acc: 0.7207 - val_loss: 2.5091 - val_acc: 0.3353\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7475 - acc: 0.6076 - val_loss: 2.0299 - val_acc: 0.4532\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4306 - acc: 0.7298 - val_loss: 2.0312 - val_acc: 0.4502\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3614 - acc: 0.7855 - val_loss: 2.1152 - val_acc: 0.4411\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3706 - acc: 0.7672 - val_loss: 2.0966 - val_acc: 0.4653\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3708 - acc: 0.7728 - val_loss: 2.0871 - val_acc: 0.4743\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4330 - acc: 0.7369 - val_loss: 1.9683 - val_acc: 0.4834\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4351 - acc: 0.7305 - val_loss: 1.9633 - val_acc: 0.4441\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.3949 - acc: 0.7334 - val_loss: 2.1251 - val_acc: 0.4471\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3505 - acc: 0.7872 - val_loss: 2.1211 - val_acc: 0.4894\n",
      "Epoch 708/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3761 - acc: 0.7735 - val_loss: 2.0560 - val_acc: 0.4653\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4108 - acc: 0.7460 - val_loss: 1.9853 - val_acc: 0.4653\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4477 - acc: 0.7133 - val_loss: 1.9828 - val_acc: 0.4804\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3934 - acc: 0.7563 - val_loss: 2.1479 - val_acc: 0.4713\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3978 - acc: 0.7647 - val_loss: 2.3416 - val_acc: 0.4713\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5763 - acc: 0.7105 - val_loss: 2.3783 - val_acc: 0.4713\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5300 - acc: 0.7397 - val_loss: 2.2353 - val_acc: 0.4320\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3746 - acc: 0.7813 - val_loss: 2.3464 - val_acc: 0.4169\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3787 - acc: 0.7901 - val_loss: 2.4559 - val_acc: 0.4079\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4230 - acc: 0.7559 - val_loss: 2.5085 - val_acc: 0.3988\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.4612 - acc: 0.7330 - val_loss: 2.3354 - val_acc: 0.4441\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.3988 - acc: 0.7827 - val_loss: 2.1959 - val_acc: 0.4502\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3536 - acc: 0.7820 - val_loss: 2.2039 - val_acc: 0.4683\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3490 - acc: 0.7989 - val_loss: 2.2926 - val_acc: 0.4532\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3640 - acc: 0.7939 - val_loss: 2.3208 - val_acc: 0.4441\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4082 - acc: 0.7682 - val_loss: 2.2360 - val_acc: 0.4592\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.5795 - acc: 0.7224 - val_loss: 2.1970 - val_acc: 0.4683\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7852 - acc: 0.6777 - val_loss: 2.2996 - val_acc: 0.3897\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4367 - acc: 0.7513 - val_loss: 2.1915 - val_acc: 0.4139\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3699 - acc: 0.7834 - val_loss: 2.2000 - val_acc: 0.4713\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3381 - acc: 0.8031 - val_loss: 2.4072 - val_acc: 0.4290\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3680 - acc: 0.7862 - val_loss: 2.5461 - val_acc: 0.3897\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4432 - acc: 0.7573 - val_loss: 2.5979 - val_acc: 0.3988\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4584 - acc: 0.7390 - val_loss: 2.1935 - val_acc: 0.4411\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3488 - acc: 0.7996 - val_loss: 2.2139 - val_acc: 0.4532\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3644 - acc: 0.7946 - val_loss: 2.1472 - val_acc: 0.4290\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3592 - acc: 0.7816 - val_loss: 2.1798 - val_acc: 0.4199\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4606 - acc: 0.7129 - val_loss: 2.1869 - val_acc: 0.4502\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4645 - acc: 0.7267 - val_loss: 2.3240 - val_acc: 0.4350\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4197 - acc: 0.7393 - val_loss: 2.4044 - val_acc: 0.4381\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4269 - acc: 0.7545 - val_loss: 2.5557 - val_acc: 0.4260\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4315 - acc: 0.7538 - val_loss: 2.3710 - val_acc: 0.4199\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3878 - acc: 0.7725 - val_loss: 2.3033 - val_acc: 0.4260\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3504 - acc: 0.8003 - val_loss: 2.2795 - val_acc: 0.4743\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3676 - acc: 0.8013 - val_loss: 2.3398 - val_acc: 0.4683\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3516 - acc: 0.7975 - val_loss: 2.4262 - val_acc: 0.4683\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3581 - acc: 0.7982 - val_loss: 2.4999 - val_acc: 0.4562\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3581 - acc: 0.7929 - val_loss: 2.4799 - val_acc: 0.4169\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4369 - acc: 0.7570 - val_loss: 2.6739 - val_acc: 0.3686\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5483 - acc: 0.7164 - val_loss: 2.3849 - val_acc: 0.4320\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4068 - acc: 0.7742 - val_loss: 2.2948 - val_acc: 0.4622\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3545 - acc: 0.8010 - val_loss: 2.3959 - val_acc: 0.4350\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3397 - acc: 0.7978 - val_loss: 2.4587 - val_acc: 0.4109\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3727 - acc: 0.7936 - val_loss: 2.8127 - val_acc: 0.3776\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.7557 - acc: 0.6728 - val_loss: 2.3942 - val_acc: 0.3776\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6720 - acc: 0.6161 - val_loss: 1.9471 - val_acc: 0.4471\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4886 - acc: 0.7094 - val_loss: 2.1069 - val_acc: 0.4622\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3577 - acc: 0.7869 - val_loss: 2.1875 - val_acc: 0.4622\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3328 - acc: 0.8031 - val_loss: 2.2739 - val_acc: 0.4592\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3392 - acc: 0.8035 - val_loss: 2.2304 - val_acc: 0.4411\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3403 - acc: 0.7908 - val_loss: 2.2142 - val_acc: 0.4320\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3743 - acc: 0.7541 - val_loss: 2.1089 - val_acc: 0.4713\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3511 - acc: 0.7721 - val_loss: 2.1813 - val_acc: 0.4562\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3324 - acc: 0.8013 - val_loss: 2.2107 - val_acc: 0.4743\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4078 - acc: 0.7626 - val_loss: 2.1219 - val_acc: 0.5015\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4345 - acc: 0.7619 - val_loss: 2.0662 - val_acc: 0.4894\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4549 - acc: 0.7186 - val_loss: 2.0378 - val_acc: 0.4592\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4475 - acc: 0.7154 - val_loss: 2.1105 - val_acc: 0.4502\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3866 - acc: 0.7654 - val_loss: 2.2403 - val_acc: 0.4532\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3892 - acc: 0.7548 - val_loss: 2.3235 - val_acc: 0.4350\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3825 - acc: 0.7844 - val_loss: 2.2461 - val_acc: 0.4441\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3377 - acc: 0.7943 - val_loss: 2.3133 - val_acc: 0.4350\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3616 - acc: 0.7658 - val_loss: 2.2394 - val_acc: 0.4290\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3920 - acc: 0.7619 - val_loss: 2.1800 - val_acc: 0.4230\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4018 - acc: 0.7397 - val_loss: 2.1271 - val_acc: 0.4411\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4149 - acc: 0.7369 - val_loss: 2.0451 - val_acc: 0.4562\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4536 - acc: 0.7217 - val_loss: 2.1622 - val_acc: 0.4804\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3863 - acc: 0.7577 - val_loss: 2.2385 - val_acc: 0.4773\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3966 - acc: 0.7707 - val_loss: 2.2534 - val_acc: 0.4743\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5925 - acc: 0.7105 - val_loss: 2.1848 - val_acc: 0.4713\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4756 - acc: 0.7626 - val_loss: 2.1674 - val_acc: 0.4683\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3311 - acc: 0.8017 - val_loss: 2.2163 - val_acc: 0.4713\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3293 - acc: 0.8059 - val_loss: 2.2209 - val_acc: 0.4532\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3151 - acc: 0.8013 - val_loss: 2.2401 - val_acc: 0.4562\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3411 - acc: 0.7883 - val_loss: 2.1592 - val_acc: 0.4532\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4525 - acc: 0.7066 - val_loss: 2.0724 - val_acc: 0.4834\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4626 - acc: 0.7193 - val_loss: 2.0604 - val_acc: 0.4713\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3645 - acc: 0.7675 - val_loss: 2.2259 - val_acc: 0.4683\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3234 - acc: 0.8024 - val_loss: 2.2568 - val_acc: 0.4532\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3180 - acc: 0.7982 - val_loss: 2.3059 - val_acc: 0.4773\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3120 - acc: 0.8154 - val_loss: 2.2380 - val_acc: 0.4350\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3542 - acc: 0.7760 - val_loss: 2.2314 - val_acc: 0.4471\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4891 - acc: 0.7062 - val_loss: 2.0970 - val_acc: 0.4713\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5180 - acc: 0.6957 - val_loss: 2.1303 - val_acc: 0.5106\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4818 - acc: 0.7559 - val_loss: 2.2422 - val_acc: 0.4834\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4551 - acc: 0.7693 - val_loss: 2.3200 - val_acc: 0.4532\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3363 - acc: 0.8080 - val_loss: 2.3254 - val_acc: 0.4773\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3181 - acc: 0.8154 - val_loss: 2.3602 - val_acc: 0.4592\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3314 - acc: 0.8070 - val_loss: 2.3670 - val_acc: 0.4562\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3035 - acc: 0.8221 - val_loss: 2.6552 - val_acc: 0.4320\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3717 - acc: 0.7728 - val_loss: 2.7726 - val_acc: 0.3837\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4499 - acc: 0.7545 - val_loss: 2.5960 - val_acc: 0.4109\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4047 - acc: 0.7732 - val_loss: 2.3528 - val_acc: 0.4622\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3494 - acc: 0.7968 - val_loss: 2.4508 - val_acc: 0.4532\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3363 - acc: 0.8045 - val_loss: 2.5347 - val_acc: 0.4532\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3764 - acc: 0.7961 - val_loss: 2.6041 - val_acc: 0.3958\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5782 - acc: 0.7260 - val_loss: 2.7763 - val_acc: 0.3988\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5743 - acc: 0.6650 - val_loss: 2.1126 - val_acc: 0.4743\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3550 - acc: 0.7943 - val_loss: 2.3031 - val_acc: 0.4441\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3235 - acc: 0.7992 - val_loss: 2.2928 - val_acc: 0.4502\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3396 - acc: 0.7827 - val_loss: 2.2940 - val_acc: 0.4471\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3700 - acc: 0.7633 - val_loss: 2.1934 - val_acc: 0.4471\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4489 - acc: 0.7182 - val_loss: 2.1348 - val_acc: 0.4713\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3666 - acc: 0.7682 - val_loss: 2.2662 - val_acc: 0.4532\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3224 - acc: 0.8073 - val_loss: 2.3490 - val_acc: 0.4532\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3158 - acc: 0.8080 - val_loss: 2.5613 - val_acc: 0.4622\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3020 - acc: 0.8221 - val_loss: 2.4796 - val_acc: 0.4683\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3059 - acc: 0.8133 - val_loss: 2.4363 - val_acc: 0.4683\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4577 - acc: 0.7467 - val_loss: 2.3515 - val_acc: 0.4924\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8892 - acc: 0.6840 - val_loss: 2.2534 - val_acc: 0.4320\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3626 - acc: 0.7904 - val_loss: 2.4621 - val_acc: 0.4350\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3413 - acc: 0.8105 - val_loss: 2.4454 - val_acc: 0.4290\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3071 - acc: 0.8281 - val_loss: 2.4606 - val_acc: 0.4562\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 94us/step - loss: 0.3186 - acc: 0.8056 - val_loss: 2.5534 - val_acc: 0.4350\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.3313 - acc: 0.8094 - val_loss: 2.6102 - val_acc: 0.3988\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3680 - acc: 0.7996 - val_loss: 2.8255 - val_acc: 0.4079\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4538 - acc: 0.7534 - val_loss: 2.6762 - val_acc: 0.4109\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4251 - acc: 0.7612 - val_loss: 2.4765 - val_acc: 0.4320\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3839 - acc: 0.7915 - val_loss: 2.3754 - val_acc: 0.4350\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.3377 - acc: 0.8091 - val_loss: 2.3481 - val_acc: 0.4502\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3388 - acc: 0.7964 - val_loss: 2.3040 - val_acc: 0.4441\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3426 - acc: 0.7830 - val_loss: 2.3839 - val_acc: 0.4804\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4184 - acc: 0.7689 - val_loss: 2.4053 - val_acc: 0.4441\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.4054 - acc: 0.7622 - val_loss: 2.3853 - val_acc: 0.4532\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3336 - acc: 0.7904 - val_loss: 2.4659 - val_acc: 0.4532\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3007 - acc: 0.8235 - val_loss: 2.5444 - val_acc: 0.4864\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 97us/step - loss: 0.3002 - acc: 0.8225 - val_loss: 2.3999 - val_acc: 0.4169\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4040 - acc: 0.7622 - val_loss: 2.1378 - val_acc: 0.4260\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5611 - acc: 0.6678 - val_loss: 2.1036 - val_acc: 0.4743\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4268 - acc: 0.7386 - val_loss: 2.3056 - val_acc: 0.4532\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3229 - acc: 0.8186 - val_loss: 2.4440 - val_acc: 0.4622\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3041 - acc: 0.8281 - val_loss: 2.5104 - val_acc: 0.4713\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2977 - acc: 0.8232 - val_loss: 2.7193 - val_acc: 0.4290\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3306 - acc: 0.8070 - val_loss: 2.7236 - val_acc: 0.4169\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3864 - acc: 0.7802 - val_loss: 2.7986 - val_acc: 0.4199\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4649 - acc: 0.7651 - val_loss: 2.4218 - val_acc: 0.4864\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 94us/step - loss: 0.4684 - acc: 0.7608 - val_loss: 2.2265 - val_acc: 0.4834\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.4483 - acc: 0.7622 - val_loss: 2.3415 - val_acc: 0.4924\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3304 - acc: 0.8112 - val_loss: 2.4498 - val_acc: 0.4653\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2888 - acc: 0.8292 - val_loss: 2.5856 - val_acc: 0.4532\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2906 - acc: 0.8263 - val_loss: 2.6587 - val_acc: 0.4290\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3067 - acc: 0.8295 - val_loss: 2.7408 - val_acc: 0.4048\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.3760 - acc: 0.7746 - val_loss: 2.7602 - val_acc: 0.3927\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3733 - acc: 0.7816 - val_loss: 2.6072 - val_acc: 0.4411\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3230 - acc: 0.8133 - val_loss: 2.6054 - val_acc: 0.4502\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3148 - acc: 0.8278 - val_loss: 2.6038 - val_acc: 0.4441\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2907 - acc: 0.8249 - val_loss: 2.5804 - val_acc: 0.4653\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3194 - acc: 0.8094 - val_loss: 2.8316 - val_acc: 0.4169\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4330 - acc: 0.7668 - val_loss: 2.6055 - val_acc: 0.4139\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4003 - acc: 0.7827 - val_loss: 2.5681 - val_acc: 0.4592\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3131 - acc: 0.8133 - val_loss: 2.4750 - val_acc: 0.4924\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3575 - acc: 0.7978 - val_loss: 2.4392 - val_acc: 0.4834\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6878 - acc: 0.7105 - val_loss: 2.5478 - val_acc: 0.4562\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.7519 - acc: 0.6985 - val_loss: 2.2939 - val_acc: 0.4743\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3335 - acc: 0.8165 - val_loss: 2.3708 - val_acc: 0.4622\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.2937 - acc: 0.8302 - val_loss: 2.4696 - val_acc: 0.4683\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3046 - acc: 0.8228 - val_loss: 2.4974 - val_acc: 0.4653\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2951 - acc: 0.8309 - val_loss: 2.6410 - val_acc: 0.4350\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2876 - acc: 0.8306 - val_loss: 2.6770 - val_acc: 0.4320\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3184 - acc: 0.8119 - val_loss: 2.7044 - val_acc: 0.4290\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3353 - acc: 0.8137 - val_loss: 2.7892 - val_acc: 0.4139\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4051 - acc: 0.7784 - val_loss: 2.8324 - val_acc: 0.4018\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3730 - acc: 0.7939 - val_loss: 2.3907 - val_acc: 0.4441\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.2938 - acc: 0.8246 - val_loss: 2.4536 - val_acc: 0.4773\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2849 - acc: 0.8394 - val_loss: 2.6396 - val_acc: 0.4592\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2968 - acc: 0.8376 - val_loss: 2.6968 - val_acc: 0.4350\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4583 - acc: 0.7661 - val_loss: 3.1419 - val_acc: 0.3625\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5609 - acc: 0.7101 - val_loss: 2.5906 - val_acc: 0.4532\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3775 - acc: 0.7813 - val_loss: 2.2424 - val_acc: 0.4924\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3412 - acc: 0.7968 - val_loss: 2.2687 - val_acc: 0.4713\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3183 - acc: 0.8017 - val_loss: 2.3495 - val_acc: 0.4562\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3053 - acc: 0.8147 - val_loss: 2.4180 - val_acc: 0.4471\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3003 - acc: 0.8228 - val_loss: 2.4993 - val_acc: 0.4502\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2771 - acc: 0.8263 - val_loss: 2.4902 - val_acc: 0.4502\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3052 - acc: 0.8084 - val_loss: 2.3874 - val_acc: 0.4169\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4372 - acc: 0.7235 - val_loss: 2.2156 - val_acc: 0.4653\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4284 - acc: 0.7267 - val_loss: 2.2792 - val_acc: 0.4683\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3335 - acc: 0.8013 - val_loss: 2.4462 - val_acc: 0.5015\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3182 - acc: 0.8123 - val_loss: 2.5856 - val_acc: 0.4773\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3068 - acc: 0.8228 - val_loss: 2.6455 - val_acc: 0.4683\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3060 - acc: 0.8267 - val_loss: 2.6398 - val_acc: 0.4773\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3077 - acc: 0.8207 - val_loss: 2.6563 - val_acc: 0.4441\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3648 - acc: 0.8056 - val_loss: 2.6201 - val_acc: 0.5317\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.8935 - acc: 0.7105 - val_loss: 2.2136 - val_acc: 0.4260\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4331 - acc: 0.7453 - val_loss: 2.2831 - val_acc: 0.4381\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3555 - acc: 0.7615 - val_loss: 2.3136 - val_acc: 0.4411\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3279 - acc: 0.7901 - val_loss: 2.3604 - val_acc: 0.4924\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2970 - acc: 0.8242 - val_loss: 2.4892 - val_acc: 0.4592\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2813 - acc: 0.8337 - val_loss: 2.6210 - val_acc: 0.4411\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2789 - acc: 0.8359 - val_loss: 2.5944 - val_acc: 0.4350\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2693 - acc: 0.8362 - val_loss: 2.5735 - val_acc: 0.4441\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2867 - acc: 0.8352 - val_loss: 2.5355 - val_acc: 0.4471\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3538 - acc: 0.7795 - val_loss: 2.3286 - val_acc: 0.4411\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.5412 - acc: 0.6936 - val_loss: 2.2279 - val_acc: 0.4773\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4314 - acc: 0.7467 - val_loss: 2.3239 - val_acc: 0.4502\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2964 - acc: 0.8154 - val_loss: 2.3995 - val_acc: 0.4773\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3029 - acc: 0.8246 - val_loss: 2.5394 - val_acc: 0.4773\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3840 - acc: 0.8017 - val_loss: 2.6052 - val_acc: 0.4985\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5076 - acc: 0.7742 - val_loss: 2.5638 - val_acc: 0.4592\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3140 - acc: 0.8302 - val_loss: 2.5541 - val_acc: 0.4622\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2727 - acc: 0.8461 - val_loss: 2.6873 - val_acc: 0.4411\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2873 - acc: 0.8348 - val_loss: 2.9466 - val_acc: 0.4079\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3798 - acc: 0.7915 - val_loss: 2.6307 - val_acc: 0.4411\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3258 - acc: 0.8197 - val_loss: 2.6597 - val_acc: 0.4471\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3079 - acc: 0.8302 - val_loss: 2.6425 - val_acc: 0.4592\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2986 - acc: 0.8320 - val_loss: 2.8331 - val_acc: 0.4381\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3320 - acc: 0.8094 - val_loss: 2.9994 - val_acc: 0.4139\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4500 - acc: 0.7647 - val_loss: 2.5733 - val_acc: 0.4260\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3276 - acc: 0.8108 - val_loss: 2.4791 - val_acc: 0.4834\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2924 - acc: 0.8376 - val_loss: 2.5848 - val_acc: 0.4622\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2689 - acc: 0.8496 - val_loss: 2.7047 - val_acc: 0.4441\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2657 - acc: 0.8485 - val_loss: 2.6228 - val_acc: 0.4502\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2611 - acc: 0.8418 - val_loss: 2.9142 - val_acc: 0.4290\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3626 - acc: 0.7950 - val_loss: 2.9272 - val_acc: 0.4260\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4100 - acc: 0.7760 - val_loss: 2.6918 - val_acc: 0.4411\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3870 - acc: 0.7975 - val_loss: 2.5083 - val_acc: 0.4683\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5696 - acc: 0.7446 - val_loss: 2.3544 - val_acc: 0.5045\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4713 - acc: 0.7679 - val_loss: 2.4157 - val_acc: 0.4562\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2912 - acc: 0.8309 - val_loss: 2.5094 - val_acc: 0.4894\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2633 - acc: 0.8563 - val_loss: 2.5738 - val_acc: 0.5045\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2707 - acc: 0.8517 - val_loss: 2.5850 - val_acc: 0.4894\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2851 - acc: 0.8390 - val_loss: 2.4288 - val_acc: 0.4320\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3894 - acc: 0.7467 - val_loss: 2.3820 - val_acc: 0.4502\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 100us/step - loss: 0.3506 - acc: 0.7841 - val_loss: 2.3951 - val_acc: 0.4773\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3091 - acc: 0.8126 - val_loss: 2.5065 - val_acc: 0.4653\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2588 - acc: 0.8390 - val_loss: 2.7035 - val_acc: 0.4592\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2553 - acc: 0.8563 - val_loss: 2.9068 - val_acc: 0.4381\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2669 - acc: 0.8422 - val_loss: 2.8408 - val_acc: 0.4502\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.2765 - acc: 0.8366 - val_loss: 2.9503 - val_acc: 0.4532\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3452 - acc: 0.8038 - val_loss: 3.0371 - val_acc: 0.4018\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4191 - acc: 0.7830 - val_loss: 3.2086 - val_acc: 0.3595\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4342 - acc: 0.7710 - val_loss: 2.6184 - val_acc: 0.4230\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3521 - acc: 0.8112 - val_loss: 2.6739 - val_acc: 0.4290\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3281 - acc: 0.7922 - val_loss: 2.7436 - val_acc: 0.4230\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2777 - acc: 0.8380 - val_loss: 2.7203 - val_acc: 0.4653\n",
      "Epoch 943/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2707 - acc: 0.8348 - val_loss: 2.7727 - val_acc: 0.4653\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2586 - acc: 0.8549 - val_loss: 2.9720 - val_acc: 0.4139\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3232 - acc: 0.8193 - val_loss: 3.0149 - val_acc: 0.4230\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4098 - acc: 0.7760 - val_loss: 2.7273 - val_acc: 0.4139\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3242 - acc: 0.8137 - val_loss: 2.6620 - val_acc: 0.4773\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2654 - acc: 0.8552 - val_loss: 2.6932 - val_acc: 0.4804\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2837 - acc: 0.8404 - val_loss: 2.6719 - val_acc: 0.4562\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2471 - acc: 0.8580 - val_loss: 2.9267 - val_acc: 0.4260\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3092 - acc: 0.8299 - val_loss: 3.1788 - val_acc: 0.4109\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5138 - acc: 0.7686 - val_loss: 2.8335 - val_acc: 0.4260\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6606 - acc: 0.7436 - val_loss: 2.4461 - val_acc: 0.4713\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3537 - acc: 0.7989 - val_loss: 2.4463 - val_acc: 0.4894\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2596 - acc: 0.8422 - val_loss: 2.6796 - val_acc: 0.4743\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2443 - acc: 0.8619 - val_loss: 2.6433 - val_acc: 0.4834\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2631 - acc: 0.8440 - val_loss: 2.4806 - val_acc: 0.4502\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3193 - acc: 0.7961 - val_loss: 2.4198 - val_acc: 0.4592\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3061 - acc: 0.7939 - val_loss: 2.5457 - val_acc: 0.4411\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2665 - acc: 0.8256 - val_loss: 2.6972 - val_acc: 0.4562\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2833 - acc: 0.8235 - val_loss: 2.7893 - val_acc: 0.4411\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2747 - acc: 0.8369 - val_loss: 2.6396 - val_acc: 0.4562\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2602 - acc: 0.8510 - val_loss: 2.6614 - val_acc: 0.4441\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2932 - acc: 0.8151 - val_loss: 2.4848 - val_acc: 0.4411\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4083 - acc: 0.7362 - val_loss: 2.3425 - val_acc: 0.4653\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4693 - acc: 0.7112 - val_loss: 2.4772 - val_acc: 0.4955\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5380 - acc: 0.7580 - val_loss: 2.8687 - val_acc: 0.4683\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5218 - acc: 0.7777 - val_loss: 2.6214 - val_acc: 0.4502\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2752 - acc: 0.8411 - val_loss: 2.6033 - val_acc: 0.4653\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2575 - acc: 0.8510 - val_loss: 2.6658 - val_acc: 0.4441\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.2450 - acc: 0.8545 - val_loss: 2.6454 - val_acc: 0.5045\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2856 - acc: 0.8397 - val_loss: 2.4813 - val_acc: 0.4955\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3590 - acc: 0.7809 - val_loss: 2.4084 - val_acc: 0.4713\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.2988 - acc: 0.8105 - val_loss: 2.4942 - val_acc: 0.4502\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2593 - acc: 0.8359 - val_loss: 2.5733 - val_acc: 0.4683\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2571 - acc: 0.8499 - val_loss: 2.6270 - val_acc: 0.4743\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.2773 - acc: 0.8348 - val_loss: 2.5164 - val_acc: 0.4653\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 105us/step - loss: 0.3038 - acc: 0.8063 - val_loss: 2.4523 - val_acc: 0.4471\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3409 - acc: 0.7791 - val_loss: 2.4156 - val_acc: 0.4471\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3771 - acc: 0.7714 - val_loss: 2.3392 - val_acc: 0.4894\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3344 - acc: 0.7876 - val_loss: 2.4906 - val_acc: 0.5015\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3299 - acc: 0.8126 - val_loss: 2.7349 - val_acc: 0.4804\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4715 - acc: 0.7887 - val_loss: 2.6733 - val_acc: 0.4320\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4139 - acc: 0.7908 - val_loss: 2.3767 - val_acc: 0.4834\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2903 - acc: 0.8302 - val_loss: 2.4550 - val_acc: 0.4592\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.2566 - acc: 0.8443 - val_loss: 2.5894 - val_acc: 0.4773\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2381 - acc: 0.8623 - val_loss: 2.5438 - val_acc: 0.4834\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.2455 - acc: 0.8418 - val_loss: 2.5734 - val_acc: 0.4622\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.2693 - acc: 0.8373 - val_loss: 2.4646 - val_acc: 0.4532\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3681 - acc: 0.7746 - val_loss: 2.3751 - val_acc: 0.4411\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3545 - acc: 0.7774 - val_loss: 2.4305 - val_acc: 0.4773\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.2847 - acc: 0.8211 - val_loss: 2.6067 - val_acc: 0.4683\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2762 - acc: 0.8295 - val_loss: 2.6370 - val_acc: 0.4502\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2515 - acc: 0.8461 - val_loss: 2.6140 - val_acc: 0.4622\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3222 - acc: 0.8119 - val_loss: 2.4306 - val_acc: 0.4683\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3866 - acc: 0.7629 - val_loss: 2.3103 - val_acc: 0.4502\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3468 - acc: 0.7668 - val_loss: 2.5378 - val_acc: 0.4230\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3019 - acc: 0.8108 - val_loss: 2.6910 - val_acc: 0.4411\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.2997 - acc: 0.8260 - val_loss: 2.7382 - val_acc: 0.4471\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.2690 - acc: 0.8429 - val_loss: 2.8181 - val_acc: 0.4562\n"
     ]
    }
   ],
   "source": [
    "w2v_model_2 = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "0.7962962962962963\n",
      "0.9629629629629629\n",
      "22\n",
      "0.7272727272727273\n",
      "0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_w2v)\n",
    "model_metrics(predictions, y_cat_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npKAgIiJFCgoiIlKkoCAiIkUKCiIiUvT/+YNNK8MVf7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x187aca828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model_2.history['acc'])\n",
    "plt.plot(w2v_model_2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVySsQ6skAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x187ad4978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zillow_model_2.history['val_acc'])\n",
    "plt.plot(business_model_2.history['val_acc'])\n",
    "plt.plot(w2v_model_2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['zillow', 'business', 'w2v'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.002)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/1000\n",
      "2839/2839 [==============================] - 2s 862us/step - loss: 1.1259 - acc: 0.1254 - val_loss: 1.9368 - val_acc: 0.1601\n",
      "Epoch 2/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.1175 - acc: 0.1909 - val_loss: 1.9460 - val_acc: 0.1601\n",
      "Epoch 3/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0942 - acc: 0.1997 - val_loss: 1.8857 - val_acc: 0.1601\n",
      "Epoch 4/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0813 - acc: 0.2149 - val_loss: 1.7835 - val_acc: 0.1601\n",
      "Epoch 5/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0766 - acc: 0.2233 - val_loss: 1.7950 - val_acc: 0.1601\n",
      "Epoch 6/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0503 - acc: 0.2261 - val_loss: 1.7223 - val_acc: 0.1601\n",
      "Epoch 7/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0509 - acc: 0.2279 - val_loss: 1.6586 - val_acc: 0.1601\n",
      "Epoch 8/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0278 - acc: 0.2420 - val_loss: 1.6721 - val_acc: 0.1722\n",
      "Epoch 9/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0292 - acc: 0.2437 - val_loss: 1.7730 - val_acc: 0.1631\n",
      "Epoch 10/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0327 - acc: 0.2251 - val_loss: 1.6964 - val_acc: 0.1662\n",
      "Epoch 11/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0125 - acc: 0.2497 - val_loss: 1.6117 - val_acc: 0.1601\n",
      "Epoch 12/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0133 - acc: 0.2557 - val_loss: 1.6578 - val_acc: 0.1601\n",
      "Epoch 13/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0113 - acc: 0.2416 - val_loss: 1.6748 - val_acc: 0.1541\n",
      "Epoch 14/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 1.0103 - acc: 0.2490 - val_loss: 1.6503 - val_acc: 0.1752\n",
      "Epoch 15/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.0070 - acc: 0.2515 - val_loss: 1.6100 - val_acc: 0.1601\n",
      "Epoch 16/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9940 - acc: 0.2430 - val_loss: 1.5729 - val_acc: 0.1601\n",
      "Epoch 17/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9904 - acc: 0.2529 - val_loss: 1.5854 - val_acc: 0.1601\n",
      "Epoch 18/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9849 - acc: 0.2603 - val_loss: 1.6387 - val_acc: 0.1601\n",
      "Epoch 19/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9971 - acc: 0.2600 - val_loss: 1.6193 - val_acc: 0.1601\n",
      "Epoch 20/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9931 - acc: 0.2462 - val_loss: 1.6175 - val_acc: 0.1601\n",
      "Epoch 21/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9922 - acc: 0.2381 - val_loss: 1.5752 - val_acc: 0.1601\n",
      "Epoch 22/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9872 - acc: 0.2473 - val_loss: 1.5924 - val_acc: 0.1601\n",
      "Epoch 23/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9783 - acc: 0.2543 - val_loss: 1.5362 - val_acc: 0.1601\n",
      "Epoch 24/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9744 - acc: 0.2459 - val_loss: 1.4994 - val_acc: 0.1601\n",
      "Epoch 25/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9659 - acc: 0.2642 - val_loss: 1.5888 - val_acc: 0.1601\n",
      "Epoch 26/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9917 - acc: 0.2371 - val_loss: 1.7075 - val_acc: 0.1601\n",
      "Epoch 27/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 1.0094 - acc: 0.2279 - val_loss: 1.5381 - val_acc: 0.1601\n",
      "Epoch 28/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9706 - acc: 0.2483 - val_loss: 1.4793 - val_acc: 0.1601\n",
      "Epoch 29/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9717 - acc: 0.2423 - val_loss: 1.4830 - val_acc: 0.1601\n",
      "Epoch 30/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9665 - acc: 0.2536 - val_loss: 1.5308 - val_acc: 0.1601\n",
      "Epoch 31/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9596 - acc: 0.2719 - val_loss: 1.6196 - val_acc: 0.1631\n",
      "Epoch 32/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9717 - acc: 0.2328 - val_loss: 1.5156 - val_acc: 0.1601\n",
      "Epoch 33/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9572 - acc: 0.2543 - val_loss: 1.5284 - val_acc: 0.1601\n",
      "Epoch 34/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.9541 - acc: 0.2529 - val_loss: 1.5788 - val_acc: 0.1631\n",
      "Epoch 35/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.9730 - acc: 0.2473 - val_loss: 1.6203 - val_acc: 0.1601\n",
      "Epoch 36/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9666 - acc: 0.2466 - val_loss: 1.5176 - val_acc: 0.1631\n",
      "Epoch 37/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.9458 - acc: 0.2529 - val_loss: 1.5949 - val_acc: 0.1662\n",
      "Epoch 38/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.9823 - acc: 0.2437 - val_loss: 1.5866 - val_acc: 0.1964\n",
      "Epoch 39/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9680 - acc: 0.2712 - val_loss: 1.4947 - val_acc: 0.1601\n",
      "Epoch 40/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.9537 - acc: 0.2557 - val_loss: 1.5889 - val_acc: 0.1631\n",
      "Epoch 41/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.9618 - acc: 0.2434 - val_loss: 1.5097 - val_acc: 0.1601\n",
      "Epoch 42/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9450 - acc: 0.2688 - val_loss: 1.5466 - val_acc: 0.1631\n",
      "Epoch 43/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9532 - acc: 0.2483 - val_loss: 1.5788 - val_acc: 0.1934\n",
      "Epoch 44/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9573 - acc: 0.2494 - val_loss: 1.5405 - val_acc: 0.1480\n",
      "Epoch 45/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9377 - acc: 0.2638 - val_loss: 1.4818 - val_acc: 0.1541\n",
      "Epoch 46/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9340 - acc: 0.2557 - val_loss: 1.5334 - val_acc: 0.1752\n",
      "Epoch 47/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9417 - acc: 0.2494 - val_loss: 1.5965 - val_acc: 0.1601\n",
      "Epoch 48/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9650 - acc: 0.2445 - val_loss: 1.6101 - val_acc: 0.1752\n",
      "Epoch 49/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9542 - acc: 0.2497 - val_loss: 1.5135 - val_acc: 0.1631\n",
      "Epoch 50/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9346 - acc: 0.2864 - val_loss: 1.5601 - val_acc: 0.1601\n",
      "Epoch 51/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.9433 - acc: 0.2621 - val_loss: 1.4989 - val_acc: 0.1964\n",
      "Epoch 52/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9320 - acc: 0.2814 - val_loss: 1.5641 - val_acc: 0.2266\n",
      "Epoch 53/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9498 - acc: 0.2828 - val_loss: 1.5488 - val_acc: 0.1601\n",
      "Epoch 54/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9357 - acc: 0.2607 - val_loss: 1.5301 - val_acc: 0.2085\n",
      "Epoch 55/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9325 - acc: 0.2765 - val_loss: 1.5250 - val_acc: 0.1903\n",
      "Epoch 56/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9418 - acc: 0.2673 - val_loss: 1.6170 - val_acc: 0.2054\n",
      "Epoch 57/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9469 - acc: 0.2529 - val_loss: 1.4566 - val_acc: 0.3172\n",
      "Epoch 58/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9241 - acc: 0.2941 - val_loss: 1.5039 - val_acc: 0.2840\n",
      "Epoch 59/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9143 - acc: 0.2938 - val_loss: 1.4068 - val_acc: 0.3172\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9216 - acc: 0.2990 - val_loss: 1.4096 - val_acc: 0.3112\n",
      "Epoch 61/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9407 - acc: 0.2839 - val_loss: 1.4566 - val_acc: 0.1873\n",
      "Epoch 62/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9277 - acc: 0.2747 - val_loss: 1.4364 - val_acc: 0.2931\n",
      "Epoch 63/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9177 - acc: 0.3054 - val_loss: 1.4107 - val_acc: 0.3082\n",
      "Epoch 64/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9259 - acc: 0.2959 - val_loss: 1.4824 - val_acc: 0.3595\n",
      "Epoch 65/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9149 - acc: 0.2934 - val_loss: 1.5134 - val_acc: 0.2115\n",
      "Epoch 66/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9199 - acc: 0.2920 - val_loss: 1.6228 - val_acc: 0.2296\n",
      "Epoch 67/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.9420 - acc: 0.2656 - val_loss: 1.4324 - val_acc: 0.4230\n",
      "Epoch 68/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9070 - acc: 0.3283 - val_loss: 1.4614 - val_acc: 0.3656\n",
      "Epoch 69/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9049 - acc: 0.3026 - val_loss: 1.5182 - val_acc: 0.3807\n",
      "Epoch 70/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9286 - acc: 0.3001 - val_loss: 1.6591 - val_acc: 0.2719\n",
      "Epoch 71/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9576 - acc: 0.2420 - val_loss: 1.4993 - val_acc: 0.3595\n",
      "Epoch 72/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9080 - acc: 0.3050 - val_loss: 1.4705 - val_acc: 0.2628\n",
      "Epoch 73/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9004 - acc: 0.3072 - val_loss: 1.4494 - val_acc: 0.2538\n",
      "Epoch 74/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.9012 - acc: 0.2917 - val_loss: 1.4236 - val_acc: 0.3867\n",
      "Epoch 75/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.9097 - acc: 0.2980 - val_loss: 1.4305 - val_acc: 0.2659\n",
      "Epoch 76/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.9081 - acc: 0.3019 - val_loss: 1.4222 - val_acc: 0.3021\n",
      "Epoch 77/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.9107 - acc: 0.3029 - val_loss: 1.4857 - val_acc: 0.1662\n",
      "Epoch 78/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.9029 - acc: 0.2857 - val_loss: 1.4294 - val_acc: 0.3897\n",
      "Epoch 79/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8916 - acc: 0.3258 - val_loss: 1.4652 - val_acc: 0.3202\n",
      "Epoch 80/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8818 - acc: 0.3153 - val_loss: 1.4347 - val_acc: 0.3323\n",
      "Epoch 81/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8971 - acc: 0.2917 - val_loss: 1.4163 - val_acc: 0.3776\n",
      "Epoch 82/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.9000 - acc: 0.3093 - val_loss: 1.4626 - val_acc: 0.3867\n",
      "Epoch 83/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8855 - acc: 0.3068 - val_loss: 1.5647 - val_acc: 0.2719\n",
      "Epoch 84/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.9163 - acc: 0.2779 - val_loss: 1.6081 - val_acc: 0.1964\n",
      "Epoch 85/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.9157 - acc: 0.2776 - val_loss: 1.4908 - val_acc: 0.3776\n",
      "Epoch 86/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8947 - acc: 0.3339 - val_loss: 1.5936 - val_acc: 0.2205\n",
      "Epoch 87/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.9015 - acc: 0.2895 - val_loss: 1.4980 - val_acc: 0.2598\n",
      "Epoch 88/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8744 - acc: 0.3103 - val_loss: 1.4861 - val_acc: 0.3897\n",
      "Epoch 89/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8843 - acc: 0.3205 - val_loss: 1.5245 - val_acc: 0.2810\n",
      "Epoch 90/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8919 - acc: 0.2614 - val_loss: 1.5069 - val_acc: 0.2628\n",
      "Epoch 91/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8799 - acc: 0.3001 - val_loss: 1.3791 - val_acc: 0.4773\n",
      "Epoch 92/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9088 - acc: 0.3244 - val_loss: 1.4917 - val_acc: 0.2508\n",
      "Epoch 93/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8839 - acc: 0.3005 - val_loss: 1.3963 - val_acc: 0.4018\n",
      "Epoch 94/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.9084 - acc: 0.3308 - val_loss: 1.5307 - val_acc: 0.2024\n",
      "Epoch 95/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8827 - acc: 0.2839 - val_loss: 1.4624 - val_acc: 0.3807\n",
      "Epoch 96/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8717 - acc: 0.3251 - val_loss: 1.5234 - val_acc: 0.3021\n",
      "Epoch 97/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8748 - acc: 0.3068 - val_loss: 1.5128 - val_acc: 0.2961\n",
      "Epoch 98/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8703 - acc: 0.3036 - val_loss: 1.4620 - val_acc: 0.3656\n",
      "Epoch 99/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8597 - acc: 0.3336 - val_loss: 1.5480 - val_acc: 0.2628\n",
      "Epoch 100/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8779 - acc: 0.3082 - val_loss: 1.5356 - val_acc: 0.2628\n",
      "Epoch 101/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8692 - acc: 0.3128 - val_loss: 1.7841 - val_acc: 0.1450\n",
      "Epoch 102/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.9405 - acc: 0.2504 - val_loss: 1.4515 - val_acc: 0.3021\n",
      "Epoch 103/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8730 - acc: 0.3251 - val_loss: 1.5079 - val_acc: 0.2508\n",
      "Epoch 104/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8623 - acc: 0.3008 - val_loss: 1.4834 - val_acc: 0.3082\n",
      "Epoch 105/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8595 - acc: 0.3325 - val_loss: 1.5086 - val_acc: 0.2659\n",
      "Epoch 106/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8541 - acc: 0.3244 - val_loss: 1.4890 - val_acc: 0.2689\n",
      "Epoch 107/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8572 - acc: 0.3283 - val_loss: 1.4000 - val_acc: 0.3807\n",
      "Epoch 108/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8667 - acc: 0.3392 - val_loss: 1.4288 - val_acc: 0.3595\n",
      "Epoch 109/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8425 - acc: 0.3494 - val_loss: 1.4433 - val_acc: 0.3384\n",
      "Epoch 110/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8683 - acc: 0.3329 - val_loss: 1.5501 - val_acc: 0.2840\n",
      "Epoch 111/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8879 - acc: 0.3110 - val_loss: 1.6715 - val_acc: 0.2145\n",
      "Epoch 112/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.9245 - acc: 0.2723 - val_loss: 1.5019 - val_acc: 0.2840\n",
      "Epoch 113/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8837 - acc: 0.2716 - val_loss: 1.4648 - val_acc: 0.3716\n",
      "Epoch 114/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8465 - acc: 0.3477 - val_loss: 1.5578 - val_acc: 0.2236\n",
      "Epoch 115/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8616 - acc: 0.3181 - val_loss: 1.5975 - val_acc: 0.2115\n",
      "Epoch 116/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.8709 - acc: 0.2836 - val_loss: 1.4481 - val_acc: 0.3625\n",
      "Epoch 117/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.8269 - acc: 0.3462 - val_loss: 1.4617 - val_acc: 0.3384\n",
      "Epoch 118/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8455 - acc: 0.3283 - val_loss: 1.4400 - val_acc: 0.3384\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8636 - acc: 0.3149 - val_loss: 1.4710 - val_acc: 0.3293\n",
      "Epoch 120/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8552 - acc: 0.3420 - val_loss: 1.4579 - val_acc: 0.3414\n",
      "Epoch 121/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.9083 - acc: 0.3308 - val_loss: 1.4489 - val_acc: 0.2840\n",
      "Epoch 122/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8591 - acc: 0.3061 - val_loss: 1.4250 - val_acc: 0.3776\n",
      "Epoch 123/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8610 - acc: 0.3212 - val_loss: 1.4169 - val_acc: 0.3897\n",
      "Epoch 124/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8369 - acc: 0.3515 - val_loss: 1.4557 - val_acc: 0.3414\n",
      "Epoch 125/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8428 - acc: 0.3470 - val_loss: 1.4852 - val_acc: 0.3112\n",
      "Epoch 126/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.8376 - acc: 0.3410 - val_loss: 1.4302 - val_acc: 0.3927\n",
      "Epoch 127/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8282 - acc: 0.3660 - val_loss: 1.4205 - val_acc: 0.3807\n",
      "Epoch 128/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8610 - acc: 0.3279 - val_loss: 1.4865 - val_acc: 0.3535\n",
      "Epoch 129/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8393 - acc: 0.3501 - val_loss: 1.6339 - val_acc: 0.2326\n",
      "Epoch 130/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.8849 - acc: 0.2807 - val_loss: 1.6069 - val_acc: 0.2054\n",
      "Epoch 131/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8666 - acc: 0.2800 - val_loss: 1.3686 - val_acc: 0.4320\n",
      "Epoch 132/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8493 - acc: 0.3695 - val_loss: 1.4585 - val_acc: 0.3172\n",
      "Epoch 133/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8257 - acc: 0.3364 - val_loss: 1.4528 - val_acc: 0.3112\n",
      "Epoch 134/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.8212 - acc: 0.3529 - val_loss: 1.5605 - val_acc: 0.2508\n",
      "Epoch 135/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.8580 - acc: 0.3040 - val_loss: 1.6021 - val_acc: 0.2326\n",
      "Epoch 136/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8480 - acc: 0.3286 - val_loss: 1.5865 - val_acc: 0.2387\n",
      "Epoch 137/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8422 - acc: 0.3226 - val_loss: 1.5685 - val_acc: 0.2628\n",
      "Epoch 138/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.8288 - acc: 0.3318 - val_loss: 1.5662 - val_acc: 0.2568\n",
      "Epoch 139/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8526 - acc: 0.2966 - val_loss: 1.4543 - val_acc: 0.3686\n",
      "Epoch 140/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8102 - acc: 0.3716 - val_loss: 1.4371 - val_acc: 0.3595\n",
      "Epoch 141/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.8271 - acc: 0.3515 - val_loss: 1.4645 - val_acc: 0.3535\n",
      "Epoch 142/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8310 - acc: 0.3389 - val_loss: 1.4270 - val_acc: 0.3927\n",
      "Epoch 143/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8228 - acc: 0.3737 - val_loss: 1.4523 - val_acc: 0.3746\n",
      "Epoch 144/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.8056 - acc: 0.3734 - val_loss: 1.4667 - val_acc: 0.3595\n",
      "Epoch 145/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.8325 - acc: 0.3364 - val_loss: 1.5883 - val_acc: 0.2447\n",
      "Epoch 146/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8320 - acc: 0.3392 - val_loss: 1.6223 - val_acc: 0.2356\n",
      "Epoch 147/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8313 - acc: 0.3248 - val_loss: 1.4623 - val_acc: 0.3353\n",
      "Epoch 148/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8345 - acc: 0.3230 - val_loss: 1.4179 - val_acc: 0.3867\n",
      "Epoch 149/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8201 - acc: 0.3536 - val_loss: 1.4105 - val_acc: 0.4018\n",
      "Epoch 150/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8288 - acc: 0.3544 - val_loss: 1.4534 - val_acc: 0.3353\n",
      "Epoch 151/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8082 - acc: 0.3498 - val_loss: 1.5194 - val_acc: 0.2749\n",
      "Epoch 152/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.8243 - acc: 0.3131 - val_loss: 1.4833 - val_acc: 0.3625\n",
      "Epoch 153/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7886 - acc: 0.3758 - val_loss: 1.4898 - val_acc: 0.3384\n",
      "Epoch 154/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8042 - acc: 0.3413 - val_loss: 1.5341 - val_acc: 0.3293\n",
      "Epoch 155/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8352 - acc: 0.3339 - val_loss: 1.6065 - val_acc: 0.2870\n",
      "Epoch 156/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.8599 - acc: 0.3600 - val_loss: 1.6328 - val_acc: 0.2296\n",
      "Epoch 157/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8351 - acc: 0.3131 - val_loss: 1.5635 - val_acc: 0.2749\n",
      "Epoch 158/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8130 - acc: 0.3607 - val_loss: 1.5917 - val_acc: 0.2538\n",
      "Epoch 159/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.8199 - acc: 0.3339 - val_loss: 1.4870 - val_acc: 0.3535\n",
      "Epoch 160/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7812 - acc: 0.3741 - val_loss: 1.6721 - val_acc: 0.2387\n",
      "Epoch 161/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.8383 - acc: 0.2994 - val_loss: 1.5590 - val_acc: 0.3233\n",
      "Epoch 162/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8211 - acc: 0.3755 - val_loss: 1.5136 - val_acc: 0.3021\n",
      "Epoch 163/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8042 - acc: 0.3494 - val_loss: 1.5550 - val_acc: 0.2900\n",
      "Epoch 164/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.8112 - acc: 0.3600 - val_loss: 1.7153 - val_acc: 0.2054\n",
      "Epoch 165/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8347 - acc: 0.3241 - val_loss: 1.4654 - val_acc: 0.3776\n",
      "Epoch 166/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.8062 - acc: 0.3653 - val_loss: 1.4224 - val_acc: 0.3807\n",
      "Epoch 167/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8163 - acc: 0.3572 - val_loss: 1.4923 - val_acc: 0.3535\n",
      "Epoch 168/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8100 - acc: 0.3646 - val_loss: 1.5918 - val_acc: 0.2538\n",
      "Epoch 169/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.8008 - acc: 0.3374 - val_loss: 1.6207 - val_acc: 0.2477\n",
      "Epoch 170/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.7915 - acc: 0.3441 - val_loss: 1.5354 - val_acc: 0.3142\n",
      "Epoch 171/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7751 - acc: 0.3639 - val_loss: 1.5728 - val_acc: 0.2870\n",
      "Epoch 172/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.8077 - acc: 0.3403 - val_loss: 1.5947 - val_acc: 0.2417\n",
      "Epoch 173/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8402 - acc: 0.2899 - val_loss: 1.5697 - val_acc: 0.2870\n",
      "Epoch 174/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7871 - acc: 0.3406 - val_loss: 1.6461 - val_acc: 0.2417\n",
      "Epoch 175/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8018 - acc: 0.3290 - val_loss: 1.5202 - val_acc: 0.3082\n",
      "Epoch 176/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7801 - acc: 0.3617 - val_loss: 1.5167 - val_acc: 0.3716\n",
      "Epoch 177/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7741 - acc: 0.3677 - val_loss: 1.4961 - val_acc: 0.3656\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.7772 - acc: 0.3540 - val_loss: 1.6051 - val_acc: 0.2508\n",
      "Epoch 179/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.8090 - acc: 0.3262 - val_loss: 1.6834 - val_acc: 0.2296\n",
      "Epoch 180/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.8153 - acc: 0.3293 - val_loss: 1.6268 - val_acc: 0.2447\n",
      "Epoch 181/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.7980 - acc: 0.3272 - val_loss: 1.5503 - val_acc: 0.2900\n",
      "Epoch 182/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7672 - acc: 0.3709 - val_loss: 1.6704 - val_acc: 0.2266\n",
      "Epoch 183/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.8060 - acc: 0.3184 - val_loss: 1.5536 - val_acc: 0.2900\n",
      "Epoch 184/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.7750 - acc: 0.3617 - val_loss: 1.5546 - val_acc: 0.2870\n",
      "Epoch 185/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.7733 - acc: 0.3716 - val_loss: 1.6396 - val_acc: 0.2598\n",
      "Epoch 186/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8068 - acc: 0.3205 - val_loss: 1.5924 - val_acc: 0.2719\n",
      "Epoch 187/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7861 - acc: 0.3431 - val_loss: 1.5324 - val_acc: 0.2870\n",
      "Epoch 188/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8016 - acc: 0.3082 - val_loss: 1.4294 - val_acc: 0.3595\n",
      "Epoch 189/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7865 - acc: 0.3625 - val_loss: 1.4033 - val_acc: 0.4350\n",
      "Epoch 190/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7736 - acc: 0.3797 - val_loss: 1.3877 - val_acc: 0.4230\n",
      "Epoch 191/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.8136 - acc: 0.4026 - val_loss: 1.4604 - val_acc: 0.3474\n",
      "Epoch 192/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7790 - acc: 0.3406 - val_loss: 1.4883 - val_acc: 0.3263\n",
      "Epoch 193/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7866 - acc: 0.3424 - val_loss: 1.4888 - val_acc: 0.3686\n",
      "Epoch 194/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7394 - acc: 0.3892 - val_loss: 1.4872 - val_acc: 0.3414\n",
      "Epoch 195/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7367 - acc: 0.3903 - val_loss: 1.4948 - val_acc: 0.3353\n",
      "Epoch 196/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7464 - acc: 0.3906 - val_loss: 1.6308 - val_acc: 0.2900\n",
      "Epoch 197/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8042 - acc: 0.3283 - val_loss: 1.7996 - val_acc: 0.2145\n",
      "Epoch 198/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.8490 - acc: 0.3005 - val_loss: 1.4674 - val_acc: 0.3656\n",
      "Epoch 199/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.7598 - acc: 0.3977 - val_loss: 1.4537 - val_acc: 0.4441\n",
      "Epoch 200/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7502 - acc: 0.3889 - val_loss: 1.4931 - val_acc: 0.3172\n",
      "Epoch 201/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.8128 - acc: 0.3040 - val_loss: 1.3898 - val_acc: 0.4713\n",
      "Epoch 202/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7630 - acc: 0.3938 - val_loss: 1.4046 - val_acc: 0.4290\n",
      "Epoch 203/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7413 - acc: 0.3846 - val_loss: 1.4158 - val_acc: 0.4381\n",
      "Epoch 204/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7630 - acc: 0.3917 - val_loss: 1.5332 - val_acc: 0.3444\n",
      "Epoch 205/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7969 - acc: 0.3466 - val_loss: 1.6199 - val_acc: 0.3021\n",
      "Epoch 206/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7845 - acc: 0.3515 - val_loss: 1.5892 - val_acc: 0.2689\n",
      "Epoch 207/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7672 - acc: 0.3392 - val_loss: 1.5185 - val_acc: 0.3142\n",
      "Epoch 208/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7299 - acc: 0.3924 - val_loss: 1.6346 - val_acc: 0.2870\n",
      "Epoch 209/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7665 - acc: 0.3677 - val_loss: 1.5355 - val_acc: 0.3142\n",
      "Epoch 210/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7459 - acc: 0.3765 - val_loss: 1.5172 - val_acc: 0.3263\n",
      "Epoch 211/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.7276 - acc: 0.3889 - val_loss: 1.5269 - val_acc: 0.3263\n",
      "Epoch 212/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7352 - acc: 0.3642 - val_loss: 1.7001 - val_acc: 0.2417\n",
      "Epoch 213/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.8029 - acc: 0.3399 - val_loss: 1.5456 - val_acc: 0.3202\n",
      "Epoch 214/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7621 - acc: 0.3547 - val_loss: 1.7788 - val_acc: 0.2326\n",
      "Epoch 215/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.8274 - acc: 0.3177 - val_loss: 1.5450 - val_acc: 0.2810\n",
      "Epoch 216/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7464 - acc: 0.3628 - val_loss: 1.4607 - val_acc: 0.3897\n",
      "Epoch 217/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.7114 - acc: 0.3857 - val_loss: 1.4977 - val_acc: 0.3535\n",
      "Epoch 218/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7480 - acc: 0.3628 - val_loss: 1.5578 - val_acc: 0.3202\n",
      "Epoch 219/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.7565 - acc: 0.3632 - val_loss: 1.4482 - val_acc: 0.4320\n",
      "Epoch 220/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7236 - acc: 0.4037 - val_loss: 1.3943 - val_acc: 0.4471\n",
      "Epoch 221/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7600 - acc: 0.3991 - val_loss: 1.4079 - val_acc: 0.4018\n",
      "Epoch 222/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7384 - acc: 0.3839 - val_loss: 1.4773 - val_acc: 0.3293\n",
      "Epoch 223/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7806 - acc: 0.3371 - val_loss: 1.4431 - val_acc: 0.4139\n",
      "Epoch 224/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7146 - acc: 0.3903 - val_loss: 1.4547 - val_acc: 0.4109\n",
      "Epoch 225/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7565 - acc: 0.3934 - val_loss: 1.4458 - val_acc: 0.3776\n",
      "Epoch 226/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7462 - acc: 0.3674 - val_loss: 1.5551 - val_acc: 0.3233\n",
      "Epoch 227/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7475 - acc: 0.3720 - val_loss: 1.6288 - val_acc: 0.2719\n",
      "Epoch 228/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7475 - acc: 0.3787 - val_loss: 1.4995 - val_acc: 0.3142\n",
      "Epoch 229/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7153 - acc: 0.3871 - val_loss: 1.4282 - val_acc: 0.3867\n",
      "Epoch 230/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7408 - acc: 0.3861 - val_loss: 1.4278 - val_acc: 0.3595\n",
      "Epoch 231/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7759 - acc: 0.3540 - val_loss: 1.3924 - val_acc: 0.4653\n",
      "Epoch 232/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7341 - acc: 0.3991 - val_loss: 1.4149 - val_acc: 0.3958\n",
      "Epoch 233/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7306 - acc: 0.3861 - val_loss: 1.5352 - val_acc: 0.3565\n",
      "Epoch 234/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7724 - acc: 0.3283 - val_loss: 1.5377 - val_acc: 0.3293\n",
      "Epoch 235/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7290 - acc: 0.3984 - val_loss: 1.6174 - val_acc: 0.2659\n",
      "Epoch 236/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7305 - acc: 0.3741 - val_loss: 1.5305 - val_acc: 0.3323\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7154 - acc: 0.3783 - val_loss: 1.5555 - val_acc: 0.3233\n",
      "Epoch 238/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7267 - acc: 0.3617 - val_loss: 1.4729 - val_acc: 0.3746\n",
      "Epoch 239/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6975 - acc: 0.4019 - val_loss: 1.5899 - val_acc: 0.3535\n",
      "Epoch 240/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7246 - acc: 0.3762 - val_loss: 1.5678 - val_acc: 0.2779\n",
      "Epoch 241/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7328 - acc: 0.3649 - val_loss: 1.4721 - val_acc: 0.4048\n",
      "Epoch 242/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7362 - acc: 0.3963 - val_loss: 1.4760 - val_acc: 0.3807\n",
      "Epoch 243/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7168 - acc: 0.3917 - val_loss: 1.3785 - val_acc: 0.4381\n",
      "Epoch 244/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.7381 - acc: 0.3949 - val_loss: 1.3574 - val_acc: 0.4653\n",
      "Epoch 245/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7563 - acc: 0.4132 - val_loss: 1.4655 - val_acc: 0.3535\n",
      "Epoch 246/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6809 - acc: 0.4160 - val_loss: 1.5923 - val_acc: 0.3051\n",
      "Epoch 247/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7663 - acc: 0.3646 - val_loss: 1.7563 - val_acc: 0.2477\n",
      "Epoch 248/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7775 - acc: 0.3283 - val_loss: 1.4438 - val_acc: 0.3595\n",
      "Epoch 249/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7131 - acc: 0.3882 - val_loss: 1.4365 - val_acc: 0.3746\n",
      "Epoch 250/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7287 - acc: 0.3790 - val_loss: 1.4941 - val_acc: 0.3595\n",
      "Epoch 251/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6812 - acc: 0.4199 - val_loss: 1.5402 - val_acc: 0.2991\n",
      "Epoch 252/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7294 - acc: 0.3498 - val_loss: 1.4463 - val_acc: 0.3505\n",
      "Epoch 253/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6938 - acc: 0.4089 - val_loss: 1.4416 - val_acc: 0.3353\n",
      "Epoch 254/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.7297 - acc: 0.3589 - val_loss: 1.4620 - val_acc: 0.3384\n",
      "Epoch 255/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7863 - acc: 0.3399 - val_loss: 1.4493 - val_acc: 0.3776\n",
      "Epoch 256/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6900 - acc: 0.4125 - val_loss: 1.4384 - val_acc: 0.4290\n",
      "Epoch 257/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6798 - acc: 0.4030 - val_loss: 1.3709 - val_acc: 0.4743\n",
      "Epoch 258/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7200 - acc: 0.4192 - val_loss: 1.3611 - val_acc: 0.4864\n",
      "Epoch 259/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7597 - acc: 0.4139 - val_loss: 1.4362 - val_acc: 0.3776\n",
      "Epoch 260/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6902 - acc: 0.3994 - val_loss: 1.5200 - val_acc: 0.3565\n",
      "Epoch 261/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7394 - acc: 0.3663 - val_loss: 1.4341 - val_acc: 0.3988\n",
      "Epoch 262/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6701 - acc: 0.4304 - val_loss: 1.4352 - val_acc: 0.3867\n",
      "Epoch 263/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6544 - acc: 0.4178 - val_loss: 1.4002 - val_acc: 0.3927\n",
      "Epoch 264/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6885 - acc: 0.4026 - val_loss: 1.3592 - val_acc: 0.4079\n",
      "Epoch 265/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7616 - acc: 0.3706 - val_loss: 1.4213 - val_acc: 0.3595\n",
      "Epoch 266/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6807 - acc: 0.4097 - val_loss: 1.4812 - val_acc: 0.4048\n",
      "Epoch 267/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6746 - acc: 0.4170 - val_loss: 1.5870 - val_acc: 0.3293\n",
      "Epoch 268/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6981 - acc: 0.3853 - val_loss: 1.6888 - val_acc: 0.3082\n",
      "Epoch 269/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7503 - acc: 0.3769 - val_loss: 1.5893 - val_acc: 0.2719\n",
      "Epoch 270/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7649 - acc: 0.3364 - val_loss: 1.5184 - val_acc: 0.3142\n",
      "Epoch 271/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7323 - acc: 0.3522 - val_loss: 1.3680 - val_acc: 0.4048\n",
      "Epoch 272/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.6707 - acc: 0.4220 - val_loss: 1.3379 - val_acc: 0.4592\n",
      "Epoch 273/1000\n",
      "2839/2839 [==============================] - 0s 96us/step - loss: 0.7338 - acc: 0.4097 - val_loss: 1.3994 - val_acc: 0.3867\n",
      "Epoch 274/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6664 - acc: 0.4167 - val_loss: 1.4297 - val_acc: 0.3444\n",
      "Epoch 275/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6723 - acc: 0.3945 - val_loss: 1.5346 - val_acc: 0.3021\n",
      "Epoch 276/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.7463 - acc: 0.3519 - val_loss: 1.5013 - val_acc: 0.3595\n",
      "Epoch 277/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6650 - acc: 0.4128 - val_loss: 1.6514 - val_acc: 0.3082\n",
      "Epoch 278/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7269 - acc: 0.3632 - val_loss: 1.4175 - val_acc: 0.3958\n",
      "Epoch 279/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.6568 - acc: 0.4149 - val_loss: 1.4260 - val_acc: 0.4018\n",
      "Epoch 280/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6592 - acc: 0.4209 - val_loss: 1.4737 - val_acc: 0.3958\n",
      "Epoch 281/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7221 - acc: 0.3811 - val_loss: 1.3435 - val_acc: 0.4592\n",
      "Epoch 282/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6748 - acc: 0.4389 - val_loss: 1.3584 - val_acc: 0.4290\n",
      "Epoch 283/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7039 - acc: 0.4220 - val_loss: 1.3827 - val_acc: 0.3776\n",
      "Epoch 284/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6647 - acc: 0.4251 - val_loss: 1.4355 - val_acc: 0.3837\n",
      "Epoch 285/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6295 - acc: 0.4315 - val_loss: 1.3945 - val_acc: 0.3958\n",
      "Epoch 286/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6714 - acc: 0.4019 - val_loss: 1.3786 - val_acc: 0.3897\n",
      "Epoch 287/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7126 - acc: 0.3850 - val_loss: 1.3749 - val_acc: 0.4230\n",
      "Epoch 288/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6784 - acc: 0.4442 - val_loss: 1.3711 - val_acc: 0.4924\n",
      "Epoch 289/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.7485 - acc: 0.3998 - val_loss: 1.4158 - val_acc: 0.4139\n",
      "Epoch 290/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7191 - acc: 0.3737 - val_loss: 1.5518 - val_acc: 0.3535\n",
      "Epoch 291/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.7036 - acc: 0.4012 - val_loss: 1.3953 - val_acc: 0.4260\n",
      "Epoch 292/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6396 - acc: 0.4280 - val_loss: 1.4262 - val_acc: 0.4048\n",
      "Epoch 293/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.6380 - acc: 0.4230 - val_loss: 1.4821 - val_acc: 0.4018\n",
      "Epoch 294/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6450 - acc: 0.4170 - val_loss: 1.6167 - val_acc: 0.3565\n",
      "Epoch 295/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.7312 - acc: 0.3843 - val_loss: 1.6451 - val_acc: 0.3021\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.7082 - acc: 0.3758 - val_loss: 1.5081 - val_acc: 0.3263\n",
      "Epoch 297/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6711 - acc: 0.4047 - val_loss: 1.5195 - val_acc: 0.3263\n",
      "Epoch 298/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6412 - acc: 0.4086 - val_loss: 1.4381 - val_acc: 0.3323\n",
      "Epoch 299/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6233 - acc: 0.4093 - val_loss: 1.3705 - val_acc: 0.3927\n",
      "Epoch 300/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.7093 - acc: 0.3843 - val_loss: 1.3830 - val_acc: 0.3897\n",
      "Epoch 301/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.7069 - acc: 0.4026 - val_loss: 1.4870 - val_acc: 0.3263\n",
      "Epoch 302/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6542 - acc: 0.4065 - val_loss: 1.4787 - val_acc: 0.3535\n",
      "Epoch 303/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.6253 - acc: 0.4329 - val_loss: 1.5033 - val_acc: 0.3384\n",
      "Epoch 304/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6267 - acc: 0.4301 - val_loss: 1.4753 - val_acc: 0.3444\n",
      "Epoch 305/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7127 - acc: 0.3660 - val_loss: 1.4493 - val_acc: 0.3414\n",
      "Epoch 306/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6972 - acc: 0.3779 - val_loss: 1.4615 - val_acc: 0.3746\n",
      "Epoch 307/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6258 - acc: 0.4354 - val_loss: 1.4394 - val_acc: 0.3474\n",
      "Epoch 308/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6233 - acc: 0.4315 - val_loss: 1.7257 - val_acc: 0.3293\n",
      "Epoch 309/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.7910 - acc: 0.3927 - val_loss: 1.7322 - val_acc: 0.2296\n",
      "Epoch 310/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7671 - acc: 0.3036 - val_loss: 1.5168 - val_acc: 0.3414\n",
      "Epoch 311/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6593 - acc: 0.4093 - val_loss: 1.4842 - val_acc: 0.3353\n",
      "Epoch 312/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6713 - acc: 0.3674 - val_loss: 1.3737 - val_acc: 0.3776\n",
      "Epoch 313/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6744 - acc: 0.4097 - val_loss: 1.4332 - val_acc: 0.3746\n",
      "Epoch 314/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.6090 - acc: 0.4526 - val_loss: 1.5183 - val_acc: 0.3384\n",
      "Epoch 315/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6472 - acc: 0.4163 - val_loss: 1.6220 - val_acc: 0.2931\n",
      "Epoch 316/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6457 - acc: 0.4079 - val_loss: 1.5720 - val_acc: 0.3384\n",
      "Epoch 317/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6822 - acc: 0.3734 - val_loss: 1.4654 - val_acc: 0.3988\n",
      "Epoch 318/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6280 - acc: 0.4604 - val_loss: 1.4689 - val_acc: 0.3837\n",
      "Epoch 319/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5924 - acc: 0.4551 - val_loss: 1.5055 - val_acc: 0.3656\n",
      "Epoch 320/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6230 - acc: 0.4487 - val_loss: 1.6300 - val_acc: 0.2931\n",
      "Epoch 321/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6594 - acc: 0.4068 - val_loss: 1.5584 - val_acc: 0.3293\n",
      "Epoch 322/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6360 - acc: 0.4033 - val_loss: 1.4925 - val_acc: 0.4018\n",
      "Epoch 323/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6576 - acc: 0.4008 - val_loss: 1.4375 - val_acc: 0.4139\n",
      "Epoch 324/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6263 - acc: 0.4237 - val_loss: 1.4429 - val_acc: 0.3988\n",
      "Epoch 325/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.6271 - acc: 0.4442 - val_loss: 1.5193 - val_acc: 0.3927\n",
      "Epoch 326/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6313 - acc: 0.4185 - val_loss: 1.6297 - val_acc: 0.3535\n",
      "Epoch 327/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6876 - acc: 0.4195 - val_loss: 1.6436 - val_acc: 0.2749\n",
      "Epoch 328/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6742 - acc: 0.3769 - val_loss: 1.5414 - val_acc: 0.3233\n",
      "Epoch 329/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6393 - acc: 0.4111 - val_loss: 1.4823 - val_acc: 0.3535\n",
      "Epoch 330/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.7405 - acc: 0.3607 - val_loss: 1.4075 - val_acc: 0.4139\n",
      "Epoch 331/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6089 - acc: 0.4223 - val_loss: 1.5027 - val_acc: 0.4048\n",
      "Epoch 332/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5949 - acc: 0.4554 - val_loss: 1.4544 - val_acc: 0.4109\n",
      "Epoch 333/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5812 - acc: 0.4618 - val_loss: 1.4692 - val_acc: 0.4169\n",
      "Epoch 334/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6096 - acc: 0.4533 - val_loss: 1.5866 - val_acc: 0.3807\n",
      "Epoch 335/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.7443 - acc: 0.3607 - val_loss: 1.3649 - val_acc: 0.4743\n",
      "Epoch 336/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6111 - acc: 0.4745 - val_loss: 1.3224 - val_acc: 0.5347\n",
      "Epoch 337/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6551 - acc: 0.4632 - val_loss: 1.4076 - val_acc: 0.4260\n",
      "Epoch 338/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5805 - acc: 0.4466 - val_loss: 1.4058 - val_acc: 0.4230\n",
      "Epoch 339/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5863 - acc: 0.4586 - val_loss: 1.4231 - val_acc: 0.4290\n",
      "Epoch 340/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.6099 - acc: 0.4470 - val_loss: 1.5742 - val_acc: 0.4079\n",
      "Epoch 341/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6677 - acc: 0.3956 - val_loss: 1.6297 - val_acc: 0.3625\n",
      "Epoch 342/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6628 - acc: 0.4237 - val_loss: 1.5314 - val_acc: 0.3807\n",
      "Epoch 343/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5902 - acc: 0.4262 - val_loss: 1.4851 - val_acc: 0.3837\n",
      "Epoch 344/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5999 - acc: 0.4199 - val_loss: 1.6047 - val_acc: 0.3595\n",
      "Epoch 345/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6510 - acc: 0.4089 - val_loss: 1.6784 - val_acc: 0.3535\n",
      "Epoch 346/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6291 - acc: 0.4385 - val_loss: 1.6229 - val_acc: 0.3082\n",
      "Epoch 347/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.6470 - acc: 0.3984 - val_loss: 1.6314 - val_acc: 0.3082\n",
      "Epoch 348/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6182 - acc: 0.4132 - val_loss: 1.5921 - val_acc: 0.3082\n",
      "Epoch 349/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6060 - acc: 0.4350 - val_loss: 1.5497 - val_acc: 0.3535\n",
      "Epoch 350/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6053 - acc: 0.4153 - val_loss: 1.5393 - val_acc: 0.3353\n",
      "Epoch 351/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6964 - acc: 0.3558 - val_loss: 1.4027 - val_acc: 0.4230\n",
      "Epoch 352/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6036 - acc: 0.4723 - val_loss: 1.3973 - val_acc: 0.3988\n",
      "Epoch 353/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5724 - acc: 0.4452 - val_loss: 1.3823 - val_acc: 0.4713\n",
      "Epoch 354/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6190 - acc: 0.4611 - val_loss: 1.3524 - val_acc: 0.4834\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.6167 - acc: 0.4502 - val_loss: 1.4111 - val_acc: 0.3988\n",
      "Epoch 356/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.5881 - acc: 0.4516 - val_loss: 1.3766 - val_acc: 0.4350\n",
      "Epoch 357/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6266 - acc: 0.4533 - val_loss: 1.4390 - val_acc: 0.3656\n",
      "Epoch 358/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6980 - acc: 0.3952 - val_loss: 1.5912 - val_acc: 0.3051\n",
      "Epoch 359/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6506 - acc: 0.4290 - val_loss: 1.6559 - val_acc: 0.2931\n",
      "Epoch 360/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.6187 - acc: 0.4174 - val_loss: 1.4460 - val_acc: 0.4048\n",
      "Epoch 361/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5740 - acc: 0.4544 - val_loss: 1.4639 - val_acc: 0.3716\n",
      "Epoch 362/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.5710 - acc: 0.4593 - val_loss: 1.4112 - val_acc: 0.4773\n",
      "Epoch 363/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.5799 - acc: 0.4808 - val_loss: 1.4249 - val_acc: 0.4592\n",
      "Epoch 364/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5734 - acc: 0.4910 - val_loss: 1.3937 - val_acc: 0.4653\n",
      "Epoch 365/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6372 - acc: 0.4445 - val_loss: 1.4351 - val_acc: 0.4502\n",
      "Epoch 366/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5789 - acc: 0.4801 - val_loss: 1.6055 - val_acc: 0.4199\n",
      "Epoch 367/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6573 - acc: 0.4167 - val_loss: 1.4932 - val_acc: 0.4139\n",
      "Epoch 368/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.5998 - acc: 0.4607 - val_loss: 1.4790 - val_acc: 0.4018\n",
      "Epoch 369/1000\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.5570 - acc: 0.4727 - val_loss: 1.5492 - val_acc: 0.3837\n",
      "Epoch 370/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6050 - acc: 0.4551 - val_loss: 1.7113 - val_acc: 0.3263\n",
      "Epoch 371/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.6514 - acc: 0.4033 - val_loss: 1.5111 - val_acc: 0.3958\n",
      "Epoch 372/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.5712 - acc: 0.4632 - val_loss: 1.4810 - val_acc: 0.4139\n",
      "Epoch 373/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5796 - acc: 0.4505 - val_loss: 1.5311 - val_acc: 0.4502\n",
      "Epoch 374/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.8160 - acc: 0.4132 - val_loss: 1.4009 - val_acc: 0.4230\n",
      "Epoch 375/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5951 - acc: 0.4523 - val_loss: 1.4293 - val_acc: 0.4109\n",
      "Epoch 376/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.5598 - acc: 0.4731 - val_loss: 1.4718 - val_acc: 0.3807\n",
      "Epoch 377/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5675 - acc: 0.4635 - val_loss: 1.4854 - val_acc: 0.3535\n",
      "Epoch 378/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6188 - acc: 0.4030 - val_loss: 1.3982 - val_acc: 0.4350\n",
      "Epoch 379/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6658 - acc: 0.4304 - val_loss: 1.3962 - val_acc: 0.4502\n",
      "Epoch 380/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6018 - acc: 0.4537 - val_loss: 1.4409 - val_acc: 0.4411\n",
      "Epoch 381/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5500 - acc: 0.4635 - val_loss: 1.4435 - val_acc: 0.4230\n",
      "Epoch 382/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5644 - acc: 0.4593 - val_loss: 1.4315 - val_acc: 0.4048\n",
      "Epoch 383/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6722 - acc: 0.4188 - val_loss: 1.4758 - val_acc: 0.3746\n",
      "Epoch 384/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5931 - acc: 0.4667 - val_loss: 1.6022 - val_acc: 0.3414\n",
      "Epoch 385/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6105 - acc: 0.4259 - val_loss: 1.5236 - val_acc: 0.3353\n",
      "Epoch 386/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5568 - acc: 0.4540 - val_loss: 1.5244 - val_acc: 0.3776\n",
      "Epoch 387/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5438 - acc: 0.4752 - val_loss: 1.5893 - val_acc: 0.3535\n",
      "Epoch 388/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5730 - acc: 0.4600 - val_loss: 1.7009 - val_acc: 0.3112\n",
      "Epoch 389/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6622 - acc: 0.4385 - val_loss: 1.6736 - val_acc: 0.2628\n",
      "Epoch 390/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6356 - acc: 0.3899 - val_loss: 1.4817 - val_acc: 0.3837\n",
      "Epoch 391/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5337 - acc: 0.4738 - val_loss: 1.5185 - val_acc: 0.4079\n",
      "Epoch 392/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5414 - acc: 0.4769 - val_loss: 1.5975 - val_acc: 0.4109\n",
      "Epoch 393/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6868 - acc: 0.4146 - val_loss: 1.5488 - val_acc: 0.4018\n",
      "Epoch 394/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5823 - acc: 0.4678 - val_loss: 1.4987 - val_acc: 0.4441\n",
      "Epoch 395/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6247 - acc: 0.4674 - val_loss: 1.3962 - val_acc: 0.4683\n",
      "Epoch 396/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6230 - acc: 0.4297 - val_loss: 1.4036 - val_acc: 0.4290\n",
      "Epoch 397/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5408 - acc: 0.4984 - val_loss: 1.4017 - val_acc: 0.4079\n",
      "Epoch 398/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5560 - acc: 0.4755 - val_loss: 1.4399 - val_acc: 0.3656\n",
      "Epoch 399/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6115 - acc: 0.4343 - val_loss: 1.4396 - val_acc: 0.3988\n",
      "Epoch 400/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5705 - acc: 0.4723 - val_loss: 1.5431 - val_acc: 0.3776\n",
      "Epoch 401/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.5639 - acc: 0.4709 - val_loss: 1.4830 - val_acc: 0.3565\n",
      "Epoch 402/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.5822 - acc: 0.4417 - val_loss: 1.5977 - val_acc: 0.3565\n",
      "Epoch 403/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6519 - acc: 0.4297 - val_loss: 1.5241 - val_acc: 0.3263\n",
      "Epoch 404/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5620 - acc: 0.4480 - val_loss: 1.4916 - val_acc: 0.4109\n",
      "Epoch 405/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5233 - acc: 0.4826 - val_loss: 1.6945 - val_acc: 0.3263\n",
      "Epoch 406/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6455 - acc: 0.4414 - val_loss: 1.7317 - val_acc: 0.2659\n",
      "Epoch 407/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6116 - acc: 0.3882 - val_loss: 1.4924 - val_acc: 0.3958\n",
      "Epoch 408/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5512 - acc: 0.4769 - val_loss: 1.4357 - val_acc: 0.4471\n",
      "Epoch 409/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5241 - acc: 0.4949 - val_loss: 1.5105 - val_acc: 0.4441\n",
      "Epoch 410/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5584 - acc: 0.4805 - val_loss: 1.7851 - val_acc: 0.3958\n",
      "Epoch 411/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6689 - acc: 0.4015 - val_loss: 1.4861 - val_acc: 0.3807\n",
      "Epoch 412/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5706 - acc: 0.4505 - val_loss: 1.5738 - val_acc: 0.3625\n",
      "Epoch 413/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5354 - acc: 0.4914 - val_loss: 1.5007 - val_acc: 0.3897\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5072 - acc: 0.4819 - val_loss: 1.4998 - val_acc: 0.4230\n",
      "Epoch 415/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5054 - acc: 0.4945 - val_loss: 1.5990 - val_acc: 0.4199\n",
      "Epoch 416/1000\n",
      "2839/2839 [==============================] - 0s 89us/step - loss: 0.6192 - acc: 0.4251 - val_loss: 1.6053 - val_acc: 0.4230\n",
      "Epoch 417/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6066 - acc: 0.4667 - val_loss: 1.5608 - val_acc: 0.3927\n",
      "Epoch 418/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5268 - acc: 0.4836 - val_loss: 1.5896 - val_acc: 0.4018\n",
      "Epoch 419/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5253 - acc: 0.4699 - val_loss: 1.5686 - val_acc: 0.4260\n",
      "Epoch 420/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5442 - acc: 0.4797 - val_loss: 1.6399 - val_acc: 0.3776\n",
      "Epoch 421/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5861 - acc: 0.4259 - val_loss: 1.5377 - val_acc: 0.4381\n",
      "Epoch 422/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6031 - acc: 0.4512 - val_loss: 1.4788 - val_acc: 0.4713\n",
      "Epoch 423/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5671 - acc: 0.4917 - val_loss: 1.5030 - val_acc: 0.4441\n",
      "Epoch 424/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5299 - acc: 0.4931 - val_loss: 1.4975 - val_acc: 0.4441\n",
      "Epoch 425/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5289 - acc: 0.4829 - val_loss: 1.4968 - val_acc: 0.4592\n",
      "Epoch 426/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5671 - acc: 0.4540 - val_loss: 1.4875 - val_acc: 0.4169\n",
      "Epoch 427/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5652 - acc: 0.4600 - val_loss: 1.5704 - val_acc: 0.4381\n",
      "Epoch 428/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5430 - acc: 0.4808 - val_loss: 1.6434 - val_acc: 0.3958\n",
      "Epoch 429/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.6522 - acc: 0.4551 - val_loss: 1.9833 - val_acc: 0.2266\n",
      "Epoch 430/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.7027 - acc: 0.3480 - val_loss: 1.5409 - val_acc: 0.3927\n",
      "Epoch 431/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5364 - acc: 0.4921 - val_loss: 1.5317 - val_acc: 0.3837\n",
      "Epoch 432/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5185 - acc: 0.4822 - val_loss: 1.5781 - val_acc: 0.4169\n",
      "Epoch 433/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5170 - acc: 0.4868 - val_loss: 1.5317 - val_acc: 0.4109\n",
      "Epoch 434/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5008 - acc: 0.4790 - val_loss: 1.5610 - val_acc: 0.4350\n",
      "Epoch 435/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5581 - acc: 0.4843 - val_loss: 1.8304 - val_acc: 0.2779\n",
      "Epoch 436/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.6168 - acc: 0.4142 - val_loss: 1.7632 - val_acc: 0.2870\n",
      "Epoch 437/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6349 - acc: 0.4008 - val_loss: 1.6554 - val_acc: 0.3414\n",
      "Epoch 438/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6419 - acc: 0.3808 - val_loss: 1.3996 - val_acc: 0.4411\n",
      "Epoch 439/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5574 - acc: 0.4878 - val_loss: 1.4404 - val_acc: 0.4441\n",
      "Epoch 440/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5129 - acc: 0.5167 - val_loss: 1.4770 - val_acc: 0.4320\n",
      "Epoch 441/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4990 - acc: 0.5174 - val_loss: 1.4874 - val_acc: 0.4441\n",
      "Epoch 442/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5218 - acc: 0.4935 - val_loss: 1.5622 - val_acc: 0.4350\n",
      "Epoch 443/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.6509 - acc: 0.4375 - val_loss: 1.5384 - val_acc: 0.4199\n",
      "Epoch 444/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5720 - acc: 0.4745 - val_loss: 1.6521 - val_acc: 0.3202\n",
      "Epoch 445/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5269 - acc: 0.4815 - val_loss: 1.6114 - val_acc: 0.3656\n",
      "Epoch 446/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5217 - acc: 0.4628 - val_loss: 1.6602 - val_acc: 0.3565\n",
      "Epoch 447/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5250 - acc: 0.4635 - val_loss: 1.6504 - val_acc: 0.3746\n",
      "Epoch 448/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5429 - acc: 0.4593 - val_loss: 1.6703 - val_acc: 0.3958\n",
      "Epoch 449/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5618 - acc: 0.4723 - val_loss: 1.6118 - val_acc: 0.3897\n",
      "Epoch 450/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5350 - acc: 0.4727 - val_loss: 1.6073 - val_acc: 0.4260\n",
      "Epoch 451/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5532 - acc: 0.4773 - val_loss: 1.7017 - val_acc: 0.3353\n",
      "Epoch 452/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5977 - acc: 0.4410 - val_loss: 1.5328 - val_acc: 0.3837\n",
      "Epoch 453/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5211 - acc: 0.4773 - val_loss: 1.5406 - val_acc: 0.4079\n",
      "Epoch 454/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5204 - acc: 0.4797 - val_loss: 1.6749 - val_acc: 0.3353\n",
      "Epoch 455/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5725 - acc: 0.4466 - val_loss: 1.6367 - val_acc: 0.3323\n",
      "Epoch 456/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.5425 - acc: 0.4459 - val_loss: 1.5963 - val_acc: 0.3565\n",
      "Epoch 457/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4953 - acc: 0.4861 - val_loss: 1.5383 - val_acc: 0.4169\n",
      "Epoch 458/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4920 - acc: 0.5086 - val_loss: 1.5274 - val_acc: 0.4350\n",
      "Epoch 459/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4817 - acc: 0.5111 - val_loss: 1.5689 - val_acc: 0.4320\n",
      "Epoch 460/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5436 - acc: 0.4903 - val_loss: 1.7714 - val_acc: 0.3867\n",
      "Epoch 461/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6242 - acc: 0.4132 - val_loss: 1.7559 - val_acc: 0.3776\n",
      "Epoch 462/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.6228 - acc: 0.4780 - val_loss: 1.7978 - val_acc: 0.3202\n",
      "Epoch 463/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5563 - acc: 0.4723 - val_loss: 1.6150 - val_acc: 0.3474\n",
      "Epoch 464/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5189 - acc: 0.4593 - val_loss: 1.6689 - val_acc: 0.3656\n",
      "Epoch 465/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5339 - acc: 0.4681 - val_loss: 1.5445 - val_acc: 0.3988\n",
      "Epoch 466/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5044 - acc: 0.4893 - val_loss: 1.5752 - val_acc: 0.4381\n",
      "Epoch 467/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5148 - acc: 0.4893 - val_loss: 1.5574 - val_acc: 0.4864\n",
      "Epoch 468/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5471 - acc: 0.5139 - val_loss: 1.5050 - val_acc: 0.4562\n",
      "Epoch 469/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5296 - acc: 0.4875 - val_loss: 1.4646 - val_acc: 0.4622\n",
      "Epoch 470/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5702 - acc: 0.4910 - val_loss: 1.4430 - val_acc: 0.4743\n",
      "Epoch 471/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5014 - acc: 0.5192 - val_loss: 1.5851 - val_acc: 0.3837\n",
      "Epoch 472/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5368 - acc: 0.4826 - val_loss: 1.4966 - val_acc: 0.4169\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5310 - acc: 0.4857 - val_loss: 1.4770 - val_acc: 0.4441\n",
      "Epoch 474/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5340 - acc: 0.5012 - val_loss: 1.4997 - val_acc: 0.4743\n",
      "Epoch 475/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4835 - acc: 0.5143 - val_loss: 1.5272 - val_acc: 0.4562\n",
      "Epoch 476/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5523 - acc: 0.4917 - val_loss: 1.5044 - val_acc: 0.4471\n",
      "Epoch 477/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.5751 - acc: 0.4928 - val_loss: 1.7527 - val_acc: 0.3233\n",
      "Epoch 478/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5992 - acc: 0.4350 - val_loss: 1.6747 - val_acc: 0.3776\n",
      "Epoch 479/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6388 - acc: 0.4311 - val_loss: 1.5918 - val_acc: 0.3505\n",
      "Epoch 480/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5251 - acc: 0.4692 - val_loss: 1.5104 - val_acc: 0.4079\n",
      "Epoch 481/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4728 - acc: 0.5012 - val_loss: 1.5178 - val_acc: 0.4471\n",
      "Epoch 482/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4728 - acc: 0.5284 - val_loss: 1.5509 - val_acc: 0.4622\n",
      "Epoch 483/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4742 - acc: 0.5354 - val_loss: 1.5370 - val_acc: 0.4653\n",
      "Epoch 484/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4586 - acc: 0.5456 - val_loss: 1.5322 - val_acc: 0.4955\n",
      "Epoch 485/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4734 - acc: 0.5446 - val_loss: 1.5609 - val_acc: 0.4532\n",
      "Epoch 486/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5995 - acc: 0.4822 - val_loss: 1.5107 - val_acc: 0.4592\n",
      "Epoch 487/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6859 - acc: 0.4635 - val_loss: 1.6084 - val_acc: 0.3505\n",
      "Epoch 488/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5325 - acc: 0.4628 - val_loss: 1.5903 - val_acc: 0.3746\n",
      "Epoch 489/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5715 - acc: 0.4477 - val_loss: 1.4792 - val_acc: 0.4230\n",
      "Epoch 490/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.5342 - acc: 0.4956 - val_loss: 1.5101 - val_acc: 0.3776\n",
      "Epoch 491/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.5027 - acc: 0.5041 - val_loss: 1.5102 - val_acc: 0.4230\n",
      "Epoch 492/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5037 - acc: 0.5019 - val_loss: 1.5200 - val_acc: 0.4592\n",
      "Epoch 493/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4952 - acc: 0.5266 - val_loss: 1.5950 - val_acc: 0.3927\n",
      "Epoch 494/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4947 - acc: 0.4956 - val_loss: 1.6878 - val_acc: 0.3474\n",
      "Epoch 495/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5403 - acc: 0.4667 - val_loss: 1.6002 - val_acc: 0.3958\n",
      "Epoch 496/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5367 - acc: 0.4886 - val_loss: 1.6321 - val_acc: 0.3837\n",
      "Epoch 497/1000\n",
      "2839/2839 [==============================] - 0s 95us/step - loss: 0.5228 - acc: 0.4815 - val_loss: 1.6478 - val_acc: 0.4109\n",
      "Epoch 498/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4834 - acc: 0.5100 - val_loss: 1.7794 - val_acc: 0.3142\n",
      "Epoch 499/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5392 - acc: 0.4516 - val_loss: 1.8334 - val_acc: 0.3233\n",
      "Epoch 500/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.6206 - acc: 0.4403 - val_loss: 1.7086 - val_acc: 0.3353\n",
      "Epoch 501/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5400 - acc: 0.4523 - val_loss: 1.6393 - val_acc: 0.3625\n",
      "Epoch 502/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5364 - acc: 0.4706 - val_loss: 1.8094 - val_acc: 0.2900\n",
      "Epoch 503/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5167 - acc: 0.4590 - val_loss: 1.5978 - val_acc: 0.4350\n",
      "Epoch 504/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4607 - acc: 0.5298 - val_loss: 1.5692 - val_acc: 0.4562\n",
      "Epoch 505/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4795 - acc: 0.5287 - val_loss: 1.6190 - val_acc: 0.4018\n",
      "Epoch 506/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4750 - acc: 0.5125 - val_loss: 1.6339 - val_acc: 0.3897\n",
      "Epoch 507/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.4952 - val_loss: 1.7600 - val_acc: 0.3474\n",
      "Epoch 508/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6189 - acc: 0.4371 - val_loss: 1.5455 - val_acc: 0.3927\n",
      "Epoch 509/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5018 - acc: 0.5058 - val_loss: 1.5327 - val_acc: 0.4139\n",
      "Epoch 510/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4661 - acc: 0.5301 - val_loss: 1.6367 - val_acc: 0.4109\n",
      "Epoch 511/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4732 - acc: 0.5439 - val_loss: 1.7700 - val_acc: 0.3384\n",
      "Epoch 512/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.4884 - acc: 0.4907 - val_loss: 1.7950 - val_acc: 0.3353\n",
      "Epoch 513/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.5411 - acc: 0.4808 - val_loss: 1.7950 - val_acc: 0.3384\n",
      "Epoch 514/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5418 - acc: 0.4579 - val_loss: 1.6514 - val_acc: 0.3867\n",
      "Epoch 515/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5019 - acc: 0.4801 - val_loss: 1.6173 - val_acc: 0.4381\n",
      "Epoch 516/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4796 - acc: 0.4956 - val_loss: 1.6442 - val_acc: 0.4441\n",
      "Epoch 517/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.6215 - acc: 0.4576 - val_loss: 1.6352 - val_acc: 0.3837\n",
      "Epoch 518/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.5317 - acc: 0.4843 - val_loss: 1.5290 - val_acc: 0.4502\n",
      "Epoch 519/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4683 - acc: 0.5231 - val_loss: 1.6002 - val_acc: 0.4350\n",
      "Epoch 520/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4488 - acc: 0.5417 - val_loss: 1.7090 - val_acc: 0.4079\n",
      "Epoch 521/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4533 - acc: 0.5111 - val_loss: 1.6076 - val_acc: 0.4532\n",
      "Epoch 522/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4746 - acc: 0.5305 - val_loss: 1.6881 - val_acc: 0.4924\n",
      "Epoch 523/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.6054 - acc: 0.4664 - val_loss: 1.4837 - val_acc: 0.4622\n",
      "Epoch 524/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5206 - acc: 0.5403 - val_loss: 1.5814 - val_acc: 0.4592\n",
      "Epoch 525/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4596 - acc: 0.5206 - val_loss: 1.5633 - val_acc: 0.4471\n",
      "Epoch 526/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4620 - acc: 0.5350 - val_loss: 1.5875 - val_acc: 0.4653\n",
      "Epoch 527/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4960 - acc: 0.5153 - val_loss: 1.5224 - val_acc: 0.4773\n",
      "Epoch 528/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5175 - acc: 0.5308 - val_loss: 1.5695 - val_acc: 0.4199\n",
      "Epoch 529/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4665 - acc: 0.5277 - val_loss: 1.6920 - val_acc: 0.3927\n",
      "Epoch 530/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4903 - acc: 0.4893 - val_loss: 1.5967 - val_acc: 0.4592\n",
      "Epoch 531/1000\n",
      "2839/2839 [==============================] - 0s 98us/step - loss: 0.5032 - acc: 0.5368 - val_loss: 1.6421 - val_acc: 0.4199\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4860 - acc: 0.5122 - val_loss: 1.6600 - val_acc: 0.4320\n",
      "Epoch 533/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5195 - acc: 0.5019 - val_loss: 1.6670 - val_acc: 0.4169\n",
      "Epoch 534/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5146 - acc: 0.5058 - val_loss: 1.6523 - val_acc: 0.4018\n",
      "Epoch 535/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4668 - acc: 0.5129 - val_loss: 1.7986 - val_acc: 0.3444\n",
      "Epoch 536/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4726 - acc: 0.5248 - val_loss: 1.8545 - val_acc: 0.3444\n",
      "Epoch 537/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5338 - acc: 0.4716 - val_loss: 1.8880 - val_acc: 0.2991\n",
      "Epoch 538/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5556 - acc: 0.4565 - val_loss: 1.6702 - val_acc: 0.3776\n",
      "Epoch 539/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4988 - acc: 0.4857 - val_loss: 1.6001 - val_acc: 0.3988\n",
      "Epoch 540/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5478 - acc: 0.4907 - val_loss: 1.7027 - val_acc: 0.4260\n",
      "Epoch 541/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5800 - acc: 0.4787 - val_loss: 1.5413 - val_acc: 0.4139\n",
      "Epoch 542/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4575 - acc: 0.5238 - val_loss: 1.5843 - val_acc: 0.4411\n",
      "Epoch 543/1000\n",
      "2839/2839 [==============================] - 0s 91us/step - loss: 0.4218 - acc: 0.5400 - val_loss: 1.6225 - val_acc: 0.4381\n",
      "Epoch 544/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4483 - acc: 0.5403 - val_loss: 1.6313 - val_acc: 0.4683\n",
      "Epoch 545/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4635 - acc: 0.5132 - val_loss: 1.5746 - val_acc: 0.4683\n",
      "Epoch 546/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.5996 - acc: 0.542 - 0s 70us/step - loss: 0.5805 - acc: 0.5051 - val_loss: 1.5444 - val_acc: 0.4290\n",
      "Epoch 547/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.5294 - acc: 0.5076 - val_loss: 1.6194 - val_acc: 0.4562\n",
      "Epoch 548/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4844 - acc: 0.5185 - val_loss: 1.7016 - val_acc: 0.3897\n",
      "Epoch 549/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5729 - acc: 0.4621 - val_loss: 1.5614 - val_acc: 0.4441\n",
      "Epoch 550/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4970 - acc: 0.5122 - val_loss: 1.6055 - val_acc: 0.4350\n",
      "Epoch 551/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4378 - acc: 0.5498 - val_loss: 1.6656 - val_acc: 0.4260\n",
      "Epoch 552/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4566 - acc: 0.5157 - val_loss: 1.5970 - val_acc: 0.4350\n",
      "Epoch 553/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4740 - acc: 0.5259 - val_loss: 1.6344 - val_acc: 0.4471\n",
      "Epoch 554/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4740 - acc: 0.5308 - val_loss: 1.5098 - val_acc: 0.4834\n",
      "Epoch 555/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4837 - acc: 0.5231 - val_loss: 1.4967 - val_acc: 0.5015\n",
      "Epoch 556/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4816 - acc: 0.5192 - val_loss: 1.5536 - val_acc: 0.4834\n",
      "Epoch 557/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5001 - acc: 0.5326 - val_loss: 1.5896 - val_acc: 0.4592\n",
      "Epoch 558/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4990 - acc: 0.5266 - val_loss: 1.5448 - val_acc: 0.4441\n",
      "Epoch 559/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4579 - acc: 0.5467 - val_loss: 1.7097 - val_acc: 0.3837\n",
      "Epoch 560/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4942 - acc: 0.5041 - val_loss: 1.7214 - val_acc: 0.3776\n",
      "Epoch 561/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4931 - acc: 0.5467 - val_loss: 1.8373 - val_acc: 0.3535\n",
      "Epoch 562/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5317 - acc: 0.4716 - val_loss: 1.5963 - val_acc: 0.4411\n",
      "Epoch 563/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.4852 - acc: 0.5160 - val_loss: 1.6169 - val_acc: 0.4169\n",
      "Epoch 564/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4628 - acc: 0.5284 - val_loss: 1.5983 - val_acc: 0.4502\n",
      "Epoch 565/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4296 - acc: 0.5636 - val_loss: 1.6880 - val_acc: 0.4109\n",
      "Epoch 566/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4911 - acc: 0.5322 - val_loss: 1.7009 - val_acc: 0.3927\n",
      "Epoch 567/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5708 - acc: 0.4945 - val_loss: 1.6778 - val_acc: 0.4230\n",
      "Epoch 568/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.5383 - acc: 0.5100 - val_loss: 1.7115 - val_acc: 0.3686\n",
      "Epoch 569/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4570 - acc: 0.5111 - val_loss: 1.7122 - val_acc: 0.3927\n",
      "Epoch 570/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4477 - acc: 0.5414 - val_loss: 1.6948 - val_acc: 0.3958\n",
      "Epoch 571/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4173 - acc: 0.5315 - val_loss: 1.7210 - val_acc: 0.4169\n",
      "Epoch 572/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4285 - acc: 0.5530 - val_loss: 1.7611 - val_acc: 0.3776\n",
      "Epoch 573/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4439 - acc: 0.532 - 0s 70us/step - loss: 0.4850 - acc: 0.5315 - val_loss: 2.1321 - val_acc: 0.2931\n",
      "Epoch 574/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.6392 - acc: 0.4075 - val_loss: 1.6361 - val_acc: 0.3686\n",
      "Epoch 575/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4713 - acc: 0.5329 - val_loss: 1.6865 - val_acc: 0.3746\n",
      "Epoch 576/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4571 - acc: 0.5291 - val_loss: 1.8135 - val_acc: 0.3353\n",
      "Epoch 577/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.5197 - acc: 0.4878 - val_loss: 1.9720 - val_acc: 0.3233\n",
      "Epoch 578/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.5056 - acc: 0.4783 - val_loss: 1.7398 - val_acc: 0.3927\n",
      "Epoch 579/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4526 - acc: 0.5199 - val_loss: 1.6564 - val_acc: 0.4199\n",
      "Epoch 580/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4313 - acc: 0.5505 - val_loss: 1.6848 - val_acc: 0.4199\n",
      "Epoch 581/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4358 - acc: 0.5562 - val_loss: 1.7819 - val_acc: 0.3565\n",
      "Epoch 582/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5195 - acc: 0.4681 - val_loss: 1.6251 - val_acc: 0.4079\n",
      "Epoch 583/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4603 - acc: 0.5375 - val_loss: 1.6873 - val_acc: 0.3988\n",
      "Epoch 584/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4427 - acc: 0.5350 - val_loss: 1.6200 - val_acc: 0.4592\n",
      "Epoch 585/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4371 - acc: 0.5530 - val_loss: 1.6895 - val_acc: 0.4743\n",
      "Epoch 586/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5472 - acc: 0.4967 - val_loss: 1.6665 - val_acc: 0.4562\n",
      "Epoch 587/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.6006 - acc: 0.4988 - val_loss: 1.6095 - val_acc: 0.4653\n",
      "Epoch 588/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4599 - acc: 0.5358 - val_loss: 1.6206 - val_acc: 0.4381\n",
      "Epoch 589/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.4170 - acc: 0.5562 - val_loss: 1.6587 - val_acc: 0.4622\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4059 - acc: 0.5770 - val_loss: 1.7023 - val_acc: 0.4562\n",
      "Epoch 591/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4163 - acc: 0.5643 - val_loss: 1.7251 - val_acc: 0.4502\n",
      "Epoch 592/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4179 - acc: 0.5653 - val_loss: 1.8518 - val_acc: 0.3958\n",
      "Epoch 593/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.5036 - acc: 0.5005 - val_loss: 1.8656 - val_acc: 0.3807\n",
      "Epoch 594/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.6991 - acc: 0.4907 - val_loss: 2.1215 - val_acc: 0.2779\n",
      "Epoch 595/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.6408 - acc: 0.3910 - val_loss: 1.9021 - val_acc: 0.3082\n",
      "Epoch 596/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5103 - acc: 0.4533 - val_loss: 1.6093 - val_acc: 0.4320\n",
      "Epoch 597/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4239 - acc: 0.5498 - val_loss: 1.6620 - val_acc: 0.4169\n",
      "Epoch 598/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4093 - acc: 0.5583 - val_loss: 1.7231 - val_acc: 0.4048\n",
      "Epoch 599/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4320 - acc: 0.5576 - val_loss: 1.7727 - val_acc: 0.4169\n",
      "Epoch 600/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4695 - acc: 0.5122 - val_loss: 1.8135 - val_acc: 0.3625\n",
      "Epoch 601/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5102 - acc: 0.5153 - val_loss: 1.6434 - val_acc: 0.4381\n",
      "Epoch 602/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4451 - acc: 0.5597 - val_loss: 1.7445 - val_acc: 0.4320\n",
      "Epoch 603/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4291 - acc: 0.5583 - val_loss: 1.7093 - val_acc: 0.4048\n",
      "Epoch 604/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4572 - acc: 0.5439 - val_loss: 1.6387 - val_acc: 0.4864\n",
      "Epoch 605/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4322 - acc: 0.5787 - val_loss: 1.7208 - val_acc: 0.4532\n",
      "Epoch 606/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4220 - acc: 0.5756 - val_loss: 1.7090 - val_acc: 0.4653\n",
      "Epoch 607/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4292 - acc: 0.5671 - val_loss: 1.7831 - val_acc: 0.4683\n",
      "Epoch 608/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.6591 - acc: 0.4759 - val_loss: 1.6115 - val_acc: 0.4350\n",
      "Epoch 609/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.5255 - acc: 0.5181 - val_loss: 1.5729 - val_acc: 0.4683\n",
      "Epoch 610/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4458 - acc: 0.5632 - val_loss: 1.6149 - val_acc: 0.4683\n",
      "Epoch 611/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4104 - acc: 0.5720 - val_loss: 1.7020 - val_acc: 0.4471\n",
      "Epoch 612/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4565 - acc: 0.5336 - val_loss: 1.7267 - val_acc: 0.3958\n",
      "Epoch 613/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5146 - acc: 0.4790 - val_loss: 1.7956 - val_acc: 0.3686\n",
      "Epoch 614/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4645 - acc: 0.5150 - val_loss: 1.7016 - val_acc: 0.4169\n",
      "Epoch 615/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4056 - acc: 0.5703 - val_loss: 1.6970 - val_acc: 0.4562\n",
      "Epoch 616/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4344 - acc: 0.5710 - val_loss: 1.7546 - val_acc: 0.4230\n",
      "Epoch 617/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4728 - acc: 0.5090 - val_loss: 1.6713 - val_acc: 0.4834\n",
      "Epoch 618/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4309 - acc: 0.5766 - val_loss: 1.7457 - val_acc: 0.4381\n",
      "Epoch 619/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4348 - acc: 0.5431 - val_loss: 1.6986 - val_acc: 0.4411\n",
      "Epoch 620/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4331 - acc: 0.5379 - val_loss: 1.6644 - val_acc: 0.4562\n",
      "Epoch 621/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4018 - acc: 0.6023 - val_loss: 1.8559 - val_acc: 0.3867\n",
      "Epoch 622/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4152 - acc: 0.5586 - val_loss: 2.0015 - val_acc: 0.3444\n",
      "Epoch 623/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4445 - acc: 0.5439 - val_loss: 1.8650 - val_acc: 0.3746\n",
      "Epoch 624/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4473 - acc: 0.5379 - val_loss: 1.7874 - val_acc: 0.3656\n",
      "Epoch 625/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4671 - acc: 0.5245 - val_loss: 1.9940 - val_acc: 0.3293\n",
      "Epoch 626/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5134 - acc: 0.4667 - val_loss: 1.8622 - val_acc: 0.3384\n",
      "Epoch 627/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.5904 - acc: 0.4509 - val_loss: 1.5833 - val_acc: 0.4985\n",
      "Epoch 628/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4869 - acc: 0.5502 - val_loss: 1.6244 - val_acc: 0.4592\n",
      "Epoch 629/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4347 - acc: 0.5608 - val_loss: 1.6692 - val_acc: 0.4804\n",
      "Epoch 630/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4244 - acc: 0.5548 - val_loss: 1.6774 - val_acc: 0.4864\n",
      "Epoch 631/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4385 - acc: 0.5558 - val_loss: 1.7171 - val_acc: 0.4320\n",
      "Epoch 632/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4389 - acc: 0.5453 - val_loss: 1.7710 - val_acc: 0.4350\n",
      "Epoch 633/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4339 - acc: 0.5766 - val_loss: 1.7510 - val_acc: 0.4441\n",
      "Epoch 634/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4151 - acc: 0.5667 - val_loss: 1.7707 - val_acc: 0.4622\n",
      "Epoch 635/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4533 - acc: 0.5601 - val_loss: 1.7351 - val_acc: 0.4350\n",
      "Epoch 636/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4187 - acc: 0.5685 - val_loss: 1.7960 - val_acc: 0.4320\n",
      "Epoch 637/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4443 - acc: 0.5696 - val_loss: 1.6463 - val_acc: 0.4743\n",
      "Epoch 638/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4526 - acc: 0.5752 - val_loss: 1.7032 - val_acc: 0.4683\n",
      "Epoch 639/1000\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.4823 - acc: 0.5435 - val_loss: 1.7120 - val_acc: 0.4743\n",
      "Epoch 640/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4653 - acc: 0.5548 - val_loss: 1.7582 - val_acc: 0.4713\n",
      "Epoch 641/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4910 - acc: 0.5551 - val_loss: 1.6665 - val_acc: 0.4622\n",
      "Epoch 642/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4594 - acc: 0.5315 - val_loss: 1.6824 - val_acc: 0.4411\n",
      "Epoch 643/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4661 - acc: 0.5491 - val_loss: 1.8284 - val_acc: 0.3746\n",
      "Epoch 644/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4478 - acc: 0.5241 - val_loss: 1.8775 - val_acc: 0.3837\n",
      "Epoch 645/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4106 - acc: 0.5322 - val_loss: 1.7708 - val_acc: 0.4381\n",
      "Epoch 646/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4230 - acc: 0.5424 - val_loss: 1.8151 - val_acc: 0.4199\n",
      "Epoch 647/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4560 - acc: 0.5400 - val_loss: 1.7229 - val_acc: 0.4562\n",
      "Epoch 648/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4425 - acc: 0.5410 - val_loss: 1.8267 - val_acc: 0.4320\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4616 - acc: 0.5449 - val_loss: 1.6721 - val_acc: 0.4743\n",
      "Epoch 650/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4145 - acc: 0.5724 - val_loss: 1.7559 - val_acc: 0.4230\n",
      "Epoch 651/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3894 - acc: 0.5699 - val_loss: 1.8364 - val_acc: 0.4290\n",
      "Epoch 652/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4335 - acc: 0.5601 - val_loss: 1.7663 - val_acc: 0.4834\n",
      "Epoch 653/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4942 - acc: 0.5347 - val_loss: 1.7296 - val_acc: 0.4441\n",
      "Epoch 654/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4673 - acc: 0.5516 - val_loss: 1.7794 - val_acc: 0.4169\n",
      "Epoch 655/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4290 - acc: 0.5347 - val_loss: 1.8343 - val_acc: 0.3988\n",
      "Epoch 656/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4074 - acc: 0.5505 - val_loss: 1.8935 - val_acc: 0.3535\n",
      "Epoch 657/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4153 - acc: 0.5372 - val_loss: 1.8675 - val_acc: 0.3867\n",
      "Epoch 658/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4240 - acc: 0.5601 - val_loss: 1.9327 - val_acc: 0.4048\n",
      "Epoch 659/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4864 - acc: 0.5181 - val_loss: 1.9573 - val_acc: 0.3142\n",
      "Epoch 660/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4944 - acc: 0.5023 - val_loss: 1.7477 - val_acc: 0.4139\n",
      "Epoch 661/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.4233 - acc: 0.5481 - val_loss: 2.0040 - val_acc: 0.3776\n",
      "Epoch 662/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.6235 - acc: 0.4628 - val_loss: 1.6281 - val_acc: 0.4230\n",
      "Epoch 663/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4363 - acc: 0.5692 - val_loss: 1.7092 - val_acc: 0.4653\n",
      "Epoch 664/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3837 - acc: 0.5851 - val_loss: 1.7830 - val_acc: 0.4562\n",
      "Epoch 665/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3865 - acc: 0.5791 - val_loss: 1.7763 - val_acc: 0.4260\n",
      "Epoch 666/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4028 - acc: 0.5907 - val_loss: 1.9711 - val_acc: 0.3897\n",
      "Epoch 667/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4626 - acc: 0.5766 - val_loss: 2.1236 - val_acc: 0.3474\n",
      "Epoch 668/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4730 - acc: 0.4924 - val_loss: 1.7734 - val_acc: 0.4109\n",
      "Epoch 669/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4643 - acc: 0.5280 - val_loss: 1.7459 - val_acc: 0.4713\n",
      "Epoch 670/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4843 - acc: 0.5343 - val_loss: 1.6245 - val_acc: 0.4985\n",
      "Epoch 671/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4286 - acc: 0.5763 - val_loss: 1.6821 - val_acc: 0.4441\n",
      "Epoch 672/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3624 - acc: 0.6157 - val_loss: 1.7856 - val_acc: 0.4653\n",
      "Epoch 673/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3748 - acc: 0.6051 - val_loss: 1.9287 - val_acc: 0.4169\n",
      "Epoch 674/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4027 - acc: 0.5777 - val_loss: 1.9570 - val_acc: 0.3958\n",
      "Epoch 675/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4103 - acc: 0.5653 - val_loss: 1.9018 - val_acc: 0.4290\n",
      "Epoch 676/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4244 - acc: 0.5741 - val_loss: 1.9312 - val_acc: 0.4079\n",
      "Epoch 677/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4109 - acc: 0.5463 - val_loss: 1.8156 - val_acc: 0.3867\n",
      "Epoch 678/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5253 - acc: 0.4646 - val_loss: 1.6238 - val_acc: 0.4864\n",
      "Epoch 679/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4607 - acc: 0.5601 - val_loss: 1.7312 - val_acc: 0.4804\n",
      "Epoch 680/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4118 - acc: 0.5805 - val_loss: 1.8496 - val_acc: 0.4713\n",
      "Epoch 681/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4486 - acc: 0.5819 - val_loss: 1.7006 - val_acc: 0.4713\n",
      "Epoch 682/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4164 - acc: 0.5903 - val_loss: 1.9198 - val_acc: 0.3988\n",
      "Epoch 683/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5435 - acc: 0.5051 - val_loss: 1.9443 - val_acc: 0.3807\n",
      "Epoch 684/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4773 - acc: 0.5639 - val_loss: 1.8068 - val_acc: 0.3927\n",
      "Epoch 685/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4288 - acc: 0.5513 - val_loss: 1.7616 - val_acc: 0.4502\n",
      "Epoch 686/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3860 - acc: 0.5854 - val_loss: 1.7435 - val_acc: 0.4743\n",
      "Epoch 687/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4012 - acc: 0.5935 - val_loss: 1.8268 - val_acc: 0.4350\n",
      "Epoch 688/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4084 - acc: 0.5502 - val_loss: 1.7852 - val_acc: 0.4290\n",
      "Epoch 689/1000\n",
      "2839/2839 [==============================] - 0s 88us/step - loss: 0.4148 - acc: 0.5911 - val_loss: 1.8582 - val_acc: 0.4139\n",
      "Epoch 690/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4208 - acc: 0.5622 - val_loss: 1.9653 - val_acc: 0.3837\n",
      "Epoch 691/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4654 - acc: 0.5350 - val_loss: 1.9323 - val_acc: 0.4048\n",
      "Epoch 692/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3840 - acc: 0.5643 - val_loss: 1.8015 - val_acc: 0.4592\n",
      "Epoch 693/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.3929 - acc: 0.608 - 0s 70us/step - loss: 0.3892 - acc: 0.6048 - val_loss: 1.7856 - val_acc: 0.4411\n",
      "Epoch 694/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4003 - acc: 0.6108 - val_loss: 1.7625 - val_acc: 0.4532\n",
      "Epoch 695/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3842 - acc: 0.6006 - val_loss: 1.8725 - val_acc: 0.3867\n",
      "Epoch 696/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4278 - acc: 0.5618 - val_loss: 2.0276 - val_acc: 0.3746\n",
      "Epoch 697/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4677 - acc: 0.5090 - val_loss: 1.8537 - val_acc: 0.4109\n",
      "Epoch 698/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5057 - acc: 0.5005 - val_loss: 1.7985 - val_acc: 0.4592\n",
      "Epoch 699/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.5124 - acc: 0.5280 - val_loss: 1.7193 - val_acc: 0.4743\n",
      "Epoch 700/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4781 - acc: 0.5678 - val_loss: 1.7161 - val_acc: 0.4743\n",
      "Epoch 701/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4259 - acc: 0.5685 - val_loss: 1.7659 - val_acc: 0.4773\n",
      "Epoch 702/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4004 - acc: 0.5854 - val_loss: 1.7002 - val_acc: 0.4743\n",
      "Epoch 703/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3826 - acc: 0.6066 - val_loss: 1.7989 - val_acc: 0.4502\n",
      "Epoch 704/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3807 - acc: 0.6076 - val_loss: 1.8171 - val_acc: 0.4622\n",
      "Epoch 705/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4034 - acc: 0.5844 - val_loss: 1.7752 - val_acc: 0.4924\n",
      "Epoch 706/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4374 - acc: 0.5815 - val_loss: 1.7751 - val_acc: 0.4713\n",
      "Epoch 707/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4426 - acc: 0.5893 - val_loss: 1.8518 - val_acc: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4129 - acc: 0.5629 - val_loss: 1.8655 - val_acc: 0.4079\n",
      "Epoch 709/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4165 - acc: 0.5664 - val_loss: 2.2811 - val_acc: 0.3505\n",
      "Epoch 710/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5894 - acc: 0.4579 - val_loss: 1.7339 - val_acc: 0.4653\n",
      "Epoch 711/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4168 - acc: 0.5918 - val_loss: 1.8183 - val_acc: 0.4350\n",
      "Epoch 712/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3647 - acc: 0.6164 - val_loss: 1.8989 - val_acc: 0.4230\n",
      "Epoch 713/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3855 - acc: 0.5942 - val_loss: 1.8721 - val_acc: 0.4048\n",
      "Epoch 714/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4007 - acc: 0.5579 - val_loss: 1.8019 - val_acc: 0.4471\n",
      "Epoch 715/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3831 - acc: 0.5840 - val_loss: 1.7661 - val_acc: 0.4804\n",
      "Epoch 716/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4528 - acc: 0.5594 - val_loss: 1.7387 - val_acc: 0.4834\n",
      "Epoch 717/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4163 - acc: 0.5794 - val_loss: 1.8067 - val_acc: 0.4381\n",
      "Epoch 718/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4055 - acc: 0.5608 - val_loss: 1.8203 - val_acc: 0.4411\n",
      "Epoch 719/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.4043 - acc: 0.5918 - val_loss: 1.9037 - val_acc: 0.3927\n",
      "Epoch 720/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4235 - acc: 0.5488 - val_loss: 2.0186 - val_acc: 0.3776\n",
      "Epoch 721/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4628 - acc: 0.5322 - val_loss: 2.0802 - val_acc: 0.3837\n",
      "Epoch 722/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4513 - acc: 0.5481 - val_loss: 1.9737 - val_acc: 0.4199\n",
      "Epoch 723/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4295 - acc: 0.5579 - val_loss: 1.9724 - val_acc: 0.3746\n",
      "Epoch 724/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3807 - acc: 0.5675 - val_loss: 1.8547 - val_acc: 0.4411\n",
      "Epoch 725/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3766 - acc: 0.6069 - val_loss: 1.9898 - val_acc: 0.4139\n",
      "Epoch 726/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4008 - acc: 0.5893 - val_loss: 1.9043 - val_acc: 0.4502\n",
      "Epoch 727/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3953 - acc: 0.6069 - val_loss: 1.9245 - val_acc: 0.4230\n",
      "Epoch 728/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3999 - acc: 0.5995 - val_loss: 1.9816 - val_acc: 0.4290\n",
      "Epoch 729/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5317 - acc: 0.5241 - val_loss: 1.9607 - val_acc: 0.3958\n",
      "Epoch 730/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.4963 - acc: 0.5555 - val_loss: 1.9506 - val_acc: 0.3656\n",
      "Epoch 731/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4159 - acc: 0.5502 - val_loss: 1.9156 - val_acc: 0.3716\n",
      "Epoch 732/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3898 - acc: 0.5639 - val_loss: 1.8505 - val_acc: 0.4350\n",
      "Epoch 733/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3789 - acc: 0.6178 - val_loss: 1.8509 - val_acc: 0.4350\n",
      "Epoch 734/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3606 - acc: 0.6080 - val_loss: 1.8667 - val_acc: 0.4592\n",
      "Epoch 735/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3692 - acc: 0.6168 - val_loss: 1.8401 - val_acc: 0.4592\n",
      "Epoch 736/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3938 - acc: 0.6027 - val_loss: 1.8029 - val_acc: 0.4955\n",
      "Epoch 737/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4021 - acc: 0.6228 - val_loss: 1.9728 - val_acc: 0.4169\n",
      "Epoch 738/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5560 - acc: 0.4928 - val_loss: 1.7211 - val_acc: 0.4773\n",
      "Epoch 739/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4136 - acc: 0.5886 - val_loss: 1.7860 - val_acc: 0.4532\n",
      "Epoch 740/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3685 - acc: 0.6062 - val_loss: 1.8737 - val_acc: 0.4502\n",
      "Epoch 741/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3713 - acc: 0.6016 - val_loss: 1.9590 - val_acc: 0.4290\n",
      "Epoch 742/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3851 - acc: 0.6002 - val_loss: 2.2051 - val_acc: 0.3716\n",
      "Epoch 743/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4674 - acc: 0.5305 - val_loss: 2.2010 - val_acc: 0.3323\n",
      "Epoch 744/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4718 - acc: 0.5509 - val_loss: 1.9714 - val_acc: 0.3958\n",
      "Epoch 745/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3860 - acc: 0.5488 - val_loss: 1.9218 - val_acc: 0.4441\n",
      "Epoch 746/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3727 - acc: 0.5854 - val_loss: 1.8978 - val_acc: 0.4683\n",
      "Epoch 747/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3915 - acc: 0.6030 - val_loss: 1.9261 - val_acc: 0.4230\n",
      "Epoch 748/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4390 - acc: 0.5689 - val_loss: 1.9436 - val_acc: 0.4260\n",
      "Epoch 749/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4234 - acc: 0.5692 - val_loss: 1.9149 - val_acc: 0.4169\n",
      "Epoch 750/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4385 - acc: 0.5569 - val_loss: 1.9107 - val_acc: 0.3897\n",
      "Epoch 751/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4031 - acc: 0.5548 - val_loss: 1.9115 - val_acc: 0.4562\n",
      "Epoch 752/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3593 - acc: 0.6002 - val_loss: 1.8899 - val_acc: 0.4622\n",
      "Epoch 753/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3710 - acc: 0.6087 - val_loss: 1.9175 - val_acc: 0.4743\n",
      "Epoch 754/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3676 - acc: 0.5918 - val_loss: 2.0397 - val_acc: 0.4471\n",
      "Epoch 755/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4648 - acc: 0.5446 - val_loss: 1.7570 - val_acc: 0.5015\n",
      "Epoch 756/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.5607 - acc: 0.5618 - val_loss: 1.6974 - val_acc: 0.4773\n",
      "Epoch 757/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.4072 - acc: 0.5713 - val_loss: 1.7681 - val_acc: 0.4864\n",
      "Epoch 758/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3777 - acc: 0.5865 - val_loss: 1.8264 - val_acc: 0.4713\n",
      "Epoch 759/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3582 - acc: 0.6196 - val_loss: 1.8321 - val_acc: 0.4804\n",
      "Epoch 760/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3446 - acc: 0.6340 - val_loss: 1.9324 - val_acc: 0.4502\n",
      "Epoch 761/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4045 - acc: 0.6034 - val_loss: 1.9796 - val_acc: 0.4411\n",
      "Epoch 762/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.6361 - acc: 0.4805 - val_loss: 2.1034 - val_acc: 0.3565\n",
      "Epoch 763/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.5371 - acc: 0.4900 - val_loss: 1.7561 - val_acc: 0.4320\n",
      "Epoch 764/1000\n",
      "2839/2839 [==============================] - 0s 85us/step - loss: 0.3833 - acc: 0.5875 - val_loss: 1.8725 - val_acc: 0.4350\n",
      "Epoch 765/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3784 - acc: 0.5826 - val_loss: 1.8455 - val_acc: 0.4924\n",
      "Epoch 766/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4043 - acc: 0.5928 - val_loss: 1.8154 - val_acc: 0.4804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3497 - acc: 0.6386 - val_loss: 1.8948 - val_acc: 0.4653\n",
      "Epoch 768/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3265 - acc: 0.6386 - val_loss: 1.8998 - val_acc: 0.4713\n",
      "Epoch 769/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3666 - acc: 0.6221 - val_loss: 1.8874 - val_acc: 0.4955\n",
      "Epoch 770/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3985 - acc: 0.6027 - val_loss: 1.9396 - val_acc: 0.4562\n",
      "Epoch 771/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.4203 - acc: 0.5837 - val_loss: 1.8781 - val_acc: 0.4622\n",
      "Epoch 772/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3806 - acc: 0.6136 - val_loss: 1.8568 - val_acc: 0.4743\n",
      "Epoch 773/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3852 - acc: 0.6182 - val_loss: 1.9979 - val_acc: 0.4653\n",
      "Epoch 774/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4151 - acc: 0.5903 - val_loss: 1.8431 - val_acc: 0.4804\n",
      "Epoch 775/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3951 - acc: 0.5988 - val_loss: 1.8938 - val_acc: 0.4290\n",
      "Epoch 776/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.4547 - acc: 0.5583 - val_loss: 2.2317 - val_acc: 0.3202\n",
      "Epoch 777/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4634 - acc: 0.5164 - val_loss: 1.9079 - val_acc: 0.4109\n",
      "Epoch 778/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4098 - acc: 0.5675 - val_loss: 1.7769 - val_acc: 0.4562\n",
      "Epoch 779/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3715 - acc: 0.6058 - val_loss: 1.8720 - val_acc: 0.4834\n",
      "Epoch 780/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3571 - acc: 0.6175 - val_loss: 1.9030 - val_acc: 0.4743\n",
      "Epoch 781/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3561 - acc: 0.6231 - val_loss: 1.9633 - val_acc: 0.4743\n",
      "Epoch 782/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4383 - acc: 0.5551 - val_loss: 1.9166 - val_acc: 0.3927\n",
      "Epoch 783/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.5230 - acc: 0.5051 - val_loss: 1.7767 - val_acc: 0.4381\n",
      "Epoch 784/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3815 - acc: 0.6020 - val_loss: 1.8942 - val_acc: 0.4320\n",
      "Epoch 785/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3532 - acc: 0.6101 - val_loss: 1.9300 - val_acc: 0.4381\n",
      "Epoch 786/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3903 - acc: 0.6097 - val_loss: 2.2191 - val_acc: 0.3776\n",
      "Epoch 787/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4410 - acc: 0.5569 - val_loss: 2.0447 - val_acc: 0.3414\n",
      "Epoch 788/1000\n",
      "2839/2839 [==============================] - 0s 90us/step - loss: 0.4271 - acc: 0.5277 - val_loss: 1.9152 - val_acc: 0.4260\n",
      "Epoch 789/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3437 - acc: 0.6108 - val_loss: 1.9767 - val_acc: 0.4502\n",
      "Epoch 790/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3589 - acc: 0.6051 - val_loss: 2.0039 - val_acc: 0.4592\n",
      "Epoch 791/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3855 - acc: 0.6087 - val_loss: 2.0452 - val_acc: 0.4350\n",
      "Epoch 792/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4785 - acc: 0.5534 - val_loss: 1.8860 - val_acc: 0.4411\n",
      "Epoch 793/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3879 - acc: 0.6083 - val_loss: 1.8629 - val_acc: 0.4622\n",
      "Epoch 794/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3415 - acc: 0.6587 - val_loss: 1.9608 - val_acc: 0.4773\n",
      "Epoch 795/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3538 - acc: 0.5985 - val_loss: 1.9201 - val_acc: 0.4683\n",
      "Epoch 796/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3520 - acc: 0.6530 - val_loss: 1.9723 - val_acc: 0.5076\n",
      "Epoch 797/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.4382 - acc: 0.5907 - val_loss: 1.9564 - val_acc: 0.4683\n",
      "Epoch 798/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4704 - acc: 0.5752 - val_loss: 2.0713 - val_acc: 0.4320\n",
      "Epoch 799/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.5794 - val_loss: 2.3639 - val_acc: 0.3384\n",
      "Epoch 800/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4332 - acc: 0.5696 - val_loss: 2.0018 - val_acc: 0.4109\n",
      "Epoch 801/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3575 - acc: 0.6080 - val_loss: 2.1080 - val_acc: 0.4139\n",
      "Epoch 802/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3546 - acc: 0.6073 - val_loss: 1.9802 - val_acc: 0.4441\n",
      "Epoch 803/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3323 - acc: 0.6379 - val_loss: 2.1231 - val_acc: 0.4290\n",
      "Epoch 804/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3454 - acc: 0.6414 - val_loss: 2.0718 - val_acc: 0.4230\n",
      "Epoch 805/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3975 - acc: 0.6129 - val_loss: 2.0198 - val_acc: 0.4260\n",
      "Epoch 806/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3743 - acc: 0.5886 - val_loss: 2.0489 - val_acc: 0.4350\n",
      "Epoch 807/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3855 - acc: 0.5822 - val_loss: 2.1277 - val_acc: 0.4471\n",
      "Epoch 808/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4866 - acc: 0.5611 - val_loss: 2.0011 - val_acc: 0.4230\n",
      "Epoch 809/1000\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.4430 - acc: 0.5625 - val_loss: 1.9981 - val_acc: 0.4048\n",
      "Epoch 810/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4282 - acc: 0.5791 - val_loss: 1.9317 - val_acc: 0.4381\n",
      "Epoch 811/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3691 - acc: 0.6312 - val_loss: 1.9727 - val_acc: 0.4290\n",
      "Epoch 812/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3648 - acc: 0.6083 - val_loss: 2.0213 - val_acc: 0.4350\n",
      "Epoch 813/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3588 - acc: 0.6203 - val_loss: 2.0595 - val_acc: 0.4532\n",
      "Epoch 814/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3527 - acc: 0.6340 - val_loss: 2.0630 - val_acc: 0.4320\n",
      "Epoch 815/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3447 - acc: 0.6393 - val_loss: 2.0641 - val_acc: 0.4653\n",
      "Epoch 816/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4295 - acc: 0.6073 - val_loss: 1.9497 - val_acc: 0.5106\n",
      "Epoch 817/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.4778 - acc: 0.5896 - val_loss: 2.0048 - val_acc: 0.4381\n",
      "Epoch 818/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4714 - acc: 0.5590 - val_loss: 1.8722 - val_acc: 0.4532\n",
      "Epoch 819/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3726 - acc: 0.6235 - val_loss: 1.9455 - val_acc: 0.4592\n",
      "Epoch 820/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3299 - acc: 0.6252 - val_loss: 2.0229 - val_acc: 0.4471\n",
      "Epoch 821/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3395 - acc: 0.6309 - val_loss: 1.9383 - val_acc: 0.4834\n",
      "Epoch 822/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3312 - acc: 0.6471 - val_loss: 2.0557 - val_acc: 0.4320\n",
      "Epoch 823/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3637 - acc: 0.6027 - val_loss: 2.0156 - val_acc: 0.4562\n",
      "Epoch 824/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3906 - acc: 0.5903 - val_loss: 1.9581 - val_acc: 0.4562\n",
      "Epoch 825/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3897 - acc: 0.5914 - val_loss: 1.9865 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3957 - acc: 0.6210 - val_loss: 1.9429 - val_acc: 0.4713\n",
      "Epoch 827/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3692 - acc: 0.6118 - val_loss: 1.8433 - val_acc: 0.4864\n",
      "Epoch 828/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4352 - acc: 0.6175 - val_loss: 2.0047 - val_acc: 0.4713\n",
      "Epoch 829/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4900 - acc: 0.5727 - val_loss: 1.8167 - val_acc: 0.4804\n",
      "Epoch 830/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3907 - acc: 0.6182 - val_loss: 1.9308 - val_acc: 0.4441\n",
      "Epoch 831/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3343 - acc: 0.6439 - val_loss: 2.0983 - val_acc: 0.4350\n",
      "Epoch 832/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3486 - acc: 0.6210 - val_loss: 2.0630 - val_acc: 0.4683\n",
      "Epoch 833/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3377 - acc: 0.6467 - val_loss: 2.1722 - val_acc: 0.4230\n",
      "Epoch 834/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3859 - acc: 0.5946 - val_loss: 2.0481 - val_acc: 0.3958\n",
      "Epoch 835/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3814 - acc: 0.6154 - val_loss: 2.0999 - val_acc: 0.4109\n",
      "Epoch 836/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4000 - acc: 0.6034 - val_loss: 2.0146 - val_acc: 0.4562\n",
      "Epoch 837/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4626 - acc: 0.5667 - val_loss: 1.9320 - val_acc: 0.4350\n",
      "Epoch 838/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4297 - acc: 0.5879 - val_loss: 1.9672 - val_acc: 0.4653\n",
      "Epoch 839/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3624 - acc: 0.6361 - val_loss: 2.0017 - val_acc: 0.4260\n",
      "Epoch 840/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3721 - acc: 0.6097 - val_loss: 2.0462 - val_acc: 0.4683\n",
      "Epoch 841/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4521 - acc: 0.5911 - val_loss: 1.9576 - val_acc: 0.4592\n",
      "Epoch 842/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3712 - acc: 0.6185 - val_loss: 2.0119 - val_acc: 0.4471\n",
      "Epoch 843/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3237 - acc: 0.6231 - val_loss: 1.9970 - val_acc: 0.4622\n",
      "Epoch 844/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3298 - acc: 0.6523 - val_loss: 2.0721 - val_acc: 0.4683\n",
      "Epoch 845/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.3183 - acc: 0.6527 - val_loss: 2.2004 - val_acc: 0.4320\n",
      "Epoch 846/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3685 - acc: 0.6340 - val_loss: 2.0922 - val_acc: 0.4804\n",
      "Epoch 847/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4895 - acc: 0.5717 - val_loss: 2.2752 - val_acc: 0.3565\n",
      "Epoch 848/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.5534 - acc: 0.5122 - val_loss: 2.1754 - val_acc: 0.3353\n",
      "Epoch 849/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4466 - acc: 0.5315 - val_loss: 1.8446 - val_acc: 0.4683\n",
      "Epoch 850/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3360 - acc: 0.6259 - val_loss: 1.9395 - val_acc: 0.4653\n",
      "Epoch 851/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3361 - acc: 0.6414 - val_loss: 1.9640 - val_acc: 0.4562\n",
      "Epoch 852/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3108 - acc: 0.6548 - val_loss: 2.0807 - val_acc: 0.4562\n",
      "Epoch 853/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3309 - acc: 0.6559 - val_loss: 2.1427 - val_acc: 0.4381\n",
      "Epoch 854/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3675 - acc: 0.6161 - val_loss: 2.0443 - val_acc: 0.4562\n",
      "Epoch 855/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3420 - acc: 0.6266 - val_loss: 2.1656 - val_acc: 0.4381\n",
      "Epoch 856/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4655 - acc: 0.5579 - val_loss: 2.0667 - val_acc: 0.4260\n",
      "Epoch 857/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4720 - acc: 0.5537 - val_loss: 1.9442 - val_acc: 0.3988\n",
      "Epoch 858/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3375 - acc: 0.6266 - val_loss: 1.9890 - val_acc: 0.4471\n",
      "Epoch 859/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3331 - acc: 0.6302 - val_loss: 2.0133 - val_acc: 0.4713\n",
      "Epoch 860/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3398 - acc: 0.6386 - val_loss: 2.1334 - val_acc: 0.4532\n",
      "Epoch 861/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4020 - acc: 0.6375 - val_loss: 2.0282 - val_acc: 0.4924\n",
      "Epoch 862/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4785 - acc: 0.6090 - val_loss: 1.8360 - val_acc: 0.4804\n",
      "Epoch 863/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3493 - acc: 0.6368 - val_loss: 1.9912 - val_acc: 0.4502\n",
      "Epoch 864/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3339 - acc: 0.6502 - val_loss: 2.1741 - val_acc: 0.4109\n",
      "Epoch 865/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3601 - acc: 0.6171 - val_loss: 2.2517 - val_acc: 0.4139\n",
      "Epoch 866/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4624 - acc: 0.5618 - val_loss: 2.1733 - val_acc: 0.3867\n",
      "Epoch 867/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4039 - acc: 0.6006 - val_loss: 1.9526 - val_acc: 0.4592\n",
      "Epoch 868/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3342 - acc: 0.6523 - val_loss: 1.9970 - val_acc: 0.4713\n",
      "Epoch 869/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3217 - acc: 0.6516 - val_loss: 2.2316 - val_acc: 0.4048\n",
      "Epoch 870/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3630 - acc: 0.6147 - val_loss: 2.1095 - val_acc: 0.4109\n",
      "Epoch 871/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.4051 - acc: 0.5946 - val_loss: 1.8378 - val_acc: 0.5015\n",
      "Epoch 872/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.4152 - acc: 0.6361 - val_loss: 2.0638 - val_acc: 0.4713\n",
      "Epoch 873/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3466 - acc: 0.6291 - val_loss: 1.9945 - val_acc: 0.4894\n",
      "Epoch 874/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3753 - acc: 0.6492 - val_loss: 1.9396 - val_acc: 0.4713\n",
      "Epoch 875/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4437 - acc: 0.6132 - val_loss: 1.9206 - val_acc: 0.4683\n",
      "Epoch 876/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3414 - acc: 0.6626 - val_loss: 2.0213 - val_acc: 0.4743\n",
      "Epoch 877/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.3430 - acc: 0.6474 - val_loss: 2.1352 - val_acc: 0.4441\n",
      "Epoch 878/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3998 - acc: 0.5830 - val_loss: 2.1943 - val_acc: 0.3897\n",
      "Epoch 879/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3824 - acc: 0.5865 - val_loss: 1.9256 - val_acc: 0.4864\n",
      "Epoch 880/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3865 - acc: 0.6245 - val_loss: 2.1083 - val_acc: 0.4350\n",
      "Epoch 881/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4332 - acc: 0.6097 - val_loss: 1.9453 - val_acc: 0.4683\n",
      "Epoch 882/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3494 - acc: 0.6580 - val_loss: 2.0878 - val_acc: 0.4199\n",
      "Epoch 883/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3296 - acc: 0.6354 - val_loss: 2.0828 - val_acc: 0.4592\n",
      "Epoch 884/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3430 - acc: 0.6594 - val_loss: 1.9709 - val_acc: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3266 - acc: 0.6671 - val_loss: 2.0353 - val_acc: 0.4773\n",
      "Epoch 886/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3659 - acc: 0.6488 - val_loss: 2.1127 - val_acc: 0.4804\n",
      "Epoch 887/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.5176 - acc: 0.5224 - val_loss: 1.8774 - val_acc: 0.4864\n",
      "Epoch 888/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.4446 - acc: 0.6023 - val_loss: 1.9654 - val_acc: 0.4471\n",
      "Epoch 889/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3581 - acc: 0.6414 - val_loss: 1.9495 - val_acc: 0.4320\n",
      "Epoch 890/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3335 - acc: 0.6404 - val_loss: 1.9375 - val_acc: 0.4743\n",
      "Epoch 891/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3268 - acc: 0.6566 - val_loss: 2.1052 - val_acc: 0.4592\n",
      "Epoch 892/1000\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.3441 - acc: 0.6330 - val_loss: 1.9728 - val_acc: 0.4834\n",
      "Epoch 893/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3567 - acc: 0.6664 - val_loss: 2.1079 - val_acc: 0.4592\n",
      "Epoch 894/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3211 - acc: 0.6710 - val_loss: 2.1231 - val_acc: 0.4592\n",
      "Epoch 895/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3178 - acc: 0.6784 - val_loss: 2.1519 - val_acc: 0.4804\n",
      "Epoch 896/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3201 - acc: 0.6795 - val_loss: 2.1193 - val_acc: 0.4743\n",
      "Epoch 897/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3490 - acc: 0.6791 - val_loss: 2.1521 - val_acc: 0.4199\n",
      "Epoch 898/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.4061 - acc: 0.5780 - val_loss: 2.3040 - val_acc: 0.3958\n",
      "Epoch 899/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4506 - acc: 0.5576 - val_loss: 1.9442 - val_acc: 0.4894\n",
      "Epoch 900/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3901 - acc: 0.6287 - val_loss: 2.0831 - val_acc: 0.4743\n",
      "Epoch 901/1000\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.4110 - acc: 0.5977 - val_loss: 1.9202 - val_acc: 0.4924\n",
      "Epoch 902/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3419 - acc: 0.6745 - val_loss: 2.0742 - val_acc: 0.4713\n",
      "Epoch 903/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3368 - acc: 0.6668 - val_loss: 2.0186 - val_acc: 0.4834\n",
      "Epoch 904/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.3233 - acc: 0.6682 - val_loss: 2.1491 - val_acc: 0.4653\n",
      "Epoch 905/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3577 - acc: 0.6231 - val_loss: 2.1501 - val_acc: 0.4350\n",
      "Epoch 906/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3539 - acc: 0.6407 - val_loss: 2.0772 - val_acc: 0.4441\n",
      "Epoch 907/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3235 - acc: 0.6647 - val_loss: 2.1830 - val_acc: 0.4502\n",
      "Epoch 908/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3058 - acc: 0.6657 - val_loss: 2.1268 - val_acc: 0.4864\n",
      "Epoch 909/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3446 - acc: 0.6703 - val_loss: 2.2538 - val_acc: 0.4502\n",
      "Epoch 910/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4456 - acc: 0.5896 - val_loss: 2.0160 - val_acc: 0.4592\n",
      "Epoch 911/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.4042 - acc: 0.6337 - val_loss: 2.0971 - val_acc: 0.4471\n",
      "Epoch 912/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3611 - acc: 0.6266 - val_loss: 2.0200 - val_acc: 0.4924\n",
      "Epoch 913/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3711 - acc: 0.6439 - val_loss: 2.1392 - val_acc: 0.4592\n",
      "Epoch 914/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3703 - acc: 0.6291 - val_loss: 2.1314 - val_acc: 0.4290\n",
      "Epoch 915/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3379 - acc: 0.6400 - val_loss: 2.2038 - val_acc: 0.4169\n",
      "Epoch 916/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3192 - acc: 0.6516 - val_loss: 2.2789 - val_acc: 0.4018\n",
      "Epoch 917/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3458 - acc: 0.6442 - val_loss: 2.3933 - val_acc: 0.3746\n",
      "Epoch 918/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4123 - acc: 0.5872 - val_loss: 2.2602 - val_acc: 0.3807\n",
      "Epoch 919/1000\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.4503 - acc: 0.545 - 0s 70us/step - loss: 0.4376 - acc: 0.5801 - val_loss: 2.0815 - val_acc: 0.4139\n",
      "Epoch 920/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3691 - acc: 0.6238 - val_loss: 2.1176 - val_acc: 0.3958\n",
      "Epoch 921/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3419 - acc: 0.6361 - val_loss: 2.1297 - val_acc: 0.4471\n",
      "Epoch 922/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3177 - acc: 0.6777 - val_loss: 2.2818 - val_acc: 0.4139\n",
      "Epoch 923/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3132 - acc: 0.6492 - val_loss: 2.3177 - val_acc: 0.4048\n",
      "Epoch 924/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3796 - acc: 0.5999 - val_loss: 2.3125 - val_acc: 0.3776\n",
      "Epoch 925/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.5435 - val_loss: 2.0757 - val_acc: 0.4109\n",
      "Epoch 926/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3557 - acc: 0.6319 - val_loss: 2.0147 - val_acc: 0.4622\n",
      "Epoch 927/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3361 - acc: 0.6629 - val_loss: 2.0726 - val_acc: 0.4320\n",
      "Epoch 928/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3391 - acc: 0.6520 - val_loss: 2.0736 - val_acc: 0.4381\n",
      "Epoch 929/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3291 - acc: 0.6819 - val_loss: 1.9662 - val_acc: 0.4924\n",
      "Epoch 930/1000\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3684 - acc: 0.6492 - val_loss: 2.1278 - val_acc: 0.4320\n",
      "Epoch 931/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3484 - acc: 0.6495 - val_loss: 1.9780 - val_acc: 0.4894\n",
      "Epoch 932/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3434 - acc: 0.6499 - val_loss: 2.1677 - val_acc: 0.4199\n",
      "Epoch 933/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.4348 - acc: 0.5611 - val_loss: 1.9727 - val_acc: 0.4653\n",
      "Epoch 934/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.4658 - acc: 0.5738 - val_loss: 1.9771 - val_acc: 0.4713\n",
      "Epoch 935/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3947 - acc: 0.6442 - val_loss: 2.0017 - val_acc: 0.4713\n",
      "Epoch 936/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3102 - acc: 0.6883 - val_loss: 2.0887 - val_acc: 0.4653\n",
      "Epoch 937/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3296 - acc: 0.6619 - val_loss: 2.2974 - val_acc: 0.4381\n",
      "Epoch 938/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3166 - acc: 0.6805 - val_loss: 2.2130 - val_acc: 0.4622\n",
      "Epoch 939/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3129 - acc: 0.6936 - val_loss: 2.3951 - val_acc: 0.4018\n",
      "Epoch 940/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3754 - acc: 0.6337 - val_loss: 2.2304 - val_acc: 0.4381\n",
      "Epoch 941/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.3836 - acc: 0.6365 - val_loss: 2.3584 - val_acc: 0.3897\n",
      "Epoch 942/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3617 - acc: 0.6273 - val_loss: 2.3045 - val_acc: 0.3716\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3690 - acc: 0.6213 - val_loss: 2.1446 - val_acc: 0.3867\n",
      "Epoch 944/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3794 - acc: 0.6372 - val_loss: 2.1464 - val_acc: 0.4048\n",
      "Epoch 945/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3464 - acc: 0.6171 - val_loss: 2.1270 - val_acc: 0.4532\n",
      "Epoch 946/1000\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.3354 - acc: 0.6414 - val_loss: 2.1109 - val_acc: 0.4471\n",
      "Epoch 947/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3150 - acc: 0.6819 - val_loss: 2.1875 - val_acc: 0.4471\n",
      "Epoch 948/1000\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.3223 - acc: 0.6675 - val_loss: 2.1544 - val_acc: 0.4713\n",
      "Epoch 949/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3669 - acc: 0.6111 - val_loss: 2.1154 - val_acc: 0.4532\n",
      "Epoch 950/1000\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.3430 - acc: 0.6506 - val_loss: 2.1653 - val_acc: 0.4622\n",
      "Epoch 951/1000\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.3349 - acc: 0.6414 - val_loss: 2.3130 - val_acc: 0.4411\n",
      "Epoch 952/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3106 - acc: 0.6534 - val_loss: 2.2414 - val_acc: 0.4260\n",
      "Epoch 953/1000\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.3284 - acc: 0.6566 - val_loss: 2.1576 - val_acc: 0.4502\n",
      "Epoch 954/1000\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.3379 - acc: 0.6541 - val_loss: 2.3159 - val_acc: 0.4230\n",
      "Epoch 955/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3695 - acc: 0.6171 - val_loss: 2.3156 - val_acc: 0.3686\n",
      "Epoch 956/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.4175 - acc: 0.5562 - val_loss: 2.1877 - val_acc: 0.3746\n",
      "Epoch 957/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.4008 - acc: 0.5766 - val_loss: 2.0188 - val_acc: 0.4683\n",
      "Epoch 958/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.4368 - acc: 0.6066 - val_loss: 1.9456 - val_acc: 0.4834\n",
      "Epoch 959/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.4530 - acc: 0.6125 - val_loss: 2.0489 - val_acc: 0.4683\n",
      "Epoch 960/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3455 - acc: 0.6668 - val_loss: 2.1298 - val_acc: 0.4622\n",
      "Epoch 961/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3079 - acc: 0.6830 - val_loss: 2.1608 - val_acc: 0.4592\n",
      "Epoch 962/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.2963 - acc: 0.6809 - val_loss: 2.1278 - val_acc: 0.4683\n",
      "Epoch 963/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3126 - acc: 0.6777 - val_loss: 2.2272 - val_acc: 0.4290\n",
      "Epoch 964/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3245 - acc: 0.6538 - val_loss: 2.2911 - val_acc: 0.4199\n",
      "Epoch 965/1000\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.4104 - acc: 0.5731 - val_loss: 2.0858 - val_acc: 0.4048\n",
      "Epoch 966/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.4171 - acc: 0.5801 - val_loss: 2.0370 - val_acc: 0.4834\n",
      "Epoch 967/1000\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.3316 - acc: 0.6435 - val_loss: 2.0753 - val_acc: 0.4773\n",
      "Epoch 968/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3406 - acc: 0.6626 - val_loss: 2.1826 - val_acc: 0.4924\n",
      "Epoch 969/1000\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.4081 - acc: 0.6552 - val_loss: 2.0672 - val_acc: 0.4683\n",
      "Epoch 970/1000\n",
      "2839/2839 [==============================] - 0s 57us/step - loss: 0.3591 - acc: 0.6471 - val_loss: 2.0761 - val_acc: 0.4804\n",
      "Epoch 971/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3188 - acc: 0.6795 - val_loss: 2.2075 - val_acc: 0.4350\n",
      "Epoch 972/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.3233 - acc: 0.6766 - val_loss: 2.1822 - val_acc: 0.4713\n",
      "Epoch 973/1000\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 0.2942 - acc: 0.7034 - val_loss: 2.1314 - val_acc: 0.4743\n",
      "Epoch 974/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3112 - acc: 0.6950 - val_loss: 2.1083 - val_acc: 0.4743\n",
      "Epoch 975/1000\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.3081 - acc: 0.6756 - val_loss: 2.1856 - val_acc: 0.4804\n",
      "Epoch 976/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3786 - acc: 0.6383 - val_loss: 2.1609 - val_acc: 0.4773\n",
      "Epoch 977/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.5127 - acc: 0.5527 - val_loss: 1.9491 - val_acc: 0.4743\n",
      "Epoch 978/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4542 - acc: 0.6132 - val_loss: 2.0255 - val_acc: 0.4441\n",
      "Epoch 979/1000\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.3605 - acc: 0.6418 - val_loss: 2.0464 - val_acc: 0.4290\n",
      "Epoch 980/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3077 - acc: 0.6449 - val_loss: 2.0428 - val_acc: 0.4683\n",
      "Epoch 981/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3170 - acc: 0.6707 - val_loss: 2.1016 - val_acc: 0.4441\n",
      "Epoch 982/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3056 - acc: 0.6893 - val_loss: 2.2898 - val_acc: 0.4230\n",
      "Epoch 983/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.3036 - acc: 0.6890 - val_loss: 2.4094 - val_acc: 0.4109\n",
      "Epoch 984/1000\n",
      "2839/2839 [==============================] - 0s 97us/step - loss: 0.3462 - acc: 0.6404 - val_loss: 2.3870 - val_acc: 0.3807\n",
      "Epoch 985/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3643 - acc: 0.6206 - val_loss: 2.2336 - val_acc: 0.4320\n",
      "Epoch 986/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.3761 - acc: 0.6312 - val_loss: 2.2549 - val_acc: 0.4199\n",
      "Epoch 987/1000\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.3643 - acc: 0.6280 - val_loss: 2.0759 - val_acc: 0.4894\n",
      "Epoch 988/1000\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.3346 - acc: 0.6569 - val_loss: 2.1367 - val_acc: 0.4592\n",
      "Epoch 989/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3539 - acc: 0.6735 - val_loss: 2.1702 - val_acc: 0.4562\n",
      "Epoch 990/1000\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.3214 - acc: 0.6756 - val_loss: 2.2792 - val_acc: 0.4471\n",
      "Epoch 991/1000\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3351 - acc: 0.6668 - val_loss: 2.4146 - val_acc: 0.4109\n",
      "Epoch 992/1000\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.3891 - acc: 0.6034 - val_loss: 2.1066 - val_acc: 0.4532\n",
      "Epoch 993/1000\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.3363 - acc: 0.6608 - val_loss: 2.1839 - val_acc: 0.4471\n",
      "Epoch 994/1000\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2945 - acc: 0.6883 - val_loss: 2.1194 - val_acc: 0.4653\n",
      "Epoch 995/1000\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 0.2963 - acc: 0.6914 - val_loss: 2.2822 - val_acc: 0.4502\n",
      "Epoch 996/1000\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.3311 - acc: 0.6784 - val_loss: 2.1694 - val_acc: 0.4743\n",
      "Epoch 997/1000\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.3372 - acc: 0.6710 - val_loss: 2.2536 - val_acc: 0.5045\n",
      "Epoch 998/1000\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.3997 - acc: 0.6710 - val_loss: 2.1028 - val_acc: 0.4834\n",
      "Epoch 999/1000\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.4581 - acc: 0.6238 - val_loss: 2.0391 - val_acc: 0.4804\n",
      "Epoch 1000/1000\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.3651 - acc: 0.6368 - val_loss: 2.1546 - val_acc: 0.4199\n"
     ]
    }
   ],
   "source": [
    "w2v_model = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Will add confusion matrix from below, play with more metrics, and further tune w2v model but end of effective\n",
    "#### notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCWDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x198ec7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2v_model.history['acc'])\n",
    "plt.plot(w2v_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991869918699187\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_w2v)\n",
    "model_metrics(predictions, X_test, y_cat_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod = model.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df = pd.DataFrame(X_test_cat_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df['loss'] = np.where(X_test_cat_mod_df[0]> X_test_cat_mod_df[3], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df['gain'] = np.where(X_test_cat_mod_df[4]> X_test_cat_mod_df[1], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2 = pd.merge(X_test_cat_mod_df, y_cat_test_w2v, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_large'] = np.where(X_test_cat_mod_df[4]> X_test_cat_mod_df[2], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_large'] = np.where(X_test_cat_mod_df[0]> X_test_cat_mod_df[2], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_large_true'] = np.where((X_test_cat_mod_df_2['loss_large'] == 1) & (X_test_cat_mod_df_2['2'] == 1) | (X_test_cat_mod_df_2['1'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_large_true'] = np.where((X_test_cat_mod_df_2['gain_large'] == 1) & (X_test_cat_mod_df_2['4'] == 1) | (X_test_cat_mod_df_2['5'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'] = np.where((X_test_cat_mod_df_2['gain'] == 1) & (X_test_cat_mod_df_2['4'] == 1) | (X_test_cat_mod_df_2['5'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_large'] = np.where(X_test_cat_mod_df[0]> X_test_cat_mod_df[2], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['gain_stay'] = np.where((X_test_cat_mod_df_2['gain'] == 1) & (X_test_cat_mod_df_2['3'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_true_true'] = np.where((X_test_cat_mod_df_2['loss'] == 1) & (X_test_cat_mod_df_2['2'] == 1) | (X_test_cat_mod_df_2['1'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_mod_df_2['loss_stay'] = np.where((X_test_cat_mod_df_2['loss'] == 1) & (X_test_cat_mod_df_2['3'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991869918699187"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'].sum() / X_test_cat_mod_df_2['gain'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791666666666666"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_large_true'].sum() / X_test_cat_mod_df_2['gain_large'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_large_true'].sum() / X_test_cat_mod_df_2['loss_large'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2926829268292683"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_stay'].sum() / X_test_cat_mod_df_2['gain'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_true_true'].sum() / X_test_cat_mod_df_2['loss'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_stay'].sum() / X_test_cat_mod_df_2['loss'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6615384615384615"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'].sum() / (X_test_cat_mod_df_2['4'].sum() + X_test_cat_mod_df_2['5'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.105263157894737"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss'].sum() / (X_test_cat_mod_df_2['1'].sum() + X_test_cat_mod_df_2['2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_true_true'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_true_true'].sum() / (X_test_cat_mod_df_2['1'].sum() + X_test_cat_mod_df_2['2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.105263157894737"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss'].sum() / (X_test_cat_mod_df_2['1'].sum() + X_test_cat_mod_df_2['2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['loss_stay'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat_mod_df_2['gain_large_true'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = X_test_cat_mod.argmax(axis=1)\n",
    "true_classes = y_cat_test_w2v.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 2, 3, 2, 3, 1, 2, 2, 3, 3, 3, 4, 3, 3, 3, 4, 3, 4, 3, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 2, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 4, 2, 3, 3, 2, 1,\n",
       "       3, 3, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 3, 2,\n",
       "       3, 3, 4, 3, 4, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 4, 2, 3, 2, 3, 2,\n",
       "       2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 2, 1, 3, 1, 3, 2, 3, 2, 1, 1,\n",
       "       4, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 3, 3, 1, 3, 1, 2,\n",
       "       2, 3, 1, 4, 2, 1, 2, 3, 2, 4, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 0, 2, 2, 3, 2, 1, 2, 2, 3, 2, 3, 2, 2,\n",
       "       3, 3, 2, 1, 3, 1, 2, 2, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 3, 4, 3, 3, 3,\n",
       "       2, 2, 1, 0, 2, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3,\n",
       "       3, 3, 2, 2, 2, 2, 3, 3, 1, 1, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1,\n",
       "       1, 4, 1, 1, 2, 1, 0, 3, 4, 0, 2, 3, 2, 1, 1, 2, 4, 0, 1, 2, 1, 2, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 3])"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tst = pd.DataFrame(X_test_cat_mod)\n",
    "y_cat_test_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(predicted_classes, true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6,  4,  2,  1],\n",
       "       [ 3, 26, 32, 12,  5],\n",
       "       [ 1, 14, 63, 33,  1],\n",
       "       [ 0,  4, 40, 61, 10],\n",
       "       [ 0,  2,  5,  2,  3]])"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  52, 144, 110,  20])"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4350453172205438"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144 /331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
