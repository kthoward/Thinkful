{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import keras\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of importing functions from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import my_practice_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "my_practice_module.hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        #data = unicode(data, errors='replace')\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "#read_data_list\n",
    "#fail_list\n",
    "list_of_file_names_org = list_of_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Listings_PriceCut_SeasAdj_AllHomes.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset]\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(str)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_df = build_useful_df(read_data_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_list = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 10000:\n",
    "        sixteen_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for file in useful_df:\n",
    "    file_2 = len(file)\n",
    "    len_list.append(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 19.,  11.,   4.,   5.,   0.,   0.,   3.,   1.,   0.,   5.,   2.,\n",
       "          0.,   8.,   4.,   0.,   0.,   3.,   2.,   2.,  14.]),\n",
       " array([  8.00000000e+00,   8.02550000e+02,   1.59710000e+03,\n",
       "          2.39165000e+03,   3.18620000e+03,   3.98075000e+03,\n",
       "          4.77530000e+03,   5.56985000e+03,   6.36440000e+03,\n",
       "          7.15895000e+03,   7.95350000e+03,   8.74805000e+03,\n",
       "          9.54260000e+03,   1.03371500e+04,   1.11317000e+04,\n",
       "          1.19262500e+04,   1.27208000e+04,   1.35153500e+04,\n",
       "          1.43099000e+04,   1.51044500e+04,   1.58990000e+04]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x173eebcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(len_list, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews = []\n",
    "with open('./yelp_dataset/review.json') as data_file:    \n",
    "    for line in data_file:\n",
    "        data = json.loads(line)\n",
    "        yelp_reviews.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_business = []\n",
    "with open('./yelp_dataset/business.json') as data_file:    \n",
    "    for line in data_file:\n",
    "        data = json.loads(line)\n",
    "        yelp_business.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business = pd.DataFrame(yelp_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_reviews = pd.DataFrame(yelp_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp = pd.merge(df_yelp_business, df_yelp_reviews, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp['avg_review_count'] = df_yelp.groupby('postal_code')['review_count'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_business = df_yelp_business.sort_values('postal_code',ascending=False)\n",
    "df_yelp_business = df_yelp_business.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '1990-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "                    #big swing and gain, big swing and loss, big swing and big gain, big swing and big loss\n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_add(good_range, df_list, pure_feature_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for feature in pure_feature_list:\n",
    "        df = df_list[feature]\n",
    "        feature_df_list.append(df)\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '2011-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_bugs(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        df = df.loc[:, '2011-01':'2016-12']\n",
    "        features = pd.DataFrame()\n",
    "        for i, year in enumerate(year_list):\n",
    "            try:\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    \n",
    "                feature_df_list.append(features)\n",
    "            except:\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                #change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                \n",
    "                feature_df_list.append(features)\n",
    "        #    bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_list_swing(good_range, df_list):\n",
    "    year_list = ['2011', '2012', '2013', '2014', '2015', '2016']\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        try:\n",
    "            df = df.loc[:, '2011-01':'2016-12']\n",
    "            features = pd.DataFrame()\n",
    "            for i, year in enumerate(year_list):\n",
    "                mean = df.loc[:, year + '-01': year + '-12'].mean(axis=1)\n",
    "                features[year + '_mean'] = mean\n",
    "                std = df.loc[:, year + '-01': year + '-12'].std(axis=1)\n",
    "                features[year + '_std'] = std\n",
    "                mn = df.loc[:, year + '-01': year + '-12'].min(axis=1)\n",
    "                features[year + '_min'] = mn\n",
    "                mx = df.loc[:, year + '-01': year + '-12'].max(axis=1)\n",
    "                features[year + '_max'] = mx\n",
    "                features[year + '_swing'] = mx - mn\n",
    "                change = df[year + '-12'] - df[year + '-01']\n",
    "                features[year + '_change'] = change\n",
    "                if i > 0:\n",
    "                    yoy = features[year + '_mean'] / df.loc[:, year_list[i - 1] + '-01': year_list[i - 1] + '-12'].mean(axis=1)\n",
    "                    features[year + '_yoy'] = yoy\n",
    "                    features[year + '_gain'] = np.where(features[year + '_yoy']>1, 1, 0)\n",
    "                    mean_yoy = features[year + '_yoy'].mean()\n",
    "                    features[year + '_yoy_pos'] = np.where(features[year + '_yoy']>mean_yoy, 1, 0)\n",
    "                    big_yoy = features[year + '_yoy'].std() + mean_yoy\n",
    "                    features[year + '_yoy_big'] = np.where(features[year + '_yoy']>big_yoy, 1, 0)\n",
    "                    features[year + '_yoy_neg'] = np.where(features[year + '_yoy']<mean_yoy, 1, 0)\n",
    "                    big_loss = mean_yoy - features[year + '_yoy'].std() \n",
    "                    features[year + '_yoy_loss_big'] = np.where(features[year + '_yoy']<big_loss, 1, 0)\n",
    "                mean_swing = features[year + '_swing'].mean()\n",
    "                features[year + '_swing_pos'] = np.where(features[year + '_swing']>mean_swing, 1, 0)\n",
    "                big_swing = features[year + '_swing'].std() + mean_swing\n",
    "                features[year + '_swing_big'] = np.where(features[year + '_swing']>big_swing, 1, 0)\n",
    "                features[year + '_swing_neg'] = np.where(features[year + '_swing']<mean_swing, 1, 0)\n",
    "                swing_big_loss = mean_swing - features[year + '_swing'].std() \n",
    "                features[year + '_swing_loss_big'] = np.where(features[year + '_swing']<swing_big_loss, 1, 0)\n",
    "            feature_df_list.append(features)\n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return feature_df_list, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(useful_df)\n",
    "for num in range(len(useful_df)):\n",
    "    useful_df[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixteen_doc_features, bugs = build_feature_list_swing(sixteen_list, useful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sixteen_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./zip_2/Zip_Zri_AllHomesPlusMultifamily_Summary.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_file_names[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean</th>\n",
       "      <th>2011_std</th>\n",
       "      <th>2011_min</th>\n",
       "      <th>2011_max</th>\n",
       "      <th>2011_swing</th>\n",
       "      <th>2011_change</th>\n",
       "      <th>2011_swing_pos</th>\n",
       "      <th>2011_swing_big</th>\n",
       "      <th>2011_swing_neg</th>\n",
       "      <th>2011_swing_loss_big</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_yoy</th>\n",
       "      <th>2016_gain</th>\n",
       "      <th>2016_yoy_pos</th>\n",
       "      <th>2016_yoy_big</th>\n",
       "      <th>2016_yoy_neg</th>\n",
       "      <th>2016_yoy_loss_big</th>\n",
       "      <th>2016_swing_pos</th>\n",
       "      <th>2016_swing_big</th>\n",
       "      <th>2016_swing_neg</th>\n",
       "      <th>2016_swing_loss_big</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>221412.500000</td>\n",
       "      <td>12083.763054</td>\n",
       "      <td>206950.0</td>\n",
       "      <td>240950.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>-5550.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042953</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>228991.666667</td>\n",
       "      <td>4901.847209</td>\n",
       "      <td>219900.0</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>-3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99701</th>\n",
       "      <td>177891.666667</td>\n",
       "      <td>12940.595626</td>\n",
       "      <td>149900.0</td>\n",
       "      <td>191500.0</td>\n",
       "      <td>41600.0</td>\n",
       "      <td>-32600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052968</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99669</th>\n",
       "      <td>242495.833333</td>\n",
       "      <td>8514.091483</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>-3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99654</th>\n",
       "      <td>224546.458333</td>\n",
       "      <td>6069.795981</td>\n",
       "      <td>209500.0</td>\n",
       "      <td>232250.0</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                2011_mean      2011_std  2011_min  2011_max  2011_swing  \\\n",
       "RegionName                                                                \n",
       "99709       221412.500000  12083.763054  206950.0  240950.0     34000.0   \n",
       "99705       228991.666667   4901.847209  219900.0  234900.0     15000.0   \n",
       "99701       177891.666667  12940.595626  149900.0  191500.0     41600.0   \n",
       "99669       242495.833333   8514.091483  225000.0  252000.0     27000.0   \n",
       "99654       224546.458333   6069.795981  209500.0  232250.0     22750.0   \n",
       "\n",
       "            2011_change  2011_swing_pos  2011_swing_big  2011_swing_neg  \\\n",
       "RegionName                                                                \n",
       "99709           -5550.0               1               0               0   \n",
       "99705           -3000.0               0               0               1   \n",
       "99701          -32600.0               1               0               0   \n",
       "99669           -3000.0               0               0               1   \n",
       "99654           15500.0               0               0               1   \n",
       "\n",
       "            2011_swing_loss_big         ...           2016_yoy  2016_gain  \\\n",
       "RegionName                              ...                                 \n",
       "99709                         0         ...           1.042953          1   \n",
       "99705                         0         ...           1.007205          1   \n",
       "99701                         0         ...           1.052968          1   \n",
       "99669                         0         ...           0.973424          0   \n",
       "99654                         0         ...           1.018328          1   \n",
       "\n",
       "            2016_yoy_pos  2016_yoy_big  2016_yoy_neg  2016_yoy_loss_big  \\\n",
       "RegionName                                                                \n",
       "99709                  1             0             0                  0   \n",
       "99705                  0             0             1                  0   \n",
       "99701                  1             0             0                  0   \n",
       "99669                  0             0             1                  1   \n",
       "99654                  0             0             1                  0   \n",
       "\n",
       "            2016_swing_pos  2016_swing_big  2016_swing_neg  \\\n",
       "RegionName                                                   \n",
       "99709                    0               0               1   \n",
       "99705                    0               0               1   \n",
       "99701                    0               0               1   \n",
       "99669                    0               0               1   \n",
       "99654                    0               0               1   \n",
       "\n",
       "            2016_swing_loss_big  \n",
       "RegionName                       \n",
       "99709                         0  \n",
       "99705                         0  \n",
       "99701                         0  \n",
       "99669                         0  \n",
       "99654                         0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "sixteen_doc_features[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>1996-07</th>\n",
       "      <th>1996-08</th>\n",
       "      <th>1996-09</th>\n",
       "      <th>1996-10</th>\n",
       "      <th>1996-11</th>\n",
       "      <th>1996-12</th>\n",
       "      <th>1997-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2013-04</th>\n",
       "      <th>2013-05</th>\n",
       "      <th>2013-06</th>\n",
       "      <th>2013-07</th>\n",
       "      <th>2013-08</th>\n",
       "      <th>2013-09</th>\n",
       "      <th>2013-10</th>\n",
       "      <th>2013-11</th>\n",
       "      <th>2013-12</th>\n",
       "      <th>2014-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99901</th>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>206.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99712</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1996-04  1996-05  1996-06  1996-07  1996-08  1996-09  1996-10  \\\n",
       "RegionName                                                                  \n",
       "99901         162.0    162.0    162.0    162.0    162.0    162.0    162.0   \n",
       "99801           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "99712           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "99709           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "99705           NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "            1996-11  1996-12  1997-01   ...     2013-04  2013-05  2013-06  \\\n",
       "RegionName                              ...                                 \n",
       "99901         162.0    162.0    162.0   ...       161.0    162.0    162.0   \n",
       "99801           NaN      NaN      NaN   ...       206.0    207.0    208.0   \n",
       "99712           NaN      NaN      NaN   ...       123.0    122.0    122.0   \n",
       "99709           NaN      NaN      NaN   ...       119.0    119.0    119.0   \n",
       "99705           NaN      NaN      NaN   ...       124.0    124.0    124.0   \n",
       "\n",
       "            2013-07  2013-08  2013-09  2013-10  2013-11  2013-12  2014-01  \n",
       "RegionName                                                                 \n",
       "99901         162.0    162.0    162.0    162.0    161.0    161.0    161.0  \n",
       "99801         209.0    210.0    211.0    212.0    212.0    211.0    211.0  \n",
       "99712         122.0    120.0    120.0    120.0    120.0    120.0    120.0  \n",
       "99709         119.0    119.0    118.0    118.0    118.0    119.0    119.0  \n",
       "99705         123.0    123.0    123.0    122.0    123.0    123.0    124.0  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_df[52].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(sixteen_doc_features)\n",
    "for num in range(len(sixteen_doc_features)):\n",
    "    sixteen_doc_features[num].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging all dfs into one. Merging on indez which is zipcode. I was hoping for inner join but it looks like\n",
    "# There are many zipcodes that only exist in certain dfs. Im hoping that reducing them to metro areas will fix this\n",
    "def merge_dataframes(feature_df_list):\n",
    "    df_1 = feature_df_list[0]\n",
    "    for df in feature_df_list[1:]:\n",
    "        df_1 = pd.merge(df_1, df, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = merge_dataframes(sixteen_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2011_swing_pos_x</th>\n",
       "      <th>2011_swing_big_x</th>\n",
       "      <th>2011_swing_neg_x</th>\n",
       "      <th>2011_swing_loss_big_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_yoy_y</th>\n",
       "      <th>2016_gain_y</th>\n",
       "      <th>2016_yoy_pos_y</th>\n",
       "      <th>2016_yoy_big_y</th>\n",
       "      <th>2016_yoy_neg_y</th>\n",
       "      <th>2016_yoy_loss_big_y</th>\n",
       "      <th>2016_swing_pos_y</th>\n",
       "      <th>2016_swing_big_y</th>\n",
       "      <th>2016_swing_neg_y</th>\n",
       "      <th>2016_swing_loss_big_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99223</th>\n",
       "      <td>17.470575</td>\n",
       "      <td>2.151552</td>\n",
       "      <td>13.157744</td>\n",
       "      <td>19.884243</td>\n",
       "      <td>6.726499</td>\n",
       "      <td>0.772589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99218</th>\n",
       "      <td>17.800899</td>\n",
       "      <td>2.953572</td>\n",
       "      <td>11.325792</td>\n",
       "      <td>21.163550</td>\n",
       "      <td>9.837757</td>\n",
       "      <td>2.571792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99217</th>\n",
       "      <td>16.730506</td>\n",
       "      <td>2.461923</td>\n",
       "      <td>11.315092</td>\n",
       "      <td>20.255591</td>\n",
       "      <td>8.940499</td>\n",
       "      <td>-2.257172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99212</th>\n",
       "      <td>15.310737</td>\n",
       "      <td>2.952748</td>\n",
       "      <td>11.290826</td>\n",
       "      <td>20.327481</td>\n",
       "      <td>9.036655</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044389</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99208</th>\n",
       "      <td>12.623406</td>\n",
       "      <td>1.774491</td>\n",
       "      <td>9.810553</td>\n",
       "      <td>15.617595</td>\n",
       "      <td>5.807042</td>\n",
       "      <td>1.675172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048049</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1080 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2011_mean_x  2011_std_x  2011_min_x  2011_max_x  2011_swing_x  \\\n",
       "RegionName                                                                  \n",
       "99223         17.470575    2.151552   13.157744   19.884243      6.726499   \n",
       "99218         17.800899    2.953572   11.325792   21.163550      9.837757   \n",
       "99217         16.730506    2.461923   11.315092   20.255591      8.940499   \n",
       "99212         15.310737    2.952748   11.290826   20.327481      9.036655   \n",
       "99208         12.623406    1.774491    9.810553   15.617595      5.807042   \n",
       "\n",
       "            2011_change_x  2011_swing_pos_x  2011_swing_big_x  \\\n",
       "RegionName                                                      \n",
       "99223            0.772589                 0                 0   \n",
       "99218            2.571792                 1                 0   \n",
       "99217           -2.257172                 0                 0   \n",
       "99212            0.120253                 0                 0   \n",
       "99208            1.675172                 0                 0   \n",
       "\n",
       "            2011_swing_neg_x  2011_swing_loss_big_x          ...            \\\n",
       "RegionName                                                   ...             \n",
       "99223                      1                      0          ...             \n",
       "99218                      0                      0          ...             \n",
       "99217                      1                      0          ...             \n",
       "99212                      1                      0          ...             \n",
       "99208                      1                      1          ...             \n",
       "\n",
       "            2016_yoy_y  2016_gain_y  2016_yoy_pos_y  2016_yoy_big_y  \\\n",
       "RegionName                                                            \n",
       "99223         1.050296            1               1               0   \n",
       "99218         1.057409            1               1               0   \n",
       "99217         1.035182            1               1               0   \n",
       "99212         1.044389            1               1               0   \n",
       "99208         1.048049            1               1               0   \n",
       "\n",
       "            2016_yoy_neg_y  2016_yoy_loss_big_y  2016_swing_pos_y  \\\n",
       "RegionName                                                          \n",
       "99223                    0                    0                 1   \n",
       "99218                    0                    0                 1   \n",
       "99217                    0                    0                 0   \n",
       "99212                    0                    0                 0   \n",
       "99208                    0                    0                 0   \n",
       "\n",
       "            2016_swing_big_y  2016_swing_neg_y  2016_swing_loss_big_y  \n",
       "RegionName                                                             \n",
       "99223                      0                 0                      0  \n",
       "99218                      0                 0                      0  \n",
       "99217                      0                 1                      0  \n",
       "99212                      0                 1                      0  \n",
       "99208                      0                 1                      0  \n",
       "\n",
       "[5 rows x 1080 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_business = df_yelp_business.sort_values('postal_code',ascending=False)\n",
    "df_yelp_business = df_yelp_business.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_yelp_business_merge = pd.DataFrame()\n",
    "df_yelp_business_merge['review_count'] = df_yelp_business['review_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YO22 5LY</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 5AL</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4RG</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4NT</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YO22 4JT</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_count\n",
       "postal_code              \n",
       "YO22 5LY                4\n",
       "YO22 5AL                4\n",
       "YO22 4RG                3\n",
       "YO22 4NT                3\n",
       "YO22 4JT               15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_business_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>zeroes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_count, zeroes]\n",
       "Index: []"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_business_merge.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([99362, 99354, 99352, 99337, 99224, 99223, 99218, 99217, 99216,\n",
       "            99212,\n",
       "            ...\n",
       "             1077,  1075,  1069,  1056,  1040,  1028,  1020,  1013,  1002,\n",
       "             1001],\n",
       "           dtype='int64', name='RegionName', length=4149)"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the Zillow data and the yelp zipcodes \n",
    "df_2 = pd.merge(X_16, df_yelp_business_merge, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2011_swing_pos_x</th>\n",
       "      <th>2011_swing_big_x</th>\n",
       "      <th>2011_swing_neg_x</th>\n",
       "      <th>2011_swing_loss_big_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_gain_y</th>\n",
       "      <th>2016_yoy_pos_y</th>\n",
       "      <th>2016_yoy_big_y</th>\n",
       "      <th>2016_yoy_neg_y</th>\n",
       "      <th>2016_yoy_loss_big_y</th>\n",
       "      <th>2016_swing_pos_y</th>\n",
       "      <th>2016_swing_big_y</th>\n",
       "      <th>2016_swing_neg_y</th>\n",
       "      <th>2016_swing_loss_big_y</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>15.066711</td>\n",
       "      <td>2.11167</td>\n",
       "      <td>11.889551</td>\n",
       "      <td>19.036276</td>\n",
       "      <td>7.146725</td>\n",
       "      <td>-1.048499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>15.066711</td>\n",
       "      <td>2.11167</td>\n",
       "      <td>11.889551</td>\n",
       "      <td>19.036276</td>\n",
       "      <td>7.146725</td>\n",
       "      <td>-1.048499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>15.066711</td>\n",
       "      <td>2.11167</td>\n",
       "      <td>11.889551</td>\n",
       "      <td>19.036276</td>\n",
       "      <td>7.146725</td>\n",
       "      <td>-1.048499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>15.066711</td>\n",
       "      <td>2.11167</td>\n",
       "      <td>11.889551</td>\n",
       "      <td>19.036276</td>\n",
       "      <td>7.146725</td>\n",
       "      <td>-1.048499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>15.066711</td>\n",
       "      <td>2.11167</td>\n",
       "      <td>11.889551</td>\n",
       "      <td>19.036276</td>\n",
       "      <td>7.146725</td>\n",
       "      <td>-1.048499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1081 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2011_mean_x  2011_std_x  2011_min_x  2011_max_x  2011_swing_x  \\\n",
       "15102    15.066711     2.11167   11.889551   19.036276      7.146725   \n",
       "15102    15.066711     2.11167   11.889551   19.036276      7.146725   \n",
       "15102    15.066711     2.11167   11.889551   19.036276      7.146725   \n",
       "15102    15.066711     2.11167   11.889551   19.036276      7.146725   \n",
       "15102    15.066711     2.11167   11.889551   19.036276      7.146725   \n",
       "\n",
       "       2011_change_x  2011_swing_pos_x  2011_swing_big_x  2011_swing_neg_x  \\\n",
       "15102      -1.048499                 0                 0                 1   \n",
       "15102      -1.048499                 0                 0                 1   \n",
       "15102      -1.048499                 0                 0                 1   \n",
       "15102      -1.048499                 0                 0                 1   \n",
       "15102      -1.048499                 0                 0                 1   \n",
       "\n",
       "       2011_swing_loss_big_x      ...       2016_gain_y  2016_yoy_pos_y  \\\n",
       "15102                      0      ...                 1               0   \n",
       "15102                      0      ...                 1               0   \n",
       "15102                      0      ...                 1               0   \n",
       "15102                      0      ...                 1               0   \n",
       "15102                      0      ...                 1               0   \n",
       "\n",
       "       2016_yoy_big_y  2016_yoy_neg_y  2016_yoy_loss_big_y  2016_swing_pos_y  \\\n",
       "15102               0               1                    0                 0   \n",
       "15102               0               1                    0                 0   \n",
       "15102               0               1                    0                 0   \n",
       "15102               0               1                    0                 0   \n",
       "15102               0               1                    0                 0   \n",
       "\n",
       "       2016_swing_big_y  2016_swing_neg_y  2016_swing_loss_big_y  review_count  \n",
       "15102                 0                 1                      0             3  \n",
       "15102                 0                 1                      0             9  \n",
       "15102                 0                 1                      0            15  \n",
       "15102                 0                 1                      0             4  \n",
       "15102                 0                 1                      0             4  \n",
       "\n",
       "[5 rows x 1081 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2017-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3484\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_searchsorted_monotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3485\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_searchsorted_monotonic\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3443\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index must be monotonic increasing or decreasing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: index must be monotonic increasing or decreasing",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-36235b891e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_modeling_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0museful_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museful_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2017-01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_modeling_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0museful_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museful_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2016-07\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-36235b891e7e>\u001b[0m in \u001b[0;36mmake_modeling_data\u001b[0;34m(df, df_features, now_string)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#df_to_use_for_features= df_features.loc[:, :now_string]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msixteen_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_time_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-36235b891e7e>\u001b[0m in \u001b[0;36mmake_features\u001b[0;34m(df_list, good_range, past_time_string, now_string)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgood_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnow_string\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n\u001b[0;32m-> 1356\u001b[0;31m                                        slice_obj.step, kind=self.name)\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \"\"\"\n\u001b[1;32m   3349\u001b[0m         start_slice, end_slice = self.slice_locs(start, end, step=step,\n\u001b[0;32m-> 3350\u001b[0;31m                                                  kind=kind)\n\u001b[0m\u001b[1;32m   3351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   3542\u001b[0m         \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3544\u001b[0;31m             \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3546\u001b[0m             \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3485\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m                 \u001b[0;31m# raise the original KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   3479\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3481\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_only_exact_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_loc_only_exact_matches\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3448\u001b[0m         \u001b[0mget_slice_bound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m         \"\"\"\n\u001b[0;32m-> 3450\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2017-01'"
     ]
    }
   ],
   "source": [
    "def make_features(df_list, good_range, past_time_string, now_string):\n",
    "    feature_df_list = []\n",
    "    bugs = []\n",
    "    for num in good_range:\n",
    "        df = df_list[num]\n",
    "        df = df.loc[:, :now_string]\n",
    "        try:\n",
    "            features = pd.DataFrame()\n",
    "            mean = df.loc[:, past_time_string : now_string].mean(axis=1)\n",
    "            features[now_string + '_mean'] = mean\n",
    "            std = df.loc[:, past_time_string : now_string].std(axis=1)\n",
    "            features[now_string + '_std'] = std\n",
    "            mn = df.loc[:, past_time_string : now_string].min(axis=1)\n",
    "            features[now_string + '_min'] = mn\n",
    "            mx = df.loc[:, past_time_string : now_string].max(axis=1)\n",
    "            features[now_string + '_max'] = mx\n",
    "            features[now_string + '_swing'] = mx - mn\n",
    "            change = df[now_string] - df[past_time_string]\n",
    "            features[now_string + '_change'] = change\n",
    "            feature_df_list.append(features)\n",
    "                \n",
    "        except:\n",
    "            bugs.append(num)\n",
    "    return features_df_list\n",
    "    \n",
    "\n",
    "def make_modeling_data(df, df_features, now_string):\n",
    "    now_time = pd.to_datetime(now_string)\n",
    "    now_value = df[now_string]\n",
    "    \n",
    "    future_time = now_time + timedelta(days=6*31)\n",
    "    future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    past_time = now_time - timedelta(days=6*31)\n",
    "    past_time_string= past_time.strftime(\"%Y-%m\")\n",
    "    past_value = df[past_time_string]\n",
    "    future_value = df[future_time_string]\n",
    "   \n",
    "    target = future_value/now_value\n",
    "    \n",
    "    #df_to_use_for_features= df_features.loc[:, :now_string]\n",
    "    \n",
    "    features = make_features(df_features, sixteen_list, past_time_string, now_string)\n",
    "    \n",
    "    return features, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_features, test_targets = make_modeling_data(useful_df[23], useful_df, \"2017-01\")\n",
    "train_features, train_targets = make_modeling_data(useful_df[23], useful_df, \"2016-07\")\n",
    "\n",
    "#for year in [\"2014\",'2015',\"2016\"]:\n",
    " #   for month in [\"01\",'07']:\n",
    "  #      extra_train_features, extra_train_targets = make_modeling_data(read_data_list_2[3], year+\"-\"+month)\n",
    "   #     train_features = train_features.append(extra_train_features)\n",
    "    #    train_targets = train_targets.append(extra_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10521"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10521"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1513.2575757575798",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1513.2575757575798",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-8869b41fcb45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_y_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_data_list_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-24d3d65dee28>\u001b[0m in \u001b[0;36mcreate_y_ratio\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mwindow_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow_2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#y = y.sort_values('RegionName',ascending=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#y = y.set_index('RegionName')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1513.2575757575798"
     ]
    }
   ],
   "source": [
    "y = create_y_ratio(read_data_list_2[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10521"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_data_list_2[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10025</td>\n",
       "      <td>0.950185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10023</td>\n",
       "      <td>0.995899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77494</td>\n",
       "      <td>1.031827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75070</td>\n",
       "      <td>0.981885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RegionName         y\n",
       "0      10025  0.950185\n",
       "1      60657       NaN\n",
       "2      10023  0.995899\n",
       "3      77494  1.031827\n",
       "4      75070  0.981885"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-69c587d04836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_16_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "X_16_df = pd.merge(X_16, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2_df = pd.merge(df_2, y, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2011_swing_pos_x</th>\n",
       "      <th>2011_swing_big_x</th>\n",
       "      <th>2011_swing_neg_x</th>\n",
       "      <th>2011_swing_loss_big_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_yoy_pos_y</th>\n",
       "      <th>2016_yoy_big_y</th>\n",
       "      <th>2016_yoy_neg_y</th>\n",
       "      <th>2016_yoy_loss_big_y</th>\n",
       "      <th>2016_swing_pos_y</th>\n",
       "      <th>2016_swing_big_y</th>\n",
       "      <th>2016_swing_neg_y</th>\n",
       "      <th>2016_swing_loss_big_y</th>\n",
       "      <th>review_count</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.663362</td>\n",
       "      <td>3.136821</td>\n",
       "      <td>10.19523</td>\n",
       "      <td>18.892134</td>\n",
       "      <td>8.696905</td>\n",
       "      <td>-2.455884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.663362</td>\n",
       "      <td>3.136821</td>\n",
       "      <td>10.19523</td>\n",
       "      <td>18.892134</td>\n",
       "      <td>8.696905</td>\n",
       "      <td>-2.455884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.663362</td>\n",
       "      <td>3.136821</td>\n",
       "      <td>10.19523</td>\n",
       "      <td>18.892134</td>\n",
       "      <td>8.696905</td>\n",
       "      <td>-2.455884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.663362</td>\n",
       "      <td>3.136821</td>\n",
       "      <td>10.19523</td>\n",
       "      <td>18.892134</td>\n",
       "      <td>8.696905</td>\n",
       "      <td>-2.455884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>13.663362</td>\n",
       "      <td>3.136821</td>\n",
       "      <td>10.19523</td>\n",
       "      <td>18.892134</td>\n",
       "      <td>8.696905</td>\n",
       "      <td>-2.455884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.004622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2011_mean_x  2011_std_x  2011_min_x  2011_max_x  2011_swing_x  \\\n",
       "15003    13.663362    3.136821    10.19523   18.892134      8.696905   \n",
       "15003    13.663362    3.136821    10.19523   18.892134      8.696905   \n",
       "15003    13.663362    3.136821    10.19523   18.892134      8.696905   \n",
       "15003    13.663362    3.136821    10.19523   18.892134      8.696905   \n",
       "15003    13.663362    3.136821    10.19523   18.892134      8.696905   \n",
       "\n",
       "       2011_change_x  2011_swing_pos_x  2011_swing_big_x  2011_swing_neg_x  \\\n",
       "15003      -2.455884                 0                 0                 1   \n",
       "15003      -2.455884                 0                 0                 1   \n",
       "15003      -2.455884                 0                 0                 1   \n",
       "15003      -2.455884                 0                 0                 1   \n",
       "15003      -2.455884                 0                 0                 1   \n",
       "\n",
       "       2011_swing_loss_big_x    ...     2016_yoy_pos_y  2016_yoy_big_y  \\\n",
       "15003                      0    ...                  0               0   \n",
       "15003                      0    ...                  0               0   \n",
       "15003                      0    ...                  0               0   \n",
       "15003                      0    ...                  0               0   \n",
       "15003                      0    ...                  0               0   \n",
       "\n",
       "       2016_yoy_neg_y  2016_yoy_loss_big_y  2016_swing_pos_y  \\\n",
       "15003               1                    0                 0   \n",
       "15003               1                    0                 0   \n",
       "15003               1                    0                 0   \n",
       "15003               1                    0                 0   \n",
       "15003               1                    0                 0   \n",
       "\n",
       "       2016_swing_big_y  2016_swing_neg_y  2016_swing_loss_big_y  \\\n",
       "15003                 0                 1                      0   \n",
       "15003                 0                 1                      0   \n",
       "15003                 0                 1                      0   \n",
       "15003                 0                 1                      0   \n",
       "15003                 0                 1                      0   \n",
       "\n",
       "       review_count         y  \n",
       "15003             4  1.004622  \n",
       "15003             8  1.004622  \n",
       "15003            39  1.004622  \n",
       "15003             3  1.004622  \n",
       "15003             8  1.004622  \n",
       "\n",
       "[5 rows x 542 columns]"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dropna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-948-1c31721c04ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dropna'"
     ]
    }
   ],
   "source": [
    "X_2.dropna(inplace=True)\n",
    "X_2.isnull().sum().sum()\n",
    "X_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347079037800687"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_df['2016_gain'].sum() / len(X_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011_mean_x</th>\n",
       "      <th>2011_std_x</th>\n",
       "      <th>2011_min_x</th>\n",
       "      <th>2011_max_x</th>\n",
       "      <th>2011_swing_x</th>\n",
       "      <th>2011_change_x</th>\n",
       "      <th>2011_swing_pos_x</th>\n",
       "      <th>2011_swing_big_x</th>\n",
       "      <th>2011_swing_neg_x</th>\n",
       "      <th>2011_swing_loss_big_x</th>\n",
       "      <th>...</th>\n",
       "      <th>2016_gain_y</th>\n",
       "      <th>2016_yoy_pos_y</th>\n",
       "      <th>2016_yoy_big_y</th>\n",
       "      <th>2016_yoy_neg_y</th>\n",
       "      <th>2016_yoy_loss_big_y</th>\n",
       "      <th>2016_swing_pos_y</th>\n",
       "      <th>2016_swing_big_y</th>\n",
       "      <th>2016_swing_neg_y</th>\n",
       "      <th>2016_swing_loss_big_y</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "      <td>5129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.281579</td>\n",
       "      <td>2.873584</td>\n",
       "      <td>9.687841</td>\n",
       "      <td>19.192768</td>\n",
       "      <td>9.504927</td>\n",
       "      <td>-1.164982</td>\n",
       "      <td>0.428154</td>\n",
       "      <td>0.149152</td>\n",
       "      <td>0.571846</td>\n",
       "      <td>0.149152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.551764</td>\n",
       "      <td>0.156561</td>\n",
       "      <td>0.448236</td>\n",
       "      <td>0.049912</td>\n",
       "      <td>0.360889</td>\n",
       "      <td>0.098265</td>\n",
       "      <td>0.639111</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>1.067475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.122251</td>\n",
       "      <td>1.019149</td>\n",
       "      <td>3.194033</td>\n",
       "      <td>4.072836</td>\n",
       "      <td>3.459762</td>\n",
       "      <td>4.325728</td>\n",
       "      <td>0.494859</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>0.494859</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333358</td>\n",
       "      <td>0.497362</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>0.497362</td>\n",
       "      <td>0.217785</td>\n",
       "      <td>0.480305</td>\n",
       "      <td>0.297701</td>\n",
       "      <td>0.480305</td>\n",
       "      <td>0.144236</td>\n",
       "      <td>0.072273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.149246</td>\n",
       "      <td>0.717761</td>\n",
       "      <td>-1.717095</td>\n",
       "      <td>7.217994</td>\n",
       "      <td>2.280413</td>\n",
       "      <td>-23.062877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.116049</td>\n",
       "      <td>2.138989</td>\n",
       "      <td>7.456067</td>\n",
       "      <td>16.480570</td>\n",
       "      <td>7.036975</td>\n",
       "      <td>-3.732543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.023399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.286639</td>\n",
       "      <td>2.739566</td>\n",
       "      <td>9.738339</td>\n",
       "      <td>19.012437</td>\n",
       "      <td>9.001742</td>\n",
       "      <td>-0.989435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.061971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.355682</td>\n",
       "      <td>3.455925</td>\n",
       "      <td>11.863632</td>\n",
       "      <td>21.755320</td>\n",
       "      <td>11.443071</td>\n",
       "      <td>1.592072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.106317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.309110</td>\n",
       "      <td>9.054726</td>\n",
       "      <td>21.888196</td>\n",
       "      <td>38.354467</td>\n",
       "      <td>32.033667</td>\n",
       "      <td>17.008037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.425089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2011_mean_x   2011_std_x   2011_min_x   2011_max_x  2011_swing_x  \\\n",
       "count  5129.000000  5129.000000  5129.000000  5129.000000   5129.000000   \n",
       "mean     14.281579     2.873584     9.687841    19.192768      9.504927   \n",
       "std       3.122251     1.019149     3.194033     4.072836      3.459762   \n",
       "min       5.149246     0.717761    -1.717095     7.217994      2.280413   \n",
       "25%      12.116049     2.138989     7.456067    16.480570      7.036975   \n",
       "50%      14.286639     2.739566     9.738339    19.012437      9.001742   \n",
       "75%      16.355682     3.455925    11.863632    21.755320     11.443071   \n",
       "max      25.309110     9.054726    21.888196    38.354467     32.033667   \n",
       "\n",
       "       2011_change_x  2011_swing_pos_x  2011_swing_big_x  2011_swing_neg_x  \\\n",
       "count    5129.000000       5129.000000       5129.000000       5129.000000   \n",
       "mean       -1.164982          0.428154          0.149152          0.571846   \n",
       "std         4.325728          0.494859          0.356273          0.494859   \n",
       "min       -23.062877          0.000000          0.000000          0.000000   \n",
       "25%        -3.732543          0.000000          0.000000          0.000000   \n",
       "50%        -0.989435          0.000000          0.000000          1.000000   \n",
       "75%         1.592072          1.000000          0.000000          1.000000   \n",
       "max        17.008037          1.000000          1.000000          1.000000   \n",
       "\n",
       "       2011_swing_loss_big_x     ...       2016_gain_y  2016_yoy_pos_y  \\\n",
       "count            5129.000000     ...       5129.000000     5129.000000   \n",
       "mean                0.149152     ...          0.872685        0.551764   \n",
       "std                 0.356273     ...          0.333358        0.497362   \n",
       "min                 0.000000     ...          0.000000        0.000000   \n",
       "25%                 0.000000     ...          1.000000        0.000000   \n",
       "50%                 0.000000     ...          1.000000        1.000000   \n",
       "75%                 0.000000     ...          1.000000        1.000000   \n",
       "max                 1.000000     ...          1.000000        1.000000   \n",
       "\n",
       "       2016_yoy_big_y  2016_yoy_neg_y  2016_yoy_loss_big_y  2016_swing_pos_y  \\\n",
       "count     5129.000000     5129.000000          5129.000000       5129.000000   \n",
       "mean         0.156561        0.448236             0.049912          0.360889   \n",
       "std          0.363422        0.497362             0.217785          0.480305   \n",
       "min          0.000000        0.000000             0.000000          0.000000   \n",
       "25%          0.000000        0.000000             0.000000          0.000000   \n",
       "50%          0.000000        0.000000             0.000000          0.000000   \n",
       "75%          0.000000        1.000000             0.000000          1.000000   \n",
       "max          1.000000        1.000000             1.000000          1.000000   \n",
       "\n",
       "       2016_swing_big_y  2016_swing_neg_y  2016_swing_loss_big_y            y  \n",
       "count       5129.000000       5129.000000            5129.000000  5129.000000  \n",
       "mean           0.098265          0.639111               0.021252     1.067475  \n",
       "std            0.297701          0.480305               0.144236     0.072273  \n",
       "min            0.000000          0.000000               0.000000     0.791820  \n",
       "25%            0.000000          0.000000               0.000000     1.023399  \n",
       "50%            0.000000          1.000000               0.000000     1.061971  \n",
       "75%            0.000000          1.000000               0.000000     1.106317  \n",
       "max            1.000000          1.000000               1.000000     1.425089  \n",
       "\n",
       "[8 rows x 541 columns]"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df.dropna(inplace=True)\n",
    "X_16_df.isnull().sum().sum()\n",
    "X_16_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = X_2_df.iloc[:, :-1].values\n",
    "y_2 = X_2_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = X_16_df.iloc[:, :-1].values\n",
    "y_16 = X_16_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    97745.000000\n",
       "mean         1.091032\n",
       "std          0.069050\n",
       "min          0.884748\n",
       "25%          1.047925\n",
       "50%          1.073544\n",
       "75%          1.123171\n",
       "max          1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_df['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5129.000000\n",
       "mean        1.067475\n",
       "std         0.072273\n",
       "min         0.791820\n",
       "25%         1.023399\n",
       "50%         1.061971\n",
       "75%         1.106317\n",
       "max         1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.98408333e+01,   5.28288568e+00,   1.26100000e+01, ...,\n",
       "          4.44783710e-02,   1.11710935e+00,   1.00000000e+00],\n",
       "       [  8.59416667e+00,   2.68156148e+00,   4.90000000e+00, ...,\n",
       "          3.36152944e-02,   1.16117045e+00,   1.00000000e+00],\n",
       "       [  9.57916667e+00,   4.12912815e+00,   4.05000000e+00, ...,\n",
       "          2.08722085e-02,   1.76863352e+00,   1.00000000e+00],\n",
       "       ..., \n",
       "       [  3.84833333e+00,   7.56057457e+00,   3.00000000e-02, ...,\n",
       "         -1.84320184e-02,   2.15476923e+01,   1.00000000e+00],\n",
       "       [  7.37000000e+00,   8.97160267e+00,   1.15000000e+00, ...,\n",
       "          1.24468539e-02,   9.77659456e-01,   0.00000000e+00],\n",
       "       [  2.06333333e+00,   1.31138604e+00,   6.10000000e-01, ...,\n",
       "         -1.59529241e-02,   8.84642600e-01,   0.00000000e+00]])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_per_column(X):\n",
    "    new_array = []\n",
    "    shape = X.shape\n",
    "    columns = shape[1]\n",
    "    for num in range(columns):\n",
    "        mx = X[:, num].max()\n",
    "        if mx == 0:\n",
    "            new_array.append(X[:, num])\n",
    "        else:\n",
    "            X[:, num] = X[:, num] / mx\n",
    "            new_array.append(X[:, num])\n",
    "    new_array = np.array(new_array)\n",
    "    new_array = np.transpose(new_array)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = norm_per_column(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = norm_per_column(X_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5129, 540)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 541), dtype=float64)"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12984.457456492662"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16 = X_16 * 12900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = X_2 / 400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_16_df = X_16_df / 94650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size= .2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(X_16, y_16, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold overfit model for now\n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(540,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(540,), activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4103 samples, validate on 1026 samples\n",
      "Epoch 1/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.9291e-04 - val_loss: 0.3209\n",
      "Epoch 2/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.0620e-04 - val_loss: 0.3204\n",
      "Epoch 3/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.8823e-05 - val_loss: 0.3209\n",
      "Epoch 4/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.0509e-04 - val_loss: 0.3214\n",
      "Epoch 5/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.9939e-04 - val_loss: 0.3217\n",
      "Epoch 6/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.1241e-04 - val_loss: 0.3213\n",
      "Epoch 7/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.4091e-04 - val_loss: 0.3196\n",
      "Epoch 8/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 6.1681e-05 - val_loss: 0.3184\n",
      "Epoch 9/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.4459e-05 - val_loss: 0.3186\n",
      "Epoch 10/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.6849e-05 - val_loss: 0.3199\n",
      "Epoch 11/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.3029e-05 - val_loss: 0.3223\n",
      "Epoch 12/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.9986e-05 - val_loss: 0.3244\n",
      "Epoch 13/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.7444e-05 - val_loss: 0.3257\n",
      "Epoch 14/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 8.6525e-05 - val_loss: 0.3257\n",
      "Epoch 15/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.4758e-04 - val_loss: 0.3242\n",
      "Epoch 16/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.2184e-04 - val_loss: 0.3231\n",
      "Epoch 17/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.0027e-04 - val_loss: 0.3216\n",
      "Epoch 18/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.6929e-04 - val_loss: 0.3192\n",
      "Epoch 19/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.9284e-04 - val_loss: 0.3191\n",
      "Epoch 20/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.3177e-04 - val_loss: 0.3211\n",
      "Epoch 21/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.0668e-04 - val_loss: 0.3240\n",
      "Epoch 22/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 8.5931e-05 - val_loss: 0.3277\n",
      "Epoch 23/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.4960e-05 - val_loss: 0.3315\n",
      "Epoch 24/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.0127e-05 - val_loss: 0.3347\n",
      "Epoch 25/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 8.2880e-05 - val_loss: 0.3371\n",
      "Epoch 26/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.8338e-04 - val_loss: 0.3405\n",
      "Epoch 27/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.6377e-04 - val_loss: 0.3426\n",
      "Epoch 28/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 6.3083e-04 - val_loss: 0.3448\n",
      "Epoch 29/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 8.5701e-04 - val_loss: 0.3437\n",
      "Epoch 30/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 6.6732e-04 - val_loss: 0.3380\n",
      "Epoch 31/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.8535e-04 - val_loss: 0.3327\n",
      "Epoch 32/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 7.5508e-05 - val_loss: 0.3307\n",
      "Epoch 33/100\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 2.6369e-04 - val_loss: 0.3325\n",
      "Epoch 34/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.2573e-04 - val_loss: 0.3359\n",
      "Epoch 35/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.3890e-04 - val_loss: 0.3397\n",
      "Epoch 36/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.1182e-04 - val_loss: 0.3430\n",
      "Epoch 37/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.0603e-05 - val_loss: 0.3451\n",
      "Epoch 38/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.4720e-05 - val_loss: 0.3464\n",
      "Epoch 39/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.0812e-05 - val_loss: 0.3475\n",
      "Epoch 40/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.7035e-05 - val_loss: 0.3478\n",
      "Epoch 41/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.6391e-05 - val_loss: 0.3476\n",
      "Epoch 42/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.7083e-05 - val_loss: 0.3472\n",
      "Epoch 43/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.8130e-05 - val_loss: 0.3466\n",
      "Epoch 44/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.6012e-05 - val_loss: 0.3462\n",
      "Epoch 45/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.7203e-05 - val_loss: 0.3467\n",
      "Epoch 46/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 9.4670e-05 - val_loss: 0.3475\n",
      "Epoch 47/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.8606e-04 - val_loss: 0.3477\n",
      "Epoch 48/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.3652e-04 - val_loss: 0.3482\n",
      "Epoch 49/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 5.9426e-04 - val_loss: 0.3483\n",
      "Epoch 50/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 9.3332e-04 - val_loss: 0.3477\n",
      "Epoch 51/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 0.0011 - val_loss: 0.3469\n",
      "Epoch 52/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 7.1237e-04 - val_loss: 0.3430\n",
      "Epoch 53/100\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 1.3002e-04 - val_loss: 0.3385\n",
      "Epoch 54/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.2869e-04 - val_loss: 0.3365\n",
      "Epoch 55/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 6.4630e-04 - val_loss: 0.3363\n",
      "Epoch 56/100\n",
      "4103/4103 [==============================] - 6s 2ms/step - loss: 5.8329e-04 - val_loss: 0.3358\n",
      "Epoch 57/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.8280e-04 - val_loss: 0.3380\n",
      "Epoch 58/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.3131e-05 - val_loss: 0.3410\n",
      "Epoch 59/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.5855e-04 - val_loss: 0.3443\n",
      "Epoch 60/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.1865e-04 - val_loss: 0.3465\n",
      "Epoch 61/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.7217e-04 - val_loss: 0.3476\n",
      "Epoch 62/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 8.0961e-05 - val_loss: 0.3483\n",
      "Epoch 63/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.4079e-05 - val_loss: 0.3494\n",
      "Epoch 64/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.4060e-05 - val_loss: 0.3507\n",
      "Epoch 65/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.1515e-04 - val_loss: 0.3513\n",
      "Epoch 66/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.0658e-04 - val_loss: 0.3517\n",
      "Epoch 67/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.6804e-04 - val_loss: 0.3523\n",
      "Epoch 68/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.5906e-04 - val_loss: 0.3536\n",
      "Epoch 69/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.6596e-04 - val_loss: 0.3543\n",
      "Epoch 70/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 7.4021e-05 - val_loss: 0.3546\n",
      "Epoch 71/100\n",
      "4103/4103 [==============================] - 6s 2ms/step - loss: 2.3494e-05 - val_loss: 0.3550\n",
      "Epoch 72/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.2352e-05 - val_loss: 0.3552\n",
      "Epoch 73/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 5.5009e-05 - val_loss: 0.3562\n",
      "Epoch 74/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.0336e-04 - val_loss: 0.3590\n",
      "Epoch 75/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.6590e-04 - val_loss: 0.3623\n",
      "Epoch 76/100\n",
      "4103/4103 [==============================] - 6s 2ms/step - loss: 2.5234e-04 - val_loss: 0.3644\n",
      "Epoch 77/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.0981e-04 - val_loss: 0.3662\n",
      "Epoch 78/100\n",
      "4103/4103 [==============================] - 6s 2ms/step - loss: 2.8956e-04 - val_loss: 0.3686\n",
      "Epoch 79/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.9111e-04 - val_loss: 0.3690\n",
      "Epoch 80/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 7.3875e-05 - val_loss: 0.3678\n",
      "Epoch 81/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.8717e-05 - val_loss: 0.3662\n",
      "Epoch 82/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.6650e-05 - val_loss: 0.3640\n",
      "Epoch 83/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.4553e-04 - val_loss: 0.3609\n",
      "Epoch 84/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 3.1402e-04 - val_loss: 0.3572\n",
      "Epoch 85/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 5.8125e-04 - val_loss: 0.3557\n",
      "Epoch 86/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 9.1594e-04 - val_loss: 0.3524\n",
      "Epoch 87/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 9.8862e-04 - val_loss: 0.3528\n",
      "Epoch 88/100\n",
      "4103/4103 [==============================] - 6s 2ms/step - loss: 5.0113e-04 - val_loss: 0.3589\n",
      "Epoch 89/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 7.1710e-05 - val_loss: 0.3668\n",
      "Epoch 90/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.5044e-04 - val_loss: 0.3738\n",
      "Epoch 91/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 5.5719e-04 - val_loss: 0.3769\n",
      "Epoch 92/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 5.2064e-04 - val_loss: 0.3756\n",
      "Epoch 93/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.2225e-04 - val_loss: 0.3725\n",
      "Epoch 94/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 4.2055e-05 - val_loss: 0.3699\n",
      "Epoch 95/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 5.8075e-05 - val_loss: 0.3685\n",
      "Epoch 96/100\n",
      "4103/4103 [==============================] - 6s 2ms/step - loss: 1.4015e-04 - val_loss: 0.3673\n",
      "Epoch 97/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 2.0067e-04 - val_loss: 0.3678\n",
      "Epoch 98/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.9146e-04 - val_loss: 0.3692\n",
      "Epoch 99/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 1.4364e-04 - val_loss: 0.3716\n",
      "Epoch 100/100\n",
      "4103/4103 [==============================] - 6s 1ms/step - loss: 7.2094e-05 - val_loss: 0.3739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a258e10>"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_16, y=y_train_16, \n",
    "          batch_size=2500, \n",
    "          epochs=100, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_16, y_test_16),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss = .00001441 (overfit) = .0038\n",
    "\n",
    "#std = .072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding reviews. No overfit! \n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(541,), activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78196 samples, validate on 19549 samples\n",
      "Epoch 1/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 4.7343 - val_loss: 0.0027\n",
      "Epoch 2/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 0.0937 - val_loss: 0.0046\n",
      "Epoch 3/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 4/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 3.2574e-04 - val_loss: 0.0059\n",
      "Epoch 5/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 7.3467e-05 - val_loss: 0.0059\n",
      "Epoch 6/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 4.5027e-05 - val_loss: 0.0060\n",
      "Epoch 7/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 3.2798e-05 - val_loss: 0.0061\n",
      "Epoch 8/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.5425e-05 - val_loss: 0.0062\n",
      "Epoch 9/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.0523e-05 - val_loss: 0.0063\n",
      "Epoch 10/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.7073e-05 - val_loss: 0.0064\n",
      "Epoch 11/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 1.4884e-05 - val_loss: 0.0064\n",
      "Epoch 12/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 1.2662e-05 - val_loss: 0.0065\n",
      "Epoch 13/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 1.1025e-05 - val_loss: 0.0065\n",
      "Epoch 14/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 9.6451e-06 - val_loss: 0.0066\n",
      "Epoch 15/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 8.4698e-06 - val_loss: 0.0066\n",
      "Epoch 16/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 7.5258e-06 - val_loss: 0.0066\n",
      "Epoch 17/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 6.6461e-06 - val_loss: 0.0067\n",
      "Epoch 18/1000\n",
      "78196/78196 [==============================] - 10895s 139ms/step - loss: 5.9375e-06 - val_loss: 0.0068\n",
      "Epoch 19/1000\n",
      "78196/78196 [==============================] - 7298s 93ms/step - loss: 5.2844e-06 - val_loss: 0.0068\n",
      "Epoch 20/1000\n",
      "78196/78196 [==============================] - 1125s 14ms/step - loss: 4.7737e-06 - val_loss: 0.0068\n",
      "Epoch 21/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 4.2512e-06 - val_loss: 0.0069\n",
      "Epoch 22/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 3.8335e-06 - val_loss: 0.0069\n",
      "Epoch 23/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 3.5044e-06 - val_loss: 0.0069\n",
      "Epoch 24/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 3.1160e-06 - val_loss: 0.0069\n",
      "Epoch 25/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.8295e-06 - val_loss: 0.0069\n",
      "Epoch 26/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.5962e-06 - val_loss: 0.0070\n",
      "Epoch 27/1000\n",
      "78196/78196 [==============================] - 112s 1ms/step - loss: 2.4202e-06 - val_loss: 0.0070\n",
      "Epoch 28/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.1700e-06 - val_loss: 0.0070\n",
      "Epoch 29/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.0196e-06 - val_loss: 0.0071\n",
      "Epoch 30/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.8961e-06 - val_loss: 0.0071\n",
      "Epoch 31/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.7118e-06 - val_loss: 0.0071\n",
      "Epoch 32/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.7906e-06 - val_loss: 0.0071\n",
      "Epoch 33/1000\n",
      "78196/78196 [==============================] - 112s 1ms/step - loss: 1.5684e-06 - val_loss: 0.0071\n",
      "Epoch 34/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.4365e-06 - val_loss: 0.0071\n",
      "Epoch 35/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.3009e-06 - val_loss: 0.0072\n",
      "Epoch 36/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.2430e-06 - val_loss: 0.0072\n",
      "Epoch 37/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.1966e-06 - val_loss: 0.0071\n",
      "Epoch 38/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.1307e-06 - val_loss: 0.0072\n",
      "Epoch 39/1000\n",
      "78196/78196 [==============================] - 125s 2ms/step - loss: 1.0713e-06 - val_loss: 0.0073\n",
      "Epoch 40/1000\n",
      "78196/78196 [==============================] - 114s 1ms/step - loss: 1.4843e-06 - val_loss: 0.0072\n",
      "Epoch 41/1000\n",
      "78196/78196 [==============================] - 121s 2ms/step - loss: 1.0901e-06 - val_loss: 0.0072\n",
      "Epoch 42/1000\n",
      "78196/78196 [==============================] - 128s 2ms/step - loss: 1.0082e-06 - val_loss: 0.0073\n",
      "Epoch 43/1000\n",
      "78196/78196 [==============================] - 123s 2ms/step - loss: 1.0009e-06 - val_loss: 0.0073\n",
      "Epoch 44/1000\n",
      "78196/78196 [==============================] - 116s 1ms/step - loss: 1.8567e-06 - val_loss: 0.0073\n",
      "Epoch 45/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 5.0224e-06 - val_loss: 0.0073\n",
      "Epoch 46/1000\n",
      "78196/78196 [==============================] - 7299s 93ms/step - loss: 9.5015e-07 - val_loss: 0.0074\n",
      "Epoch 47/1000\n",
      "78196/78196 [==============================] - 7298s 93ms/step - loss: 1.0685e-06 - val_loss: 0.0074\n",
      "Epoch 48/1000\n",
      "78196/78196 [==============================] - 3707s 47ms/step - loss: 1.0764e-05 - val_loss: 0.0075\n",
      "Epoch 49/1000\n",
      "78196/78196 [==============================] - 7301s 93ms/step - loss: 5.1339e-06 - val_loss: 0.0075\n",
      "Epoch 50/1000\n",
      "78196/78196 [==============================] - 7298s 93ms/step - loss: 1.1024e-06 - val_loss: 0.0074\n",
      "Epoch 51/1000\n",
      "78196/78196 [==============================] - 7298s 93ms/step - loss: 5.9525e-07 - val_loss: 0.0074\n",
      "Epoch 52/1000\n",
      "78196/78196 [==============================] - 7298s 93ms/step - loss: 5.8703e-07 - val_loss: 0.0074\n",
      "Epoch 53/1000\n",
      "78196/78196 [==============================] - 3413s 44ms/step - loss: 8.2009e-07 - val_loss: 0.0073\n",
      "Epoch 54/1000\n",
      "78196/78196 [==============================] - 112s 1ms/step - loss: 1.2467e-05 - val_loss: 0.0072\n",
      "Epoch 55/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.2361e-06 - val_loss: 0.0076\n",
      "Epoch 56/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.7377e-06 - val_loss: 0.0075\n",
      "Epoch 57/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.8206e-05 - val_loss: 0.0076\n",
      "Epoch 58/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 4.3757e-06 - val_loss: 0.0072\n",
      "Epoch 59/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 1.0779e-06 - val_loss: 0.0073\n",
      "Epoch 60/1000\n",
      "78196/78196 [==============================] - 111s 1ms/step - loss: 6.7133e-07 - val_loss: 0.0073\n",
      "Epoch 61/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 5.7408e-07 - val_loss: 0.0074\n",
      "Epoch 62/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 4.1388e-05 - val_loss: 0.0073\n",
      "Epoch 63/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 2.0241e-05 - val_loss: 0.0070\n",
      "Epoch 64/1000\n",
      "78196/78196 [==============================] - 111s 1ms/step - loss: 1.5835e-06 - val_loss: 0.0072\n",
      "Epoch 65/1000\n",
      "78196/78196 [==============================] - 109s 1ms/step - loss: 6.8067e-07 - val_loss: 0.0074\n",
      "Epoch 66/1000\n",
      "78196/78196 [==============================] - 110s 1ms/step - loss: 3.9125e-06 - val_loss: 0.0080\n",
      "Epoch 67/1000\n",
      "78196/78196 [==============================] - 116s 1ms/step - loss: 6.4615e-05 - val_loss: 0.0074\n",
      "Epoch 68/1000\n",
      "78196/78196 [==============================] - 111s 1ms/step - loss: 5.9912e-06 - val_loss: 0.0076\n",
      "Epoch 69/1000\n",
      "78196/78196 [==============================] - 200s 3ms/step - loss: 1.7642e-06 - val_loss: 0.0074\n",
      "Epoch 70/1000\n",
      "78196/78196 [==============================] - 202s 3ms/step - loss: 6.6541e-05 - val_loss: 0.0099\n",
      "Epoch 71/1000\n",
      "78196/78196 [==============================] - 195s 2ms/step - loss: 5.9380e-05 - val_loss: 0.0075\n",
      "Epoch 72/1000\n",
      "78196/78196 [==============================] - 192s 2ms/step - loss: 2.3167e-06 - val_loss: 0.0074\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78196/78196 [==============================] - 198s 3ms/step - loss: 8.0601e-07 - val_loss: 0.0074\n",
      "Epoch 74/1000\n",
      "78196/78196 [==============================] - 188s 2ms/step - loss: 4.5826e-07 - val_loss: 0.0073\n",
      "Epoch 75/1000\n",
      "78196/78196 [==============================] - 191s 2ms/step - loss: 1.0517e-04 - val_loss: 0.0065\n",
      "Epoch 76/1000\n",
      "78196/78196 [==============================] - 196s 3ms/step - loss: 3.7467e-05 - val_loss: 0.0073\n",
      "Epoch 77/1000\n",
      "78196/78196 [==============================] - 188s 2ms/step - loss: 2.5486e-06 - val_loss: 0.0073\n",
      "Epoch 78/1000\n",
      "67500/78196 [========================>.....] - ETA: 26s - loss: 4.9238e-07"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-980-85741cd0d845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=None)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_2, y=y_train_2, \n",
    "          batch_size=2500, \n",
    "          epochs=1000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_2, y_test_2),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Val_loss = .00000306\n",
    "# loss = .000000415\n",
    "# STD = .069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(90,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5336 samples, validate on 1334 samples\n",
      "Epoch 1/2000\n",
      "5336/5336 [==============================] - 5s 906us/step - loss: 1.0742 - val_loss: 0.8664\n",
      "Epoch 2/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.8218 - val_loss: 0.6511\n",
      "Epoch 3/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.6200 - val_loss: 0.4853\n",
      "Epoch 4/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.4641 - val_loss: 0.3586\n",
      "Epoch 5/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.3450 - val_loss: 0.2620\n",
      "Epoch 6/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.2540 - val_loss: 0.1897\n",
      "Epoch 7/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.1856 - val_loss: 0.1357\n",
      "Epoch 8/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.1340 - val_loss: 0.0961\n",
      "Epoch 9/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0967 - val_loss: 0.0677\n",
      "Epoch 10/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0694 - val_loss: 0.0474\n",
      "Epoch 11/2000\n",
      "5336/5336 [==============================] - 3s 603us/step - loss: 0.0498 - val_loss: 0.0334\n",
      "Epoch 12/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0362 - val_loss: 0.0237\n",
      "Epoch 13/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0265 - val_loss: 0.0170\n",
      "Epoch 14/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0198 - val_loss: 0.0126\n",
      "Epoch 15/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 16/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 17/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 18/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 19/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 20/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 21/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 22/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 23/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 24/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 25/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 26/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 27/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 28/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 29/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 30/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 31/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 32/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 33/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 34/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 35/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 36/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 37/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 38/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 39/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 40/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 41/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 42/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 43/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 44/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 45/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 46/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 47/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 48/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 49/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 50/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 51/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 52/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 53/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 54/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 55/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 56/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 57/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 58/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 59/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 60/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 61/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 62/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 63/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 64/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 65/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 66/2000\n",
      "5336/5336 [==============================] - 3s 512us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 67/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 68/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 69/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 70/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 71/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 72/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 73/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 74/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 75/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 76/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 77/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 78/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 79/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 80/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 81/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 82/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 83/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 84/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 85/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 86/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 87/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 88/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 89/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 90/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 91/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 92/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 93/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 94/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 95/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 96/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 97/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 98/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 99/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 100/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 101/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 102/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 103/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 105/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 106/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 107/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 108/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 109/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 110/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 111/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 112/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 113/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 114/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 115/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 116/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 117/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 118/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 119/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 120/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 121/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 122/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 124/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 125/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 126/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 127/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 128/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 129/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 130/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 131/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 132/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 133/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 134/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 135/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 136/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 137/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 138/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 139/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 140/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 141/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 142/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 143/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 144/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 145/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 146/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 147/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 148/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 149/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 150/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 151/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 152/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 154/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 155/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 156/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 157/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 158/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 159/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 160/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 161/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 162/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 163/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 164/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 165/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 166/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 167/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 168/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 169/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 170/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 171/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 172/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 173/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 174/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 175/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 176/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 177/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 178/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 179/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 180/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 181/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 182/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 184/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 185/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 186/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 187/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 188/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 189/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 190/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 191/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 192/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 193/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 194/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 195/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 196/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 197/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 198/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 199/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 200/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 201/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 202/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 203/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 204/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 205/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 206/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 207/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 208/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 209/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 210/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 211/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 213/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 214/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 215/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 216/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 217/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 218/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 219/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 220/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 221/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 222/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 223/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 224/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 225/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 226/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 227/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 228/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 230/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 231/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 232/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 233/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 234/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 235/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 236/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 237/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 238/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 239/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 240/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 241/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 242/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 243/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 244/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 245/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 246/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 247/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 249/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 250/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 251/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 252/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 253/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 254/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 255/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 256/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 258/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 259/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 260/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 261/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 262/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 263/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 264/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 265/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 266/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 267/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 268/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 269/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 270/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 271/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 272/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 273/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 274/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 275/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 276/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 277/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 278/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 279/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 280/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 281/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 282/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 283/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 284/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 285/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 286/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 287/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 288/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 289/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 290/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 291/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 292/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 293/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 294/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 295/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 296/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 297/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 298/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 299/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 300/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 301/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 302/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 303/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 304/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 306/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 307/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 308/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 309/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 310/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 311/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 312/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 313/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 314/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 315/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 316/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 317/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 318/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 319/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 320/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 321/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 322/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 323/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 324/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 325/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 326/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 327/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 328/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 329/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 330/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 331/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 332/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 333/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 334/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 335/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 336/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 337/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 338/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 339/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 340/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 341/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 342/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 343/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 344/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 345/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 346/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 347/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 348/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 349/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 350/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 351/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 352/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 353/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 354/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 355/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 356/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 357/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 358/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 359/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 360/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 361/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 362/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 363/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 364/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 365/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 366/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 367/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 368/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 369/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 370/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 371/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 372/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 373/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 374/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 375/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 376/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 377/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 378/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 379/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 380/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 382/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 383/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 384/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 385/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 386/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 387/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 388/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 389/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 390/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 391/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 392/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 393/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 394/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 395/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 396/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 397/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 398/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 399/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 400/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 401/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 402/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 403/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 404/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 405/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 406/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 407/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 408/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 409/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 410/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 411/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 412/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 413/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 414/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 415/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 416/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 417/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 418/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 419/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 420/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 421/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 422/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 423/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 424/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 425/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 427/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 428/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 429/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 430/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 431/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 432/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 433/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 434/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 435/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 436/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 437/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 438/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 439/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 440/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 441/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 442/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 443/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 444/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 445/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 446/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 448/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 449/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 450/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 451/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 452/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 453/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 454/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 455/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 456/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 458/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 459/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 460/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 461/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 462/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 463/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 464/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 465/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 466/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 467/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 468/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 469/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 470/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 471/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 473/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 474/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 475/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 477/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 478/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 479/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 480/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 481/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 482/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 483/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 485/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 486/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 487/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 488/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 489/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 490/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 491/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 492/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 494/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 495/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 496/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 497/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 498/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 499/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 500/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 501/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 502/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 503/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 504/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 505/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 506/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 507/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 508/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 509/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 510/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 511/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 512/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 513/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 514/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 515/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 516/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 517/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 518/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 519/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 520/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 521/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 522/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 523/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 524/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 525/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 526/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 527/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 528/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 529/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 530/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 531/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 532/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 534/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 535/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 536/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 537/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 538/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 539/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 540/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 541/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 542/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 543/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 544/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 545/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 546/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 547/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 548/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 549/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 550/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 551/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 552/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 553/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 554/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 555/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 556/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 557/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 558/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 559/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 560/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 561/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 562/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 563/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 564/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 565/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 566/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 567/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 568/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 569/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 570/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 571/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 572/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 573/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 574/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 576/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 577/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 578/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 579/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 580/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 581/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 582/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 583/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 584/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 585/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 586/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 587/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 588/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 589/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 590/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 591/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 592/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 593/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 594/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 595/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 596/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 597/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 598/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 599/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 600/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 601/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 602/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 603/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 604/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 605/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 606/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 607/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 608/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/2000\n",
      "5336/5336 [==============================] - 3s 517us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 610/2000\n",
      "5336/5336 [==============================] - 3s 592us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 611/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 612/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 613/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 614/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 615/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 616/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 617/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 618/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 619/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 620/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 621/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 622/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 623/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 624/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 625/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 626/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 627/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 628/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 629/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 630/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 631/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 632/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 633/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 634/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 635/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 636/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 637/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 638/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 639/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 640/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 641/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 642/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 643/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 644/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 645/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 646/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 647/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 648/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 649/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 650/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 651/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 652/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 653/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 654/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 655/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 656/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 657/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 658/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 659/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 660/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 661/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 662/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 663/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 664/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 665/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 666/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 667/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 668/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 669/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 670/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 671/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 672/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 673/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 674/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 675/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 676/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 677/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 678/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 679/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 680/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 681/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 682/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 683/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 684/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 686/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 687/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 688/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 689/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 690/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 691/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 692/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 693/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 694/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 695/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 696/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 697/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 698/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 699/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 700/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 701/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 702/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 703/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 704/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 705/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 706/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 707/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 708/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 709/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 710/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 711/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 712/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 713/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 714/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 715/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 716/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 717/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 718/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 719/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 720/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 721/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 722/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 723/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 724/2000\n",
      "5336/5336 [==============================] - 3034s 569ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 725/2000\n",
      "5336/5336 [==============================] - 3s 653us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 726/2000\n",
      "5336/5336 [==============================] - 4s 680us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 727/2000\n",
      "5336/5336 [==============================] - 4s 767us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 728/2000\n",
      "5336/5336 [==============================] - 5s 891us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 729/2000\n",
      "5336/5336 [==============================] - 5s 930us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 730/2000\n",
      "5336/5336 [==============================] - 4s 750us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 731/2000\n",
      "5336/5336 [==============================] - 5s 853us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 732/2000\n",
      "5336/5336 [==============================] - 5s 959us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 733/2000\n",
      "5336/5336 [==============================] - 5s 951us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 734/2000\n",
      "5336/5336 [==============================] - 4s 704us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 735/2000\n",
      "5336/5336 [==============================] - 5s 859us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 736/2000\n",
      "5336/5336 [==============================] - 4s 835us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 737/2000\n",
      "5336/5336 [==============================] - 5s 989us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 738/2000\n",
      "5336/5336 [==============================] - 5s 950us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 739/2000\n",
      "5336/5336 [==============================] - 3s 561us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 740/2000\n",
      "5336/5336 [==============================] - 3s 540us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 741/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 742/2000\n",
      "5336/5336 [==============================] - 3s 569us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 743/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 744/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 745/2000\n",
      "5336/5336 [==============================] - 3s 628us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 746/2000\n",
      "5336/5336 [==============================] - 3s 577us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 747/2000\n",
      "5336/5336 [==============================] - 3s 566us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 748/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 749/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 750/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 751/2000\n",
      "5336/5336 [==============================] - 3s 635us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 752/2000\n",
      "5336/5336 [==============================] - 3s 546us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 753/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 754/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 755/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 756/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 757/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 758/2000\n",
      "5336/5336 [==============================] - 3s 537us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 759/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 760/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 762/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 763/2000\n",
      "5336/5336 [==============================] - 3s 553us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 764/2000\n",
      "5336/5336 [==============================] - 3s 557us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 765/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 766/2000\n",
      "5336/5336 [==============================] - 3s 523us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 767/2000\n",
      "5336/5336 [==============================] - 3s 528us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 768/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 769/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 770/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 771/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 772/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 773/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 774/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 775/2000\n",
      "5336/5336 [==============================] - 3s 515us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 776/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 777/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 778/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 779/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 780/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 781/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 782/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 783/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 784/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 785/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 787/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 788/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 789/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 790/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 791/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 792/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 793/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 794/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 795/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 796/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 797/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 798/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 799/2000\n",
      "5336/5336 [==============================] - 3s 519us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 800/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 801/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 802/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 804/2000\n",
      "5336/5336 [==============================] - 3s 529us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 805/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 806/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 807/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 808/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 809/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 810/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 811/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 812/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 813/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 814/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 815/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 816/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 817/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 818/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 819/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 820/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 821/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 822/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 823/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 824/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 825/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 826/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 827/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 828/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 829/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 830/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 831/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 832/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 833/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 834/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 835/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 836/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 838/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 839/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 840/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 841/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 842/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 843/2000\n",
      "5336/5336 [==============================] - 3s 520us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 844/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 845/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 846/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 847/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 848/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 849/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 850/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 851/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 852/2000\n",
      "5336/5336 [==============================] - 3s 524us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 853/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 854/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 855/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 856/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 857/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 858/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 859/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 860/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 861/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 862/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 863/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 864/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 865/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 866/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 867/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 868/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 869/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 870/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 871/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 872/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 873/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 874/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 875/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 876/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 877/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 878/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 879/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 880/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 881/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 882/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 883/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 884/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 885/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 886/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 887/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 888/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 889/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 890/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 891/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 892/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 893/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 894/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 895/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 896/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 897/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 898/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 899/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 900/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 901/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 902/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 903/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 904/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 905/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 906/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 907/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 908/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 909/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 910/2000\n",
      "5336/5336 [==============================] - 3s 510us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 911/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 912/2000\n",
      "5336/5336 [==============================] - 3s 517us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 914/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 915/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 916/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 917/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 918/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 919/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 920/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 921/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 922/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 923/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 925/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 926/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 927/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 928/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 929/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 930/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 931/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 932/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 933/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 934/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 935/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 936/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 937/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 938/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 939/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 940/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 941/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 942/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 943/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 944/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 945/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 946/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 947/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 948/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 949/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 950/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 951/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 952/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 953/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 954/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 955/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 956/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 957/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 958/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 959/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 960/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 961/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 962/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 963/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 964/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 965/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 966/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 967/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 968/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 969/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 970/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 971/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 972/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 973/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 974/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 975/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 976/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 977/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 978/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 979/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 980/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 981/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 982/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 983/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 984/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 985/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 986/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 987/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 988/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 990/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 991/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 992/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 993/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 994/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 995/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 996/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 997/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 998/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 999/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1000/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1001/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1002/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1003/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1004/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1005/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1006/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1007/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1008/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1009/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1010/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1011/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1012/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1013/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1014/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1015/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1016/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1017/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1018/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1019/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1020/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1021/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1022/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1023/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1024/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1025/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1026/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 1027/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1028/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1029/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1030/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1031/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1032/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1033/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1034/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1035/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1036/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1037/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1038/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1039/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1040/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1041/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1042/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1043/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1044/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1045/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1046/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1047/2000\n",
      "5336/5336 [==============================] - 3s 506us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1048/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1049/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1050/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1051/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1052/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1053/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1054/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1055/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1056/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1057/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1058/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1059/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1060/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1061/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1062/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1063/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1064/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1065/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1066/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1067/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1068/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1069/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1070/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1071/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1072/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1073/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1074/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1075/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1076/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1077/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1078/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1079/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1080/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1081/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1082/2000\n",
      "5336/5336 [==============================] - 3s 507us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1083/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1084/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1085/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1086/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1087/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1088/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1089/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1090/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1091/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1092/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1093/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1094/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1095/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1096/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1097/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1098/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1099/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1100/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1101/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1102/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1103/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1104/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1105/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1106/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1107/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1108/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1109/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1110/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1111/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1112/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1113/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1114/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1115/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1116/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1117/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1118/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1119/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1120/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1121/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1122/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1123/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1124/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1125/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1126/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1127/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1128/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1129/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1130/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1131/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1132/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1133/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1134/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1135/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1136/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1137/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1138/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1139/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1140/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1141/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1142/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1143/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1144/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1145/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1146/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1147/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1148/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1149/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1150/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1151/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1152/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1153/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1154/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1155/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1156/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1157/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1158/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1159/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1160/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1161/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1162/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1163/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1164/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1165/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1166/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1167/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1168/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1169/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1170/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1171/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1172/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1173/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1174/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1175/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1176/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1177/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1178/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1179/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1180/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1181/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1182/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1183/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1184/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1185/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1186/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1187/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1188/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1189/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1190/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1191/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1192/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1193/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1194/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1195/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1196/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1197/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1198/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1199/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1200/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1201/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1202/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1203/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1204/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1205/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1206/2000\n",
      "5336/5336 [==============================] - 3s 568us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1207/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1208/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1209/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1210/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1211/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1212/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1213/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1214/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1215/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1216/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1217/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1218/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1219/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1220/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1221/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1222/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1223/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1224/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1225/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1226/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1227/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1228/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1229/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1230/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1231/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1232/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1233/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1234/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1235/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1236/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1237/2000\n",
      "5336/5336 [==============================] - 3s 522us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1238/2000\n",
      "5336/5336 [==============================] - 3s 575us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1239/2000\n",
      "5336/5336 [==============================] - 3s 618us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1240/2000\n",
      "5336/5336 [==============================] - 3s 621us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1241/2000\n",
      "5336/5336 [==============================] - 3s 616us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1242/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1243/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1244/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1245/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1246/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1247/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1248/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1249/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1250/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1251/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1252/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1253/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1254/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1255/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1256/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1257/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1258/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1259/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1260/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1261/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1262/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1263/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1264/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1265/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1266/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1267/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1268/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1269/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1270/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1271/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1272/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1273/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1274/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1275/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1276/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1277/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1278/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1279/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1280/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1281/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1282/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1283/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1284/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1285/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1286/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1287/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1288/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1290/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1291/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1292/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1293/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1294/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1295/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1296/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1297/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1298/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1299/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1300/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1301/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1302/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1303/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1304/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1305/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1306/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1307/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1308/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1309/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1310/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1311/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1312/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1313/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1314/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1315/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1316/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1317/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1318/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1319/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1320/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1321/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1322/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1323/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1324/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1325/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1326/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1327/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1328/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1329/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1330/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1331/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1332/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1333/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1334/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1335/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1336/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1337/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1338/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1339/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1340/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1341/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1342/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1343/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1344/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1345/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1346/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1347/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1348/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1349/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1350/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1351/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1352/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1353/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1354/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1355/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1356/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1357/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1358/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1359/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1360/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1361/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1362/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1363/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 1364/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1365/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1366/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1367/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1368/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1369/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1370/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1371/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1372/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1373/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1374/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1375/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1376/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1377/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1378/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1379/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1380/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1381/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1382/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1383/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1384/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1385/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1386/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1387/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1388/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1389/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1390/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1391/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1392/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1393/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1394/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1395/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1396/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1397/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1398/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1399/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1400/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1401/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1402/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1403/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1404/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1405/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1406/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1407/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1408/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1409/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1410/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1411/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1412/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1413/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1414/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1415/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1416/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1417/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1418/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1419/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1420/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1421/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1422/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1423/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1424/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1425/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1426/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1427/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1428/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1429/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1430/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1431/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1432/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1433/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1434/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1435/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1436/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1437/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1438/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1439/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1440/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1441/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1442/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1443/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1444/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1445/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1446/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1447/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1448/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1449/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1450/2000\n",
      "5336/5336 [==============================] - 3s 505us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1451/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1452/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1453/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1454/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1455/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1456/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1457/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1458/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1459/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1460/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1461/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1462/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1463/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1464/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1465/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1466/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1467/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1468/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1469/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1470/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1471/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1472/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1473/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1474/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1475/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1476/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1477/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1478/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1479/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1480/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1481/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1482/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1483/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1484/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1485/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1486/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1487/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1488/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1489/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1490/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1491/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1492/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1493/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1494/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1495/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1496/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1497/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1498/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1499/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1500/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1501/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1502/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1503/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1504/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1505/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1506/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1507/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1508/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1509/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1510/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1511/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1512/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1513/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1514/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1515/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1516/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1517/2000\n",
      "5336/5336 [==============================] - 3s 480us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1518/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1519/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1520/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1521/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1522/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1523/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1524/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1525/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1526/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1527/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1528/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1529/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1530/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1531/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1532/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1533/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1534/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1535/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1536/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1537/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1538/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1539/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1540/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1541/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1542/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1543/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1544/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1545/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1546/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1547/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1548/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1549/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1550/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1551/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1552/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1553/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1554/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1555/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1556/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1557/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1558/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1559/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1560/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1561/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1562/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1563/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1564/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1565/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1566/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1567/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1568/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1569/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1570/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1571/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1572/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1573/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1574/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1575/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1576/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1577/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1578/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1579/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1580/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1581/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1582/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1583/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1584/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1585/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1586/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1587/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1588/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1590/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1591/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1592/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1593/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1594/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1595/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1596/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1597/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1598/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1599/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1600/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1601/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1602/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1603/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1604/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1605/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1606/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1607/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1608/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1609/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1610/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1611/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1612/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1613/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1614/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1615/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1616/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1617/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1618/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1619/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1620/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1621/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1622/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1623/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1624/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1625/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1626/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1627/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1628/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1629/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1630/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1631/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1632/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1633/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1634/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1635/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1636/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1637/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1638/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1639/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1640/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1641/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1642/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1643/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1644/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1645/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1646/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1647/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1648/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1649/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1650/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1651/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1652/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1653/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1654/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1655/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1656/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1657/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1658/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1659/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1660/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1661/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1662/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1663/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1664/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1665/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1666/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1667/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1668/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1669/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1670/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1671/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1672/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1673/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1674/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1675/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1676/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1677/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1678/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1679/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1680/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1681/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1682/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1683/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1684/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1685/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1686/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1687/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1688/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1689/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1690/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1691/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1692/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1693/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1694/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1695/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1696/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1697/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1698/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1699/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1700/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1701/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1702/2000\n",
      "5336/5336 [==============================] - 3s 526us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1703/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1704/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1705/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1706/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1707/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1708/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1709/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1710/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1711/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1712/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1713/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1714/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1715/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1716/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1717/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1718/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1719/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1720/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1721/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1722/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1723/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1724/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1725/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1726/2000\n",
      "5336/5336 [==============================] - 3s 504us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1727/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1728/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1729/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1730/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1731/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1732/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1733/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1734/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1735/2000\n",
      "5336/5336 [==============================] - 3s 502us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1736/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1737/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1738/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1740/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1741/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1742/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1743/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1744/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1745/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1746/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1747/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1748/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1749/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1750/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1751/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1752/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1753/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1754/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1755/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1756/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1757/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1758/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1759/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1760/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1761/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1762/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1763/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1764/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1765/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1766/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1767/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1768/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1769/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1770/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1771/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1772/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1773/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1774/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1775/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1776/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1777/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1778/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1779/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1780/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1781/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1782/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1783/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1784/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1785/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1786/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1787/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1788/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1789/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1790/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1791/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1792/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1793/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1794/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1795/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1796/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1797/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1798/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1799/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1800/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1801/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1802/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1803/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1804/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1805/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1806/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1807/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1808/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1809/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1810/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1811/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1812/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1813/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1814/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1815/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1816/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1817/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1818/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1819/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1820/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1821/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1822/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1823/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1824/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1825/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1826/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1827/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1828/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1829/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1830/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1831/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1832/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1833/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1834/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1835/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1836/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1837/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1838/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1839/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1840/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1841/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1842/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1843/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1844/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1845/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1846/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1847/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1848/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1849/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1850/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1851/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1852/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1853/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1854/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1855/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1856/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1857/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1858/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1859/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1860/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1861/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1862/2000\n",
      "5336/5336 [==============================] - 3s 499us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1863/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1864/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1865/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1866/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1867/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1868/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1869/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1870/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1871/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1872/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1873/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1874/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1875/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1876/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1877/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1878/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1879/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1880/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1881/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1882/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1883/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1884/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1885/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1886/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1887/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1888/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1889/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1890/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1891/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1892/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1893/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1894/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1895/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1896/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1897/2000\n",
      "5336/5336 [==============================] - 3s 501us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1898/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1899/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1900/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1901/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1902/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1903/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1904/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1905/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1906/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1907/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1908/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1909/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1910/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1911/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1912/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1913/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1914/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1915/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1916/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1917/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1918/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1919/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1920/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1921/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1922/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1923/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1924/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1925/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1926/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1927/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1928/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1929/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1930/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1931/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1932/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1933/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1934/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1935/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1936/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1937/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1938/2000\n",
      "5336/5336 [==============================] - 3s 503us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1939/2000\n",
      "5336/5336 [==============================] - 3s 509us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1940/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1941/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1942/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1943/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1944/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1945/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1946/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1947/2000\n",
      "5336/5336 [==============================] - 3597s 674ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1948/2000\n",
      "5336/5336 [==============================] - 3s 511us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1949/2000\n",
      "5336/5336 [==============================] - 3s 498us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1950/2000\n",
      "5336/5336 [==============================] - 3s 536us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1951/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1952/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1953/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1954/2000\n",
      "5336/5336 [==============================] - 3s 491us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1955/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1956/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1957/2000\n",
      "5336/5336 [==============================] - 3s 513us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1958/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1959/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1960/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1961/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1962/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1963/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1964/2000\n",
      "5336/5336 [==============================] - 3s 489us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1965/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1966/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1967/2000\n",
      "5336/5336 [==============================] - 3598s 674ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1968/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1969/2000\n",
      "5336/5336 [==============================] - 3s 518us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1970/2000\n",
      "5336/5336 [==============================] - 3s 516us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1971/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1972/2000\n",
      "5336/5336 [==============================] - 3s 493us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1973/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1974/2000\n",
      "5336/5336 [==============================] - 3s 514us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1975/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1976/2000\n",
      "5336/5336 [==============================] - 3s 482us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1977/2000\n",
      "5336/5336 [==============================] - 3s 485us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1978/2000\n",
      "5336/5336 [==============================] - 3s 497us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1979/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 1980/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1981/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1982/2000\n",
      "5336/5336 [==============================] - 3s 496us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1983/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1984/2000\n",
      "5336/5336 [==============================] - 3s 492us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1985/2000\n",
      "5336/5336 [==============================] - 3s 487us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 1986/2000\n",
      "5336/5336 [==============================] - 2135s 400ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1987/2000\n",
      "5336/5336 [==============================] - 3s 490us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1988/2000\n",
      "5336/5336 [==============================] - 3s 500us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1989/2000\n",
      "5336/5336 [==============================] - 3s 527us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1990/2000\n",
      "5336/5336 [==============================] - 3s 488us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1991/2000\n",
      "5336/5336 [==============================] - 3s 486us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1992/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1993/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1994/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1995/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1996/2000\n",
      "5336/5336 [==============================] - 3s 484us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 1997/2000\n",
      "5336/5336 [==============================] - 3s 494us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1998/2000\n",
      "5336/5336 [==============================] - 3s 495us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 1999/2000\n",
      "5336/5336 [==============================] - 3s 483us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 2000/2000\n",
      "5336/5336 [==============================] - 3s 481us/step - loss: 0.0055 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15455b550>"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_s, y=y_train_s, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_s, y_test_s),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split(X_16, y_16, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size= .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.05329405,  1.12662344,  1.08065202, ...,  0.99302723,\n",
       "        1.0074516 ,  1.07181999])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2498697469914781"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_16.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07416198487095663"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0055 ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(690,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .02\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(1350,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "# Added\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .005\n",
    "sgd = keras.optimizers.SGD(lr=0.005)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New datasets\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(875,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "# Added\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# best lr .005\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 662 samples, validate on 166 samples\n",
      "Epoch 1/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0591\n",
      "Epoch 2/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0606\n",
      "Epoch 3/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0574\n",
      "Epoch 4/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0169 - val_loss: 0.0568\n",
      "Epoch 5/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0587\n",
      "Epoch 6/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0616\n",
      "Epoch 7/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0591\n",
      "Epoch 8/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0579\n",
      "Epoch 9/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0570\n",
      "Epoch 10/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0169 - val_loss: 0.0551\n",
      "Epoch 11/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0149 - val_loss: 0.0557\n",
      "Epoch 12/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0567\n",
      "Epoch 13/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0151 - val_loss: 0.0578\n",
      "Epoch 14/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0564\n",
      "Epoch 15/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0170 - val_loss: 0.0579\n",
      "Epoch 16/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0152 - val_loss: 0.0567\n",
      "Epoch 17/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0163 - val_loss: 0.0561\n",
      "Epoch 18/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0163 - val_loss: 0.0550\n",
      "Epoch 19/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0155 - val_loss: 0.0553\n",
      "Epoch 20/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0153 - val_loss: 0.0565\n",
      "Epoch 21/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0146 - val_loss: 0.0545\n",
      "Epoch 22/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0534\n",
      "Epoch 23/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0563\n",
      "Epoch 24/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0584\n",
      "Epoch 25/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0166 - val_loss: 0.0552\n",
      "Epoch 26/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0152 - val_loss: 0.0568\n",
      "Epoch 27/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0163 - val_loss: 0.0544\n",
      "Epoch 28/30\n",
      "662/662 [==============================] - 1s 2ms/step - loss: 0.0147 - val_loss: 0.0531\n",
      "Epoch 29/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0154 - val_loss: 0.0530\n",
      "Epoch 30/30\n",
      "662/662 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1661f8f98>"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_16, y=y_train_16, \n",
    "          batch_size=300, \n",
    "          epochs=30, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_16, y_test_16),\n",
    "          callbacks=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Without new features\n",
    "root = .0040 ** .5\n",
    "# .071\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2400.000000\n",
       "mean        1.066686\n",
       "std         0.065818\n",
       "min         0.831398\n",
       "25%         1.024956\n",
       "50%         1.061385\n",
       "75%         1.101586\n",
       "max         1.425089\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2186 samples, validate on 547 samples\n",
      "Epoch 1/2000\n",
      "2186/2186 [==============================] - 3s 2ms/step - loss: 1.1054 - val_loss: 1.0352\n",
      "Epoch 2/2000\n",
      "2186/2186 [==============================] - 1s 502us/step - loss: 1.0320 - val_loss: 0.9584\n",
      "Epoch 3/2000\n",
      "2186/2186 [==============================] - 1s 519us/step - loss: 0.9561 - val_loss: 0.8839\n",
      "Epoch 4/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.8826 - val_loss: 0.8130\n",
      "Epoch 5/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.8131 - val_loss: 0.7462\n",
      "Epoch 6/2000\n",
      "2186/2186 [==============================] - 1s 506us/step - loss: 0.7475 - val_loss: 0.6837\n",
      "Epoch 7/2000\n",
      "2186/2186 [==============================] - 1s 508us/step - loss: 0.6858 - val_loss: 0.6255\n",
      "Epoch 8/2000\n",
      "2186/2186 [==============================] - 1s 505us/step - loss: 0.6284 - val_loss: 0.5714\n",
      "Epoch 9/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.5750 - val_loss: 0.5213\n",
      "Epoch 10/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.5258 - val_loss: 0.4750\n",
      "Epoch 11/2000\n",
      "2186/2186 [==============================] - 1s 540us/step - loss: 0.4802 - val_loss: 0.4323\n",
      "Epoch 12/2000\n",
      "2186/2186 [==============================] - 1s 537us/step - loss: 0.4374 - val_loss: 0.3929\n",
      "Epoch 13/2000\n",
      "2186/2186 [==============================] - 1s 507us/step - loss: 0.3984 - val_loss: 0.3566\n",
      "Epoch 14/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.3623 - val_loss: 0.3233\n",
      "Epoch 15/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.3296 - val_loss: 0.2927\n",
      "Epoch 16/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.2987 - val_loss: 0.2646\n",
      "Epoch 17/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.2709 - val_loss: 0.2389\n",
      "Epoch 18/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.2446 - val_loss: 0.2155\n",
      "Epoch 19/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.2219 - val_loss: 0.1941\n",
      "Epoch 20/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.2004 - val_loss: 0.1746\n",
      "Epoch 21/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.1811 - val_loss: 0.1568\n",
      "Epoch 22/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.1634 - val_loss: 0.1407\n",
      "Epoch 23/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.1468 - val_loss: 0.1261\n",
      "Epoch 24/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.1323 - val_loss: 0.1129\n",
      "Epoch 25/2000\n",
      "2186/2186 [==============================] - 1s 501us/step - loss: 0.1189 - val_loss: 0.1010\n",
      "Epoch 26/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.1068 - val_loss: 0.0902\n",
      "Epoch 27/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0957 - val_loss: 0.0805\n",
      "Epoch 28/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0864 - val_loss: 0.0718\n",
      "Epoch 29/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0774 - val_loss: 0.0640\n",
      "Epoch 30/2000\n",
      "2186/2186 [==============================] - 1s 510us/step - loss: 0.0694 - val_loss: 0.0570\n",
      "Epoch 31/2000\n",
      "2186/2186 [==============================] - 1s 514us/step - loss: 0.0621 - val_loss: 0.0507\n",
      "Epoch 32/2000\n",
      "2186/2186 [==============================] - 1s 678us/step - loss: 0.0556 - val_loss: 0.0451\n",
      "Epoch 33/2000\n",
      "2186/2186 [==============================] - 1s 599us/step - loss: 0.0500 - val_loss: 0.0401\n",
      "Epoch 34/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.0452 - val_loss: 0.0356\n",
      "Epoch 35/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.0402 - val_loss: 0.0317\n",
      "Epoch 36/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0363 - val_loss: 0.0282\n",
      "Epoch 37/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0326 - val_loss: 0.0251\n",
      "Epoch 38/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.0293 - val_loss: 0.0223\n",
      "Epoch 39/2000\n",
      "2186/2186 [==============================] - 1s 524us/step - loss: 0.0262 - val_loss: 0.0199\n",
      "Epoch 40/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0238 - val_loss: 0.0178\n",
      "Epoch 41/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0214 - val_loss: 0.0159\n",
      "Epoch 42/2000\n",
      "2186/2186 [==============================] - 1s 500us/step - loss: 0.0192 - val_loss: 0.0142\n",
      "Epoch 43/2000\n",
      "2186/2186 [==============================] - 1s 497us/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 44/2000\n",
      "2186/2186 [==============================] - 1s 499us/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 45/2000\n",
      "2186/2186 [==============================] - 1s 498us/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 46/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 47/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 48/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 49/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 50/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 51/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 52/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 53/2000\n",
      "2186/2186 [==============================] - 1s 501us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 54/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 55/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 56/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 57/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 58/2000\n",
      "2186/2186 [==============================] - 1s 524us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 59/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 60/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 61/2000\n",
      "2186/2186 [==============================] - 1s 511us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 62/2000\n",
      "2186/2186 [==============================] - 1s 505us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 63/2000\n",
      "2186/2186 [==============================] - 1s 506us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 64/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 65/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 66/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 67/2000\n",
      "2186/2186 [==============================] - 1s 521us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 68/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 69/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 70/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 71/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 72/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 73/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 74/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 75/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 76/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 77/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0043 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 79/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 80/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 81/2000\n",
      "2186/2186 [==============================] - 1s 489us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 82/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 83/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 84/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 85/2000\n",
      "2186/2186 [==============================] - 1s 508us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 86/2000\n",
      "2186/2186 [==============================] - 1s 499us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 87/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 88/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 89/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 90/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 91/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 92/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 93/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 94/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 95/2000\n",
      "2186/2186 [==============================] - 1s 522us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 96/2000\n",
      "2186/2186 [==============================] - 1s 494us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 97/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 98/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 99/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 100/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 101/2000\n",
      "2186/2186 [==============================] - 1s 490us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 102/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 103/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 104/2000\n",
      "2186/2186 [==============================] - 1s 491us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 105/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 106/2000\n",
      "2186/2186 [==============================] - 1s 493us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 107/2000\n",
      "2186/2186 [==============================] - 1s 496us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 108/2000\n",
      "2186/2186 [==============================] - 1s 488us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 109/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 110/2000\n",
      "2186/2186 [==============================] - 1s 488us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 111/2000\n",
      "2186/2186 [==============================] - 1s 495us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 112/2000\n",
      "2186/2186 [==============================] - 1s 489us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 113/2000\n",
      "2186/2186 [==============================] - 1s 513us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 114/2000\n",
      "2186/2186 [==============================] - 1s 492us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 115/2000\n",
      "2186/2186 [==============================] - 1s 502us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 116/2000\n",
      "2186/2186 [==============================] - 1s 586us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 117/2000\n",
      "2186/2186 [==============================] - 2s 726us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 118/2000\n",
      "2186/2186 [==============================] - 1s 628us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 119/2000\n",
      "2186/2186 [==============================] - 1s 655us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 120/2000\n",
      "2186/2186 [==============================] - 1s 634us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 121/2000\n",
      "2186/2186 [==============================] - 2s 723us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 122/2000\n",
      "2186/2186 [==============================] - 1s 594us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 123/2000\n",
      "2186/2186 [==============================] - 1s 592us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 124/2000\n",
      "2186/2186 [==============================] - 1s 555us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 125/2000\n",
      "2186/2186 [==============================] - 1s 595us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 126/2000\n",
      "2186/2186 [==============================] - 1s 659us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 127/2000\n",
      "2186/2186 [==============================] - 1s 623us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 128/2000\n",
      "2186/2186 [==============================] - 1s 534us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 129/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-562-052235ad6671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=None)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thinkful/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing) and new layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2186 samples, validate on 547 samples\n",
      "Epoch 1/2000\n",
      "2186/2186 [==============================] - 9s 4ms/step - loss: 1.1104 - val_loss: 1.0365\n",
      "Epoch 2/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 1.0305 - val_loss: 0.9589\n",
      "Epoch 3/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.9543 - val_loss: 0.8822\n",
      "Epoch 4/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.8791 - val_loss: 0.8091\n",
      "Epoch 5/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.8070 - val_loss: 0.7405\n",
      "Epoch 6/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.7393 - val_loss: 0.6766\n",
      "Epoch 7/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.6760 - val_loss: 0.6172\n",
      "Epoch 8/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.6172 - val_loss: 0.5622\n",
      "Epoch 9/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.5626 - val_loss: 0.5114\n",
      "Epoch 10/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.5124 - val_loss: 0.4645\n",
      "Epoch 11/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.4658 - val_loss: 0.4213\n",
      "Epoch 12/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.4228 - val_loss: 0.3816\n",
      "Epoch 13/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3833 - val_loss: 0.3451\n",
      "Epoch 14/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3474 - val_loss: 0.3117\n",
      "Epoch 15/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.3142 - val_loss: 0.2811\n",
      "Epoch 16/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2837 - val_loss: 0.2532\n",
      "Epoch 17/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2559 - val_loss: 0.2277\n",
      "Epoch 18/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2306 - val_loss: 0.2045\n",
      "Epoch 19/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.2076 - val_loss: 0.1834\n",
      "Epoch 20/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1868 - val_loss: 0.1643\n",
      "Epoch 21/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1672 - val_loss: 0.1470\n",
      "Epoch 22/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1500 - val_loss: 0.1313\n",
      "Epoch 23/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1343 - val_loss: 0.1171\n",
      "Epoch 24/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1203 - val_loss: 0.1044\n",
      "Epoch 25/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.1076 - val_loss: 0.0929\n",
      "Epoch 26/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0959 - val_loss: 0.0826\n",
      "Epoch 27/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0856 - val_loss: 0.0734\n",
      "Epoch 28/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0765 - val_loss: 0.0652\n",
      "Epoch 29/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0681 - val_loss: 0.0578\n",
      "Epoch 30/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0607 - val_loss: 0.0513\n",
      "Epoch 31/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0542 - val_loss: 0.0454\n",
      "Epoch 32/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0481 - val_loss: 0.0403\n",
      "Epoch 33/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0428 - val_loss: 0.0357\n",
      "Epoch 34/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0382 - val_loss: 0.0316\n",
      "Epoch 35/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0341 - val_loss: 0.0280\n",
      "Epoch 36/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0302 - val_loss: 0.0249\n",
      "Epoch 37/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0270 - val_loss: 0.0221\n",
      "Epoch 38/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0243 - val_loss: 0.0197\n",
      "Epoch 39/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0217 - val_loss: 0.0175\n",
      "Epoch 40/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 41/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0175 - val_loss: 0.0140\n",
      "Epoch 42/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 43/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 44/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 45/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 46/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 47/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 48/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 49/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 50/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 51/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 52/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 53/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 54/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 55/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 56/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 57/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 58/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 59/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 60/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 61/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 62/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 63/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 64/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 65/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 66/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 67/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 68/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 69/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 70/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 71/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 72/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 73/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 74/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 75/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 76/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 77/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 78/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 80/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 81/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 82/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 83/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 84/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 85/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 86/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 87/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 88/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 89/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 90/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 91/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 92/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 93/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 94/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 95/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 96/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 97/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 98/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 99/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 100/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 101/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 102/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 103/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 104/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 105/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 106/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 107/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 108/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 109/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 110/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 111/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 112/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 113/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 114/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 115/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 116/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 117/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 118/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 119/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 120/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 121/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 122/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 123/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 124/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 125/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 126/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 127/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 128/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 129/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 130/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 131/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 132/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 133/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 134/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 135/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 136/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 137/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 138/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 139/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 140/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 141/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 142/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 143/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 144/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 145/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 146/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 147/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 148/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 149/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 150/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 151/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 152/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 153/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 154/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 155/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 156/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 158/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 159/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 160/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 161/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 162/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 163/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 164/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 165/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 166/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 167/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 168/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 169/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 170/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 171/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 172/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 173/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 174/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 175/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 176/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 177/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 178/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 179/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 180/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 181/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 182/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 183/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 184/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 185/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 186/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 187/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 188/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 189/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 190/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 191/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 192/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 193/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 194/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 195/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 196/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 197/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 198/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 199/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 200/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 201/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 202/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 203/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 204/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 205/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 206/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 207/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 208/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 209/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 210/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 211/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 212/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 213/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 214/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 215/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 216/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 217/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 218/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 219/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 220/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 221/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 222/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 223/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 224/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 225/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 226/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 227/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 228/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 229/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 230/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 231/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 232/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 233/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 234/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 236/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 237/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 238/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 239/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 240/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 241/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 242/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 243/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 244/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 245/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 246/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 247/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 248/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 249/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 250/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 251/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 252/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 253/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 254/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 255/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 256/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 257/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 258/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 259/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 260/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 261/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 262/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 263/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 264/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 265/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 266/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 267/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 268/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 269/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 270/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 271/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 272/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 273/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 274/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 275/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 276/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 277/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 278/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 279/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 280/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 281/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 282/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 283/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 284/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 285/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 286/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 287/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 288/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 289/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 290/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 291/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 292/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 293/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 294/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 295/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 296/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 297/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 298/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 299/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 300/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 301/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 302/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 303/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 304/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 305/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 306/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 307/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 308/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 309/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 310/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 311/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 312/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 314/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 315/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 316/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 317/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 318/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 319/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 320/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 321/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 322/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 323/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 324/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 325/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 326/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 327/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 328/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 329/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 330/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 331/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 332/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 333/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 334/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 335/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 336/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 337/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 338/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 339/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 340/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 341/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 342/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 343/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 344/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 345/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 346/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 347/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 348/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 349/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 350/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 351/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 352/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 353/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 354/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 355/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 356/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 357/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 358/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 359/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 360/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 361/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 362/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 363/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 364/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 365/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 366/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 367/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 368/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 369/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 370/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 371/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 372/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 373/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 374/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 375/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 376/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 377/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 378/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 379/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 380/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 381/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 382/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 383/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 384/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 385/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 386/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 387/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 388/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 389/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 390/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 392/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 393/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 394/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 395/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 396/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 397/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 398/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 399/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 400/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 401/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 402/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 403/2000\n",
      "2186/2186 [==============================] - 7s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 404/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 405/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 406/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 407/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 408/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 409/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 410/2000\n",
      "2186/2186 [==============================] - 245s 112ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 411/2000\n",
      "2186/2186 [==============================] - 8s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 412/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 413/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 414/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 415/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 416/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 417/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 418/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 419/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 420/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 421/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 422/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 423/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 424/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 425/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 426/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 427/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 428/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 429/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 430/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 431/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 432/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 433/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 434/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 435/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 436/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 437/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 438/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 439/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 440/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 441/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 442/2000\n",
      "2186/2186 [==============================] - 6s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 443/2000\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new datasets with new features (big swing) and new layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(450,), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.0001)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=X_train_sm, y=y_train_sm, \n",
    "          batch_size=2500, \n",
    "          epochs=2000, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_sm, y_test_sm),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
