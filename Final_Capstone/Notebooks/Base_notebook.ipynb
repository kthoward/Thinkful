{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of Zillow fie names for import and ensuring that all files can be read in properly\n",
    "list_of_file_names = glob.glob(\"./zip_2/*.csv\")\n",
    "\n",
    "read_data_list_2 = []\n",
    "fail_list = []\n",
    "for i, data in enumerate(list_of_file_names):\n",
    "    try:\n",
    "        data = pd.read_csv(data)\n",
    "        read_data_list_2.append(data)\n",
    "    except UnicodeDecodeError:\n",
    "        fail_list.append(i)\n",
    "list_of_file_names_org = list_of_file_names\n",
    "# Removing files that do not load properly\n",
    "for x in fail_list:\n",
    "    del list_of_file_names[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build loop for data we can work with. Only dates and zip\n",
    "def build_useful_df(data_list):\n",
    "    useful_df = []\n",
    "    for dataset in range(len(data_list)):\n",
    "        data = read_data_list_2[dataset].copy()\n",
    "        region_name = data['RegionName']\n",
    "        region_name = region_name.astype(str)\n",
    "        new_df = data.select_dtypes(include=['float64'])\n",
    "        new_df.insert(loc=0, column='RegionName', value=region_name) \n",
    "        new_df = new_df.sort_values('RegionName',ascending=False)\n",
    "        new_df = new_df.set_index('RegionName')\n",
    "        useful_df.append(new_df)\n",
    "    return useful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running the above function and making sure that our files contain enough zipcodes to give us sufficient data to merge\n",
    "\n",
    "useful_df = build_useful_df(read_data_list_2)\n",
    "sixteen_list = []\n",
    "good_columns = []\n",
    "sixteen_good = []\n",
    "for i, file in enumerate(useful_df):\n",
    "    if len(file) >= 10000:\n",
    "        sixteen_list.append(i)\n",
    "# Making sure that our files contain up to date information\n",
    "for i, file in enumerate(useful_df):\n",
    "    columns = file.columns\n",
    "    if '2017-01' in columns:\n",
    "        good_columns.append(i)\n",
    "# Selecting our list of files to use by cross referencing the lists that define files with attributes that we are looking for\n",
    "for num in sixteen_list:\n",
    "    if num in good_columns:\n",
    "        sixteen_good.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting our target data (price per square foot)\n",
    "target_data = useful_df[23]\n",
    "# Extracting the files themselves from the glob\n",
    "final_data_list = []\n",
    "for i, data in enumerate(useful_df):\n",
    "    if i in sixteen_good:\n",
    "        final_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Docs that don't need feature engineering. They are already aggregates. These may be used for future feature engineering\n",
    "pure_features = [0, 71, 75, 77, 79, 81]\n",
    "#useful_df[0].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function that builds the features for the model\n",
    "def make_features(df, past_time_string, now_string):\n",
    "    #df.dropna(inplace=True)\n",
    "    features = pd.DataFrame()\n",
    "    #features['RegionName'] = df['RegionName']\n",
    "    mean = df.loc[:, past_time_string : now_string].mean(axis=1)\n",
    "    features['mean'] = mean\n",
    "    std = df.loc[:, past_time_string : now_string].std(axis=1)\n",
    "    features['std'] = std\n",
    "    mn = df.loc[:, past_time_string : now_string].min(axis=1)\n",
    "    features['min'] = mn\n",
    "    mx = df.loc[:, past_time_string : now_string].max(axis=1)\n",
    "    features['max'] = mx\n",
    "    features['swing'] = mx - mn\n",
    "    change = df[now_string] - df[past_time_string]\n",
    "    features['change'] = change\n",
    "    mean_swing = features['swing'].mean()\n",
    "    features['swing_pos'] = np.where(features['swing']>mean_swing, 1, 0)\n",
    "    big_swing = features['swing'].std() + mean_swing\n",
    "    features['swing_big'] = np.where(features['swing']>big_swing, 1, 0)\n",
    "    features['swing_neg'] = np.where(features['swing']<mean_swing, 1, 0)\n",
    "    swing_big_loss = mean_swing - features['swing'].std() \n",
    "    features['swing_loss_big'] = np.where(features['swing']<swing_big_loss, 1, 0)\n",
    "    return features\n",
    "    \n",
    "# Creating the time frame we want to utilize for our prediction as well as generting the features and checking the data\n",
    "# to be certain that it fits the timeframe we are looking for\n",
    "def make_modeling_data(df_list, df_for_target, now_string):\n",
    "    df_one = pd.DataFrame()\n",
    "    target = pd.DataFrame()\n",
    "    now_time = pd.to_datetime(now_string)\n",
    "    now_value = df_for_target[now_string]\n",
    "    future_time = now_time + timedelta(days=6*31)\n",
    "    future_time_string= future_time.strftime(\"%Y-%m\")\n",
    "    future_value = df_for_target[future_time_string]\n",
    "    target['target'] = future_value/now_value\n",
    "    \n",
    "    \n",
    "    past_time = now_time - timedelta(days=6*31)\n",
    "    past_time_string= past_time.strftime(\"%Y-%m\")\n",
    "    df_to_use_for_features_org= df_list[0].loc[:, :now_string]\n",
    "    features_org = make_features(df_to_use_for_features_org, past_time_string, now_string)\n",
    "    df_one = pd.merge(df_one, features_org, left_index=True, right_index=True, how = 'right')\n",
    "    for i, df in enumerate(df_list[1:]):\n",
    "        ind = str(i)\n",
    "        columns = df.columns\n",
    "        if '2011-01' in columns and '2012-01' in columns and '2013-01' in columns and '2014-01' in columns and '2015-01' in columns and '2016-01' in columns and '2017-01' in columns:\n",
    "            df_to_use_for_features= df.loc[:, :now_string]\n",
    "            features = make_features(df_to_use_for_features, past_time_string, now_string)\n",
    "            df_one = pd.merge(df_one, features, right_index=True, left_index=True, how='inner')\n",
    "    target = target.loc[df_one.index]    \n",
    "    \n",
    "\n",
    "    \n",
    "    return df_one, target\n",
    "\n",
    "\n",
    "\n",
    "# Generate the initial modeling data\n",
    "test_features, test_targets = make_modeling_data(final_data_list, target_data, \"2017-06\")\n",
    "train_features, train_targets = make_modeling_data(final_data_list, target_data, \"2017-01\")\n",
    "train_features = train_features.append(train_features)\n",
    "train_targets = train_targets.append(train_targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specifying different timeframes that we will use to generate data from the past and appending it to our training dataset\n",
    "date_counter = 0\n",
    "for year in [\"2012\", \"2013\", \"2014\", \"2015\", \"2016\"]:\n",
    "    for month in [\"06\",\"12\"]:\n",
    "            new_time = year+\"-\"+month\n",
    "            date_counter += 1\n",
    "            extra_train_features, extra_train_targets = make_modeling_data(final_data_list, target_data, new_time)\n",
    "            train_features = train_features.append(extra_train_features)\n",
    "            train_targets = train_targets.append(extra_train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### w2v features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing w2v features\n",
    "w2v_features = pd.read_csv('real_business_w2v_features_3_6')\n",
    "# Making sure that the type is compatible with other files\n",
    "w2v_features['postal_code'] = w2v_features['postal_code'].astype(str)\n",
    "# Using the zip code as an index\n",
    "w2v_features.index = w2v_features['postal_code']\n",
    "# Removing unnecessary columns\n",
    "w2v_features = w2v_features.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing business data features\n",
    "business_features = pd.read_csv('real_business_features_3_4')\n",
    "# Making sure that the type is compatible with other files\n",
    "business_features['postal_code'] = business_features['postal_code'].astype(str)\n",
    "# Using the zip code as an index\n",
    "business_features = business_features.set_index('postal_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting train test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resetting the index for the Zillow features\n",
    "train_features = train_features.reset_index()\n",
    "test_features = test_features.reset_index()\n",
    "train_targets = train_targets.reset_index()\n",
    "test_targets = test_targets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging on index for train and test features and targets so it doesn't multiply rows as well as resetting the index to zips\n",
    "train_merge = pd.merge(train_features, train_targets, right_index=True, left_index=True, how='inner')\n",
    "test_merge = pd.merge(test_features, test_targets, right_index=True, left_index=True, how='inner')\n",
    "train_merge = train_merge.set_index('RegionName_x')\n",
    "test_merge = test_merge.set_index('RegionName_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging on index for business train and test features and targets so it doesn't multiply rows\n",
    "business_train_merge = pd.merge(train_merge, business_features, right_index=True, left_index=True, how='inner')\n",
    "business_test_merge = pd.merge(test_merge, business_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging on index for w2v train and test features and targets so it doesn't multiply rows\n",
    "w2v_train_merge = pd.merge(train_merge, w2v_features, right_index=True, left_index=True, how='inner')\n",
    "w2v_test_merge = pd.merge(test_merge, w2v_features, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making sure that all zipcodes are shared in the different feature sets and dropping NA values\n",
    "new_zillow_test_merge = pd.merge(test_merge, business_features, right_index=True, left_index=True, how='inner')\n",
    "test_merge = new_zillow_test_merge.iloc[:, :-10]\n",
    "new_zillow_train_merge = pd.merge(train_merge, business_features, right_index=True, left_index=True, how='inner')\n",
    "train_merge = new_zillow_train_merge.iloc[:, :-10]\n",
    "train_merge = train_merge.drop('RegionName_y', 1)\n",
    "test_merge = test_merge.drop('RegionName_y', 1)\n",
    "train_merge.dropna(inplace=True)\n",
    "test_merge.dropna(inplace=True)\n",
    "business_train_merge.dropna(inplace=True)\n",
    "business_test_merge.dropna(inplace=True)\n",
    "w2v_train_merge.dropna(inplace=True)\n",
    "w2v_test_merge.dropna(inplace=True)\n",
    "test_merge.to_csv('test_set_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating arrays and train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_merge.iloc[:, :-1].values\n",
    "y_train = train_merge.iloc[:, -1].values\n",
    "X_test = test_merge.iloc[:, :-1].values\n",
    "y_test = test_merge.iloc[:, -1].values\n",
    "business_train_merge = business_train_merge.drop('RegionName_y', 1)\n",
    "business_test_merge = business_test_merge.drop('RegionName_y', 1)\n",
    "y_train_business = business_train_merge.loc[:, 'target'].values\n",
    "y_test_business = business_test_merge.loc[:, 'target'].values\n",
    "business_train = pd.DataFrame()\n",
    "business_train_features = business_train_merge.drop('target', 1).values\n",
    "X_train_business = pd.DataFrame()\n",
    "X_train_business = business_train_features\n",
    "X_test_business_features = pd.DataFrame()\n",
    "X_test_business_features = business_test_merge.drop('target', 1).values\n",
    "X_test_business = pd.DataFrame()\n",
    "X_test_business = X_test_business_features\n",
    "w2v_train_merge = w2v_train_merge.drop('RegionName_y', 1)\n",
    "w2v_test_merge = w2v_test_merge.drop('RegionName_y', 1)\n",
    "y_train_w2v = w2v_train_merge.loc[:, 'target'].values\n",
    "y_test_w2v = w2v_test_merge.loc[:, 'target'].values\n",
    "w2v_train = pd.DataFrame()\n",
    "w2v_train_features = w2v_train_merge.drop('target', 1).values\n",
    "X_train_w2v = pd.DataFrame()\n",
    "X_train_w2v = w2v_train_features\n",
    "X_test_w2v_features = pd.DataFrame()\n",
    "X_test_w2v_features = w2v_test_merge.drop('target', 1).values\n",
    "X_test_w2v = pd.DataFrame()\n",
    "X_test_w2v = X_test_w2v_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function that normalizes the arrays\n",
    "def norm_per_column(X):\n",
    "    new_array = []\n",
    "    shape = X.shape\n",
    "    columns = shape[1]\n",
    "    for num in range(columns):\n",
    "        mx = X[:, num].max()\n",
    "        if mx == 0:\n",
    "            new_array.append(X[:, num])\n",
    "        else:\n",
    "            X[:, num] = X[:, num] / mx\n",
    "            new_array.append(X[:, num])\n",
    "    new_array = np.array(new_array)\n",
    "    new_array = np.transpose(new_array)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028560998107322942"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the arrays\n",
    "X_train = norm_per_column(X_train)\n",
    "X_test = norm_per_column(X_test)\n",
    "X_train_business = norm_per_column(X_train_business)\n",
    "X_test_business = norm_per_column(X_test_business)\n",
    "X_train_w2v = norm_per_column(X_train_w2v)\n",
    "X_test_w2v = norm_per_column(X_test_w2v)\n",
    "y_test.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean\n",
      "1.03568676443\n",
      "train min\n",
      "0.809566962437\n",
      "train max\n",
      "1.32300764356\n",
      "test mean\n",
      "1.01812630226\n",
      "test min\n",
      "0.833675690212\n",
      "test max\n",
      "1.18704258259\n"
     ]
    }
   ],
   "source": [
    "# Checking the variance in training set and test set\n",
    "print('train mean')\n",
    "print(y_train.mean())\n",
    "print('train min')\n",
    "print(y_train.min())\n",
    "print('train max')\n",
    "print(y_train.max())\n",
    "print('test mean')\n",
    "print(y_test.mean())\n",
    "print('test min')\n",
    "print(y_test.min())\n",
    "print('test max')\n",
    "print( y_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating classes for targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a function to generate classes for categorical model\n",
    "def create_y_class_2(y_list):\n",
    "    y_df = pd.DataFrame()\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    y_3 = []\n",
    "    y_4 = []\n",
    "    y_5 = []\n",
    "    \n",
    "    for y in y_list:\n",
    "        if y <= .9:\n",
    "            y_1.append(1)\n",
    "        else:\n",
    "            y_1.append(0)\n",
    "        if y > .9 and y <= .97:\n",
    "            y_2.append(1)\n",
    "        else:\n",
    "            y_2.append(0)\n",
    "        if y > .97 and y < 1.03:\n",
    "            y_3.append(1)\n",
    "        else:\n",
    "            y_3.append(0)\n",
    "        if y >= 1.03 and y < 1.1:\n",
    "            y_4.append(1)\n",
    "        else:\n",
    "            y_4.append(0)\n",
    "        if y >= 1.1:\n",
    "            y_5.append(1)\n",
    "        else:\n",
    "            y_5.append(0)\n",
    "    y_df['1'] = y_1\n",
    "    y_df['2'] = y_2\n",
    "    y_df['3'] = y_3\n",
    "    y_df['4'] = y_4\n",
    "    y_df['5'] = y_5\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028560998107322942"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating classes for categorical model\n",
    "y_cat_train = create_y_class_2(y_train)\n",
    "y_cat_test = create_y_class_2(y_test)\n",
    "y_cat_train_w2v = create_y_class_2(y_train_w2v)\n",
    "y_cat_test_w2v = create_y_class_2(y_test_w2v)\n",
    "y_cat_train_business = create_y_class_2(y_train_business)\n",
    "y_cat_test_business = create_y_class_2(y_test_business)\n",
    "y_test_business.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(120,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.005)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/200\n",
      "2839/2839 [==============================] - 29s 10ms/step - loss: 18.7427 - val_loss: 0.3602\n",
      "Epoch 2/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.3542 - val_loss: 0.1392\n",
      "Epoch 3/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.2824 - val_loss: 0.1391\n",
      "Epoch 4/200\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2419 - val_loss: 0.0930\n",
      "Epoch 5/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2136 - val_loss: 0.0818\n",
      "Epoch 6/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.2065 - val_loss: 0.0596\n",
      "Epoch 7/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1926 - val_loss: 0.0398\n",
      "Epoch 8/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1765 - val_loss: 0.0476\n",
      "Epoch 9/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1768 - val_loss: 0.0522\n",
      "Epoch 10/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1558 - val_loss: 0.0486\n",
      "Epoch 11/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1564 - val_loss: 0.0671\n",
      "Epoch 12/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.1462 - val_loss: 0.0701\n",
      "Epoch 13/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.1384 - val_loss: 0.0701\n",
      "Epoch 14/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.1336 - val_loss: 0.0867\n",
      "Epoch 15/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.1421 - val_loss: 0.1900\n",
      "Epoch 16/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1701 - val_loss: 0.0825\n",
      "Epoch 17/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1290 - val_loss: 0.1001\n",
      "Epoch 18/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.1354 - val_loss: 0.1788\n",
      "Epoch 19/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1485 - val_loss: 0.0941\n",
      "Epoch 20/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1233 - val_loss: 0.0739\n",
      "Epoch 21/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1106 - val_loss: 0.0754\n",
      "Epoch 22/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1118 - val_loss: 0.0810\n",
      "Epoch 23/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.1124 - val_loss: 0.0990\n",
      "Epoch 24/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.1124 - val_loss: 0.1852\n",
      "Epoch 25/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1399 - val_loss: 0.2269\n",
      "Epoch 26/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1583 - val_loss: 0.1231\n",
      "Epoch 27/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1091 - val_loss: 0.1154\n",
      "Epoch 28/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1039 - val_loss: 0.1386\n",
      "Epoch 29/200\n",
      "2839/2839 [==============================] - 0s 53us/step - loss: 0.1117 - val_loss: 0.1516\n",
      "Epoch 30/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.1122 - val_loss: 0.1393\n",
      "Epoch 31/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.1244 - val_loss: 0.2353\n",
      "Epoch 32/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.1455 - val_loss: 0.1897\n",
      "Epoch 33/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1195 - val_loss: 0.1271\n",
      "Epoch 34/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0985 - val_loss: 0.1501\n",
      "Epoch 35/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1053 - val_loss: 0.1939\n",
      "Epoch 36/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1257 - val_loss: 0.2508\n",
      "Epoch 37/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1503 - val_loss: 0.1808\n",
      "Epoch 38/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1191 - val_loss: 0.1724\n",
      "Epoch 39/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1176 - val_loss: 0.2130\n",
      "Epoch 40/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1274 - val_loss: 0.1789\n",
      "Epoch 41/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1132 - val_loss: 0.1796\n",
      "Epoch 42/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1083 - val_loss: 0.1308\n",
      "Epoch 43/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0904 - val_loss: 0.1797\n",
      "Epoch 44/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1121 - val_loss: 0.1753\n",
      "Epoch 45/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1100 - val_loss: 0.1869\n",
      "Epoch 46/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.1100 - val_loss: 0.1651\n",
      "Epoch 47/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.1005 - val_loss: 0.1549\n",
      "Epoch 48/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0955 - val_loss: 0.1412\n",
      "Epoch 49/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0916 - val_loss: 0.1156\n",
      "Epoch 50/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0742 - val_loss: 0.1095\n",
      "Epoch 51/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0761 - val_loss: 0.1288\n",
      "Epoch 52/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0907 - val_loss: 0.1345\n",
      "Epoch 53/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0869 - val_loss: 0.0976\n",
      "Epoch 54/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0695 - val_loss: 0.0815\n",
      "Epoch 55/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0615 - val_loss: 0.0827\n",
      "Epoch 56/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0700 - val_loss: 0.0878\n",
      "Epoch 57/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0686 - val_loss: 0.0821\n",
      "Epoch 58/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0668 - val_loss: 0.0624\n",
      "Epoch 59/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0562 - val_loss: 0.0557\n",
      "Epoch 60/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0547 - val_loss: 0.0668\n",
      "Epoch 61/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0577 - val_loss: 0.0565\n",
      "Epoch 62/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0520 - val_loss: 0.0387\n",
      "Epoch 63/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0482 - val_loss: 0.0305\n",
      "Epoch 64/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0419 - val_loss: 0.0294\n",
      "Epoch 65/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0435 - val_loss: 0.0352\n",
      "Epoch 66/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0477 - val_loss: 0.0237\n",
      "Epoch 67/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0415 - val_loss: 0.0202\n",
      "Epoch 68/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0403 - val_loss: 0.0228\n",
      "Epoch 69/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0379 - val_loss: 0.0141\n",
      "Epoch 70/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0344 - val_loss: 0.0095\n",
      "Epoch 71/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0313 - val_loss: 0.0088\n",
      "Epoch 72/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0316 - val_loss: 0.0062\n",
      "Epoch 73/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0288 - val_loss: 0.0059\n",
      "Epoch 74/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0287 - val_loss: 0.0065\n",
      "Epoch 75/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0282 - val_loss: 0.0057\n",
      "Epoch 76/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0282 - val_loss: 0.0054\n",
      "Epoch 77/200\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0267 - val_loss: 0.0067\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0295 - val_loss: 0.0133\n",
      "Epoch 79/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0327 - val_loss: 0.0115\n",
      "Epoch 80/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0288 - val_loss: 0.0044\n",
      "Epoch 81/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0247 - val_loss: 0.0036\n",
      "Epoch 82/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0242 - val_loss: 0.0038\n",
      "Epoch 83/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0235 - val_loss: 0.0029\n",
      "Epoch 84/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0232 - val_loss: 0.0030\n",
      "Epoch 85/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0235 - val_loss: 0.0032\n",
      "Epoch 86/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0219 - val_loss: 0.0029\n",
      "Epoch 87/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0224 - val_loss: 0.0037\n",
      "Epoch 88/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 89/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0299 - val_loss: 0.0102\n",
      "Epoch 90/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0248 - val_loss: 0.0028\n",
      "Epoch 91/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0199 - val_loss: 0.0029\n",
      "Epoch 92/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0194 - val_loss: 0.0030\n",
      "Epoch 93/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0202 - val_loss: 0.0027\n",
      "Epoch 94/200\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0189 - val_loss: 0.0027\n",
      "Epoch 95/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0197 - val_loss: 0.0028\n",
      "Epoch 96/200\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.018 - 0s 33us/step - loss: 0.0185 - val_loss: 0.0030\n",
      "Epoch 97/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0184 - val_loss: 0.0031\n",
      "Epoch 98/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0177 - val_loss: 0.0035\n",
      "Epoch 99/200\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0190 - val_loss: 0.0035\n",
      "Epoch 100/200\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0177 - val_loss: 0.0050\n",
      "Epoch 101/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0204 - val_loss: 0.0033\n",
      "Epoch 102/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0181 - val_loss: 0.0035\n",
      "Epoch 103/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0176 - val_loss: 0.0027\n",
      "Epoch 104/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0162 - val_loss: 0.0028\n",
      "Epoch 105/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0162 - val_loss: 0.0027\n",
      "Epoch 106/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0158 - val_loss: 0.0027\n",
      "Epoch 107/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0148 - val_loss: 0.0029\n",
      "Epoch 108/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0153 - val_loss: 0.0033\n",
      "Epoch 109/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0156 - val_loss: 0.0032\n",
      "Epoch 110/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0155 - val_loss: 0.0029\n",
      "Epoch 111/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0143 - val_loss: 0.0033\n",
      "Epoch 112/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0146 - val_loss: 0.0030\n",
      "Epoch 113/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0139 - val_loss: 0.0037\n",
      "Epoch 114/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0141 - val_loss: 0.0033\n",
      "Epoch 115/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0140 - val_loss: 0.0031\n",
      "Epoch 116/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 117/200\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.0123 - val_loss: 0.0032\n",
      "Epoch 118/200\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0039\n",
      "Epoch 119/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0131 - val_loss: 0.0034\n",
      "Epoch 120/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0119 - val_loss: 0.0035\n",
      "Epoch 121/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0114 - val_loss: 0.0033\n",
      "Epoch 122/200\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0043\n",
      "Epoch 123/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0135 - val_loss: 0.0032\n",
      "Epoch 124/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0116 - val_loss: 0.0030\n",
      "Epoch 125/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 126/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0104 - val_loss: 0.0030\n",
      "Epoch 127/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0103 - val_loss: 0.0030\n",
      "Epoch 128/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0097 - val_loss: 0.0033\n",
      "Epoch 129/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0102 - val_loss: 0.0040\n",
      "Epoch 130/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0117 - val_loss: 0.0035\n",
      "Epoch 131/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0101 - val_loss: 0.0029\n",
      "Epoch 132/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0092 - val_loss: 0.0034\n",
      "Epoch 133/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0096 - val_loss: 0.0038\n",
      "Epoch 134/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 135/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0087 - val_loss: 0.0035\n",
      "Epoch 136/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 137/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 138/200\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.008 - 0s 36us/step - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 139/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0079 - val_loss: 0.0036\n",
      "Epoch 140/200\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.0081 - val_loss: 0.0033\n",
      "Epoch 141/200\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 142/200\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.0097 - val_loss: 0.0038\n",
      "Epoch 143/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0086 - val_loss: 0.0034\n",
      "Epoch 144/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 145/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 146/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 147/200\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 0.0067 - val_loss: 0.0031\n",
      "Epoch 148/200\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 149/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 150/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 151/200\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 152/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 153/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 154/200\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 43us/step - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 156/200\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 157/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 158/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 159/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 160/200\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 161/200\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 162/200\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 163/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 164/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 165/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 166/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 167/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 168/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 169/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 170/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 171/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 172/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 173/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 174/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 175/200\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 176/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 177/200\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 178/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 179/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 180/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 181/200\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 182/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 183/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 184/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 185/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 186/200\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 187/200\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 188/200\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 189/200\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 190/200\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 191/200\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 192/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 193/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 194/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 195/200\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 196/200\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 197/200\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 198/200\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 199/200\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 200/200\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0034 - val_loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ea88710>"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, \n",
    "          batch_size=2000, \n",
    "          epochs=200, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(130,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.01)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0055 - val_loss: 0.0088\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0160 - val_loss: 0.0030\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0053 - val_loss: 0.1210\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5420 - val_loss: 0.1706\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2718 - val_loss: 0.0036\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0186 - val_loss: 0.0032\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0106 - val_loss: 0.0034\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0082 - val_loss: 0.0111\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0190 - val_loss: 0.0035\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0062 - val_loss: 0.4126\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.6169 - val_loss: 0.3842\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.4058 - val_loss: 0.0042\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0046 - val_loss: 0.0164\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0922 - val_loss: 1.0088\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2131 - val_loss: 0.0246\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0393 - val_loss: 0.0048\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0087 - val_loss: 0.0030\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0095 - val_loss: 0.0556\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.1012 - val_loss: 0.0047\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0991 - val_loss: 0.8047\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.8528 - val_loss: 9.5942\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 11.2623 - val_loss: 1.8581\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.4809 - val_loss: 0.0179\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0347 - val_loss: 0.0039\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0207 - val_loss: 0.0038\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0180 - val_loss: 0.0033\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0137 - val_loss: 0.0038\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0088 - val_loss: 0.0035\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0056 - val_loss: 0.0225\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0384 - val_loss: 0.3079\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.7884 - val_loss: 3.0779\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.3607 - val_loss: 0.0446\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0363 - val_loss: 0.0121\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0095 - val_loss: 0.0067\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0085 - val_loss: 0.0226\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0290 - val_loss: 0.1125\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1538 - val_loss: 0.2634\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2671 - val_loss: 0.2698\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2900 - val_loss: 0.8574\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 4.1008 - val_loss: 30.9265\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 37.3535 - val_loss: 24.0820\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 18.2658 - val_loss: 0.0029\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0098 - val_loss: 0.0029\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0070 - val_loss: 0.0029\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0069 - val_loss: 0.0214\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0375 - val_loss: 0.3485\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.8947 - val_loss: 7.7936\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 12.0376 - val_loss: 19.0341\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 14.7902 - val_loss: 0.0914\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0736 - val_loss: 0.0077\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0271 - val_loss: 0.1794\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.4322 - val_loss: 7.0663\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 11.6984 - val_loss: 1.5417\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.2566 - val_loss: 0.0320\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0238 - val_loss: 0.0042\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0112 - val_loss: 0.0867\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2202 - val_loss: 3.8801\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 5.0471 - val_loss: 0.0526\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0450 - val_loss: 0.0060\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0080 - val_loss: 0.0341\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.1079 - val_loss: 2.4706\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 6.7249 - val_loss: 18.3961\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 31.2690 - val_loss: 23.2112\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 18.4562 - val_loss: 0.0401\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0472 - val_loss: 0.0029\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0168 - val_loss: 0.1399\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4274 - val_loss: 5.2691\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 11.3014 - val_loss: 67.5562\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 60.0220 - val_loss: 0.3208\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.2505 - val_loss: 0.0073\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0096\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0126 - val_loss: 0.0939\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1889 - val_loss: 2.0366\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 5.0588 - val_loss: 16.2810\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 12.2137 - val_loss: 0.5355\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5032 - val_loss: 0.2358\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2301 - val_loss: 0.1611\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.1714 - val_loss: 0.2214\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2493 - val_loss: 0.4269\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.5756 - val_loss: 2.5519\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 6.1397 - val_loss: 19.9508\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 15.5076 - val_loss: 0.0581\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0629 - val_loss: 0.0029\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0104 - val_loss: 0.0328\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0726 - val_loss: 0.5266\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 1.5459 - val_loss: 23.9728\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 34.7491 - val_loss: 20.9841\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 16.6981 - val_loss: 0.0029\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0192 - val_loss: 0.0029\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0133 - val_loss: 0.0029\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0052 - val_loss: 0.0224\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0499 - val_loss: 0.8239\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.6580 - val_loss: 13.1671\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 10.5746 - val_loss: 0.0645\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0595 - val_loss: 0.0029\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0103 - val_loss: 0.1003\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.4130 - val_loss: 4.4048\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 4.0120 - val_loss: 0.0670\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0672 - val_loss: 0.0059\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0174 - val_loss: 0.1153\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.2134 - val_loss: 0.0084\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0142 - val_loss: 0.0028\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0135 - val_loss: 0.0028\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 27us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0388 - val_loss: 0.0664\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.2143 - val_loss: 0.9015\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.6988 - val_loss: 5.7502\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 8.9211 - val_loss: 5.0362\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 6.955 - 0s 29us/step - loss: 4.9079 - val_loss: 0.0048\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0186 - val_loss: 0.0035\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0162 - val_loss: 0.0031\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0137 - val_loss: 0.0032\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0100 - val_loss: 0.0029\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0087 - val_loss: 0.0027\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0085 - val_loss: 0.0236\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0608 - val_loss: 0.4231\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4826 - val_loss: 2.4886\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 2.7621 - val_loss: 0.0174\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0204 - val_loss: 0.0031\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0056 - val_loss: 0.0159\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0566 - val_loss: 0.5200\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.8449 - val_loss: 2.5200\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 2.7800 - val_loss: 0.0028\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0106 - val_loss: 0.0345\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0952 - val_loss: 0.3965\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.5595 - val_loss: 0.0336\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0377 - val_loss: 0.0028\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0508\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2127 - val_loss: 0.5418\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.6122 - val_loss: 0.0032\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0070 - val_loss: 0.0123\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0224 - val_loss: 0.0033\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 49us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0074 - val_loss: 0.0031\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0204 - val_loss: 0.1557\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.2628 - val_loss: 0.0043\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0134 - val_loss: 0.0031\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 29us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train_business, y=y_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_test_business),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(631,), activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(.35))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "ada = keras.optimizers.Adagrad()\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rms = keras.optimizers.RMSprop(lr=0.002)\n",
    "sgd = keras.optimizers.SGD(lr=0.75)\n",
    "model.compile(optimizer=rms,\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/500\n",
      "2839/2839 [==============================] - 4s 1ms/step - loss: 3.1253 - val_loss: 0.3215\n",
      "Epoch 2/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.3927 - val_loss: 0.2637\n",
      "Epoch 3/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.3240 - val_loss: 0.2399\n",
      "Epoch 4/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2909 - val_loss: 0.1291\n",
      "Epoch 5/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2447 - val_loss: 0.1072\n",
      "Epoch 6/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.2297 - val_loss: 0.1186\n",
      "Epoch 7/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.2025 - val_loss: 0.2005\n",
      "Epoch 8/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.2366 - val_loss: 0.2338\n",
      "Epoch 9/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.2277 - val_loss: 0.1693\n",
      "Epoch 10/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1877 - val_loss: 0.1282\n",
      "Epoch 11/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1745 - val_loss: 0.1411\n",
      "Epoch 12/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.1660 - val_loss: 0.1104\n",
      "Epoch 13/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.1478 - val_loss: 0.1603\n",
      "Epoch 14/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.1639 - val_loss: 0.2238\n",
      "Epoch 15/500\n",
      "2839/2839 [==============================] - 0s 92us/step - loss: 0.1798 - val_loss: 0.2185\n",
      "Epoch 16/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.1586 - val_loss: 0.1309\n",
      "Epoch 17/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.1269 - val_loss: 0.1460\n",
      "Epoch 18/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1226 - val_loss: 0.1419\n",
      "Epoch 19/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1188 - val_loss: 0.1322\n",
      "Epoch 20/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1142 - val_loss: 0.2100\n",
      "Epoch 21/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.1477 - val_loss: 0.1941\n",
      "Epoch 22/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.1351 - val_loss: 0.1434\n",
      "Epoch 23/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.1089 - val_loss: 0.1333\n",
      "Epoch 24/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1087 - val_loss: 0.1734\n",
      "Epoch 25/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1242 - val_loss: 0.1681\n",
      "Epoch 26/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.1236 - val_loss: 0.1397\n",
      "Epoch 27/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.1041 - val_loss: 0.1265\n",
      "Epoch 28/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0930 - val_loss: 0.1414\n",
      "Epoch 29/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1073 - val_loss: 0.1549\n",
      "Epoch 30/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.1063 - val_loss: 0.1308\n",
      "Epoch 31/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0955 - val_loss: 0.1328\n",
      "Epoch 32/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0950 - val_loss: 0.1184\n",
      "Epoch 33/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0840 - val_loss: 0.1127\n",
      "Epoch 34/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0848 - val_loss: 0.1371\n",
      "Epoch 35/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0962 - val_loss: 0.1347\n",
      "Epoch 36/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0994 - val_loss: 0.1492\n",
      "Epoch 37/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0920 - val_loss: 0.1038\n",
      "Epoch 38/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0761 - val_loss: 0.0920\n",
      "Epoch 39/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0710 - val_loss: 0.0986\n",
      "Epoch 40/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0798 - val_loss: 0.1339\n",
      "Epoch 41/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0883 - val_loss: 0.1173\n",
      "Epoch 42/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0795 - val_loss: 0.0971\n",
      "Epoch 43/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0691 - val_loss: 0.0996\n",
      "Epoch 44/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0750 - val_loss: 0.1234\n",
      "Epoch 45/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0834 - val_loss: 0.1221\n",
      "Epoch 46/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0818 - val_loss: 0.1055\n",
      "Epoch 47/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0705 - val_loss: 0.0837\n",
      "Epoch 48/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0635 - val_loss: 0.0809\n",
      "Epoch 49/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0631 - val_loss: 0.0942\n",
      "Epoch 50/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0679 - val_loss: 0.0971\n",
      "Epoch 51/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0705 - val_loss: 0.0994\n",
      "Epoch 52/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0712 - val_loss: 0.0786\n",
      "Epoch 53/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0592 - val_loss: 0.0679\n",
      "Epoch 54/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0567 - val_loss: 0.0868\n",
      "Epoch 55/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0620 - val_loss: 0.0766\n",
      "Epoch 56/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0638 - val_loss: 0.0971\n",
      "Epoch 57/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0646 - val_loss: 0.0700\n",
      "Epoch 58/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0572 - val_loss: 0.0794\n",
      "Epoch 59/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0543 - val_loss: 0.0706\n",
      "Epoch 60/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0554 - val_loss: 0.0651\n",
      "Epoch 61/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0532 - val_loss: 0.0694\n",
      "Epoch 62/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0542 - val_loss: 0.0654\n",
      "Epoch 63/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0492 - val_loss: 0.0531\n",
      "Epoch 64/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0471 - val_loss: 0.0646\n",
      "Epoch 65/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0525 - val_loss: 0.0713\n",
      "Epoch 66/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.0543 - val_loss: 0.0587\n",
      "Epoch 67/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0473 - val_loss: 0.0570\n",
      "Epoch 68/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0506 - val_loss: 0.0612\n",
      "Epoch 69/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0480 - val_loss: 0.0486\n",
      "Epoch 70/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0421 - val_loss: 0.0495\n",
      "Epoch 71/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0411 - val_loss: 0.0367\n",
      "Epoch 72/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0426 - val_loss: 0.0547\n",
      "Epoch 73/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0467 - val_loss: 0.0652\n",
      "Epoch 74/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0512 - val_loss: 0.0473\n",
      "Epoch 75/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0435 - val_loss: 0.0434\n",
      "Epoch 76/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0426 - val_loss: 0.0540\n",
      "Epoch 77/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0461 - val_loss: 0.0432\n",
      "Epoch 78/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0405 - val_loss: 0.0397\n",
      "Epoch 79/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0409 - val_loss: 0.0388\n",
      "Epoch 80/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0398 - val_loss: 0.0345\n",
      "Epoch 81/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0397 - val_loss: 0.0410\n",
      "Epoch 82/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0402 - val_loss: 0.0232\n",
      "Epoch 83/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0334 - val_loss: 0.0252\n",
      "Epoch 84/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0347 - val_loss: 0.0287\n",
      "Epoch 85/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0369 - val_loss: 0.0343\n",
      "Epoch 86/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0397 - val_loss: 0.0283\n",
      "Epoch 87/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0375 - val_loss: 0.0205\n",
      "Epoch 88/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0336 - val_loss: 0.0163\n",
      "Epoch 89/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0323 - val_loss: 0.0138\n",
      "Epoch 90/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0308 - val_loss: 0.0162\n",
      "Epoch 91/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0325 - val_loss: 0.0127\n",
      "Epoch 92/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0316 - val_loss: 0.0122\n",
      "Epoch 93/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0298 - val_loss: 0.0091\n",
      "Epoch 94/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0280 - val_loss: 0.0096\n",
      "Epoch 95/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0303 - val_loss: 0.0185\n",
      "Epoch 96/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0353 - val_loss: 0.0118\n",
      "Epoch 97/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0315 - val_loss: 0.0122\n",
      "Epoch 98/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0300 - val_loss: 0.0083\n",
      "Epoch 99/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0289 - val_loss: 0.0099\n",
      "Epoch 100/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0297 - val_loss: 0.0118\n",
      "Epoch 101/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0289 - val_loss: 0.0102\n",
      "Epoch 102/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0298 - val_loss: 0.0130\n",
      "Epoch 103/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0317 - val_loss: 0.0071\n",
      "Epoch 104/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0276 - val_loss: 0.0070\n",
      "Epoch 105/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0258 - val_loss: 0.0045\n",
      "Epoch 106/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0256 - val_loss: 0.0035\n",
      "Epoch 107/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0262 - val_loss: 0.0028\n",
      "Epoch 108/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0267 - val_loss: 0.0028\n",
      "Epoch 109/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0265 - val_loss: 0.0028\n",
      "Epoch 110/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0280 - val_loss: 0.0032\n",
      "Epoch 111/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0266 - val_loss: 0.0030\n",
      "Epoch 112/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0248 - val_loss: 0.0033\n",
      "Epoch 113/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0248 - val_loss: 0.0028\n",
      "Epoch 114/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0243 - val_loss: 0.0028\n",
      "Epoch 115/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0261 - val_loss: 0.0030\n",
      "Epoch 116/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0241 - val_loss: 0.0030\n",
      "Epoch 117/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0244 - val_loss: 0.0027\n",
      "Epoch 118/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0254 - val_loss: 0.0030\n",
      "Epoch 119/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0259 - val_loss: 0.0031\n",
      "Epoch 120/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0246 - val_loss: 0.0030\n",
      "Epoch 121/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0234 - val_loss: 0.0045\n",
      "Epoch 122/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0246 - val_loss: 0.0070\n",
      "Epoch 123/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0249 - val_loss: 0.0037\n",
      "Epoch 124/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0230 - val_loss: 0.0038\n",
      "Epoch 125/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0220 - val_loss: 0.0029\n",
      "Epoch 126/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0240 - val_loss: 0.0032\n",
      "Epoch 127/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0256 - val_loss: 0.0029\n",
      "Epoch 128/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0233 - val_loss: 0.0034\n",
      "Epoch 129/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0240 - val_loss: 0.0028\n",
      "Epoch 130/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0220 - val_loss: 0.0029\n",
      "Epoch 131/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0219 - val_loss: 0.0034\n",
      "Epoch 132/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0223 - val_loss: 0.0039\n",
      "Epoch 133/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0229 - val_loss: 0.0040\n",
      "Epoch 134/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0219 - val_loss: 0.0068\n",
      "Epoch 135/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0240 - val_loss: 0.0035\n",
      "Epoch 136/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0211 - val_loss: 0.0039\n",
      "Epoch 137/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0218 - val_loss: 0.0035\n",
      "Epoch 138/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0218 - val_loss: 0.0049\n",
      "Epoch 139/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0227 - val_loss: 0.0059\n",
      "Epoch 140/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0232 - val_loss: 0.0054\n",
      "Epoch 141/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0234 - val_loss: 0.0033\n",
      "Epoch 142/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0207 - val_loss: 0.0037\n",
      "Epoch 143/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0210 - val_loss: 0.0057\n",
      "Epoch 144/500\n",
      "2839/2839 [==============================] - 0s 93us/step - loss: 0.0216 - val_loss: 0.0045\n",
      "Epoch 145/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0204 - val_loss: 0.0030\n",
      "Epoch 146/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0206 - val_loss: 0.0029\n",
      "Epoch 147/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0211 - val_loss: 0.0028\n",
      "Epoch 148/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0212 - val_loss: 0.0029\n",
      "Epoch 149/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0203 - val_loss: 0.0028\n",
      "Epoch 150/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0195 - val_loss: 0.0028\n",
      "Epoch 151/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0199 - val_loss: 0.0028\n",
      "Epoch 152/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0196 - val_loss: 0.0032\n",
      "Epoch 153/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0210 - val_loss: 0.0034\n",
      "Epoch 154/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0207 - val_loss: 0.0028\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0199 - val_loss: 0.0030\n",
      "Epoch 156/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0184 - val_loss: 0.0029\n",
      "Epoch 157/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0193 - val_loss: 0.0029\n",
      "Epoch 158/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0183 - val_loss: 0.0029\n",
      "Epoch 159/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0184 - val_loss: 0.0027\n",
      "Epoch 160/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0198 - val_loss: 0.0031\n",
      "Epoch 161/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0197 - val_loss: 0.0031\n",
      "Epoch 162/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0185 - val_loss: 0.0030\n",
      "Epoch 163/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0189 - val_loss: 0.0029\n",
      "Epoch 164/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0177 - val_loss: 0.0028\n",
      "Epoch 165/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0187 - val_loss: 0.0028\n",
      "Epoch 166/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0177 - val_loss: 0.0033\n",
      "Epoch 167/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0199 - val_loss: 0.0032\n",
      "Epoch 168/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0178 - val_loss: 0.0029\n",
      "Epoch 169/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0177 - val_loss: 0.0029\n",
      "Epoch 170/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0176 - val_loss: 0.0028\n",
      "Epoch 171/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0179 - val_loss: 0.0029\n",
      "Epoch 172/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0177 - val_loss: 0.0028\n",
      "Epoch 173/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0176 - val_loss: 0.0028\n",
      "Epoch 174/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0178 - val_loss: 0.0030\n",
      "Epoch 175/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0180 - val_loss: 0.0031\n",
      "Epoch 176/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0166 - val_loss: 0.0030\n",
      "Epoch 177/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0175 - val_loss: 0.0030\n",
      "Epoch 178/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0161 - val_loss: 0.0028\n",
      "Epoch 179/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0159 - val_loss: 0.0029\n",
      "Epoch 180/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0171 - val_loss: 0.0031\n",
      "Epoch 181/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0166 - val_loss: 0.0028\n",
      "Epoch 182/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0161 - val_loss: 0.0038\n",
      "Epoch 183/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0169 - val_loss: 0.0045\n",
      "Epoch 184/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0168 - val_loss: 0.0034\n",
      "Epoch 185/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0157 - val_loss: 0.0029\n",
      "Epoch 186/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0158 - val_loss: 0.0030\n",
      "Epoch 187/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0152 - val_loss: 0.0034\n",
      "Epoch 188/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0163 - val_loss: 0.0051\n",
      "Epoch 189/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0171 - val_loss: 0.0030\n",
      "Epoch 190/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0157 - val_loss: 0.0030\n",
      "Epoch 191/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0152 - val_loss: 0.0046\n",
      "Epoch 192/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0164 - val_loss: 0.0031\n",
      "Epoch 193/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0147 - val_loss: 0.0030\n",
      "Epoch 194/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0143 - val_loss: 0.0036\n",
      "Epoch 195/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0153 - val_loss: 0.0045\n",
      "Epoch 196/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0153 - val_loss: 0.0029\n",
      "Epoch 197/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0140 - val_loss: 0.0030\n",
      "Epoch 198/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0144 - val_loss: 0.0027\n",
      "Epoch 199/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0146 - val_loss: 0.0031\n",
      "Epoch 200/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0140 - val_loss: 0.0029\n",
      "Epoch 201/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 202/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0143 - val_loss: 0.0030\n",
      "Epoch 203/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0139 - val_loss: 0.0031\n",
      "Epoch 204/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0142 - val_loss: 0.0031\n",
      "Epoch 205/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0141 - val_loss: 0.0029\n",
      "Epoch 206/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0137 - val_loss: 0.0028\n",
      "Epoch 207/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0136 - val_loss: 0.0035\n",
      "Epoch 208/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0141 - val_loss: 0.0038\n",
      "Epoch 209/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0138 - val_loss: 0.0031\n",
      "Epoch 210/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0127 - val_loss: 0.0028\n",
      "Epoch 211/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0128 - val_loss: 0.0027\n",
      "Epoch 212/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0126 - val_loss: 0.0029\n",
      "Epoch 213/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0137 - val_loss: 0.0034\n",
      "Epoch 214/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0134 - val_loss: 0.0030\n",
      "Epoch 215/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0139 - val_loss: 0.0033\n",
      "Epoch 216/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0127 - val_loss: 0.0028\n",
      "Epoch 217/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0125 - val_loss: 0.0027\n",
      "Epoch 218/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0127 - val_loss: 0.0027\n",
      "Epoch 219/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0129 - val_loss: 0.0032\n",
      "Epoch 220/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0129 - val_loss: 0.0029\n",
      "Epoch 221/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0126 - val_loss: 0.0028\n",
      "Epoch 222/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 223/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 224/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 225/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0120 - val_loss: 0.0029\n",
      "Epoch 226/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0114 - val_loss: 0.0027\n",
      "Epoch 227/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0119 - val_loss: 0.0029\n",
      "Epoch 228/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0123 - val_loss: 0.0043\n",
      "Epoch 229/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0126 - val_loss: 0.0028\n",
      "Epoch 230/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 231/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0113 - val_loss: 0.0028\n",
      "Epoch 232/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0113 - val_loss: 0.0027\n",
      "Epoch 233/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 234/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0121 - val_loss: 0.0030\n",
      "Epoch 235/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0109 - val_loss: 0.0028\n",
      "Epoch 236/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0109 - val_loss: 0.0030\n",
      "Epoch 237/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0120 - val_loss: 0.0031\n",
      "Epoch 238/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 239/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 240/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0102 - val_loss: 0.0034\n",
      "Epoch 241/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0114 - val_loss: 0.0028\n",
      "Epoch 242/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 243/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0099 - val_loss: 0.0028\n",
      "Epoch 244/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0109 - val_loss: 0.0033\n",
      "Epoch 245/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 246/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0104 - val_loss: 0.0029\n",
      "Epoch 247/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 248/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0100 - val_loss: 0.0031\n",
      "Epoch 249/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0098 - val_loss: 0.0028\n",
      "Epoch 250/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 251/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0113 - val_loss: 0.0030\n",
      "Epoch 252/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0098 - val_loss: 0.0028\n",
      "Epoch 253/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0098 - val_loss: 0.0027\n",
      "Epoch 254/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 255/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0097 - val_loss: 0.0034\n",
      "Epoch 256/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 257/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0096 - val_loss: 0.0028\n",
      "Epoch 258/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0095 - val_loss: 0.0027\n",
      "Epoch 259/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0092 - val_loss: 0.0034\n",
      "Epoch 260/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 261/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 262/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0092 - val_loss: 0.0026\n",
      "Epoch 263/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0088 - val_loss: 0.0030\n",
      "Epoch 264/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0101 - val_loss: 0.0041\n",
      "Epoch 265/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0104 - val_loss: 0.0027\n",
      "Epoch 266/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 267/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 268/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 269/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 270/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 271/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 272/500\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 0.008 - 0s 70us/step - loss: 0.0085 - val_loss: 0.0028\n",
      "Epoch 273/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 274/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 275/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 276/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 277/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 278/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0090 - val_loss: 0.0027\n",
      "Epoch 279/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 280/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0082 - val_loss: 0.0031\n",
      "Epoch 281/500\n",
      "2839/2839 [==============================] - 0s 97us/step - loss: 0.0089 - val_loss: 0.0029\n",
      "Epoch 282/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 283/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 284/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 285/500\n",
      "2839/2839 [==============================] - 0s 107us/step - loss: 0.0090 - val_loss: 0.0032\n",
      "Epoch 286/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 287/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 288/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 289/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0080 - val_loss: 0.0035\n",
      "Epoch 290/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0084 - val_loss: 0.0029\n",
      "Epoch 291/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 292/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0072 - val_loss: 0.0027\n",
      "Epoch 293/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 294/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 295/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0086 - val_loss: 0.0028\n",
      "Epoch 296/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 297/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 298/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 299/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 300/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 301/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0098 - val_loss: 0.0027\n",
      "Epoch 302/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 303/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 304/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 305/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0071 - val_loss: 0.0025\n",
      "Epoch 306/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 307/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 308/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 310/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 311/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 312/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 313/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0063 - val_loss: 0.0027\n",
      "Epoch 314/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 315/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 316/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 317/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 318/500\n",
      "2839/2839 [==============================] - 0s 86us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 319/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 320/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 321/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0071 - val_loss: 0.0025\n",
      "Epoch 322/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 323/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 324/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 325/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 326/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 327/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 328/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 329/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 330/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 331/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 332/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 333/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 334/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 335/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 336/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 337/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 338/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 339/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 340/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 341/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 342/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 343/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 344/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 345/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 346/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 347/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 348/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 349/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 350/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 351/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 352/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 353/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 354/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 355/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 356/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 357/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 358/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 359/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 360/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 361/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 362/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 363/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 364/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 365/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 366/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 367/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 368/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 369/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 370/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 371/500\n",
      "2839/2839 [==============================] - 0s 71us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 372/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 373/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 374/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 375/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 376/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 377/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 378/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 379/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 380/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 381/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 382/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 383/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 384/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 385/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 386/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 387/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 388/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 389/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 390/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 391/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 392/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 393/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 394/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 395/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 396/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 397/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 398/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 399/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 400/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 401/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 402/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 403/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 404/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 405/500\n",
      "2839/2839 [==============================] - 0s 69us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 406/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 407/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 408/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 409/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 410/500\n",
      "2839/2839 [==============================] - 0s 60us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 411/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 412/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 413/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 414/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 415/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 416/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 417/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 418/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 419/500\n",
      "2839/2839 [==============================] - 0s 100us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 420/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 421/500\n",
      "2839/2839 [==============================] - 0s 84us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 422/500\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 423/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 424/500\n",
      "2839/2839 [==============================] - 0s 66us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 425/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 426/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 427/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 428/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 429/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 430/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 431/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 432/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 433/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 434/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 435/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 436/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 437/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 438/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 439/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 440/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 441/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 442/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 443/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 444/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 445/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 446/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 447/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 448/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 449/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 450/500\n",
      "2839/2839 [==============================] - 0s 67us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 451/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 452/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 453/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 454/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 455/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 456/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 457/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 458/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 459/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 460/500\n",
      "2839/2839 [==============================] - 0s 79us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 461/500\n",
      "2839/2839 [==============================] - 0s 87us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 462/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 464/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 465/500\n",
      "2839/2839 [==============================] - 0s 73us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 466/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 467/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 468/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 469/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 470/500\n",
      "2839/2839 [==============================] - 0s 83us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 471/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 472/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 473/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 474/500\n",
      "2839/2839 [==============================] - 0s 64us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 475/500\n",
      "2839/2839 [==============================] - 0s 80us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 476/500\n",
      "2839/2839 [==============================] - 0s 78us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 477/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 478/500\n",
      "2839/2839 [==============================] - 0s 81us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 479/500\n",
      "2839/2839 [==============================] - 0s 70us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 480/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 481/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 482/500\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 483/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 484/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 485/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 486/500\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 487/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 488/500\n",
      "2839/2839 [==============================] - 0s 72us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 489/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 490/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 491/500\n",
      "2839/2839 [==============================] - 0s 74us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 492/500\n",
      "2839/2839 [==============================] - 0s 65us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 493/500\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 494/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 495/500\n",
      "2839/2839 [==============================] - 0s 76us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 496/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 497/500\n",
      "2839/2839 [==============================] - 0s 68us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 498/500\n",
      "2839/2839 [==============================] - 0s 62us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 499/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 500/500\n",
      "2839/2839 [==============================] - 0s 77us/step - loss: 0.0028 - val_loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b561c50>"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_w2v, y=y_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_test_w2v),\n",
    "          callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switching to categorical model and generating metrics to analyze performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating metrics for categorical model\n",
    "def model_metrics(predictions, y_test, x_train):\n",
    "    df = pd.DataFrame(predictions) \n",
    "    zips = x_train.index\n",
    "    df['zips'] = zips\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    # predicting a loss 3% or larger by seeing if max loss probability is higher then slight gain\n",
    "    df['loss'] = np.where(df[0] > df[3], 1, 0)\n",
    "    # predicting a gain 3% or larger by seeing if max gain probability is higher then slight loss\n",
    "    df['gain'] = np.where(df[4] > df[1], 1, 0)\n",
    "    df = pd.merge(df, y_test, left_index=True, right_index=True, how='inner')\n",
    "    # predicting a loss 3% or larger by seeing if max loss probability is higher then mean probibility \n",
    "    df['loss_large'] = np.where(df[0] > df[2], 1, 0)\n",
    "    # predicting a gain 3% or larger by seeing if max gain probability is higher then mean probibility \n",
    "    df['gain_large'] = np.where(df[4] > df[2], 1, 0)\n",
    "    # Cheching if loss is predicted and a loss of 3% or more occurs\n",
    "    df['loss_true_true'] = np.where((df['loss'] == 1) & ((df['2'] == 1) | (df['1'] == 1)), 1, 0)\n",
    "    # Checking if loss is predicted and price stays at the mean\n",
    "    df['loss_stay'] = np.where((df['loss'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if large loss is predicted and a loss of 3% or more occurs\n",
    "    df['loss_large_true'] = np.where((df['loss_large'] == 1) & ((df['2'] == 1) | (df['1'] == 1)), 1, 0)\n",
    "    # Cheching if large loss is predicted and price stays at the mean\n",
    "    df['loss_large_stay'] = np.where((df['loss_large'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if gain is predicted and a loss of 3% or more occurs\n",
    "    df['gain_true_true'] = np.where((df['gain'] == 1) & ((df['4'] == 1) | (df['5'] == 1)), 1, 0)\n",
    "    # Checking if gain is predicted and price stays at the mean\n",
    "    df['gain_stay'] = np.where((df['gain'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    # Cheching if large gain is predicted and a gain of 3% or more occurs\n",
    "    df['gain_large_true'] = np.where((df['gain_large'] == 1) & ((df['4'] == 1) | (df['5'] == 1)), 1, 0)\n",
    "    # Cheching if large gain is predicted and price stays at the mean\n",
    "    df['gain_large_stay'] = np.where((df['gain_large'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    #df['gain_large_large'] = np.where((df['gain_large'] == 1) & (df['5'] == 1), 1, 0)\n",
    "    # Checking if both loss and gain are selected. This appears to mean high volitility\n",
    "    df['volitile'] = np.where((df['loss'] == 1) & (df['gain'] == 1), 1, 0)\n",
    "    df['top_vs_mean_low'] = (df[4] + df[3]) - (df[2] + df[1])\n",
    "    #df['zips'] = df.index\n",
    "    df = df.sort_values('top_vs_mean_low', ascending=False)\n",
    "    top_10 = []\n",
    "    # Here I switched 10% to 15% to generate a better comparison. In production this may revert to 10%\n",
    "    top = round(len(df) * .15)\n",
    "    for num in range(top):\n",
    "        top_10.append(1)\n",
    "    finish_list = len(df) - len(top_10)\n",
    "    for num in range(finish_list):\n",
    "        top_10.append(0)\n",
    "    df['top_vs_mean_low_select'] = top_10\n",
    "    df['top_vs_mean_low_select_true'] = np.where((df['top_vs_mean_low_select'] == 1) & ((df['4'] == 1) | (df['5'] == 1)), 1, 0)\n",
    "    df['top_vs_mean_low_select_large'] = np.where((df['top_vs_mean_low_select'] == 1) & (df['5'] == 1), 1, 0)\n",
    "    df['gain_large_true_large'] = np.where((df['gain'] == 1) & (df['5'] == 1), 1, 0)\n",
    "    df['top_vs_mean_low_select_mean'] = np.where((df['top_vs_mean_low_select'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    df['predicted_classes'] = predicted_classes\n",
    "    df['predicted_classes_gain'] = np.where((df['predicted_classes'] == 3) | (df['predicted_classes'] == 4) , 1, 0)\n",
    "    df['predicted_classes_gain_true'] = np.where((df['predicted_classes_gain'] == 1)  & ((df['4'] == 1) | (df['5'] == 1)), 1, 0)\n",
    "    df['predicted_classes_gain_large_true'] = np.where((df['predicted_classes_gain'] == 1) & (df['5'] == 1), 1, 0)\n",
    "    df['predicted_classes_gain_mean'] = np.where((df['predicted_classes_gain'] == 1) & (df['3'] == 1), 1, 0)\n",
    "    df['gain_true'] = np.where((df['4'] == 1) | (df['5'] == 1), 1, 0)\n",
    "    df = df.set_index('zips')\n",
    "    \n",
    "    gain_pred = df['gain'].sum()\n",
    "    gain_large_pred = df['gain_large'].sum()\n",
    "    \n",
    "    gain_stay_true = (df['gain_true_true'].sum() + df['gain_stay'].sum()) / df['gain'].sum()\n",
    "    \n",
    "    # Since we are focused on gain at the moment the loss predictions are commited out. This may change in production\n",
    "    gain_true = df['gain_true_true'].sum() / df['gain'].sum()\n",
    "    #loss_stay_true = (df['loss_true_true'].sum() + df['loss_stay'].sum()) / df['loss'].sum()\n",
    "    #loss_stay_true = df['loss_true_true'].sum() / df['loss'].sum()\n",
    "    gain_stay_large_true = (df['gain_large_true'].sum() + df['gain_large_stay'].sum()) / df['gain_large'].sum()\n",
    "    gain_large_true = df['gain_large_true'].sum() / df['gain_large'].sum()\n",
    "    #loss_stay_large_true = (df['loss_large_true'].sum() + df['loss_large_stay']) / df['loss_large'].sum()\n",
    "    #loss_large_true = df['loss_large_true'].sum() / df['loss_large'].sum()\n",
    "    volitile = df['volitile'].sum()\n",
    "    four_five_split = df['top_vs_mean_low_select_true'].sum() / df['top_vs_mean_low_select'].sum()\n",
    "    four_five_split_large = df['top_vs_mean_low_select_large'].sum() / df['top_vs_mean_low_select'].sum()\n",
    "    four_five_split_mean = (df['top_vs_mean_low_select_true'].sum() + df['top_vs_mean_low_select_mean'].sum()) / df['top_vs_mean_low_select'].sum()\n",
    "    predicted_classes_gain_true = df['predicted_classes_gain_true'].sum() / df['predicted_classes_gain'].sum()\n",
    "    predicted_classes_gain_large_true = df['predicted_classes_gain_large_true'].sum() / df['predicted_classes_gain'].sum()\n",
    "    predicted_classes_gain_mean = (df['predicted_classes_gain_true'].sum() + df['predicted_classes_gain_mean'].sum()) / df['predicted_classes_gain'].sum()\n",
    "    gain_true_large = df['gain_large_true_large'].sum() / df['gain'].sum()\n",
    "    return gain_pred, gain_true_large, gain_true, gain_stay_true, four_five_split_large, four_five_split, four_five_split_mean, predicted_classes_gain_true, predicted_classes_gain_large_true, predicted_classes_gain_mean, df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding weights to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {0 : 2,\n",
    "    1: 1,\n",
    "    2: .5,\n",
    "    3: 1,\n",
    "    4: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 16s 6ms/step - loss: 1.8391 - acc: 0.3047 - val_loss: 1.8220 - val_acc: 0.3384\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.6948 - acc: 0.3653 - val_loss: 1.7596 - val_acc: 0.3293\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6571 - acc: 0.3776 - val_loss: 1.7454 - val_acc: 0.3293\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6190 - acc: 0.3861 - val_loss: 1.7388 - val_acc: 0.3293\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.6153 - acc: 0.3949 - val_loss: 1.6858 - val_acc: 0.3384\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5957 - acc: 0.3956 - val_loss: 1.6906 - val_acc: 0.3384\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5741 - acc: 0.3853 - val_loss: 1.7024 - val_acc: 0.3293\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5659 - acc: 0.4019 - val_loss: 1.6733 - val_acc: 0.3353\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5553 - acc: 0.3875 - val_loss: 1.6935 - val_acc: 0.3233\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.5216 - acc: 0.4068 - val_loss: 1.7247 - val_acc: 0.3172\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5216 - acc: 0.4100 - val_loss: 1.6749 - val_acc: 0.3233\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5279 - acc: 0.4082 - val_loss: 1.7014 - val_acc: 0.3172\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5247 - acc: 0.3980 - val_loss: 1.7532 - val_acc: 0.3142\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4997 - acc: 0.3959 - val_loss: 1.6268 - val_acc: 0.3142\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4932 - acc: 0.3998 - val_loss: 1.6293 - val_acc: 0.3142\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4770 - acc: 0.4107 - val_loss: 1.6783 - val_acc: 0.3142\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4778 - acc: 0.4181 - val_loss: 1.6388 - val_acc: 0.3082\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4735 - acc: 0.4093 - val_loss: 1.5498 - val_acc: 0.3323\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.4919 - acc: 0.424 - 0s 35us/step - loss: 1.4764 - acc: 0.4142 - val_loss: 1.5869 - val_acc: 0.3233\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4422 - acc: 0.4301 - val_loss: 1.5688 - val_acc: 0.3142\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4418 - acc: 0.4223 - val_loss: 1.6054 - val_acc: 0.3051\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4381 - acc: 0.4255 - val_loss: 1.6912 - val_acc: 0.3082\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4427 - acc: 0.4015 - val_loss: 1.6195 - val_acc: 0.3202\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4113 - acc: 0.4185 - val_loss: 1.5700 - val_acc: 0.3172\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4215 - acc: 0.4244 - val_loss: 1.5365 - val_acc: 0.3142\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4335 - acc: 0.4308 - val_loss: 1.6194 - val_acc: 0.3233\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4001 - acc: 0.4241 - val_loss: 1.5831 - val_acc: 0.3444\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4135 - acc: 0.4174 - val_loss: 1.5728 - val_acc: 0.3263\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3947 - acc: 0.4301 - val_loss: 1.5427 - val_acc: 0.3263\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4135 - acc: 0.4347 - val_loss: 1.6300 - val_acc: 0.3263\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3964 - acc: 0.4378 - val_loss: 1.7421 - val_acc: 0.3082\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4019 - acc: 0.4251 - val_loss: 1.6723 - val_acc: 0.3082\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.3794 - acc: 0.4276 - val_loss: 1.6321 - val_acc: 0.3172\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3663 - acc: 0.4248 - val_loss: 1.6340 - val_acc: 0.3142\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3651 - acc: 0.4417 - val_loss: 1.7128 - val_acc: 0.2961\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3846 - acc: 0.4266 - val_loss: 1.6614 - val_acc: 0.3082\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3635 - acc: 0.4389 - val_loss: 1.6308 - val_acc: 0.3263\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3475 - acc: 0.4431 - val_loss: 1.6320 - val_acc: 0.3323\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3505 - acc: 0.4371 - val_loss: 1.6317 - val_acc: 0.3172\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3426 - acc: 0.4340 - val_loss: 1.5640 - val_acc: 0.3776\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3402 - acc: 0.4452 - val_loss: 1.5534 - val_acc: 0.3474\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3203 - acc: 0.4428 - val_loss: 1.4717 - val_acc: 0.3656\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3398 - acc: 0.4385 - val_loss: 1.4506 - val_acc: 0.3595\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3483 - acc: 0.4406 - val_loss: 1.4418 - val_acc: 0.4079\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3276 - acc: 0.4723 - val_loss: 1.5535 - val_acc: 0.3444\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3003 - acc: 0.4576 - val_loss: 1.5761 - val_acc: 0.3353\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.3020 - acc: 0.4480 - val_loss: 1.5459 - val_acc: 0.3474\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2916 - acc: 0.4621 - val_loss: 1.5395 - val_acc: 0.3565\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2968 - acc: 0.4590 - val_loss: 1.6663 - val_acc: 0.3142\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3234 - acc: 0.4396 - val_loss: 1.6510 - val_acc: 0.3112\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3069 - acc: 0.4368 - val_loss: 1.5960 - val_acc: 0.3565\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3023 - acc: 0.4361 - val_loss: 1.5214 - val_acc: 0.3958\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2749 - acc: 0.4583 - val_loss: 1.5373 - val_acc: 0.3958\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2762 - acc: 0.4547 - val_loss: 1.4589 - val_acc: 0.4532\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2831 - acc: 0.4671 - val_loss: 1.4187 - val_acc: 0.4562\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2831 - acc: 0.4720 - val_loss: 1.3903 - val_acc: 0.4350\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2833 - acc: 0.4805 - val_loss: 1.4457 - val_acc: 0.4441\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2732 - acc: 0.4625 - val_loss: 1.4427 - val_acc: 0.4230\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 48us/step - loss: 1.2509 - acc: 0.4797 - val_loss: 1.4135 - val_acc: 0.4139\n",
      "Epoch 60/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.2776 - acc: 0.4797 - val_loss: 1.4692 - val_acc: 0.4139\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2607 - acc: 0.4780 - val_loss: 1.5212 - val_acc: 0.4230\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2572 - acc: 0.4713 - val_loss: 1.6011 - val_acc: 0.3837\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.2942 - acc: 0.4463 - val_loss: 1.5939 - val_acc: 0.3776\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2600 - acc: 0.4646 - val_loss: 1.5001 - val_acc: 0.4139\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2273 - acc: 0.4727 - val_loss: 1.4443 - val_acc: 0.4290\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2441 - acc: 0.4748 - val_loss: 1.4229 - val_acc: 0.4592\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2404 - acc: 0.4882 - val_loss: 1.3370 - val_acc: 0.5166\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2699 - acc: 0.4783 - val_loss: 1.3980 - val_acc: 0.4592\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2284 - acc: 0.4871 - val_loss: 1.4369 - val_acc: 0.4502\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2147 - acc: 0.4812 - val_loss: 1.4653 - val_acc: 0.4411\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2322 - acc: 0.4850 - val_loss: 1.5169 - val_acc: 0.4290\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2307 - acc: 0.4706 - val_loss: 1.5344 - val_acc: 0.4018\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2391 - acc: 0.4695 - val_loss: 1.6608 - val_acc: 0.3686\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2602 - acc: 0.4364 - val_loss: 1.5348 - val_acc: 0.3927\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2113 - acc: 0.4716 - val_loss: 1.4540 - val_acc: 0.4471\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2151 - acc: 0.4780 - val_loss: 1.4236 - val_acc: 0.4471\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1731 - acc: 0.4956 - val_loss: 1.3717 - val_acc: 0.5257\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1992 - acc: 0.5076 - val_loss: 1.3355 - val_acc: 0.5559\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2201 - acc: 0.4952 - val_loss: 1.3377 - val_acc: 0.5468\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2198 - acc: 0.4889 - val_loss: 1.3655 - val_acc: 0.5317\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1984 - acc: 0.5086 - val_loss: 1.4452 - val_acc: 0.4804\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2042 - acc: 0.4924 - val_loss: 1.3892 - val_acc: 0.4955\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1852 - acc: 0.4959 - val_loss: 1.3420 - val_acc: 0.5559\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1929 - acc: 0.5023 - val_loss: 1.3404 - val_acc: 0.5438\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1964 - acc: 0.5037 - val_loss: 1.3530 - val_acc: 0.5498\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1811 - acc: 0.5104 - val_loss: 1.3183 - val_acc: 0.5861\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1761 - acc: 0.5072 - val_loss: 1.3526 - val_acc: 0.5136\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1827 - acc: 0.5062 - val_loss: 1.3336 - val_acc: 0.5559\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1760 - acc: 0.5037 - val_loss: 1.3098 - val_acc: 0.5740\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1929 - acc: 0.5104 - val_loss: 1.3474 - val_acc: 0.5227\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1850 - acc: 0.5044 - val_loss: 1.3664 - val_acc: 0.5015\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1698 - acc: 0.5146 - val_loss: 1.3999 - val_acc: 0.5015\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1568 - acc: 0.4991 - val_loss: 1.3968 - val_acc: 0.4955\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1423 - acc: 0.5220 - val_loss: 1.4253 - val_acc: 0.5015\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1439 - acc: 0.5058 - val_loss: 1.5084 - val_acc: 0.4290\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1757 - acc: 0.4903 - val_loss: 1.4681 - val_acc: 0.4562\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1710 - acc: 0.5009 - val_loss: 1.5236 - val_acc: 0.4139\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1808 - acc: 0.4840 - val_loss: 1.4614 - val_acc: 0.4713\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1428 - acc: 0.5009 - val_loss: 1.4165 - val_acc: 0.4894\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1334 - acc: 0.5153 - val_loss: 1.4468 - val_acc: 0.4773\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1542 - acc: 0.5016 - val_loss: 1.4404 - val_acc: 0.4804\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1339 - acc: 0.5072 - val_loss: 1.3978 - val_acc: 0.4743\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1343 - acc: 0.5111 - val_loss: 1.3632 - val_acc: 0.5106\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1435 - acc: 0.5058 - val_loss: 1.3199 - val_acc: 0.5680\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1395 - acc: 0.5188 - val_loss: 1.3076 - val_acc: 0.5317\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1694 - acc: 0.5030 - val_loss: 1.3133 - val_acc: 0.5287\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1805 - acc: 0.5262 - val_loss: 1.3483 - val_acc: 0.5166\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1333 - acc: 0.5086 - val_loss: 1.3247 - val_acc: 0.5317\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1267 - acc: 0.5164 - val_loss: 1.3777 - val_acc: 0.4985\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1362 - acc: 0.5167 - val_loss: 1.4092 - val_acc: 0.4834\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1362 - acc: 0.5171 - val_loss: 1.4252 - val_acc: 0.4743\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1146 - acc: 0.5093 - val_loss: 1.4355 - val_acc: 0.4713\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1271 - acc: 0.5062 - val_loss: 1.5178 - val_acc: 0.3958\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1410 - acc: 0.4945 - val_loss: 1.4439 - val_acc: 0.4381\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1099 - acc: 0.5097 - val_loss: 1.4732 - val_acc: 0.4381\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1268 - acc: 0.5051 - val_loss: 1.4971 - val_acc: 0.4230\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1273 - acc: 0.5076 - val_loss: 1.5087 - val_acc: 0.4381\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1371 - acc: 0.4959 - val_loss: 1.4820 - val_acc: 0.4441\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1178 - acc: 0.5069 - val_loss: 1.4844 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1050 - acc: 0.5129 - val_loss: 1.3896 - val_acc: 0.4773\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1061 - acc: 0.5319 - val_loss: 1.3848 - val_acc: 0.4743\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1001 - acc: 0.5375 - val_loss: 1.3244 - val_acc: 0.5136\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1233 - acc: 0.5312 - val_loss: 1.3224 - val_acc: 0.5257\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1013 - acc: 0.5350 - val_loss: 1.3468 - val_acc: 0.5196\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0980 - acc: 0.5400 - val_loss: 1.3197 - val_acc: 0.5227\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1020 - acc: 0.5358 - val_loss: 1.3026 - val_acc: 0.5529\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1213 - acc: 0.5203 - val_loss: 1.3369 - val_acc: 0.5196\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0938 - acc: 0.5350 - val_loss: 1.3598 - val_acc: 0.5015\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0726 - acc: 0.5417 - val_loss: 1.3455 - val_acc: 0.5045\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0784 - acc: 0.5382 - val_loss: 1.2883 - val_acc: 0.5287\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1290 - acc: 0.5361 - val_loss: 1.3446 - val_acc: 0.5015\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1101 - acc: 0.5417 - val_loss: 1.4332 - val_acc: 0.4592\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0729 - acc: 0.5365 - val_loss: 1.5073 - val_acc: 0.4562\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1143 - acc: 0.5086 - val_loss: 1.5016 - val_acc: 0.4350\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0879 - acc: 0.5178 - val_loss: 1.4120 - val_acc: 0.5106\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0909 - acc: 0.5269 - val_loss: 1.4888 - val_acc: 0.4381\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0877 - acc: 0.5305 - val_loss: 1.4807 - val_acc: 0.4411\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0738 - acc: 0.5111 - val_loss: 1.4344 - val_acc: 0.4773\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0582 - acc: 0.5393 - val_loss: 1.6084 - val_acc: 0.3625\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1384 - acc: 0.4812 - val_loss: 1.4636 - val_acc: 0.4683\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0467 - acc: 0.5509 - val_loss: 1.4237 - val_acc: 0.5045\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0549 - acc: 0.5520 - val_loss: 1.5014 - val_acc: 0.4532\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0837 - acc: 0.5245 - val_loss: 1.4920 - val_acc: 0.4441\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0925 - acc: 0.5227 - val_loss: 1.4863 - val_acc: 0.4441\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0706 - acc: 0.5312 - val_loss: 1.4160 - val_acc: 0.4894\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0591 - acc: 0.5305 - val_loss: 1.4028 - val_acc: 0.4894\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0498 - acc: 0.5446 - val_loss: 1.4245 - val_acc: 0.4894\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0280 - acc: 0.5579 - val_loss: 1.3738 - val_acc: 0.5136\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0393 - acc: 0.5534 - val_loss: 1.4300 - val_acc: 0.4804\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0410 - acc: 0.5463 - val_loss: 1.4424 - val_acc: 0.4804\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0820 - acc: 0.5403 - val_loss: 1.4845 - val_acc: 0.4592\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0935 - acc: 0.5245 - val_loss: 1.6433 - val_acc: 0.3776\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1510 - acc: 0.4843 - val_loss: 1.5395 - val_acc: 0.4048\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0548 - acc: 0.5305 - val_loss: 1.3899 - val_acc: 0.5136\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0239 - acc: 0.5488 - val_loss: 1.4412 - val_acc: 0.4683\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0232 - acc: 0.5523 - val_loss: 1.5330 - val_acc: 0.4320\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0645 - acc: 0.5365 - val_loss: 1.5722 - val_acc: 0.4109\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0646 - acc: 0.5100 - val_loss: 1.4339 - val_acc: 0.4743\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0431 - acc: 0.5579 - val_loss: 1.5138 - val_acc: 0.4079\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0528 - acc: 0.5322 - val_loss: 1.4162 - val_acc: 0.4804\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0357 - acc: 0.5671 - val_loss: 1.4123 - val_acc: 0.4834\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0346 - acc: 0.5692 - val_loss: 1.4236 - val_acc: 0.4894\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0439 - acc: 0.5696 - val_loss: 1.3832 - val_acc: 0.5076\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0399 - acc: 0.5653 - val_loss: 1.3216 - val_acc: 0.5408\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.0614 - acc: 0.5548 - val_loss: 1.3265 - val_acc: 0.5166\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0627 - acc: 0.5509 - val_loss: 1.3335 - val_acc: 0.5196\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0540 - acc: 0.5579 - val_loss: 1.3535 - val_acc: 0.5076\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0099 - acc: 0.5745 - val_loss: 1.3962 - val_acc: 0.5045\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 0.9967 - acc: 0.5713 - val_loss: 1.4564 - val_acc: 0.4713\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0094 - acc: 0.5594 - val_loss: 1.4986 - val_acc: 0.4683\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0358 - acc: 0.5460 - val_loss: 1.5228 - val_acc: 0.4260\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0582 - acc: 0.5329 - val_loss: 1.4278 - val_acc: 0.4924\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0139 - acc: 0.5421 - val_loss: 1.3901 - val_acc: 0.4985\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9952 - acc: 0.5745 - val_loss: 1.3628 - val_acc: 0.5317\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0277 - acc: 0.5453 - val_loss: 1.3140 - val_acc: 0.5347\n",
      "0\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 16s 5ms/step - loss: 1.7728 - acc: 0.2413 - val_loss: 1.9732 - val_acc: 0.3323\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.7026 - acc: 0.3438 - val_loss: 1.8548 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.6555 - acc: 0.3558 - val_loss: 1.7744 - val_acc: 0.3293\n",
      "Epoch 4/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.6301 - acc: 0.3776 - val_loss: 1.7688 - val_acc: 0.3293\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6102 - acc: 0.3769 - val_loss: 1.7828 - val_acc: 0.3293\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.5861 - acc: 0.3829 - val_loss: 1.7287 - val_acc: 0.3293\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5755 - acc: 0.3956 - val_loss: 1.8074 - val_acc: 0.3293\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.5768 - acc: 0.3871 - val_loss: 1.7845 - val_acc: 0.3323\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.5689 - acc: 0.3846 - val_loss: 1.6975 - val_acc: 0.3535\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.5473 - acc: 0.4019 - val_loss: 1.7203 - val_acc: 0.3353\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5233 - acc: 0.4093 - val_loss: 1.7083 - val_acc: 0.3384\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.5230 - acc: 0.3991 - val_loss: 1.6265 - val_acc: 0.3565\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5134 - acc: 0.4209 - val_loss: 1.7118 - val_acc: 0.3384\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5066 - acc: 0.4185 - val_loss: 1.6773 - val_acc: 0.3746\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.5069 - acc: 0.4132 - val_loss: 1.7226 - val_acc: 0.3384\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4849 - acc: 0.4132 - val_loss: 1.7423 - val_acc: 0.3565\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.4709 - acc: 0.4132 - val_loss: 1.7101 - val_acc: 0.3474\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.4726 - acc: 0.4280 - val_loss: 1.5884 - val_acc: 0.3776\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4636 - acc: 0.4406 - val_loss: 1.5853 - val_acc: 0.3867\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4696 - acc: 0.4216 - val_loss: 1.5560 - val_acc: 0.4320\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4542 - acc: 0.4301 - val_loss: 1.5704 - val_acc: 0.3988\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.4336 - acc: 0.4438 - val_loss: 1.6640 - val_acc: 0.3746\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4348 - acc: 0.4220 - val_loss: 1.6707 - val_acc: 0.3807\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4292 - acc: 0.4315 - val_loss: 1.6745 - val_acc: 0.3625\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.4173 - acc: 0.4283 - val_loss: 1.6115 - val_acc: 0.3927\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.4258 - acc: 0.4361 - val_loss: 1.6219 - val_acc: 0.3837\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4079 - acc: 0.4375 - val_loss: 1.5798 - val_acc: 0.4260\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3976 - acc: 0.4442 - val_loss: 1.6407 - val_acc: 0.3807\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3870 - acc: 0.4421 - val_loss: 1.7190 - val_acc: 0.3444\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.4065 - acc: 0.4294 - val_loss: 1.7034 - val_acc: 0.3595\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3847 - acc: 0.4304 - val_loss: 1.6849 - val_acc: 0.3656\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3861 - acc: 0.4318 - val_loss: 1.5913 - val_acc: 0.3897\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3705 - acc: 0.4368 - val_loss: 1.5319 - val_acc: 0.4199\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.3671 - acc: 0.4392 - val_loss: 1.5407 - val_acc: 0.4139\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3515 - acc: 0.4695 - val_loss: 1.6354 - val_acc: 0.3867\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3698 - acc: 0.4364 - val_loss: 1.6894 - val_acc: 0.3505\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3601 - acc: 0.4329 - val_loss: 1.6511 - val_acc: 0.3716\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3657 - acc: 0.4375 - val_loss: 1.6032 - val_acc: 0.3867\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3348 - acc: 0.4523 - val_loss: 1.6107 - val_acc: 0.4018\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3365 - acc: 0.4523 - val_loss: 1.5244 - val_acc: 0.4199\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3206 - acc: 0.4660 - val_loss: 1.6138 - val_acc: 0.3867\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.3263 - acc: 0.4607 - val_loss: 1.5849 - val_acc: 0.3927\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3261 - acc: 0.4509 - val_loss: 1.6404 - val_acc: 0.3595\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3237 - acc: 0.4452 - val_loss: 1.5634 - val_acc: 0.3988\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.3243 - acc: 0.4459 - val_loss: 1.5093 - val_acc: 0.4320\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2992 - acc: 0.4667 - val_loss: 1.4541 - val_acc: 0.4592\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.3089 - acc: 0.4854 - val_loss: 1.5752 - val_acc: 0.4139\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3116 - acc: 0.4653 - val_loss: 1.6845 - val_acc: 0.3474\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3222 - acc: 0.4406 - val_loss: 1.5385 - val_acc: 0.4169\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2809 - acc: 0.4569 - val_loss: 1.5109 - val_acc: 0.4562\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2855 - acc: 0.4709 - val_loss: 1.5084 - val_acc: 0.4622\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2891 - acc: 0.4650 - val_loss: 1.5691 - val_acc: 0.4230\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2895 - acc: 0.4600 - val_loss: 1.6055 - val_acc: 0.4079\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2976 - acc: 0.4533 - val_loss: 1.6171 - val_acc: 0.3837\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2793 - acc: 0.4569 - val_loss: 1.4774 - val_acc: 0.4653\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2764 - acc: 0.4776 - val_loss: 1.4828 - val_acc: 0.4683\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.2688 - acc: 0.4808 - val_loss: 1.4663 - val_acc: 0.4653\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 53us/step - loss: 1.2652 - acc: 0.4826 - val_loss: 1.4342 - val_acc: 0.4683\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.2623 - acc: 0.4889 - val_loss: 1.4756 - val_acc: 0.4622\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2619 - acc: 0.4822 - val_loss: 1.4821 - val_acc: 0.4562\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2525 - acc: 0.4815 - val_loss: 1.5515 - val_acc: 0.4411\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2650 - acc: 0.4695 - val_loss: 1.5633 - val_acc: 0.4048\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2571 - acc: 0.4745 - val_loss: 1.5476 - val_acc: 0.4048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2473 - acc: 0.4752 - val_loss: 1.4801 - val_acc: 0.4683\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2342 - acc: 0.4783 - val_loss: 1.4478 - val_acc: 0.4924\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2416 - acc: 0.4886 - val_loss: 1.5684 - val_acc: 0.4411\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2696 - acc: 0.4558 - val_loss: 1.4997 - val_acc: 0.4562\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2373 - acc: 0.4776 - val_loss: 1.4721 - val_acc: 0.4773\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2368 - acc: 0.4801 - val_loss: 1.5283 - val_acc: 0.4320\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2294 - acc: 0.4847 - val_loss: 1.4639 - val_acc: 0.4683\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.2253 - acc: 0.4935 - val_loss: 1.4718 - val_acc: 0.4653\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2361 - acc: 0.4815 - val_loss: 1.4039 - val_acc: 0.4713\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2080 - acc: 0.5051 - val_loss: 1.3692 - val_acc: 0.5196\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2088 - acc: 0.5037 - val_loss: 1.3682 - val_acc: 0.5196\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1923 - acc: 0.4981 - val_loss: 1.3320 - val_acc: 0.5559\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2208 - acc: 0.4903 - val_loss: 1.2876 - val_acc: 0.5408\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2554 - acc: 0.5097 - val_loss: 1.3354 - val_acc: 0.5408\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2109 - acc: 0.5048 - val_loss: 1.3398 - val_acc: 0.5468\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1969 - acc: 0.5033 - val_loss: 1.3332 - val_acc: 0.5680\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1834 - acc: 0.5319 - val_loss: 1.3177 - val_acc: 0.5801\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1983 - acc: 0.5062 - val_loss: 1.2855 - val_acc: 0.5529\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2216 - acc: 0.5037 - val_loss: 1.3396 - val_acc: 0.5045\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2096 - acc: 0.5044 - val_loss: 1.3688 - val_acc: 0.5257\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1830 - acc: 0.5210 - val_loss: 1.4254 - val_acc: 0.4924\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2026 - acc: 0.4995 - val_loss: 1.4983 - val_acc: 0.4502\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1901 - acc: 0.5026 - val_loss: 1.3816 - val_acc: 0.5287\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1731 - acc: 0.5076 - val_loss: 1.3278 - val_acc: 0.5801\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1675 - acc: 0.5298 - val_loss: 1.3527 - val_acc: 0.5438\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1673 - acc: 0.5125 - val_loss: 1.3489 - val_acc: 0.5589\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1506 - acc: 0.5129 - val_loss: 1.3541 - val_acc: 0.5438\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1686 - acc: 0.5213 - val_loss: 1.4344 - val_acc: 0.4773\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1906 - acc: 0.5037 - val_loss: 1.6488 - val_acc: 0.3776\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2473 - acc: 0.4505 - val_loss: 1.4075 - val_acc: 0.4864\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1705 - acc: 0.4984 - val_loss: 1.4328 - val_acc: 0.4743\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1530 - acc: 0.5125 - val_loss: 1.3312 - val_acc: 0.5438\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1522 - acc: 0.5238 - val_loss: 1.3997 - val_acc: 0.5076\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1643 - acc: 0.5041 - val_loss: 1.4333 - val_acc: 0.4653\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1679 - acc: 0.5019 - val_loss: 1.4357 - val_acc: 0.4683\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1813 - acc: 0.4952 - val_loss: 1.4785 - val_acc: 0.4562\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1742 - acc: 0.4889 - val_loss: 1.4265 - val_acc: 0.4622\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1456 - acc: 0.5093 - val_loss: 1.3604 - val_acc: 0.5287\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1410 - acc: 0.5157 - val_loss: 1.3112 - val_acc: 0.5619\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1473 - acc: 0.5241 - val_loss: 1.3142 - val_acc: 0.5498\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1445 - acc: 0.5069 - val_loss: 1.2999 - val_acc: 0.5529\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1514 - acc: 0.5122 - val_loss: 1.2972 - val_acc: 0.5559\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1451 - acc: 0.5153 - val_loss: 1.2723 - val_acc: 0.5740\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1544 - acc: 0.5231 - val_loss: 1.2611 - val_acc: 0.5801\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1596 - acc: 0.5262 - val_loss: 1.2851 - val_acc: 0.5710\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1373 - acc: 0.5227 - val_loss: 1.2915 - val_acc: 0.5770\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1275 - acc: 0.5280 - val_loss: 1.2687 - val_acc: 0.5710\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1406 - acc: 0.5347 - val_loss: 1.2611 - val_acc: 0.5650\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1478 - acc: 0.5220 - val_loss: 1.2878 - val_acc: 0.5831\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1216 - acc: 0.5389 - val_loss: 1.2773 - val_acc: 0.5921\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1217 - acc: 0.5280 - val_loss: 1.3036 - val_acc: 0.5498\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1259 - acc: 0.5294 - val_loss: 1.3065 - val_acc: 0.5468\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1561 - acc: 0.5252 - val_loss: 1.2975 - val_acc: 0.5468\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1128 - acc: 0.5463 - val_loss: 1.2723 - val_acc: 0.5861\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1369 - acc: 0.5340 - val_loss: 1.2741 - val_acc: 0.5801\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1157 - acc: 0.5484 - val_loss: 1.2721 - val_acc: 0.5861\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1000 - acc: 0.5379 - val_loss: 1.2917 - val_acc: 0.5619\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0862 - acc: 0.5481 - val_loss: 1.2695 - val_acc: 0.5710\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1122 - acc: 0.5312 - val_loss: 1.2684 - val_acc: 0.5831\n",
      "Epoch 123/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1388 - acc: 0.5470 - val_loss: 1.2774 - val_acc: 0.5680\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0985 - acc: 0.5424 - val_loss: 1.2956 - val_acc: 0.5498\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1069 - acc: 0.5255 - val_loss: 1.3098 - val_acc: 0.5227\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0831 - acc: 0.5594 - val_loss: 1.3705 - val_acc: 0.4864\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1018 - acc: 0.5365 - val_loss: 1.5104 - val_acc: 0.4109\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1695 - acc: 0.4815 - val_loss: 1.3850 - val_acc: 0.4743\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0982 - acc: 0.5298 - val_loss: 1.3344 - val_acc: 0.5619\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0869 - acc: 0.5368 - val_loss: 1.3532 - val_acc: 0.5347\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0909 - acc: 0.5361 - val_loss: 1.5723 - val_acc: 0.3897\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1593 - acc: 0.4903 - val_loss: 1.3504 - val_acc: 0.5287\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0803 - acc: 0.5456 - val_loss: 1.3468 - val_acc: 0.5378\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0843 - acc: 0.5322 - val_loss: 1.3254 - val_acc: 0.5619\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0897 - acc: 0.5414 - val_loss: 1.3311 - val_acc: 0.5559\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0732 - acc: 0.5343 - val_loss: 1.3055 - val_acc: 0.5740\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0674 - acc: 0.5449 - val_loss: 1.2752 - val_acc: 0.5710\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0870 - acc: 0.5484 - val_loss: 1.2482 - val_acc: 0.5680\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0946 - acc: 0.5629 - val_loss: 1.2808 - val_acc: 0.5438\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1090 - acc: 0.5488 - val_loss: 1.3063 - val_acc: 0.5166\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0582 - acc: 0.5488 - val_loss: 1.2730 - val_acc: 0.5589\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0830 - acc: 0.5442 - val_loss: 1.2579 - val_acc: 0.5770\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1056 - acc: 0.5354 - val_loss: 1.2730 - val_acc: 0.5770\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0622 - acc: 0.5646 - val_loss: 1.2909 - val_acc: 0.5378\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0559 - acc: 0.5590 - val_loss: 1.2817 - val_acc: 0.5257\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0539 - acc: 0.5590 - val_loss: 1.2874 - val_acc: 0.5227\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0697 - acc: 0.5463 - val_loss: 1.2871 - val_acc: 0.5408\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1103 - acc: 0.5368 - val_loss: 1.2657 - val_acc: 0.5680\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0798 - acc: 0.5615 - val_loss: 1.3050 - val_acc: 0.5408\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0372 - acc: 0.5713 - val_loss: 1.2943 - val_acc: 0.5468\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0411 - acc: 0.5745 - val_loss: 1.2808 - val_acc: 0.5891\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0805 - acc: 0.5403 - val_loss: 1.2783 - val_acc: 0.5952\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0876 - acc: 0.5474 - val_loss: 1.3038 - val_acc: 0.5529\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0313 - acc: 0.5720 - val_loss: 1.2826 - val_acc: 0.5529\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0157 - acc: 0.5886 - val_loss: 1.2823 - val_acc: 0.5287\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0510 - acc: 0.5583 - val_loss: 1.2751 - val_acc: 0.5438\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0950 - acc: 0.5477 - val_loss: 1.2689 - val_acc: 0.5468\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0680 - acc: 0.5572 - val_loss: 1.2999 - val_acc: 0.5287\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0239 - acc: 0.5727 - val_loss: 1.2850 - val_acc: 0.5468\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0392 - acc: 0.5594 - val_loss: 1.2837 - val_acc: 0.5498\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0371 - acc: 0.5558 - val_loss: 1.2633 - val_acc: 0.5680\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1069 - acc: 0.5421 - val_loss: 1.2766 - val_acc: 0.5589\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0467 - acc: 0.5608 - val_loss: 1.2937 - val_acc: 0.5257\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0483 - acc: 0.5664 - val_loss: 1.3261 - val_acc: 0.5287\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0181 - acc: 0.5780 - val_loss: 1.3380 - val_acc: 0.4985\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0198 - acc: 0.5653 - val_loss: 1.3265 - val_acc: 0.5106\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0303 - acc: 0.5706 - val_loss: 1.3020 - val_acc: 0.5227\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0315 - acc: 0.5731 - val_loss: 1.2610 - val_acc: 0.5589\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0935 - acc: 0.5491 - val_loss: 1.2691 - val_acc: 0.5589\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0281 - acc: 0.5745 - val_loss: 1.3074 - val_acc: 0.5106\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0038 - acc: 0.5798 - val_loss: 1.3120 - val_acc: 0.5468\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0165 - acc: 0.5840 - val_loss: 1.3082 - val_acc: 0.5740\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0457 - acc: 0.5527 - val_loss: 1.3178 - val_acc: 0.5619\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0324 - acc: 0.5495 - val_loss: 1.3127 - val_acc: 0.5710\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 0.9961 - acc: 0.5766 - val_loss: 1.2564 - val_acc: 0.5740\n",
      "1\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 16s 6ms/step - loss: 1.8354 - acc: 0.2244 - val_loss: 1.9412 - val_acc: 0.3323\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.7015 - acc: 0.3614 - val_loss: 1.8387 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.6561 - acc: 0.3829 - val_loss: 1.8256 - val_acc: 0.3263\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6447 - acc: 0.3716 - val_loss: 1.7854 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6265 - acc: 0.3868 - val_loss: 1.7808 - val_acc: 0.3263\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6117 - acc: 0.3748 - val_loss: 1.7153 - val_acc: 0.3263\n",
      "Epoch 7/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5966 - acc: 0.3956 - val_loss: 1.7411 - val_acc: 0.3202\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5759 - acc: 0.3875 - val_loss: 1.7252 - val_acc: 0.3233\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5861 - acc: 0.3811 - val_loss: 1.7166 - val_acc: 0.3233\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5552 - acc: 0.3924 - val_loss: 1.7008 - val_acc: 0.3323\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5475 - acc: 0.4178 - val_loss: 1.7530 - val_acc: 0.3172\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5394 - acc: 0.3959 - val_loss: 1.7414 - val_acc: 0.3172\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5204 - acc: 0.4058 - val_loss: 1.7196 - val_acc: 0.3202\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5107 - acc: 0.4044 - val_loss: 1.7369 - val_acc: 0.3051\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5089 - acc: 0.3938 - val_loss: 1.6789 - val_acc: 0.3293\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4903 - acc: 0.4114 - val_loss: 1.7367 - val_acc: 0.3142\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4933 - acc: 0.4097 - val_loss: 1.7872 - val_acc: 0.3082\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4734 - acc: 0.4206 - val_loss: 1.6663 - val_acc: 0.3233\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4763 - acc: 0.4156 - val_loss: 1.6540 - val_acc: 0.3293\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4727 - acc: 0.4244 - val_loss: 1.5835 - val_acc: 0.3595\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4587 - acc: 0.4301 - val_loss: 1.6008 - val_acc: 0.3505\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4591 - acc: 0.4132 - val_loss: 1.5931 - val_acc: 0.3595\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4350 - acc: 0.4354 - val_loss: 1.6532 - val_acc: 0.3565\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4509 - acc: 0.4259 - val_loss: 1.6039 - val_acc: 0.4109\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4282 - acc: 0.4350 - val_loss: 1.5558 - val_acc: 0.3595\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4382 - acc: 0.4297 - val_loss: 1.6243 - val_acc: 0.3595\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4195 - acc: 0.4371 - val_loss: 1.5856 - val_acc: 0.3716\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3911 - acc: 0.4456 - val_loss: 1.5493 - val_acc: 0.4079\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4036 - acc: 0.4421 - val_loss: 1.5583 - val_acc: 0.4230\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4246 - acc: 0.4322 - val_loss: 1.5178 - val_acc: 0.4592\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4089 - acc: 0.4512 - val_loss: 1.5364 - val_acc: 0.3988\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3789 - acc: 0.4569 - val_loss: 1.5354 - val_acc: 0.3927\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3868 - acc: 0.4593 - val_loss: 1.5360 - val_acc: 0.3746\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3763 - acc: 0.4502 - val_loss: 1.5839 - val_acc: 0.3746\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3644 - acc: 0.4554 - val_loss: 1.5808 - val_acc: 0.4048\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3632 - acc: 0.4565 - val_loss: 1.6085 - val_acc: 0.3837\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3604 - acc: 0.4558 - val_loss: 1.6867 - val_acc: 0.3474\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3641 - acc: 0.4449 - val_loss: 1.6577 - val_acc: 0.3414\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3382 - acc: 0.4392 - val_loss: 1.5903 - val_acc: 0.3927\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3415 - acc: 0.4519 - val_loss: 1.6449 - val_acc: 0.3716\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3343 - acc: 0.4414 - val_loss: 1.6085 - val_acc: 0.3867\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3400 - acc: 0.4318 - val_loss: 1.6223 - val_acc: 0.3776\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3188 - acc: 0.4516 - val_loss: 1.5688 - val_acc: 0.3897\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3257 - acc: 0.4551 - val_loss: 1.6091 - val_acc: 0.3837\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3266 - acc: 0.4516 - val_loss: 1.6405 - val_acc: 0.3686\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3211 - acc: 0.4368 - val_loss: 1.5122 - val_acc: 0.4139\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3013 - acc: 0.4843 - val_loss: 1.6121 - val_acc: 0.3837\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3201 - acc: 0.4621 - val_loss: 1.5455 - val_acc: 0.4048\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2878 - acc: 0.4621 - val_loss: 1.5343 - val_acc: 0.4169\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2913 - acc: 0.4695 - val_loss: 1.5303 - val_acc: 0.4079\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2876 - acc: 0.4748 - val_loss: 1.4744 - val_acc: 0.4320\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3027 - acc: 0.4516 - val_loss: 1.3990 - val_acc: 0.4532\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3127 - acc: 0.4660 - val_loss: 1.3870 - val_acc: 0.5076\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3084 - acc: 0.4967 - val_loss: 1.4429 - val_acc: 0.4592\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2697 - acc: 0.4812 - val_loss: 1.4579 - val_acc: 0.4381\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2677 - acc: 0.4878 - val_loss: 1.4690 - val_acc: 0.4471\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2743 - acc: 0.4759 - val_loss: 1.6078 - val_acc: 0.3716\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3069 - acc: 0.4403 - val_loss: 1.5599 - val_acc: 0.3837\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2511 - acc: 0.4667 - val_loss: 1.4588 - val_acc: 0.4350\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2378 - acc: 0.4995 - val_loss: 1.4526 - val_acc: 0.4320\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2431 - acc: 0.4931 - val_loss: 1.4969 - val_acc: 0.4230\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2433 - acc: 0.4787 - val_loss: 1.5828 - val_acc: 0.3807\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2644 - acc: 0.4731 - val_loss: 1.5590 - val_acc: 0.3897\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2422 - acc: 0.4731 - val_loss: 1.4995 - val_acc: 0.4199\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2297 - acc: 0.4808 - val_loss: 1.4578 - val_acc: 0.4290\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2374 - acc: 0.4780 - val_loss: 1.4275 - val_acc: 0.4471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2129 - acc: 0.5041 - val_loss: 1.5567 - val_acc: 0.4109\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2562 - acc: 0.4738 - val_loss: 1.5941 - val_acc: 0.3807\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2433 - acc: 0.4653 - val_loss: 1.4657 - val_acc: 0.4411\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2092 - acc: 0.4822 - val_loss: 1.4032 - val_acc: 0.4502\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2343 - acc: 0.4829 - val_loss: 1.3383 - val_acc: 0.5076\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2158 - acc: 0.5058 - val_loss: 1.3691 - val_acc: 0.4955\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2050 - acc: 0.5129 - val_loss: 1.3789 - val_acc: 0.4864\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2032 - acc: 0.5122 - val_loss: 1.3794 - val_acc: 0.4713\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2034 - acc: 0.5076 - val_loss: 1.3712 - val_acc: 0.4743\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2108 - acc: 0.5107 - val_loss: 1.3771 - val_acc: 0.4804\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2039 - acc: 0.4921 - val_loss: 1.3157 - val_acc: 0.5166\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2177 - acc: 0.5086 - val_loss: 1.3263 - val_acc: 0.5287\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1910 - acc: 0.5185 - val_loss: 1.3993 - val_acc: 0.4864\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1888 - acc: 0.5051 - val_loss: 1.3462 - val_acc: 0.5196\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1918 - acc: 0.5083 - val_loss: 1.3154 - val_acc: 0.5559\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2186 - acc: 0.5055 - val_loss: 1.3195 - val_acc: 0.5196\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2085 - acc: 0.5065 - val_loss: 1.3374 - val_acc: 0.4985\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1828 - acc: 0.5174 - val_loss: 1.3623 - val_acc: 0.4773\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1881 - acc: 0.5062 - val_loss: 1.3394 - val_acc: 0.5045\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1874 - acc: 0.5199 - val_loss: 1.3313 - val_acc: 0.5287\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1800 - acc: 0.5100 - val_loss: 1.3176 - val_acc: 0.5498\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1871 - acc: 0.5139 - val_loss: 1.3055 - val_acc: 0.5438\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1865 - acc: 0.5262 - val_loss: 1.3285 - val_acc: 0.5498\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1661 - acc: 0.5266 - val_loss: 1.3067 - val_acc: 0.5347\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1839 - acc: 0.5206 - val_loss: 1.3156 - val_acc: 0.5378\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1730 - acc: 0.5139 - val_loss: 1.3330 - val_acc: 0.5257\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1616 - acc: 0.5217 - val_loss: 1.3318 - val_acc: 0.5347\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1379 - acc: 0.5241 - val_loss: 1.3181 - val_acc: 0.5438\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1427 - acc: 0.5259 - val_loss: 1.2938 - val_acc: 0.5498\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1844 - acc: 0.5093 - val_loss: 1.3003 - val_acc: 0.5498\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1703 - acc: 0.5315 - val_loss: 1.3011 - val_acc: 0.5408\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1569 - acc: 0.5206 - val_loss: 1.3156 - val_acc: 0.5196\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1606 - acc: 0.5188 - val_loss: 1.3422 - val_acc: 0.4955\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1502 - acc: 0.5033 - val_loss: 1.3120 - val_acc: 0.5196\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1441 - acc: 0.5347 - val_loss: 1.3065 - val_acc: 0.5166\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1510 - acc: 0.5294 - val_loss: 1.2956 - val_acc: 0.5468\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1503 - acc: 0.5199 - val_loss: 1.2910 - val_acc: 0.5619\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1374 - acc: 0.5336 - val_loss: 1.2881 - val_acc: 0.5468\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1448 - acc: 0.5491 - val_loss: 1.2984 - val_acc: 0.5589\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1288 - acc: 0.5343 - val_loss: 1.3377 - val_acc: 0.5317\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1331 - acc: 0.5340 - val_loss: 1.3769 - val_acc: 0.5227\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1470 - acc: 0.5319 - val_loss: 1.3781 - val_acc: 0.5015\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1226 - acc: 0.5259 - val_loss: 1.3321 - val_acc: 0.5317\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1152 - acc: 0.5389 - val_loss: 1.2717 - val_acc: 0.5438\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1571 - acc: 0.5153 - val_loss: 1.2643 - val_acc: 0.5559\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1597 - acc: 0.5389 - val_loss: 1.3307 - val_acc: 0.5378\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1041 - acc: 0.5502 - val_loss: 1.3528 - val_acc: 0.5257\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1115 - acc: 0.5467 - val_loss: 1.4193 - val_acc: 0.5076\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1108 - acc: 0.5252 - val_loss: 1.4332 - val_acc: 0.5015\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1126 - acc: 0.5326 - val_loss: 1.4647 - val_acc: 0.5106\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1393 - acc: 0.5090 - val_loss: 1.4988 - val_acc: 0.4592\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1306 - acc: 0.5076 - val_loss: 1.3966 - val_acc: 0.5076\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0956 - acc: 0.5361 - val_loss: 1.3624 - val_acc: 0.5498\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0933 - acc: 0.5305 - val_loss: 1.4545 - val_acc: 0.5408\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1173 - acc: 0.5160 - val_loss: 1.4323 - val_acc: 0.5227\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1025 - acc: 0.5340 - val_loss: 1.4515 - val_acc: 0.5227\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1128 - acc: 0.5231 - val_loss: 1.4873 - val_acc: 0.4713\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1167 - acc: 0.5093 - val_loss: 1.4544 - val_acc: 0.4683\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1118 - acc: 0.5167 - val_loss: 1.4408 - val_acc: 0.4773\n",
      "Epoch 126/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1034 - acc: 0.5150 - val_loss: 1.4406 - val_acc: 0.4773\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0968 - acc: 0.5203 - val_loss: 1.5039 - val_acc: 0.4773\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1230 - acc: 0.5037 - val_loss: 1.4000 - val_acc: 0.5378\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0947 - acc: 0.5273 - val_loss: 1.4727 - val_acc: 0.4804\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1082 - acc: 0.5213 - val_loss: 1.3983 - val_acc: 0.5136\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0846 - acc: 0.5386 - val_loss: 1.3828 - val_acc: 0.5287\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0753 - acc: 0.5467 - val_loss: 1.3943 - val_acc: 0.5106\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0757 - acc: 0.5586 - val_loss: 1.4461 - val_acc: 0.4743\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0989 - acc: 0.5322 - val_loss: 1.4591 - val_acc: 0.4622\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1138 - acc: 0.5210 - val_loss: 1.4090 - val_acc: 0.4894\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0652 - acc: 0.5502 - val_loss: 1.5292 - val_acc: 0.4320\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1276 - acc: 0.5069 - val_loss: 1.4299 - val_acc: 0.4864\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0723 - acc: 0.5343 - val_loss: 1.4410 - val_acc: 0.4955\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0538 - acc: 0.5509 - val_loss: 1.3466 - val_acc: 0.5166\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0432 - acc: 0.5534 - val_loss: 1.3782 - val_acc: 0.5106\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0664 - acc: 0.5393 - val_loss: 1.4289 - val_acc: 0.4562\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1055 - acc: 0.5343 - val_loss: 1.5371 - val_acc: 0.4350\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1230 - acc: 0.5118 - val_loss: 1.4659 - val_acc: 0.4532\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0729 - acc: 0.5269 - val_loss: 1.3706 - val_acc: 0.5227\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.0454 - acc: 0.5520 - val_loss: 1.4082 - val_acc: 0.4894\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0458 - acc: 0.5407 - val_loss: 1.3565 - val_acc: 0.5317\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0562 - acc: 0.5513 - val_loss: 1.3633 - val_acc: 0.5136\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0567 - acc: 0.5470 - val_loss: 1.2896 - val_acc: 0.5801\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1040 - acc: 0.5372 - val_loss: 1.2685 - val_acc: 0.5680\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0956 - acc: 0.5463 - val_loss: 1.2922 - val_acc: 0.5438\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0474 - acc: 0.5650 - val_loss: 1.3088 - val_acc: 0.5287\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0428 - acc: 0.5657 - val_loss: 1.3301 - val_acc: 0.5166\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0455 - acc: 0.5713 - val_loss: 1.3011 - val_acc: 0.5438\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0754 - acc: 0.5463 - val_loss: 1.2614 - val_acc: 0.5710\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1139 - acc: 0.5495 - val_loss: 1.2862 - val_acc: 0.5650\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0368 - acc: 0.5671 - val_loss: 1.3569 - val_acc: 0.5106\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0172 - acc: 0.5629 - val_loss: 1.3679 - val_acc: 0.5076\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0189 - acc: 0.5555 - val_loss: 1.3507 - val_acc: 0.5257\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0268 - acc: 0.5597 - val_loss: 1.3845 - val_acc: 0.5287\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0422 - acc: 0.5622 - val_loss: 1.3787 - val_acc: 0.5015\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0420 - acc: 0.5527 - val_loss: 1.4343 - val_acc: 0.4804\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0609 - acc: 0.5308 - val_loss: 1.6298 - val_acc: 0.4018\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1426 - acc: 0.4889 - val_loss: 1.4717 - val_acc: 0.4441\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0499 - acc: 0.5368 - val_loss: 1.4002 - val_acc: 0.4804\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0129 - acc: 0.5572 - val_loss: 1.3506 - val_acc: 0.5166\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0055 - acc: 0.5717 - val_loss: 1.3541 - val_acc: 0.4924\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0117 - acc: 0.5703 - val_loss: 1.4142 - val_acc: 0.4562\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0304 - acc: 0.5696 - val_loss: 1.4287 - val_acc: 0.4562\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0319 - acc: 0.5558 - val_loss: 1.3945 - val_acc: 0.4653\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0273 - acc: 0.5759 - val_loss: 1.3723 - val_acc: 0.4955\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 0.9993 - acc: 0.5759 - val_loss: 1.3983 - val_acc: 0.4955\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0051 - acc: 0.5727 - val_loss: 1.5772 - val_acc: 0.4139\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1043 - acc: 0.5132 - val_loss: 1.5317 - val_acc: 0.4169\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0371 - acc: 0.5347 - val_loss: 1.4159 - val_acc: 0.4653\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0132 - acc: 0.5477 - val_loss: 1.4074 - val_acc: 0.4592\n",
      "2\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 16s 6ms/step - loss: 1.8632 - acc: 0.2099 - val_loss: 1.8843 - val_acc: 0.3353\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.7289 - acc: 0.3737 - val_loss: 1.8595 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.6645 - acc: 0.4005 - val_loss: 1.8065 - val_acc: 0.3293\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6373 - acc: 0.4012 - val_loss: 1.8522 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6316 - acc: 0.4044 - val_loss: 1.8034 - val_acc: 0.3293\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6182 - acc: 0.4015 - val_loss: 1.7580 - val_acc: 0.3263\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5981 - acc: 0.3942 - val_loss: 1.7678 - val_acc: 0.3233\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5845 - acc: 0.3998 - val_loss: 1.7070 - val_acc: 0.3263\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5748 - acc: 0.4008 - val_loss: 1.6896 - val_acc: 0.3293\n",
      "Epoch 10/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5613 - acc: 0.4033 - val_loss: 1.6957 - val_acc: 0.3414\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5495 - acc: 0.4153 - val_loss: 1.7542 - val_acc: 0.3263\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5305 - acc: 0.4118 - val_loss: 1.6658 - val_acc: 0.3535\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5194 - acc: 0.4287 - val_loss: 1.7110 - val_acc: 0.3414\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5127 - acc: 0.4216 - val_loss: 1.7192 - val_acc: 0.3353\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5214 - acc: 0.4054 - val_loss: 1.7418 - val_acc: 0.3353\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5078 - acc: 0.4075 - val_loss: 1.6791 - val_acc: 0.3384\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4869 - acc: 0.4255 - val_loss: 1.6273 - val_acc: 0.3686\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4870 - acc: 0.4216 - val_loss: 1.6206 - val_acc: 0.3656\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4725 - acc: 0.4308 - val_loss: 1.6351 - val_acc: 0.3444\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4733 - acc: 0.4297 - val_loss: 1.7414 - val_acc: 0.3353\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4830 - acc: 0.4223 - val_loss: 1.6756 - val_acc: 0.3384\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4556 - acc: 0.4163 - val_loss: 1.6883 - val_acc: 0.3353\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4457 - acc: 0.4287 - val_loss: 1.6694 - val_acc: 0.3384\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4323 - acc: 0.4354 - val_loss: 1.6685 - val_acc: 0.3474\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4234 - acc: 0.4403 - val_loss: 1.6406 - val_acc: 0.3565\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4326 - acc: 0.4438 - val_loss: 1.7231 - val_acc: 0.3353\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4257 - acc: 0.4248 - val_loss: 1.7406 - val_acc: 0.3293\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4192 - acc: 0.4093 - val_loss: 1.5961 - val_acc: 0.3565\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4041 - acc: 0.4424 - val_loss: 1.6279 - val_acc: 0.3505\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4133 - acc: 0.4477 - val_loss: 1.6835 - val_acc: 0.3505\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3904 - acc: 0.4385 - val_loss: 1.5988 - val_acc: 0.3656\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3818 - acc: 0.4463 - val_loss: 1.5477 - val_acc: 0.3927\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3785 - acc: 0.4456 - val_loss: 1.5232 - val_acc: 0.3867\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3638 - acc: 0.4607 - val_loss: 1.5571 - val_acc: 0.3867\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3710 - acc: 0.4498 - val_loss: 1.6391 - val_acc: 0.3565\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3705 - acc: 0.4417 - val_loss: 1.6746 - val_acc: 0.3625\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3684 - acc: 0.4371 - val_loss: 1.6599 - val_acc: 0.3595\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.3518 - acc: 0.4410 - val_loss: 1.6222 - val_acc: 0.3595\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.3594 - acc: 0.4385 - val_loss: 1.6371 - val_acc: 0.3444\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3468 - acc: 0.4442 - val_loss: 1.5611 - val_acc: 0.3988\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3401 - acc: 0.4537 - val_loss: 1.5953 - val_acc: 0.3776\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3349 - acc: 0.4537 - val_loss: 1.5665 - val_acc: 0.3776\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3306 - acc: 0.4660 - val_loss: 1.6472 - val_acc: 0.3384\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.3341 - acc: 0.4406 - val_loss: 1.6594 - val_acc: 0.3474\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3314 - acc: 0.4308 - val_loss: 1.5186 - val_acc: 0.4139\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3068 - acc: 0.4692 - val_loss: 1.4971 - val_acc: 0.4441\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3004 - acc: 0.4716 - val_loss: 1.4850 - val_acc: 0.4502\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3247 - acc: 0.4716 - val_loss: 1.4225 - val_acc: 0.4743\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3174 - acc: 0.4748 - val_loss: 1.4173 - val_acc: 0.4622\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3136 - acc: 0.4773 - val_loss: 1.4799 - val_acc: 0.4199\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2908 - acc: 0.4674 - val_loss: 1.5426 - val_acc: 0.3927\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2964 - acc: 0.4537 - val_loss: 1.4381 - val_acc: 0.4562\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2952 - acc: 0.4766 - val_loss: 1.4096 - val_acc: 0.4653\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2961 - acc: 0.4706 - val_loss: 1.4091 - val_acc: 0.4653\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2964 - acc: 0.4833 - val_loss: 1.4263 - val_acc: 0.4653\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2774 - acc: 0.4794 - val_loss: 1.3858 - val_acc: 0.4834\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2900 - acc: 0.4847 - val_loss: 1.4042 - val_acc: 0.4743\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2759 - acc: 0.4833 - val_loss: 1.5253 - val_acc: 0.4199\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2804 - acc: 0.4632 - val_loss: 1.4011 - val_acc: 0.4773\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2808 - acc: 0.4769 - val_loss: 1.4281 - val_acc: 0.4653\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2502 - acc: 0.4914 - val_loss: 1.5065 - val_acc: 0.4381\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2562 - acc: 0.4857 - val_loss: 1.5097 - val_acc: 0.4230\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2538 - acc: 0.4907 - val_loss: 1.6579 - val_acc: 0.3595\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2672 - acc: 0.4604 - val_loss: 1.5112 - val_acc: 0.4290\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2449 - acc: 0.4752 - val_loss: 1.4982 - val_acc: 0.4320\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2335 - acc: 0.4875 - val_loss: 1.4652 - val_acc: 0.4350\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2424 - acc: 0.4812 - val_loss: 1.4314 - val_acc: 0.4562\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2300 - acc: 0.4850 - val_loss: 1.4129 - val_acc: 0.4532\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2455 - acc: 0.4882 - val_loss: 1.4077 - val_acc: 0.4773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2411 - acc: 0.4787 - val_loss: 1.3352 - val_acc: 0.5196\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2437 - acc: 0.4981 - val_loss: 1.3214 - val_acc: 0.5227\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2419 - acc: 0.5012 - val_loss: 1.4363 - val_acc: 0.4502\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2176 - acc: 0.4812 - val_loss: 1.4917 - val_acc: 0.4381\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2407 - acc: 0.4695 - val_loss: 1.5229 - val_acc: 0.4230\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2351 - acc: 0.4650 - val_loss: 1.4832 - val_acc: 0.4471\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2090 - acc: 0.4868 - val_loss: 1.4322 - val_acc: 0.4804\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2103 - acc: 0.5122 - val_loss: 1.4670 - val_acc: 0.4562\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2122 - acc: 0.4938 - val_loss: 1.5046 - val_acc: 0.4290\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2123 - acc: 0.4805 - val_loss: 1.4654 - val_acc: 0.4411\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2089 - acc: 0.4847 - val_loss: 1.5258 - val_acc: 0.4441\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2280 - acc: 0.4681 - val_loss: 1.4367 - val_acc: 0.4773\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2005 - acc: 0.4914 - val_loss: 1.4407 - val_acc: 0.4562\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1737 - acc: 0.4974 - val_loss: 1.3812 - val_acc: 0.5015\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1810 - acc: 0.5016 - val_loss: 1.3559 - val_acc: 0.5106\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2009 - acc: 0.5041 - val_loss: 1.2961 - val_acc: 0.5408\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2098 - acc: 0.5104 - val_loss: 1.3374 - val_acc: 0.5106\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1861 - acc: 0.5171 - val_loss: 1.3433 - val_acc: 0.5166\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1838 - acc: 0.5160 - val_loss: 1.3233 - val_acc: 0.5227\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1860 - acc: 0.5030 - val_loss: 1.3065 - val_acc: 0.5196\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1820 - acc: 0.5122 - val_loss: 1.3051 - val_acc: 0.5317\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1830 - acc: 0.5269 - val_loss: 1.2968 - val_acc: 0.5529\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1989 - acc: 0.5241 - val_loss: 1.3671 - val_acc: 0.5106\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1712 - acc: 0.5069 - val_loss: 1.3490 - val_acc: 0.5106\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1694 - acc: 0.5044 - val_loss: 1.2823 - val_acc: 0.5468\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1853 - acc: 0.5224 - val_loss: 1.3046 - val_acc: 0.5227\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1737 - acc: 0.5139 - val_loss: 1.3036 - val_acc: 0.5166\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1874 - acc: 0.5220 - val_loss: 1.3310 - val_acc: 0.5015\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1606 - acc: 0.5129 - val_loss: 1.2949 - val_acc: 0.5378\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1431 - acc: 0.5400 - val_loss: 1.3112 - val_acc: 0.5378\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1671 - acc: 0.5199 - val_loss: 1.2870 - val_acc: 0.5589\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1907 - acc: 0.5312 - val_loss: 1.3001 - val_acc: 0.5438\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1493 - acc: 0.5245 - val_loss: 1.3516 - val_acc: 0.5287\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1402 - acc: 0.5305 - val_loss: 1.3399 - val_acc: 0.5166\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1391 - acc: 0.5167 - val_loss: 1.3606 - val_acc: 0.4894\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1435 - acc: 0.5164 - val_loss: 1.3390 - val_acc: 0.5136\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1515 - acc: 0.5086 - val_loss: 1.2918 - val_acc: 0.5136\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1930 - acc: 0.4991 - val_loss: 1.2996 - val_acc: 0.5166\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1501 - acc: 0.5125 - val_loss: 1.2907 - val_acc: 0.5438\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1393 - acc: 0.5375 - val_loss: 1.2658 - val_acc: 0.5619\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1567 - acc: 0.5439 - val_loss: 1.3215 - val_acc: 0.5619\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1173 - acc: 0.5424 - val_loss: 1.3450 - val_acc: 0.5529\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1221 - acc: 0.5333 - val_loss: 1.3502 - val_acc: 0.5438\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1168 - acc: 0.5291 - val_loss: 1.4530 - val_acc: 0.4985\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1622 - acc: 0.4864 - val_loss: 1.4092 - val_acc: 0.5287\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1355 - acc: 0.5199 - val_loss: 1.4209 - val_acc: 0.4532\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1269 - acc: 0.5178 - val_loss: 1.3151 - val_acc: 0.5408\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1150 - acc: 0.5336 - val_loss: 1.3394 - val_acc: 0.5166\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1062 - acc: 0.5396 - val_loss: 1.4240 - val_acc: 0.5015\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1393 - acc: 0.5114 - val_loss: 1.4147 - val_acc: 0.4773\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1279 - acc: 0.5192 - val_loss: 1.4760 - val_acc: 0.4834\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1626 - acc: 0.4942 - val_loss: 1.4439 - val_acc: 0.4955\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1325 - acc: 0.5041 - val_loss: 1.3451 - val_acc: 0.5740\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1084 - acc: 0.5315 - val_loss: 1.3751 - val_acc: 0.5468\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1144 - acc: 0.5192 - val_loss: 1.2998 - val_acc: 0.5740\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1055 - acc: 0.5350 - val_loss: 1.2544 - val_acc: 0.5831\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1273 - acc: 0.5421 - val_loss: 1.2665 - val_acc: 0.5891\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1110 - acc: 0.5403 - val_loss: 1.3202 - val_acc: 0.5710\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0824 - acc: 0.5382 - val_loss: 1.3143 - val_acc: 0.5801\n",
      "Epoch 129/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1130 - acc: 0.5354 - val_loss: 1.3379 - val_acc: 0.5650\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1046 - acc: 0.5358 - val_loss: 1.3158 - val_acc: 0.5921\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1016 - acc: 0.5417 - val_loss: 1.2713 - val_acc: 0.5650\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1257 - acc: 0.5354 - val_loss: 1.2622 - val_acc: 0.5891\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1017 - acc: 0.5382 - val_loss: 1.2760 - val_acc: 0.5650\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0960 - acc: 0.5460 - val_loss: 1.2707 - val_acc: 0.5619\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1079 - acc: 0.5350 - val_loss: 1.2488 - val_acc: 0.5921\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1052 - acc: 0.5336 - val_loss: 1.2679 - val_acc: 0.5952\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0788 - acc: 0.5513 - val_loss: 1.3184 - val_acc: 0.5770\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0665 - acc: 0.5527 - val_loss: 1.3285 - val_acc: 0.5589\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0728 - acc: 0.5358 - val_loss: 1.3290 - val_acc: 0.5680\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0826 - acc: 0.5340 - val_loss: 1.3699 - val_acc: 0.4743\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1140 - acc: 0.5213 - val_loss: 1.2597 - val_acc: 0.5861\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1122 - acc: 0.5336 - val_loss: 1.2511 - val_acc: 0.5861\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1120 - acc: 0.5407 - val_loss: 1.2989 - val_acc: 0.5680\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0679 - acc: 0.5534 - val_loss: 1.2965 - val_acc: 0.5891\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0677 - acc: 0.5460 - val_loss: 1.2636 - val_acc: 0.5891\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0863 - acc: 0.5343 - val_loss: 1.2968 - val_acc: 0.5801\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0612 - acc: 0.5407 - val_loss: 1.2512 - val_acc: 0.5982\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0945 - acc: 0.5421 - val_loss: 1.2539 - val_acc: 0.5921\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0922 - acc: 0.5414 - val_loss: 1.2663 - val_acc: 0.6012\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0658 - acc: 0.5565 - val_loss: 1.2552 - val_acc: 0.5861\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0812 - acc: 0.5393 - val_loss: 1.2751 - val_acc: 0.5861\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0782 - acc: 0.5548 - val_loss: 1.2623 - val_acc: 0.5982\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0535 - acc: 0.5604 - val_loss: 1.2711 - val_acc: 0.5891\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0612 - acc: 0.5498 - val_loss: 1.2592 - val_acc: 0.5861\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0964 - acc: 0.5467 - val_loss: 1.2741 - val_acc: 0.6042\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0430 - acc: 0.5632 - val_loss: 1.2754 - val_acc: 0.5921\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0400 - acc: 0.5611 - val_loss: 1.2998 - val_acc: 0.5378\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0643 - acc: 0.5491 - val_loss: 1.2806 - val_acc: 0.5650\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0812 - acc: 0.5562 - val_loss: 1.2874 - val_acc: 0.5498\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0684 - acc: 0.5509 - val_loss: 1.3486 - val_acc: 0.5287\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0472 - acc: 0.5537 - val_loss: 1.3810 - val_acc: 0.5045\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0570 - acc: 0.5421 - val_loss: 1.3526 - val_acc: 0.5347\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0332 - acc: 0.5594 - val_loss: 1.3258 - val_acc: 0.5559\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0317 - acc: 0.5541 - val_loss: 1.4047 - val_acc: 0.5045\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0695 - acc: 0.5343 - val_loss: 1.5482 - val_acc: 0.4230\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1244 - acc: 0.4998 - val_loss: 1.3682 - val_acc: 0.5076\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0362 - acc: 0.5534 - val_loss: 1.3379 - val_acc: 0.5408\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0256 - acc: 0.5530 - val_loss: 1.3641 - val_acc: 0.5257\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.0306 - acc: 0.5565 - val_loss: 1.3636 - val_acc: 0.5287\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0401 - acc: 0.5527 - val_loss: 1.3426 - val_acc: 0.5378\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0166 - acc: 0.5604 - val_loss: 1.4313 - val_acc: 0.4864\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0738 - acc: 0.5294 - val_loss: 1.3946 - val_acc: 0.4985\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0479 - acc: 0.5393 - val_loss: 1.3724 - val_acc: 0.5106\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0321 - acc: 0.5586 - val_loss: 1.3607 - val_acc: 0.5136\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0258 - acc: 0.5474 - val_loss: 1.4980 - val_acc: 0.4381\n",
      "3\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 17s 6ms/step - loss: 1.7956 - acc: 0.2529 - val_loss: 1.7910 - val_acc: 0.3323\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.6765 - acc: 0.3709 - val_loss: 1.7812 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.6420 - acc: 0.3765 - val_loss: 1.7897 - val_acc: 0.3323\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.6360 - acc: 0.3691 - val_loss: 1.7348 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.6242 - acc: 0.3758 - val_loss: 1.7419 - val_acc: 0.3323\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.5847 - acc: 0.3709 - val_loss: 1.7472 - val_acc: 0.3353\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.5816 - acc: 0.3765 - val_loss: 1.7801 - val_acc: 0.3293\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.5698 - acc: 0.3674 - val_loss: 1.6848 - val_acc: 0.3323\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 61us/step - loss: 1.5687 - acc: 0.3899 - val_loss: 1.7879 - val_acc: 0.3142\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 75us/step - loss: 1.5651 - acc: 0.3642 - val_loss: 1.7412 - val_acc: 0.3202\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.5434 - acc: 0.3843 - val_loss: 1.7302 - val_acc: 0.3202\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.5400 - acc: 0.3839 - val_loss: 1.7112 - val_acc: 0.3172\n",
      "Epoch 13/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.5259 - acc: 0.3787 - val_loss: 1.6944 - val_acc: 0.3142\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5213 - acc: 0.3885 - val_loss: 1.7113 - val_acc: 0.3142\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5061 - acc: 0.3815 - val_loss: 1.7312 - val_acc: 0.3082\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.4991 - acc: 0.3889 - val_loss: 1.7455 - val_acc: 0.3051\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4944 - acc: 0.3723 - val_loss: 1.6485 - val_acc: 0.3202\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4721 - acc: 0.4089 - val_loss: 1.6787 - val_acc: 0.3202\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4716 - acc: 0.3952 - val_loss: 1.6914 - val_acc: 0.3112\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4570 - acc: 0.3970 - val_loss: 1.6595 - val_acc: 0.3112\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4633 - acc: 0.4033 - val_loss: 1.6279 - val_acc: 0.3172\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4404 - acc: 0.4026 - val_loss: 1.6299 - val_acc: 0.3202\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4324 - acc: 0.4005 - val_loss: 1.5472 - val_acc: 0.3323\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4398 - acc: 0.4121 - val_loss: 1.6094 - val_acc: 0.3353\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4219 - acc: 0.4135 - val_loss: 1.6910 - val_acc: 0.2961\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4269 - acc: 0.3910 - val_loss: 1.5992 - val_acc: 0.3263\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4183 - acc: 0.4149 - val_loss: 1.6361 - val_acc: 0.3202\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4060 - acc: 0.4079 - val_loss: 1.6202 - val_acc: 0.3172\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.4062 - acc: 0.384 - 0s 33us/step - loss: 1.3998 - acc: 0.4012 - val_loss: 1.6067 - val_acc: 0.3202\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4035 - acc: 0.4037 - val_loss: 1.5772 - val_acc: 0.3293\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3874 - acc: 0.4023 - val_loss: 1.5755 - val_acc: 0.3293\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3886 - acc: 0.4054 - val_loss: 1.6978 - val_acc: 0.3112\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3747 - acc: 0.4167 - val_loss: 1.6221 - val_acc: 0.3233\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3765 - acc: 0.4075 - val_loss: 1.5462 - val_acc: 0.3293\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3710 - acc: 0.4030 - val_loss: 1.4812 - val_acc: 0.3293\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 1.3678 - acc: 0.4149 - val_loss: 1.5078 - val_acc: 0.3323\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3640 - acc: 0.4213 - val_loss: 1.4912 - val_acc: 0.3323\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3515 - acc: 0.4294 - val_loss: 1.5308 - val_acc: 0.3293\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3495 - acc: 0.4262 - val_loss: 1.5334 - val_acc: 0.3384\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3293 - acc: 0.4329 - val_loss: 1.5715 - val_acc: 0.3263\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3204 - acc: 0.4304 - val_loss: 1.5753 - val_acc: 0.3202\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3319 - acc: 0.4156 - val_loss: 1.6147 - val_acc: 0.3263\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.3208 - acc: 0.4163 - val_loss: 1.6189 - val_acc: 0.3323\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.3271 - acc: 0.4195 - val_loss: 1.5889 - val_acc: 0.3323\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3050 - acc: 0.4361 - val_loss: 1.5529 - val_acc: 0.3353\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.3234 - acc: 0.4170 - val_loss: 1.4926 - val_acc: 0.3444\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2890 - acc: 0.4336 - val_loss: 1.4410 - val_acc: 0.3535\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3074 - acc: 0.4368 - val_loss: 1.4471 - val_acc: 0.3414\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2896 - acc: 0.4428 - val_loss: 1.4930 - val_acc: 0.3505\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2926 - acc: 0.4364 - val_loss: 1.5036 - val_acc: 0.3414\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.2769 - acc: 0.456 - 0s 34us/step - loss: 1.2909 - acc: 0.4378 - val_loss: 1.5107 - val_acc: 0.3202\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2986 - acc: 0.4230 - val_loss: 1.4682 - val_acc: 0.3535\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2816 - acc: 0.4445 - val_loss: 1.4428 - val_acc: 0.3716\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2833 - acc: 0.4294 - val_loss: 1.3809 - val_acc: 0.3625\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2953 - acc: 0.4364 - val_loss: 1.4459 - val_acc: 0.3595\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2751 - acc: 0.4382 - val_loss: 1.4616 - val_acc: 0.3595\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2748 - acc: 0.4406 - val_loss: 1.5406 - val_acc: 0.3263\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2804 - acc: 0.4209 - val_loss: 1.6007 - val_acc: 0.3112\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2656 - acc: 0.4241 - val_loss: 1.5026 - val_acc: 0.3414\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.2382 - acc: 0.433 - 0s 33us/step - loss: 1.2577 - acc: 0.4297 - val_loss: 1.5415 - val_acc: 0.3172\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2683 - acc: 0.4209 - val_loss: 1.4968 - val_acc: 0.3474\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2475 - acc: 0.4406 - val_loss: 1.5168 - val_acc: 0.3384\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2520 - acc: 0.4315 - val_loss: 1.4772 - val_acc: 0.3686\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2456 - acc: 0.4343 - val_loss: 1.5957 - val_acc: 0.3112\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2585 - acc: 0.4354 - val_loss: 1.5515 - val_acc: 0.3353\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2580 - acc: 0.4213 - val_loss: 1.5010 - val_acc: 0.3414\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2306 - acc: 0.4315 - val_loss: 1.4729 - val_acc: 0.3535\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2371 - acc: 0.4463 - val_loss: 1.4478 - val_acc: 0.3716\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2253 - acc: 0.4442 - val_loss: 1.5592 - val_acc: 0.3353\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2343 - acc: 0.4273 - val_loss: 1.5110 - val_acc: 0.3595\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2319 - acc: 0.4547 - val_loss: 1.5048 - val_acc: 0.3625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2326 - acc: 0.4361 - val_loss: 1.4726 - val_acc: 0.3837\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2098 - acc: 0.4597 - val_loss: 1.4532 - val_acc: 0.4230\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2192 - acc: 0.4512 - val_loss: 1.4394 - val_acc: 0.4260\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2083 - acc: 0.4618 - val_loss: 1.3650 - val_acc: 0.4562\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 50us/step - loss: 1.1982 - acc: 0.4688 - val_loss: 1.3555 - val_acc: 0.4532\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2008 - acc: 0.4653 - val_loss: 1.3524 - val_acc: 0.4864\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2280 - acc: 0.4660 - val_loss: 1.3231 - val_acc: 0.4955\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2230 - acc: 0.4695 - val_loss: 1.3369 - val_acc: 0.4743\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.2121 - acc: 0.4769 - val_loss: 1.3890 - val_acc: 0.4562\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1785 - acc: 0.4783 - val_loss: 1.3987 - val_acc: 0.4532\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1895 - acc: 0.4688 - val_loss: 1.3962 - val_acc: 0.4350\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2020 - acc: 0.4695 - val_loss: 1.3266 - val_acc: 0.4743\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 63us/step - loss: 1.2214 - acc: 0.4650 - val_loss: 1.3118 - val_acc: 0.5287\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 1.2027 - acc: 0.4914 - val_loss: 1.3443 - val_acc: 0.4924\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1881 - acc: 0.4861 - val_loss: 1.3615 - val_acc: 0.5015\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1903 - acc: 0.4826 - val_loss: 1.3010 - val_acc: 0.5498\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2122 - acc: 0.4794 - val_loss: 1.3320 - val_acc: 0.5045\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1688 - acc: 0.4805 - val_loss: 1.3721 - val_acc: 0.4562\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1544 - acc: 0.4812 - val_loss: 1.3926 - val_acc: 0.4562\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1665 - acc: 0.4773 - val_loss: 1.3539 - val_acc: 0.4713\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1450 - acc: 0.4864 - val_loss: 1.4047 - val_acc: 0.4562\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1878 - acc: 0.4741 - val_loss: 1.4275 - val_acc: 0.4502\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1662 - acc: 0.4748 - val_loss: 1.3874 - val_acc: 0.4683\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.1469 - acc: 0.493 - 0s 37us/step - loss: 1.1475 - acc: 0.4952 - val_loss: 1.3673 - val_acc: 0.4653\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 52us/step - loss: 1.1427 - acc: 0.4931 - val_loss: 1.4355 - val_acc: 0.4350\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1632 - acc: 0.4935 - val_loss: 1.6177 - val_acc: 0.3444\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.2224 - acc: 0.4227 - val_loss: 1.4356 - val_acc: 0.4350\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1567 - acc: 0.4745 - val_loss: 1.4093 - val_acc: 0.4562\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 1.1514 - acc: 0.4871 - val_loss: 1.3822 - val_acc: 0.4562\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1343 - acc: 0.4921 - val_loss: 1.4252 - val_acc: 0.4441\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1475 - acc: 0.4854 - val_loss: 1.3925 - val_acc: 0.4441\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1278 - acc: 0.4893 - val_loss: 1.3266 - val_acc: 0.4985\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1600 - acc: 0.4903 - val_loss: 1.3105 - val_acc: 0.5076\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1480 - acc: 0.4907 - val_loss: 1.2858 - val_acc: 0.5378\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1445 - acc: 0.4974 - val_loss: 1.2726 - val_acc: 0.5378\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.1614 - acc: 0.5009 - val_loss: 1.2927 - val_acc: 0.5257\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1346 - acc: 0.5065 - val_loss: 1.3224 - val_acc: 0.4894\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1056 - acc: 0.5129 - val_loss: 1.3430 - val_acc: 0.4985\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1301 - acc: 0.4910 - val_loss: 1.2736 - val_acc: 0.5408\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1376 - acc: 0.5009 - val_loss: 1.3124 - val_acc: 0.5045\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1119 - acc: 0.5058 - val_loss: 1.3244 - val_acc: 0.5015\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 53us/step - loss: 1.1001 - acc: 0.5122 - val_loss: 1.3554 - val_acc: 0.4622\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.1113 - acc: 0.5012 - val_loss: 1.4068 - val_acc: 0.4502\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1347 - acc: 0.4875 - val_loss: 1.4988 - val_acc: 0.3958\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1432 - acc: 0.4812 - val_loss: 1.4381 - val_acc: 0.4169\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1231 - acc: 0.4988 - val_loss: 1.5332 - val_acc: 0.3716\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1534 - acc: 0.4611 - val_loss: 1.4315 - val_acc: 0.4381\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 49us/step - loss: 1.1065 - acc: 0.4970 - val_loss: 1.3509 - val_acc: 0.4773\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 82us/step - loss: 1.1044 - acc: 0.5083 - val_loss: 1.3304 - val_acc: 0.4985\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 53us/step - loss: 1.0957 - acc: 0.5136 - val_loss: 1.3555 - val_acc: 0.4773\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 54us/step - loss: 1.0944 - acc: 0.5217 - val_loss: 1.4536 - val_acc: 0.4260\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 53us/step - loss: 1.1402 - acc: 0.4995 - val_loss: 1.4652 - val_acc: 0.4199\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1202 - acc: 0.4949 - val_loss: 1.4854 - val_acc: 0.4109\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1170 - acc: 0.4854 - val_loss: 1.4530 - val_acc: 0.4290\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1062 - acc: 0.4836 - val_loss: 1.4076 - val_acc: 0.4441\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 53us/step - loss: 1.1045 - acc: 0.4984 - val_loss: 1.4269 - val_acc: 0.4411\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.0947 - acc: 0.5069 - val_loss: 1.4402 - val_acc: 0.4471\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.0929 - acc: 0.5033 - val_loss: 1.4310 - val_acc: 0.4411\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0895 - acc: 0.5104 - val_loss: 1.4290 - val_acc: 0.4350\n",
      "Epoch 131/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 48us/step - loss: 1.0976 - acc: 0.4967 - val_loss: 1.4408 - val_acc: 0.4441\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.0910 - acc: 0.5012 - val_loss: 1.3639 - val_acc: 0.4773\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0708 - acc: 0.5312 - val_loss: 1.3746 - val_acc: 0.4834\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0565 - acc: 0.5343 - val_loss: 1.3642 - val_acc: 0.4743\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0985 - acc: 0.5143 - val_loss: 1.3812 - val_acc: 0.4683\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1039 - acc: 0.5118 - val_loss: 1.3491 - val_acc: 0.4804\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0593 - acc: 0.5238 - val_loss: 1.4131 - val_acc: 0.4622\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0961 - acc: 0.5041 - val_loss: 1.5797 - val_acc: 0.3656\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 51us/step - loss: 1.1524 - acc: 0.4611 - val_loss: 1.4138 - val_acc: 0.4471\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0827 - acc: 0.5072 - val_loss: 1.4361 - val_acc: 0.4502\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0821 - acc: 0.4924 - val_loss: 1.4114 - val_acc: 0.4502\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0715 - acc: 0.5019 - val_loss: 1.3450 - val_acc: 0.4864\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0747 - acc: 0.5164 - val_loss: 1.3296 - val_acc: 0.4985\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0553 - acc: 0.5308 - val_loss: 1.2865 - val_acc: 0.5166\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.0953 - acc: 0.5065 - val_loss: 1.2742 - val_acc: 0.5287\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0855 - acc: 0.5343 - val_loss: 1.2893 - val_acc: 0.5045\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0674 - acc: 0.5421 - val_loss: 1.3261 - val_acc: 0.4743\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.0753 - acc: 0.5379 - val_loss: 1.3955 - val_acc: 0.4411\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0726 - acc: 0.5241 - val_loss: 1.3662 - val_acc: 0.4622\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0426 - acc: 0.5287 - val_loss: 1.3931 - val_acc: 0.4441\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0372 - acc: 0.5431 - val_loss: 1.3792 - val_acc: 0.4562\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0560 - acc: 0.5322 - val_loss: 1.3560 - val_acc: 0.4804\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0546 - acc: 0.5396 - val_loss: 1.2555 - val_acc: 0.5227\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1400 - acc: 0.5301 - val_loss: 1.2932 - val_acc: 0.5166\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0717 - acc: 0.5382 - val_loss: 1.3284 - val_acc: 0.5106\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0392 - acc: 0.5431 - val_loss: 1.3610 - val_acc: 0.4683\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0537 - acc: 0.5372 - val_loss: 1.3259 - val_acc: 0.4894\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0353 - acc: 0.5439 - val_loss: 1.3299 - val_acc: 0.5166\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0313 - acc: 0.5470 - val_loss: 1.3171 - val_acc: 0.4894\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0405 - acc: 0.5407 - val_loss: 1.2693 - val_acc: 0.5227\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1432 - acc: 0.5210 - val_loss: 1.2772 - val_acc: 0.5287\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0847 - acc: 0.5269 - val_loss: 1.3255 - val_acc: 0.5045\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0379 - acc: 0.5301 - val_loss: 1.3192 - val_acc: 0.5045\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0519 - acc: 0.5287 - val_loss: 1.2817 - val_acc: 0.5257\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0597 - acc: 0.5358 - val_loss: 1.2996 - val_acc: 0.5287\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0270 - acc: 0.5569 - val_loss: 1.3330 - val_acc: 0.5045\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.0186 - acc: 0.5505 - val_loss: 1.3250 - val_acc: 0.4924\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0413 - acc: 0.5484 - val_loss: 1.3503 - val_acc: 0.4713\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0505 - acc: 0.5421 - val_loss: 1.3159 - val_acc: 0.4834\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0575 - acc: 0.5569 - val_loss: 1.2886 - val_acc: 0.5196\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0349 - acc: 0.5495 - val_loss: 1.2993 - val_acc: 0.5076\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.0554 - acc: 0.5368 - val_loss: 1.2922 - val_acc: 0.5287\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0361 - acc: 0.5277 - val_loss: 1.2853 - val_acc: 0.5227\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0512 - acc: 0.5474 - val_loss: 1.2849 - val_acc: 0.5136\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 1.0509 - acc: 0.5488 - val_loss: 1.3076 - val_acc: 0.5166\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>1.314027</td>\n",
       "      <td>0.534743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>0.873950</td>\n",
       "      <td>1.256399</td>\n",
       "      <td>0.574018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.0</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.483444</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>1.407440</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.089947</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.448430</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>1.498032</td>\n",
       "      <td>0.438066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.0</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>1.307601</td>\n",
       "      <td>0.516616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       122.0  0.131148  0.704918   0.967213               0.20   \n",
       "1        99.0  0.161616  0.787879   0.959596               0.22   \n",
       "2       117.0  0.136752  0.709402   0.948718               0.24   \n",
       "3       189.0  0.089947  0.587302   0.920635               0.26   \n",
       "4       107.0  0.149533  0.757009   0.962617               0.22   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.80                0.94             0.063830   \n",
       "1              0.82                0.96             0.109244   \n",
       "2              0.76                0.92             0.112583   \n",
       "3              0.80                0.94             0.071749   \n",
       "4              0.80                0.94             0.078014   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.475177              0.865248  1.314027  0.534743  \n",
       "1            0.512605              0.873950  1.256399  0.574018  \n",
       "2            0.483444              0.867550  1.407440  0.459215  \n",
       "3            0.448430              0.856502  1.498032  0.438066  \n",
       "4            0.539007              0.907801  1.307601  0.516616  "
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_analysis = pd.DataFrame()\n",
    "#, kernel_regularizer=regularizers.l1(0.0001))\n",
    "for num in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_shape=(120,), activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(25, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    ada = keras.optimizers.Adagrad()\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "    sgd = keras.optimizers.SGD(lr=0.75)\n",
    "    model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    zillow_model_2 = model.fit(x=X_train, y=y_cat_train, \n",
    "          batch_size=2000, \n",
    "          epochs=175, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_cat_test),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    loss = zillow_model_2.history['val_loss'][-1]\n",
    "    acc = zillow_model_2.history['val_acc'][-1]\n",
    "    gain_pred, gain_true_large, gain_true, gain_stay_true, four_five_split_large, four_five_split, four_five_split_mean, predicted_classes_gain_true, predicted_classes_gain_large_true, predicted_classes_gain_mean, df_metrics_z = model_metrics(predictions, y_cat_test, test_merge)\n",
    "    df_zillow_analysis.loc[num,'pred_count'] = gain_pred\n",
    "    df_zillow_analysis.loc[num,'gain_10%'] = gain_true_large\n",
    "    df_zillow_analysis.loc[num,'gain_3%'] = gain_true\n",
    "    df_zillow_analysis.loc[num,'gain_mean'] = gain_stay_true\n",
    "    df_zillow_analysis.loc[num,'top_pred_prob_10%'] = four_five_split_large\n",
    "    df_zillow_analysis.loc[num,'top_pred_prob_3%'] = four_five_split\n",
    "    df_zillow_analysis.loc[num,'top_pred_prob_mean'] = four_five_split_mean\n",
    "    df_zillow_analysis.loc[num,'model_pred_prob_10%'] = predicted_classes_gain_large_true\n",
    "    df_zillow_analysis.loc[num,'model_pred_prob_3%'] = predicted_classes_gain_true\n",
    "    df_zillow_analysis.loc[num,'model_pred_prob_mean'] = predicted_classes_gain_mean\n",
    "    df_zillow_analysis.loc[num,'loss'] = loss\n",
    "    df_zillow_analysis.loc[num,'acc'] = acc\n",
    "    print(num)\n",
    "df_175_w_z = df_zillow_analysis\n",
    "df_zillow_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>1.551617</td>\n",
       "      <td>0.332326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>1.558010</td>\n",
       "      <td>0.332326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>1.554780</td>\n",
       "      <td>0.332326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>1.561087</td>\n",
       "      <td>0.332326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>1.552505</td>\n",
       "      <td>0.332326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       331.0  0.060423  0.392749   0.827795               0.14   \n",
       "1       331.0  0.060423  0.392749   0.827795               0.14   \n",
       "2       331.0  0.060423  0.392749   0.827795               0.14   \n",
       "3       331.0  0.060423  0.392749   0.827795               0.16   \n",
       "4       331.0  0.060423  0.392749   0.827795               0.16   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.70                0.96             0.060423   \n",
       "1              0.64                0.96             0.060423   \n",
       "2              0.74                0.96             0.060423   \n",
       "3              0.68                0.98             0.060423   \n",
       "4              0.66                0.94             0.060423   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.392749              0.827795  1.551617  0.332326  \n",
       "1            0.392749              0.827795  1.558010  0.332326  \n",
       "2            0.392749              0.827795  1.554780  0.332326  \n",
       "3            0.392749              0.827795  1.561087  0.332326  \n",
       "4            0.392749              0.827795  1.552505  0.332326  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_150_z_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b76a4cf8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz9HHggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b2a98e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics['y_true'] = y_test\n",
    "data_for_model = df_metrics[['top_vs_mean_low', 'y_true']]\n",
    "plt.scatter(data_for_model['top_vs_mean_low'], data_for_model['y_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.stripplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.487342</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>1.297782</td>\n",
       "      <td>0.453172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139.0</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.491018</td>\n",
       "      <td>0.844311</td>\n",
       "      <td>1.274894</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>1.159747</td>\n",
       "      <td>0.537764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.084967</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>1.210072</td>\n",
       "      <td>0.510574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.197652</td>\n",
       "      <td>0.498489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       128.0  0.125000  0.687500   0.960938               0.24   \n",
       "1       139.0  0.115108  0.661871   0.942446               0.24   \n",
       "2       121.0  0.132231  0.702479   0.950413               0.22   \n",
       "3       119.0  0.134454  0.714286   0.941176               0.22   \n",
       "4        98.0  0.163265  0.785714   0.959184               0.24   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.78                0.92             0.069620   \n",
       "1              0.84                0.96             0.065868   \n",
       "2              0.80                0.96             0.092199   \n",
       "3              0.82                0.96             0.084967   \n",
       "4              0.82                0.96             0.090909   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.487342              0.867089  1.297782  0.453172  \n",
       "1            0.491018              0.844311  1.274894  0.459215  \n",
       "2            0.510638              0.829787  1.159747  0.537764  \n",
       "3            0.483660              0.849673  1.210072  0.510574  \n",
       "4            0.530303              0.833333  1.197652  0.498489  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>1.314027</td>\n",
       "      <td>0.534743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>0.873950</td>\n",
       "      <td>1.256399</td>\n",
       "      <td>0.574018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.0</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.483444</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>1.407440</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.089947</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.448430</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>1.498032</td>\n",
       "      <td>0.438066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.0</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>1.307601</td>\n",
       "      <td>0.516616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       122.0  0.131148  0.704918   0.967213               0.20   \n",
       "1        99.0  0.161616  0.787879   0.959596               0.22   \n",
       "2       117.0  0.136752  0.709402   0.948718               0.24   \n",
       "3       189.0  0.089947  0.587302   0.920635               0.26   \n",
       "4       107.0  0.149533  0.757009   0.962617               0.22   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.80                0.94             0.063830   \n",
       "1              0.82                0.96             0.109244   \n",
       "2              0.76                0.92             0.112583   \n",
       "3              0.80                0.94             0.071749   \n",
       "4              0.80                0.94             0.078014   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.475177              0.865248  1.314027  0.534743  \n",
       "1            0.512605              0.873950  1.256399  0.574018  \n",
       "2            0.483444              0.867550  1.407440  0.459215  \n",
       "3            0.448430              0.856502  1.498032  0.438066  \n",
       "4            0.539007              0.907801  1.307601  0.516616  "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175_w_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_400_z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-554-074d8a3e5640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_400_z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_400_z' is not defined"
     ]
    }
   ],
   "source": [
    "df_400_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>1.484431</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>1.330855</td>\n",
       "      <td>0.534743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.076142</td>\n",
       "      <td>0.482234</td>\n",
       "      <td>0.878173</td>\n",
       "      <td>1.462107</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.070922</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>1.376176</td>\n",
       "      <td>0.531722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>1.363008</td>\n",
       "      <td>0.519637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       116.0  0.094972  0.724138   0.965517           0.272727   \n",
       "1        72.0  0.094972  0.791667   0.958333           0.242424   \n",
       "2       160.0  0.094972  0.631250   0.937500           0.303030   \n",
       "3       109.0  0.094972  0.752294   0.963303           0.242424   \n",
       "4        94.0  0.094972  0.755319   0.957447           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.757576            0.909091             0.055556   \n",
       "1          0.757576            0.939394             0.120000   \n",
       "2          0.818182            0.939394             0.076142   \n",
       "3          0.757576            0.878788             0.070922   \n",
       "4          0.757576            0.939394             0.092199   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.472222              0.861111  1.484431  0.459215  \n",
       "1            0.540000              0.910000  1.330855  0.534743  \n",
       "2            0.482234              0.878173  1.462107  0.480363  \n",
       "3            0.468085              0.872340  1.376176  0.531722  \n",
       "4            0.475177              0.865248  1.363008  0.519637  "
      ]
     },
     "execution_count": 1176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_300_w_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.461039</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>1.434881</td>\n",
       "      <td>0.507553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.450340</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.533402</td>\n",
       "      <td>0.471299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>1.348234</td>\n",
       "      <td>0.513595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.089655</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>1.400084</td>\n",
       "      <td>0.486405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       123.0  0.094972  0.707317   0.951220           0.272727   \n",
       "1        97.0  0.094972  0.731959   0.969072           0.242424   \n",
       "2        95.0  0.094972  0.789474   0.957895           0.242424   \n",
       "3        89.0  0.094972  0.741573   0.943820           0.272727   \n",
       "4       110.0  0.094972  0.709091   0.936364           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.757576            0.878788             0.064935   \n",
       "1          0.787879            0.939394             0.090909   \n",
       "2          0.787879            0.939394             0.077778   \n",
       "3          0.787879            0.909091             0.083969   \n",
       "4          0.727273            0.909091             0.089655   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.461039              0.844156  1.434881  0.507553  \n",
       "1            0.518182              0.909091  1.450340  0.459215  \n",
       "2            0.488889              0.888889  1.533402  0.471299  \n",
       "3            0.488550              0.870229  1.348234  0.513595  \n",
       "4            0.496552              0.868966  1.400084  0.486405  "
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_300_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.863946</td>\n",
       "      <td>1.421515</td>\n",
       "      <td>0.510574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>1.469787</td>\n",
       "      <td>0.468278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.470270</td>\n",
       "      <td>0.881081</td>\n",
       "      <td>1.468260</td>\n",
       "      <td>0.465257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.435143</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>1.542414</td>\n",
       "      <td>0.432024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       137.0  0.094972  0.671533   0.948905           0.272727   \n",
       "1        94.0  0.094972  0.797872   0.957447           0.272727   \n",
       "2       157.0  0.094972  0.636943   0.936306           0.303030   \n",
       "3       115.0  0.094972  0.739130   0.956522           0.303030   \n",
       "4       144.0  0.094972  0.659722   0.951389           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.787879            0.939394             0.088435   \n",
       "1          0.757576            0.909091             0.090090   \n",
       "2          0.727273            0.878788             0.075676   \n",
       "3          0.757576            0.909091             0.101562   \n",
       "4          0.727273            0.909091             0.076471   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.537415              0.863946  1.421515  0.510574  \n",
       "1            0.540541              0.846847  1.469787  0.468278  \n",
       "2            0.470270              0.881081  1.468260  0.465257  \n",
       "3            0.500000              0.859375  1.435143  0.480363  \n",
       "4            0.494118              0.876471  1.542414  0.432024  "
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_250_w_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>0.852349</td>\n",
       "      <td>1.548896</td>\n",
       "      <td>0.432024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.522124</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>1.321403</td>\n",
       "      <td>0.489426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>1.274005</td>\n",
       "      <td>0.546828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>1.325635</td>\n",
       "      <td>0.489426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>1.214646</td>\n",
       "      <td>0.540785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       125.0  0.094972  0.704000   0.968000           0.272727   \n",
       "1        88.0  0.094972  0.784091   0.965909           0.272727   \n",
       "2        70.0  0.094972  0.757143   0.942857           0.242424   \n",
       "3        92.0  0.094972  0.739130   0.934783           0.272727   \n",
       "4        98.0  0.094972  0.775510   0.959184           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.727273            0.909091             0.093960   \n",
       "1          0.757576            0.909091             0.115044   \n",
       "2          0.787879            0.939394             0.048780   \n",
       "3          0.757576            0.939394             0.112903   \n",
       "4          0.818182            0.939394             0.094488   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.463087              0.852349  1.548896  0.432024  \n",
       "1            0.522124              0.858407  1.321403  0.489426  \n",
       "2            0.495935              0.861789  1.274005  0.546828  \n",
       "3            0.532258              0.830645  1.325635  0.489426  \n",
       "4            0.535433              0.881890  1.214646  0.540785  "
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_250_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.625767</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>1.407345</td>\n",
       "      <td>0.474320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.092025</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.883436</td>\n",
       "      <td>1.437591</td>\n",
       "      <td>0.483384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.669118</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.464218</td>\n",
       "      <td>0.465257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.472603</td>\n",
       "      <td>0.842466</td>\n",
       "      <td>1.397490</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>1.270403</td>\n",
       "      <td>0.543807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       163.0  0.094972  0.625767   0.938650           0.303030   \n",
       "1       144.0  0.094972  0.659722   0.951389           0.303030   \n",
       "2       136.0  0.094972  0.669118   0.955882           0.303030   \n",
       "3       133.0  0.094972  0.676692   0.954887           0.272727   \n",
       "4       110.0  0.094972  0.754545   0.963636           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.757576            0.909091             0.083770   \n",
       "1          0.787879            0.909091             0.092025   \n",
       "2          0.787879            0.969697             0.096970   \n",
       "3          0.787879            0.909091             0.095890   \n",
       "4          0.787879            0.939394             0.097561   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.465969              0.879581  1.407345  0.474320  \n",
       "1            0.496933              0.883436  1.437591  0.483384  \n",
       "2            0.515152              0.878788  1.464218  0.465257  \n",
       "3            0.472603              0.842466  1.397490  0.480363  \n",
       "4            0.495935              0.886179  1.270403  0.543807  "
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200_w_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>1.196810</td>\n",
       "      <td>0.546828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.932039</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.430894</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>1.307886</td>\n",
       "      <td>0.483384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>1.204385</td>\n",
       "      <td>0.525680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>1.294213</td>\n",
       "      <td>0.492447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.093525</td>\n",
       "      <td>0.525180</td>\n",
       "      <td>0.856115</td>\n",
       "      <td>1.235405</td>\n",
       "      <td>0.489426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        93.0  0.094972  0.795699   0.956989           0.272727   \n",
       "1       103.0  0.094972  0.718447   0.932039           0.242424   \n",
       "2        88.0  0.094972  0.784091   0.954545           0.242424   \n",
       "3        82.0  0.094972  0.804878   0.951220           0.242424   \n",
       "4        95.0  0.094972  0.768421   0.957895           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.969697             0.094828   \n",
       "1          0.757576            0.939394             0.097561   \n",
       "2          0.787879            0.939394             0.082569   \n",
       "3          0.787879            0.969697             0.078431   \n",
       "4          0.787879            0.939394             0.093525   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.439655              0.818966  1.196810  0.546828  \n",
       "1            0.430894              0.829268  1.307886  0.483384  \n",
       "2            0.495413              0.871560  1.204385  0.525680  \n",
       "3            0.500000              0.803922  1.294213  0.492447  \n",
       "4            0.525180              0.856115  1.235405  0.489426  "
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>1.245467</td>\n",
       "      <td>0.580060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.952703</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.461111</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>1.352093</td>\n",
       "      <td>0.513595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>1.461635</td>\n",
       "      <td>0.407855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.633136</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>1.357489</td>\n",
       "      <td>0.483384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.096257</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>1.349806</td>\n",
       "      <td>0.474320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        76.0  0.094972  0.815789   0.960526           0.212121   \n",
       "1       148.0  0.094972  0.668919   0.952703           0.272727   \n",
       "2       180.0  0.094972  0.611111   0.916667           0.303030   \n",
       "3       169.0  0.094972  0.633136   0.934911           0.272727   \n",
       "4       170.0  0.094972  0.623529   0.947059           0.303030   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.787879            0.969697             0.107438   \n",
       "1          0.818182            0.939394             0.077778   \n",
       "2          0.727273            0.909091             0.070796   \n",
       "3          0.757576            0.909091             0.071429   \n",
       "4          0.787879            0.939394             0.096257   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.545455              0.884298  1.245467  0.580060  \n",
       "1            0.461111              0.827778  1.352093  0.513595  \n",
       "2            0.469027              0.858407  1.461635  0.407855  \n",
       "3            0.464286              0.862245  1.357489  0.483384  \n",
       "4            0.524064              0.887701  1.349806  0.474320  "
      ]
     },
     "execution_count": 1174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_150_w_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.525926</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>1.184601</td>\n",
       "      <td>0.483384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.175836</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>1.226775</td>\n",
       "      <td>0.474320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>1.246916</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.110345</td>\n",
       "      <td>0.475862</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>1.179244</td>\n",
       "      <td>0.513595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       106.0  0.094972  0.754717   0.952830           0.272727   \n",
       "1       114.0  0.094972  0.745614   0.956140           0.303030   \n",
       "2       152.0  0.094972  0.651316   0.953947           0.303030   \n",
       "3       142.0  0.094972  0.676056   0.950704           0.333333   \n",
       "4       113.0  0.094972  0.734513   0.938053           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.787879            0.939394             0.081481   \n",
       "1          0.757576            0.878788             0.070312   \n",
       "2          0.757576            0.909091             0.084746   \n",
       "3          0.818182            0.939394             0.093750   \n",
       "4          0.787879            0.939394             0.110345   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.525926              0.851852  1.184601  0.483384  \n",
       "1            0.507812              0.843750  1.175836  0.480363  \n",
       "2            0.525424              0.847458  1.226775  0.474320  \n",
       "3            0.506250              0.862500  1.246916  0.459215  \n",
       "4            0.475862              0.882759  1.179244  0.513595  "
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_150_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 17s 6ms/step - loss: 2.2326 - acc: 0.1803 - val_loss: 1.8770 - val_acc: 0.2991\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.7467 - acc: 0.3008 - val_loss: 1.8497 - val_acc: 0.3051\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.7136 - acc: 0.3184 - val_loss: 1.8502 - val_acc: 0.2870\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.6685 - acc: 0.3318 - val_loss: 1.7744 - val_acc: 0.3293\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6534 - acc: 0.3522 - val_loss: 1.7843 - val_acc: 0.3323\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6437 - acc: 0.3625 - val_loss: 1.7868 - val_acc: 0.3323\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.6290 - acc: 0.3586 - val_loss: 1.7319 - val_acc: 0.3323\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6082 - acc: 0.3614 - val_loss: 1.7598 - val_acc: 0.3323\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5998 - acc: 0.3544 - val_loss: 1.7795 - val_acc: 0.3263\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6064 - acc: 0.3512 - val_loss: 1.7263 - val_acc: 0.3323\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5850 - acc: 0.3713 - val_loss: 1.7265 - val_acc: 0.3202\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5828 - acc: 0.3649 - val_loss: 1.7021 - val_acc: 0.3323\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5644 - acc: 0.3702 - val_loss: 1.7326 - val_acc: 0.3202\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.5684 - acc: 0.3603 - val_loss: 1.6391 - val_acc: 0.3323\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5704 - acc: 0.3737 - val_loss: 1.7110 - val_acc: 0.3263\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5494 - acc: 0.3635 - val_loss: 1.6785 - val_acc: 0.3293\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.5466 - acc: 0.3674 - val_loss: 1.6443 - val_acc: 0.3293\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5361 - acc: 0.3794 - val_loss: 1.6965 - val_acc: 0.3263\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5208 - acc: 0.3772 - val_loss: 1.6383 - val_acc: 0.3293\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5065 - acc: 0.3839 - val_loss: 1.6450 - val_acc: 0.3233\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5123 - acc: 0.3787 - val_loss: 1.6766 - val_acc: 0.3202\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5076 - acc: 0.3702 - val_loss: 1.6696 - val_acc: 0.3263\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4930 - acc: 0.3716 - val_loss: 1.6176 - val_acc: 0.3233\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4757 - acc: 0.3864 - val_loss: 1.6770 - val_acc: 0.3021\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4811 - acc: 0.3713 - val_loss: 1.6788 - val_acc: 0.2779\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4700 - acc: 0.3744 - val_loss: 1.6518 - val_acc: 0.3112\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.4560 - acc: 0.3825 - val_loss: 1.6147 - val_acc: 0.3233\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4612 - acc: 0.3751 - val_loss: 1.5311 - val_acc: 0.3202\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.4470 - acc: 0.400 - 0s 34us/step - loss: 1.4485 - acc: 0.3973 - val_loss: 1.5922 - val_acc: 0.3233\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4379 - acc: 0.3966 - val_loss: 1.6321 - val_acc: 0.3112\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4429 - acc: 0.3755 - val_loss: 1.5934 - val_acc: 0.3263\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4232 - acc: 0.3839 - val_loss: 1.6024 - val_acc: 0.3051\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4263 - acc: 0.3836 - val_loss: 1.6474 - val_acc: 0.3051\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4392 - acc: 0.3850 - val_loss: 1.6394 - val_acc: 0.2689\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4085 - acc: 0.3818 - val_loss: 1.5794 - val_acc: 0.3082\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.3975 - acc: 0.3882 - val_loss: 1.6272 - val_acc: 0.2810\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3990 - acc: 0.3751 - val_loss: 1.6004 - val_acc: 0.2931\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4067 - acc: 0.3755 - val_loss: 1.5698 - val_acc: 0.2900\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3919 - acc: 0.3917 - val_loss: 1.5802 - val_acc: 0.2840\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3854 - acc: 0.3913 - val_loss: 1.6110 - val_acc: 0.2568\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3804 - acc: 0.3776 - val_loss: 1.5750 - val_acc: 0.2870\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3708 - acc: 0.3913 - val_loss: 1.5715 - val_acc: 0.3051\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.3637 - acc: 0.3980 - val_loss: 1.6069 - val_acc: 0.2598\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3617 - acc: 0.3748 - val_loss: 1.5097 - val_acc: 0.3233\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3598 - acc: 0.3910 - val_loss: 1.6033 - val_acc: 0.2598\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3601 - acc: 0.3882 - val_loss: 1.6137 - val_acc: 0.2568\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.3593 - acc: 0.3804 - val_loss: 1.5532 - val_acc: 0.2991\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3277 - acc: 0.3977 - val_loss: 1.5213 - val_acc: 0.3142\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3266 - acc: 0.4012 - val_loss: 1.5138 - val_acc: 0.3021\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3265 - acc: 0.3896 - val_loss: 1.5210 - val_acc: 0.2991\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3234 - acc: 0.4015 - val_loss: 1.5691 - val_acc: 0.2961\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3306 - acc: 0.3980 - val_loss: 1.5121 - val_acc: 0.3263\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3300 - acc: 0.4100 - val_loss: 1.4923 - val_acc: 0.3142\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3105 - acc: 0.4079 - val_loss: 1.5037 - val_acc: 0.3142\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3119 - acc: 0.4012 - val_loss: 1.5099 - val_acc: 0.2870\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3082 - acc: 0.3987 - val_loss: 1.4910 - val_acc: 0.3112\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2957 - acc: 0.4068 - val_loss: 1.4278 - val_acc: 0.3202\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3148 - acc: 0.4178 - val_loss: 1.4285 - val_acc: 0.3172\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2893 - acc: 0.4051 - val_loss: 1.4743 - val_acc: 0.2900\n",
      "Epoch 60/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3111 - acc: 0.3945 - val_loss: 1.4309 - val_acc: 0.3142\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2999 - acc: 0.4121 - val_loss: 1.4076 - val_acc: 0.3233\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3023 - acc: 0.4111 - val_loss: 1.4565 - val_acc: 0.3112\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2771 - acc: 0.4047 - val_loss: 1.4169 - val_acc: 0.3112\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2848 - acc: 0.4135 - val_loss: 1.4935 - val_acc: 0.2810\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2845 - acc: 0.4012 - val_loss: 1.4152 - val_acc: 0.3172\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2876 - acc: 0.4104 - val_loss: 1.4148 - val_acc: 0.3142\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2946 - acc: 0.4068 - val_loss: 1.4033 - val_acc: 0.3202\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2628 - acc: 0.4146 - val_loss: 1.4716 - val_acc: 0.2961\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2610 - acc: 0.4040 - val_loss: 1.4188 - val_acc: 0.3142\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2745 - acc: 0.4160 - val_loss: 1.4207 - val_acc: 0.3142\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2727 - acc: 0.4132 - val_loss: 1.3858 - val_acc: 0.3202\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2682 - acc: 0.4248 - val_loss: 1.4424 - val_acc: 0.3082\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2413 - acc: 0.4216 - val_loss: 1.4183 - val_acc: 0.3082\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2525 - acc: 0.4079 - val_loss: 1.3685 - val_acc: 0.3202\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2740 - acc: 0.4202 - val_loss: 1.3930 - val_acc: 0.3142\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2504 - acc: 0.4181 - val_loss: 1.4076 - val_acc: 0.3172\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2420 - acc: 0.4188 - val_loss: 1.5130 - val_acc: 0.2991\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2425 - acc: 0.4114 - val_loss: 1.4801 - val_acc: 0.3021\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2441 - acc: 0.4118 - val_loss: 1.4429 - val_acc: 0.3202\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2407 - acc: 0.4276 - val_loss: 1.4723 - val_acc: 0.2961\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2397 - acc: 0.4135 - val_loss: 1.4921 - val_acc: 0.2931\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2349 - acc: 0.4142 - val_loss: 1.4858 - val_acc: 0.2810\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2363 - acc: 0.4132 - val_loss: 1.4723 - val_acc: 0.2870\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2205 - acc: 0.4132 - val_loss: 1.4814 - val_acc: 0.2810\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2255 - acc: 0.4121 - val_loss: 1.5167 - val_acc: 0.2840\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2426 - acc: 0.3945 - val_loss: 1.4370 - val_acc: 0.3233\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2070 - acc: 0.4248 - val_loss: 1.3760 - val_acc: 0.3293\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2102 - acc: 0.4378 - val_loss: 1.3691 - val_acc: 0.3353\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2116 - acc: 0.4336 - val_loss: 1.3511 - val_acc: 0.3535\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2128 - acc: 0.4347 - val_loss: 1.3265 - val_acc: 0.3686\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2145 - acc: 0.4421 - val_loss: 1.3550 - val_acc: 0.4199\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2201 - acc: 0.4495 - val_loss: 1.3769 - val_acc: 0.4109\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2056 - acc: 0.4371 - val_loss: 1.3781 - val_acc: 0.4018\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1862 - acc: 0.4569 - val_loss: 1.4171 - val_acc: 0.3444\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1987 - acc: 0.4308 - val_loss: 1.4965 - val_acc: 0.3172\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2191 - acc: 0.4251 - val_loss: 1.4117 - val_acc: 0.3595\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1816 - acc: 0.4459 - val_loss: 1.4504 - val_acc: 0.3535\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2098 - acc: 0.4244 - val_loss: 1.4651 - val_acc: 0.3474\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2043 - acc: 0.4273 - val_loss: 1.4565 - val_acc: 0.3535\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1870 - acc: 0.4280 - val_loss: 1.4360 - val_acc: 0.3716\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1920 - acc: 0.4308 - val_loss: 1.4116 - val_acc: 0.3625\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1914 - acc: 0.4435 - val_loss: 1.3736 - val_acc: 0.3837\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1925 - acc: 0.4435 - val_loss: 1.3787 - val_acc: 0.3807\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1753 - acc: 0.4512 - val_loss: 1.3854 - val_acc: 0.3867\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1858 - acc: 0.4502 - val_loss: 1.4211 - val_acc: 0.3625\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1935 - acc: 0.4414 - val_loss: 1.3888 - val_acc: 0.3686\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1763 - acc: 0.4392 - val_loss: 1.4141 - val_acc: 0.3686\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1833 - acc: 0.4456 - val_loss: 1.4086 - val_acc: 0.3686\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1802 - acc: 0.4463 - val_loss: 1.4190 - val_acc: 0.3625\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1824 - acc: 0.4399 - val_loss: 1.4126 - val_acc: 0.3867\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1752 - acc: 0.4403 - val_loss: 1.3580 - val_acc: 0.4169\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1594 - acc: 0.4547 - val_loss: 1.4379 - val_acc: 0.3625\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1834 - acc: 0.4392 - val_loss: 1.3662 - val_acc: 0.3897\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1714 - acc: 0.4484 - val_loss: 1.3230 - val_acc: 0.4411\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1429 - acc: 0.4646 - val_loss: 1.2602 - val_acc: 0.4894\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1763 - acc: 0.4752 - val_loss: 1.3051 - val_acc: 0.4562\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1693 - acc: 0.4773 - val_loss: 1.3091 - val_acc: 0.4713\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1571 - acc: 0.4639 - val_loss: 1.3197 - val_acc: 0.4592\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1486 - acc: 0.4702 - val_loss: 1.3307 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1493 - acc: 0.4664 - val_loss: 1.3391 - val_acc: 0.4411\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1526 - acc: 0.4731 - val_loss: 1.3129 - val_acc: 0.4713\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1517 - acc: 0.4660 - val_loss: 1.3277 - val_acc: 0.4381\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1422 - acc: 0.4653 - val_loss: 1.4179 - val_acc: 0.3927\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1476 - acc: 0.4611 - val_loss: 1.3484 - val_acc: 0.4260\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1438 - acc: 0.4611 - val_loss: 1.4265 - val_acc: 0.3686\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1788 - acc: 0.4442 - val_loss: 1.3918 - val_acc: 0.4018\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1410 - acc: 0.4484 - val_loss: 1.3297 - val_acc: 0.4260\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1269 - acc: 0.4646 - val_loss: 1.3750 - val_acc: 0.4018\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1456 - acc: 0.4540 - val_loss: 1.3562 - val_acc: 0.4169\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1260 - acc: 0.4650 - val_loss: 1.3232 - val_acc: 0.4381\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1167 - acc: 0.4699 - val_loss: 1.2617 - val_acc: 0.4622\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1580 - acc: 0.4706 - val_loss: 1.2781 - val_acc: 0.4502\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1486 - acc: 0.4787 - val_loss: 1.2927 - val_acc: 0.4622\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1185 - acc: 0.4942 - val_loss: 1.3474 - val_acc: 0.4350\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1667 - acc: 0.4650 - val_loss: 1.3054 - val_acc: 0.4532\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1307 - acc: 0.4857 - val_loss: 1.2802 - val_acc: 0.4834\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1231 - acc: 0.4794 - val_loss: 1.2754 - val_acc: 0.4713\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1263 - acc: 0.4773 - val_loss: 1.2551 - val_acc: 0.4834\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1539 - acc: 0.4910 - val_loss: 1.2577 - val_acc: 0.4713\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1307 - acc: 0.4819 - val_loss: 1.2532 - val_acc: 0.4834\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1150 - acc: 0.4928 - val_loss: 1.2833 - val_acc: 0.4532\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1118 - acc: 0.4783 - val_loss: 1.2654 - val_acc: 0.4743\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1193 - acc: 0.4692 - val_loss: 1.3079 - val_acc: 0.4622\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1277 - acc: 0.4790 - val_loss: 1.4053 - val_acc: 0.3958\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1264 - acc: 0.4424 - val_loss: 1.3037 - val_acc: 0.4441\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1050 - acc: 0.4794 - val_loss: 1.3006 - val_acc: 0.4713\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1089 - acc: 0.4917 - val_loss: 1.4010 - val_acc: 0.4079\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1513 - acc: 0.4480 - val_loss: 1.3612 - val_acc: 0.4199\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1162 - acc: 0.4713 - val_loss: 1.3600 - val_acc: 0.4230\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1034 - acc: 0.4709 - val_loss: 1.2970 - val_acc: 0.4562\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.0984 - acc: 0.4688 - val_loss: 1.2974 - val_acc: 0.4592\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.0882 - acc: 0.4938 - val_loss: 1.3106 - val_acc: 0.4471\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0864 - acc: 0.4815 - val_loss: 1.3306 - val_acc: 0.4411\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1109 - acc: 0.4857 - val_loss: 1.3694 - val_acc: 0.4169\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1266 - acc: 0.4748 - val_loss: 1.3633 - val_acc: 0.4260\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1399 - acc: 0.4590 - val_loss: 1.3061 - val_acc: 0.4532\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1028 - acc: 0.4797 - val_loss: 1.2961 - val_acc: 0.4532\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0860 - acc: 0.4893 - val_loss: 1.3787 - val_acc: 0.4169\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1118 - acc: 0.4727 - val_loss: 1.3785 - val_acc: 0.4169\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1153 - acc: 0.4554 - val_loss: 1.3214 - val_acc: 0.4471\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1113 - acc: 0.4727 - val_loss: 1.3112 - val_acc: 0.4502\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0965 - acc: 0.4780 - val_loss: 1.3060 - val_acc: 0.4532\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0869 - acc: 0.4759 - val_loss: 1.3143 - val_acc: 0.4471\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0869 - acc: 0.4871 - val_loss: 1.3815 - val_acc: 0.4139\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1172 - acc: 0.4604 - val_loss: 1.3543 - val_acc: 0.4230\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0952 - acc: 0.4660 - val_loss: 1.3177 - val_acc: 0.4532\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0794 - acc: 0.4896 - val_loss: 1.3192 - val_acc: 0.4320\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0964 - acc: 0.4840 - val_loss: 1.3108 - val_acc: 0.4471\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0992 - acc: 0.4907 - val_loss: 1.2926 - val_acc: 0.4713\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0869 - acc: 0.4826 - val_loss: 1.3511 - val_acc: 0.4169\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0895 - acc: 0.4600 - val_loss: 1.3173 - val_acc: 0.4471\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0814 - acc: 0.4769 - val_loss: 1.3284 - val_acc: 0.4381\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0842 - acc: 0.4854 - val_loss: 1.3791 - val_acc: 0.4048\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0960 - acc: 0.4723 - val_loss: 1.3434 - val_acc: 0.4350\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0799 - acc: 0.4812 - val_loss: 1.2531 - val_acc: 0.4743\n",
      "0\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 16s 6ms/step - loss: 2.1729 - acc: 0.1367 - val_loss: 1.9573 - val_acc: 0.3293\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.7791 - acc: 0.2853 - val_loss: 1.8555 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.7175 - acc: 0.3265 - val_loss: 1.8310 - val_acc: 0.3323\n",
      "Epoch 4/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.6926 - acc: 0.3417 - val_loss: 1.7946 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6758 - acc: 0.3526 - val_loss: 1.8019 - val_acc: 0.3323\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.6555 - acc: 0.3403 - val_loss: 1.7887 - val_acc: 0.3323\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6663 - acc: 0.3230 - val_loss: 1.7702 - val_acc: 0.3323\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6368 - acc: 0.3473 - val_loss: 1.7280 - val_acc: 0.3293\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6248 - acc: 0.3656 - val_loss: 1.7508 - val_acc: 0.3263\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6074 - acc: 0.3533 - val_loss: 1.7069 - val_acc: 0.3293\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6095 - acc: 0.3568 - val_loss: 1.7383 - val_acc: 0.3293\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6026 - acc: 0.3632 - val_loss: 1.7018 - val_acc: 0.3293\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5632 - acc: 0.3660 - val_loss: 1.7436 - val_acc: 0.3323\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5594 - acc: 0.3600 - val_loss: 1.7266 - val_acc: 0.3293\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5614 - acc: 0.3582 - val_loss: 1.7161 - val_acc: 0.3293\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5506 - acc: 0.3575 - val_loss: 1.6891 - val_acc: 0.3293\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.5357 - acc: 0.3667 - val_loss: 1.6384 - val_acc: 0.3263\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.5282 - acc: 0.3794 - val_loss: 1.6683 - val_acc: 0.3263\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5134 - acc: 0.3695 - val_loss: 1.6872 - val_acc: 0.2991\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5180 - acc: 0.3617 - val_loss: 1.6944 - val_acc: 0.3293\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5016 - acc: 0.3642 - val_loss: 1.6151 - val_acc: 0.3263\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4840 - acc: 0.3853 - val_loss: 1.6550 - val_acc: 0.3293\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4653 - acc: 0.3839 - val_loss: 1.6674 - val_acc: 0.3142\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4718 - acc: 0.3762 - val_loss: 1.5423 - val_acc: 0.3263\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4945 - acc: 0.3808 - val_loss: 1.6230 - val_acc: 0.3172\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4517 - acc: 0.3977 - val_loss: 1.6139 - val_acc: 0.3233\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4548 - acc: 0.3825 - val_loss: 1.5761 - val_acc: 0.3293\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4558 - acc: 0.3850 - val_loss: 1.6732 - val_acc: 0.2961\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4465 - acc: 0.3723 - val_loss: 1.6009 - val_acc: 0.3233\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4327 - acc: 0.3825 - val_loss: 1.7063 - val_acc: 0.2508\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4432 - acc: 0.3568 - val_loss: 1.6032 - val_acc: 0.3233\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.4150 - acc: 0.3938 - val_loss: 1.5991 - val_acc: 0.3233\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4180 - acc: 0.3913 - val_loss: 1.5505 - val_acc: 0.3233\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4156 - acc: 0.3818 - val_loss: 1.6090 - val_acc: 0.3353\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3989 - acc: 0.3737 - val_loss: 1.5412 - val_acc: 0.3384\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3870 - acc: 0.3864 - val_loss: 1.5924 - val_acc: 0.3233\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.3802 - acc: 0.383 - 0s 35us/step - loss: 1.3806 - acc: 0.3984 - val_loss: 1.6544 - val_acc: 0.2779\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3965 - acc: 0.3790 - val_loss: 1.6393 - val_acc: 0.2961\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3796 - acc: 0.3762 - val_loss: 1.5612 - val_acc: 0.3353\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3744 - acc: 0.4104 - val_loss: 1.4814 - val_acc: 0.3625\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3719 - acc: 0.4061 - val_loss: 1.5319 - val_acc: 0.3474\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3625 - acc: 0.4058 - val_loss: 1.4651 - val_acc: 0.3505\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3595 - acc: 0.4065 - val_loss: 1.5107 - val_acc: 0.3505\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3486 - acc: 0.4104 - val_loss: 1.5544 - val_acc: 0.3353\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3486 - acc: 0.3991 - val_loss: 1.5750 - val_acc: 0.3263\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3418 - acc: 0.4037 - val_loss: 1.5771 - val_acc: 0.3263\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3294 - acc: 0.4012 - val_loss: 1.5419 - val_acc: 0.3353\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3364 - acc: 0.4061 - val_loss: 1.5626 - val_acc: 0.3233\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3357 - acc: 0.3956 - val_loss: 1.5305 - val_acc: 0.3323\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3142 - acc: 0.4037 - val_loss: 1.5312 - val_acc: 0.3172\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3186 - acc: 0.4072 - val_loss: 1.5275 - val_acc: 0.3293\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2985 - acc: 0.4139 - val_loss: 1.4359 - val_acc: 0.3746\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2984 - acc: 0.4248 - val_loss: 1.4128 - val_acc: 0.3837\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2997 - acc: 0.4382 - val_loss: 1.3982 - val_acc: 0.3807\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3136 - acc: 0.4318 - val_loss: 1.4160 - val_acc: 0.3746\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2864 - acc: 0.4237 - val_loss: 1.4464 - val_acc: 0.3565\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2810 - acc: 0.4424 - val_loss: 1.6084 - val_acc: 0.2840\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3148 - acc: 0.4023 - val_loss: 1.5451 - val_acc: 0.3323\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2929 - acc: 0.4097 - val_loss: 1.4938 - val_acc: 0.3384\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2909 - acc: 0.4082 - val_loss: 1.4189 - val_acc: 0.3686\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2915 - acc: 0.4266 - val_loss: 1.4263 - val_acc: 0.3716\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2856 - acc: 0.4170 - val_loss: 1.4146 - val_acc: 0.3837\n",
      "Epoch 63/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2735 - acc: 0.4325 - val_loss: 1.4254 - val_acc: 0.3656\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2627 - acc: 0.4417 - val_loss: 1.4137 - val_acc: 0.3867\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2598 - acc: 0.4428 - val_loss: 1.3923 - val_acc: 0.4411\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2850 - acc: 0.4322 - val_loss: 1.3680 - val_acc: 0.4290\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2731 - acc: 0.4487 - val_loss: 1.3590 - val_acc: 0.4290\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2759 - acc: 0.4325 - val_loss: 1.3939 - val_acc: 0.3927\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2731 - acc: 0.4333 - val_loss: 1.4136 - val_acc: 0.3776\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2547 - acc: 0.4385 - val_loss: 1.4809 - val_acc: 0.3293\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2539 - acc: 0.4308 - val_loss: 1.4864 - val_acc: 0.3202\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2590 - acc: 0.4153 - val_loss: 1.4271 - val_acc: 0.3535\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2376 - acc: 0.4357 - val_loss: 1.3550 - val_acc: 0.4079\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2606 - acc: 0.4273 - val_loss: 1.3597 - val_acc: 0.4018\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2547 - acc: 0.4452 - val_loss: 1.4049 - val_acc: 0.3837\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2371 - acc: 0.4452 - val_loss: 1.3363 - val_acc: 0.4290\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2450 - acc: 0.4502 - val_loss: 1.4249 - val_acc: 0.3686\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2104 - acc: 0.4371 - val_loss: 1.3841 - val_acc: 0.4260\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2210 - acc: 0.4477 - val_loss: 1.3491 - val_acc: 0.4683\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2267 - acc: 0.4533 - val_loss: 1.3486 - val_acc: 0.4622\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2281 - acc: 0.4470 - val_loss: 1.3274 - val_acc: 0.4834\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2474 - acc: 0.4431 - val_loss: 1.3395 - val_acc: 0.4230\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2489 - acc: 0.4558 - val_loss: 1.3405 - val_acc: 0.4653\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2343 - acc: 0.4547 - val_loss: 1.4002 - val_acc: 0.4018\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2061 - acc: 0.4502 - val_loss: 1.3800 - val_acc: 0.4199\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1987 - acc: 0.4681 - val_loss: 1.3872 - val_acc: 0.4169\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2192 - acc: 0.4600 - val_loss: 1.3658 - val_acc: 0.4350\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1902 - acc: 0.4579 - val_loss: 1.4146 - val_acc: 0.4199\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2089 - acc: 0.4551 - val_loss: 1.5081 - val_acc: 0.3474\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2226 - acc: 0.4280 - val_loss: 1.4334 - val_acc: 0.3988\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2037 - acc: 0.4456 - val_loss: 1.4194 - val_acc: 0.3988\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1863 - acc: 0.4590 - val_loss: 1.3855 - val_acc: 0.4230\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2032 - acc: 0.4509 - val_loss: 1.3737 - val_acc: 0.4320\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2022 - acc: 0.4537 - val_loss: 1.3500 - val_acc: 0.4502\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2004 - acc: 0.4674 - val_loss: 1.4088 - val_acc: 0.4018\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1837 - acc: 0.4664 - val_loss: 1.4678 - val_acc: 0.3837\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2019 - acc: 0.4290 - val_loss: 1.4570 - val_acc: 0.3807\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2027 - acc: 0.4456 - val_loss: 1.3797 - val_acc: 0.4350\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1860 - acc: 0.4576 - val_loss: 1.3411 - val_acc: 0.4683\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1696 - acc: 0.4847 - val_loss: 1.3384 - val_acc: 0.4743\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1737 - acc: 0.4720 - val_loss: 1.3925 - val_acc: 0.4169\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2048 - acc: 0.4487 - val_loss: 1.4782 - val_acc: 0.3656\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2196 - acc: 0.4276 - val_loss: 1.3992 - val_acc: 0.4260\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1873 - acc: 0.4505 - val_loss: 1.3567 - val_acc: 0.4622\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1668 - acc: 0.4688 - val_loss: 1.2875 - val_acc: 0.5076\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1833 - acc: 0.4738 - val_loss: 1.3120 - val_acc: 0.5045\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1640 - acc: 0.4723 - val_loss: 1.2687 - val_acc: 0.5589\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2066 - acc: 0.4780 - val_loss: 1.2781 - val_acc: 0.5045\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1853 - acc: 0.4692 - val_loss: 1.2760 - val_acc: 0.4955\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1677 - acc: 0.4685 - val_loss: 1.3218 - val_acc: 0.4622\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1605 - acc: 0.4509 - val_loss: 1.3809 - val_acc: 0.4260\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1718 - acc: 0.4628 - val_loss: 1.3432 - val_acc: 0.4502\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1669 - acc: 0.4745 - val_loss: 1.3739 - val_acc: 0.4230\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1472 - acc: 0.4716 - val_loss: 1.3954 - val_acc: 0.4230\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1822 - acc: 0.4646 - val_loss: 1.4352 - val_acc: 0.3807\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1818 - acc: 0.4498 - val_loss: 1.3563 - val_acc: 0.4441\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1482 - acc: 0.4664 - val_loss: 1.3581 - val_acc: 0.4381\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1674 - acc: 0.4674 - val_loss: 1.3209 - val_acc: 0.4713\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1530 - acc: 0.4727 - val_loss: 1.3103 - val_acc: 0.4743\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1427 - acc: 0.4776 - val_loss: 1.3834 - val_acc: 0.4290\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1545 - acc: 0.4731 - val_loss: 1.4102 - val_acc: 0.4169\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1606 - acc: 0.4579 - val_loss: 1.3869 - val_acc: 0.4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1558 - acc: 0.4544 - val_loss: 1.3736 - val_acc: 0.4441\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1519 - acc: 0.4604 - val_loss: 1.3534 - val_acc: 0.4592\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1506 - acc: 0.4748 - val_loss: 1.3821 - val_acc: 0.4260\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1453 - acc: 0.4600 - val_loss: 1.3699 - val_acc: 0.4411\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1259 - acc: 0.4695 - val_loss: 1.3427 - val_acc: 0.4592\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1335 - acc: 0.4801 - val_loss: 1.3188 - val_acc: 0.4562\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1359 - acc: 0.4808 - val_loss: 1.3192 - val_acc: 0.4713\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1353 - acc: 0.4797 - val_loss: 1.3138 - val_acc: 0.4743\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1316 - acc: 0.4780 - val_loss: 1.3255 - val_acc: 0.4622\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1225 - acc: 0.4695 - val_loss: 1.3824 - val_acc: 0.4169\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1439 - acc: 0.4716 - val_loss: 1.4113 - val_acc: 0.4139\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 30us/step - loss: 1.1496 - acc: 0.4477 - val_loss: 1.3388 - val_acc: 0.4653\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1214 - acc: 0.4745 - val_loss: 1.3427 - val_acc: 0.4471\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1189 - acc: 0.4709 - val_loss: 1.3162 - val_acc: 0.4743\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1202 - acc: 0.4935 - val_loss: 1.3278 - val_acc: 0.4683\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1289 - acc: 0.4759 - val_loss: 1.3684 - val_acc: 0.4350\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1292 - acc: 0.4805 - val_loss: 1.3324 - val_acc: 0.4743\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1260 - acc: 0.4833 - val_loss: 1.3413 - val_acc: 0.4592\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.1273 - acc: 0.4871 - val_loss: 1.3845 - val_acc: 0.4381\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1294 - acc: 0.4706 - val_loss: 1.3509 - val_acc: 0.4532\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1384 - acc: 0.4660 - val_loss: 1.3282 - val_acc: 0.4592\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1210 - acc: 0.4741 - val_loss: 1.2954 - val_acc: 0.4894\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0985 - acc: 0.4977 - val_loss: 1.3431 - val_acc: 0.4683\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1121 - acc: 0.4854 - val_loss: 1.3655 - val_acc: 0.4260\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1431 - acc: 0.4776 - val_loss: 1.3451 - val_acc: 0.4532\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1019 - acc: 0.4812 - val_loss: 1.2970 - val_acc: 0.4924\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1024 - acc: 0.4868 - val_loss: 1.3170 - val_acc: 0.4653\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1207 - acc: 0.4833 - val_loss: 1.3173 - val_acc: 0.4653\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0922 - acc: 0.4974 - val_loss: 1.3027 - val_acc: 0.4804\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1035 - acc: 0.4847 - val_loss: 1.2771 - val_acc: 0.4985\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0757 - acc: 0.5150 - val_loss: 1.3106 - val_acc: 0.4834\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0913 - acc: 0.4991 - val_loss: 1.2974 - val_acc: 0.4894\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0767 - acc: 0.5107 - val_loss: 1.3677 - val_acc: 0.4320\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1136 - acc: 0.4625 - val_loss: 1.3456 - val_acc: 0.4532\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0932 - acc: 0.4857 - val_loss: 1.3158 - val_acc: 0.4804\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0913 - acc: 0.5026 - val_loss: 1.3126 - val_acc: 0.4532\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1141 - acc: 0.4871 - val_loss: 1.3002 - val_acc: 0.4804\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1029 - acc: 0.4769 - val_loss: 1.2373 - val_acc: 0.5317\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1076 - acc: 0.4896 - val_loss: 1.2232 - val_acc: 0.5106\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0874 - acc: 0.5107 - val_loss: 1.2437 - val_acc: 0.5076\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0925 - acc: 0.5164 - val_loss: 1.2449 - val_acc: 0.5196\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0992 - acc: 0.5100 - val_loss: 1.2771 - val_acc: 0.4864\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0802 - acc: 0.5174 - val_loss: 1.2220 - val_acc: 0.5166\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1113 - acc: 0.5181 - val_loss: 1.2274 - val_acc: 0.5227\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0923 - acc: 0.5160 - val_loss: 1.2263 - val_acc: 0.5227\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0962 - acc: 0.5107 - val_loss: 1.2286 - val_acc: 0.5166\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0771 - acc: 0.5164 - val_loss: 1.2314 - val_acc: 0.5136\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0713 - acc: 0.5114 - val_loss: 1.2131 - val_acc: 0.5166\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.0890 - acc: 0.5093 - val_loss: 1.2195 - val_acc: 0.5196\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0766 - acc: 0.5111 - val_loss: 1.2303 - val_acc: 0.5076\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0753 - acc: 0.5097 - val_loss: 1.2825 - val_acc: 0.4683\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1164 - acc: 0.5125 - val_loss: 1.2462 - val_acc: 0.5166\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0661 - acc: 0.5132 - val_loss: 1.2379 - val_acc: 0.5136\n",
      "1\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 16s 6ms/step - loss: 2.1807 - acc: 0.2075 - val_loss: 1.9177 - val_acc: 0.2689\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.8099 - acc: 0.2853 - val_loss: 1.8256 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.7460 - acc: 0.3237 - val_loss: 1.8252 - val_acc: 0.3323\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.6949 - acc: 0.3226 - val_loss: 1.7793 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6791 - acc: 0.3223 - val_loss: 1.7216 - val_acc: 0.3323\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6603 - acc: 0.3480 - val_loss: 1.7183 - val_acc: 0.3323\n",
      "Epoch 7/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6475 - acc: 0.3396 - val_loss: 1.6979 - val_acc: 0.3323\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.6482 - acc: 0.3512 - val_loss: 1.6771 - val_acc: 0.3323\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6097 - acc: 0.3684 - val_loss: 1.6938 - val_acc: 0.3323\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6017 - acc: 0.3568 - val_loss: 1.7082 - val_acc: 0.3293\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6045 - acc: 0.3477 - val_loss: 1.6614 - val_acc: 0.3323\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5754 - acc: 0.3698 - val_loss: 1.6738 - val_acc: 0.3323\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5961 - acc: 0.3420 - val_loss: 1.7109 - val_acc: 0.3323\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5687 - acc: 0.3466 - val_loss: 1.6437 - val_acc: 0.3323\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5688 - acc: 0.3646 - val_loss: 1.6530 - val_acc: 0.3323\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5509 - acc: 0.3723 - val_loss: 1.6507 - val_acc: 0.3293\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5560 - acc: 0.3491 - val_loss: 1.6845 - val_acc: 0.3082\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5317 - acc: 0.3484 - val_loss: 1.5983 - val_acc: 0.3323\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5415 - acc: 0.3660 - val_loss: 1.6352 - val_acc: 0.3293\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5221 - acc: 0.3642 - val_loss: 1.6232 - val_acc: 0.3293\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5061 - acc: 0.3727 - val_loss: 1.5806 - val_acc: 0.3323\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4978 - acc: 0.3871 - val_loss: 1.5959 - val_acc: 0.3293\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4916 - acc: 0.3755 - val_loss: 1.5868 - val_acc: 0.3293\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.4938 - acc: 0.3684 - val_loss: 1.5893 - val_acc: 0.3293\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4764 - acc: 0.3787 - val_loss: 1.5489 - val_acc: 0.3293\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4754 - acc: 0.3882 - val_loss: 1.5731 - val_acc: 0.3384\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.4627 - acc: 0.3790 - val_loss: 1.6102 - val_acc: 0.3051\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4657 - acc: 0.3691 - val_loss: 1.6174 - val_acc: 0.3293\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4536 - acc: 0.3832 - val_loss: 1.6032 - val_acc: 0.3082\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4412 - acc: 0.3857 - val_loss: 1.5862 - val_acc: 0.3202\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4235 - acc: 0.3853 - val_loss: 1.5619 - val_acc: 0.3233\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4265 - acc: 0.3811 - val_loss: 1.4952 - val_acc: 0.3353\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4141 - acc: 0.4030 - val_loss: 1.5802 - val_acc: 0.2870\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4137 - acc: 0.3889 - val_loss: 1.6297 - val_acc: 0.2628\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4039 - acc: 0.3794 - val_loss: 1.5668 - val_acc: 0.3202\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3963 - acc: 0.3963 - val_loss: 1.5643 - val_acc: 0.3293\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3861 - acc: 0.4019 - val_loss: 1.6006 - val_acc: 0.2991\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.3789 - acc: 0.3917 - val_loss: 1.5757 - val_acc: 0.2840\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3749 - acc: 0.3892 - val_loss: 1.5112 - val_acc: 0.3233\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3662 - acc: 0.4019 - val_loss: 1.5149 - val_acc: 0.3202\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3575 - acc: 0.3945 - val_loss: 1.5637 - val_acc: 0.2961\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3655 - acc: 0.3903 - val_loss: 1.5817 - val_acc: 0.3082\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3710 - acc: 0.3889 - val_loss: 1.6329 - val_acc: 0.2447\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3753 - acc: 0.3727 - val_loss: 1.5690 - val_acc: 0.2870\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3436 - acc: 0.3959 - val_loss: 1.5152 - val_acc: 0.2991\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3430 - acc: 0.4082 - val_loss: 1.4992 - val_acc: 0.3142\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3316 - acc: 0.4051 - val_loss: 1.4752 - val_acc: 0.3172\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3182 - acc: 0.4132 - val_loss: 1.5330 - val_acc: 0.2659\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3264 - acc: 0.4019 - val_loss: 1.4773 - val_acc: 0.3051\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3295 - acc: 0.4026 - val_loss: 1.4539 - val_acc: 0.3263\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3282 - acc: 0.4160 - val_loss: 1.4264 - val_acc: 0.3414\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3171 - acc: 0.4223 - val_loss: 1.4789 - val_acc: 0.3172\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3075 - acc: 0.4075 - val_loss: 1.4554 - val_acc: 0.3263\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2994 - acc: 0.4209 - val_loss: 1.4097 - val_acc: 0.3535\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3147 - acc: 0.4097 - val_loss: 1.4147 - val_acc: 0.3414\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3087 - acc: 0.4160 - val_loss: 1.4133 - val_acc: 0.3414\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2949 - acc: 0.4167 - val_loss: 1.4282 - val_acc: 0.3323\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2979 - acc: 0.4266 - val_loss: 1.5616 - val_acc: 0.2689\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3003 - acc: 0.3885 - val_loss: 1.4585 - val_acc: 0.3263\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 48us/step - loss: 1.2802 - acc: 0.4040 - val_loss: 1.4072 - val_acc: 0.3595\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2883 - acc: 0.4283 - val_loss: 1.4053 - val_acc: 0.3625\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.2994 - acc: 0.4308 - val_loss: 1.4202 - val_acc: 0.3323\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2654 - acc: 0.4318 - val_loss: 1.4813 - val_acc: 0.2961\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2705 - acc: 0.4139 - val_loss: 1.4397 - val_acc: 0.3293\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2629 - acc: 0.4220 - val_loss: 1.3920 - val_acc: 0.3565\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.2641 - acc: 0.4308 - val_loss: 1.3577 - val_acc: 0.4139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2774 - acc: 0.4259 - val_loss: 1.3914 - val_acc: 0.3474\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2551 - acc: 0.4340 - val_loss: 1.3951 - val_acc: 0.3837\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2598 - acc: 0.4340 - val_loss: 1.4074 - val_acc: 0.3988\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2677 - acc: 0.4424 - val_loss: 1.3816 - val_acc: 0.4018\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2494 - acc: 0.4452 - val_loss: 1.4252 - val_acc: 0.3656\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2441 - acc: 0.4273 - val_loss: 1.5105 - val_acc: 0.3112\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2648 - acc: 0.3991 - val_loss: 1.5098 - val_acc: 0.3142\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2547 - acc: 0.4089 - val_loss: 1.4099 - val_acc: 0.3776\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2285 - acc: 0.4368 - val_loss: 1.4060 - val_acc: 0.3927\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2256 - acc: 0.4435 - val_loss: 1.3727 - val_acc: 0.4109\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2315 - acc: 0.4414 - val_loss: 1.3806 - val_acc: 0.4320\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2284 - acc: 0.4385 - val_loss: 1.3665 - val_acc: 0.4683\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2518 - acc: 0.4470 - val_loss: 1.3613 - val_acc: 0.4411\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2357 - acc: 0.4586 - val_loss: 1.3580 - val_acc: 0.4653\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2574 - acc: 0.4445 - val_loss: 1.3344 - val_acc: 0.4230\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2371 - acc: 0.4480 - val_loss: 1.4157 - val_acc: 0.4109\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2186 - acc: 0.4561 - val_loss: 1.3558 - val_acc: 0.4713\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.2105 - acc: 0.4586 - val_loss: 1.3460 - val_acc: 0.4773\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2260 - acc: 0.4389 - val_loss: 1.3168 - val_acc: 0.4924\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2383 - acc: 0.4650 - val_loss: 1.3311 - val_acc: 0.4562\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2187 - acc: 0.4523 - val_loss: 1.3585 - val_acc: 0.4743\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2049 - acc: 0.4642 - val_loss: 1.3552 - val_acc: 0.5287\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2362 - acc: 0.4540 - val_loss: 1.3465 - val_acc: 0.4955\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.2283 - acc: 0.4667 - val_loss: 1.3306 - val_acc: 0.4955\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2148 - acc: 0.4667 - val_loss: 1.3522 - val_acc: 0.4743\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2133 - acc: 0.4540 - val_loss: 1.3328 - val_acc: 0.4622\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2072 - acc: 0.4639 - val_loss: 1.3835 - val_acc: 0.4532\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2073 - acc: 0.4533 - val_loss: 1.4142 - val_acc: 0.4199\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.2037 - acc: 0.4505 - val_loss: 1.4492 - val_acc: 0.4048\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2046 - acc: 0.4389 - val_loss: 1.4565 - val_acc: 0.3958\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2151 - acc: 0.4354 - val_loss: 1.4204 - val_acc: 0.4079\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2026 - acc: 0.4301 - val_loss: 1.3761 - val_acc: 0.4199\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1961 - acc: 0.4378 - val_loss: 1.3752 - val_acc: 0.4441\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1753 - acc: 0.4526 - val_loss: 1.3794 - val_acc: 0.4350\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1920 - acc: 0.4618 - val_loss: 1.3772 - val_acc: 0.4260\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.2009 - acc: 0.4604 - val_loss: 1.4374 - val_acc: 0.3988\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1971 - acc: 0.4389 - val_loss: 1.4359 - val_acc: 0.4230\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1981 - acc: 0.4495 - val_loss: 1.3967 - val_acc: 0.4230\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1823 - acc: 0.4547 - val_loss: 1.4174 - val_acc: 0.4079\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1753 - acc: 0.4487 - val_loss: 1.3636 - val_acc: 0.4622\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 48us/step - loss: 1.1748 - acc: 0.4597 - val_loss: 1.2958 - val_acc: 0.4955\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1614 - acc: 0.4688 - val_loss: 1.2820 - val_acc: 0.5257\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1667 - acc: 0.4699 - val_loss: 1.2533 - val_acc: 0.5468\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2157 - acc: 0.4864 - val_loss: 1.2923 - val_acc: 0.5347\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1787 - acc: 0.4956 - val_loss: 1.3531 - val_acc: 0.4955\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1670 - acc: 0.4738 - val_loss: 1.3004 - val_acc: 0.5529\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1770 - acc: 0.4801 - val_loss: 1.2846 - val_acc: 0.5589\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1861 - acc: 0.4692 - val_loss: 1.2794 - val_acc: 0.5408\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1618 - acc: 0.4882 - val_loss: 1.3114 - val_acc: 0.5166\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1438 - acc: 0.4776 - val_loss: 1.3433 - val_acc: 0.5166\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1415 - acc: 0.4903 - val_loss: 1.3024 - val_acc: 0.5287\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1492 - acc: 0.4836 - val_loss: 1.2877 - val_acc: 0.5529\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1851 - acc: 0.4938 - val_loss: 1.3121 - val_acc: 0.5287\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1940 - acc: 0.4970 - val_loss: 1.2521 - val_acc: 0.5619\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1724 - acc: 0.4931 - val_loss: 1.2821 - val_acc: 0.5045\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1506 - acc: 0.4861 - val_loss: 1.3157 - val_acc: 0.4924\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1499 - acc: 0.4748 - val_loss: 1.2895 - val_acc: 0.5106\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1500 - acc: 0.4780 - val_loss: 1.2992 - val_acc: 0.5227\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1321 - acc: 0.4836 - val_loss: 1.2979 - val_acc: 0.5378\n",
      "Epoch 126/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1336 - acc: 0.4801 - val_loss: 1.3482 - val_acc: 0.4743\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1629 - acc: 0.4533 - val_loss: 1.3921 - val_acc: 0.4532\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1677 - acc: 0.4466 - val_loss: 1.3438 - val_acc: 0.4804\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1424 - acc: 0.4727 - val_loss: 1.3198 - val_acc: 0.4955\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1485 - acc: 0.4762 - val_loss: 1.3163 - val_acc: 0.4955\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1396 - acc: 0.4819 - val_loss: 1.3097 - val_acc: 0.5015\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1150 - acc: 0.4731 - val_loss: 1.2938 - val_acc: 0.4894\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1267 - acc: 0.4871 - val_loss: 1.2555 - val_acc: 0.5468\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1512 - acc: 0.4755 - val_loss: 1.2522 - val_acc: 0.5408\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1746 - acc: 0.5083 - val_loss: 1.3233 - val_acc: 0.4653\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1138 - acc: 0.4889 - val_loss: 1.3454 - val_acc: 0.4411\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1098 - acc: 0.4854 - val_loss: 1.3214 - val_acc: 0.4622\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1251 - acc: 0.4836 - val_loss: 1.3359 - val_acc: 0.4622\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1250 - acc: 0.4850 - val_loss: 1.3894 - val_acc: 0.4199\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 1.1657 - acc: 0.4565 - val_loss: 1.3221 - val_acc: 0.4532\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1195 - acc: 0.4850 - val_loss: 1.3617 - val_acc: 0.4350\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 51us/step - loss: 1.1249 - acc: 0.4790 - val_loss: 1.2719 - val_acc: 0.5227\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1052 - acc: 0.4903 - val_loss: 1.2438 - val_acc: 0.5438\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1003 - acc: 0.5016 - val_loss: 1.2222 - val_acc: 0.5589\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.1268 - acc: 0.4893 - val_loss: 1.2366 - val_acc: 0.5257\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1389 - acc: 0.5069 - val_loss: 1.3080 - val_acc: 0.4773\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1373 - acc: 0.5002 - val_loss: 1.3068 - val_acc: 0.4864\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0988 - acc: 0.4977 - val_loss: 1.2738 - val_acc: 0.4773\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0891 - acc: 0.5005 - val_loss: 1.2682 - val_acc: 0.5015\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1389 - acc: 0.4977 - val_loss: 1.2192 - val_acc: 0.5498\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1487 - acc: 0.4991 - val_loss: 1.2641 - val_acc: 0.5015\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0937 - acc: 0.5083 - val_loss: 1.2751 - val_acc: 0.4894\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0860 - acc: 0.4949 - val_loss: 1.2539 - val_acc: 0.5136\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0971 - acc: 0.5033 - val_loss: 1.2301 - val_acc: 0.5227\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1061 - acc: 0.5033 - val_loss: 1.2312 - val_acc: 0.5136\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0816 - acc: 0.5090 - val_loss: 1.2343 - val_acc: 0.5136\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1083 - acc: 0.5044 - val_loss: 1.2766 - val_acc: 0.4834\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1503 - acc: 0.4998 - val_loss: 1.2907 - val_acc: 0.4804\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0937 - acc: 0.5037 - val_loss: 1.3050 - val_acc: 0.4773\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0835 - acc: 0.5051 - val_loss: 1.3041 - val_acc: 0.4773\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0782 - acc: 0.5122 - val_loss: 1.3181 - val_acc: 0.4592\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0779 - acc: 0.5051 - val_loss: 1.3640 - val_acc: 0.4169\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1471 - acc: 0.4586 - val_loss: 1.3253 - val_acc: 0.4683\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1172 - acc: 0.4769 - val_loss: 1.2802 - val_acc: 0.4955\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.0662 - acc: 0.5048 - val_loss: 1.3357 - val_acc: 0.4592\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0985 - acc: 0.5030 - val_loss: 1.3462 - val_acc: 0.4562\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1072 - acc: 0.4745 - val_loss: 1.2832 - val_acc: 0.4894\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0779 - acc: 0.4995 - val_loss: 1.2833 - val_acc: 0.4864\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1061 - acc: 0.4871 - val_loss: 1.3059 - val_acc: 0.4713\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0850 - acc: 0.4857 - val_loss: 1.3569 - val_acc: 0.4562\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0828 - acc: 0.4868 - val_loss: 1.3370 - val_acc: 0.4592\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0783 - acc: 0.4819 - val_loss: 1.3080 - val_acc: 0.4804\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0570 - acc: 0.4952 - val_loss: 1.2808 - val_acc: 0.4894\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.0572 - acc: 0.5107 - val_loss: 1.3067 - val_acc: 0.4713\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0643 - acc: 0.5030 - val_loss: 1.3769 - val_acc: 0.4320\n",
      "2\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 17s 6ms/step - loss: 2.2950 - acc: 0.1951 - val_loss: 1.8950 - val_acc: 0.3293\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.7899 - acc: 0.2786 - val_loss: 1.8174 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.7172 - acc: 0.3237 - val_loss: 1.7953 - val_acc: 0.3323\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.6960 - acc: 0.3209 - val_loss: 1.7727 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6644 - acc: 0.3318 - val_loss: 1.7502 - val_acc: 0.3323\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6466 - acc: 0.3329 - val_loss: 1.7233 - val_acc: 0.3323\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6473 - acc: 0.3551 - val_loss: 1.7383 - val_acc: 0.3323\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.6178 - acc: 0.3586 - val_loss: 1.7259 - val_acc: 0.3323\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.6200 - acc: 0.3589 - val_loss: 1.7338 - val_acc: 0.3293\n",
      "Epoch 10/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.6144 - acc: 0.3322 - val_loss: 1.7122 - val_acc: 0.3323\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5918 - acc: 0.3466 - val_loss: 1.7111 - val_acc: 0.3293\n",
      "Epoch 12/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.5713 - acc: 0.3635 - val_loss: 1.6861 - val_acc: 0.3323\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5693 - acc: 0.3596 - val_loss: 1.6800 - val_acc: 0.3293\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5791 - acc: 0.3568 - val_loss: 1.6759 - val_acc: 0.3293\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5752 - acc: 0.3610 - val_loss: 1.6716 - val_acc: 0.3293\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5627 - acc: 0.3653 - val_loss: 1.6629 - val_acc: 0.3263\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5358 - acc: 0.3691 - val_loss: 1.6598 - val_acc: 0.3293\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5278 - acc: 0.3610 - val_loss: 1.6405 - val_acc: 0.3263\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5338 - acc: 0.3727 - val_loss: 1.6435 - val_acc: 0.3293\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5126 - acc: 0.3660 - val_loss: 1.6350 - val_acc: 0.3293\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4953 - acc: 0.3748 - val_loss: 1.6406 - val_acc: 0.3323\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.4997 - acc: 0.3681 - val_loss: 1.6183 - val_acc: 0.3293\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4922 - acc: 0.3744 - val_loss: 1.6247 - val_acc: 0.3293\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4918 - acc: 0.3706 - val_loss: 1.6235 - val_acc: 0.3293\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4745 - acc: 0.3639 - val_loss: 1.6124 - val_acc: 0.3293\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4761 - acc: 0.3684 - val_loss: 1.6094 - val_acc: 0.3233\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4516 - acc: 0.3829 - val_loss: 1.6142 - val_acc: 0.3263\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4568 - acc: 0.3720 - val_loss: 1.6123 - val_acc: 0.3293\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4398 - acc: 0.3864 - val_loss: 1.5686 - val_acc: 0.3293\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4404 - acc: 0.3977 - val_loss: 1.5975 - val_acc: 0.3323\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4265 - acc: 0.4005 - val_loss: 1.5779 - val_acc: 0.3293\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4198 - acc: 0.3931 - val_loss: 1.5934 - val_acc: 0.3293\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4030 - acc: 0.3994 - val_loss: 1.5659 - val_acc: 0.3263\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4071 - acc: 0.3952 - val_loss: 1.5256 - val_acc: 0.3444\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.3941 - acc: 0.4178 - val_loss: 1.5773 - val_acc: 0.3323\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4018 - acc: 0.4026 - val_loss: 1.5508 - val_acc: 0.3474\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3950 - acc: 0.4079 - val_loss: 1.6240 - val_acc: 0.2659\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3757 - acc: 0.3878 - val_loss: 1.5627 - val_acc: 0.3384\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3637 - acc: 0.3994 - val_loss: 1.5599 - val_acc: 0.3474\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3683 - acc: 0.4118 - val_loss: 1.5981 - val_acc: 0.3293\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3617 - acc: 0.4012 - val_loss: 1.5706 - val_acc: 0.3323\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.3561 - acc: 0.4086 - val_loss: 1.5273 - val_acc: 0.3686\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3471 - acc: 0.4132 - val_loss: 1.4690 - val_acc: 0.4230\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3602 - acc: 0.4195 - val_loss: 1.4894 - val_acc: 0.3988\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3371 - acc: 0.4315 - val_loss: 1.5012 - val_acc: 0.3716\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3221 - acc: 0.4251 - val_loss: 1.6104 - val_acc: 0.3021\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3392 - acc: 0.4033 - val_loss: 1.5369 - val_acc: 0.3595\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3238 - acc: 0.4280 - val_loss: 1.5358 - val_acc: 0.3625\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.3117 - acc: 0.419 - 0s 35us/step - loss: 1.3128 - acc: 0.4241 - val_loss: 1.4651 - val_acc: 0.3927\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3115 - acc: 0.4414 - val_loss: 1.5929 - val_acc: 0.3414\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3212 - acc: 0.4237 - val_loss: 1.5372 - val_acc: 0.3686\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2996 - acc: 0.4336 - val_loss: 1.5641 - val_acc: 0.3051\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3101 - acc: 0.4209 - val_loss: 1.5575 - val_acc: 0.3323\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2925 - acc: 0.4248 - val_loss: 1.5744 - val_acc: 0.3202\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3038 - acc: 0.4188 - val_loss: 1.4970 - val_acc: 0.3776\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2796 - acc: 0.4389 - val_loss: 1.4760 - val_acc: 0.3958\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2865 - acc: 0.4502 - val_loss: 1.5135 - val_acc: 0.3686\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2776 - acc: 0.4551 - val_loss: 1.6060 - val_acc: 0.3112\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2936 - acc: 0.4237 - val_loss: 1.4883 - val_acc: 0.3897\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2673 - acc: 0.4435 - val_loss: 1.4783 - val_acc: 0.3927\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2667 - acc: 0.4445 - val_loss: 1.4795 - val_acc: 0.3958\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2620 - acc: 0.4470 - val_loss: 1.4815 - val_acc: 0.3837\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2692 - acc: 0.4459 - val_loss: 1.4661 - val_acc: 0.3958\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2580 - acc: 0.4544 - val_loss: 1.4811 - val_acc: 0.3927\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2647 - acc: 0.4473 - val_loss: 1.5578 - val_acc: 0.3414\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2660 - acc: 0.4223 - val_loss: 1.4884 - val_acc: 0.3716\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2579 - acc: 0.4579 - val_loss: 1.4994 - val_acc: 0.3625\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.2380 - acc: 0.427 - 0s 36us/step - loss: 1.2428 - acc: 0.4382 - val_loss: 1.4534 - val_acc: 0.3988\n",
      "Epoch 69/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2443 - acc: 0.4537 - val_loss: 1.4800 - val_acc: 0.3807\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2510 - acc: 0.4442 - val_loss: 1.4202 - val_acc: 0.4079\n",
      "Epoch 71/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2339 - acc: 0.4618 - val_loss: 1.5101 - val_acc: 0.3474\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2497 - acc: 0.4364 - val_loss: 1.4629 - val_acc: 0.3897\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2350 - acc: 0.4642 - val_loss: 1.5460 - val_acc: 0.3444\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2533 - acc: 0.4283 - val_loss: 1.4750 - val_acc: 0.3807\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2315 - acc: 0.4445 - val_loss: 1.4312 - val_acc: 0.4079\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2226 - acc: 0.4530 - val_loss: 1.4165 - val_acc: 0.4260\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2228 - acc: 0.4516 - val_loss: 1.4225 - val_acc: 0.4411\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2389 - acc: 0.4491 - val_loss: 1.3740 - val_acc: 0.4713\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2289 - acc: 0.4642 - val_loss: 1.3152 - val_acc: 0.4894\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2303 - acc: 0.4790 - val_loss: 1.3305 - val_acc: 0.4864\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2182 - acc: 0.4674 - val_loss: 1.3275 - val_acc: 0.5408\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2470 - acc: 0.4741 - val_loss: 1.3420 - val_acc: 0.5076\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2169 - acc: 0.4801 - val_loss: 1.3449 - val_acc: 0.5076\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2154 - acc: 0.4776 - val_loss: 1.4064 - val_acc: 0.4713\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2261 - acc: 0.4547 - val_loss: 1.3808 - val_acc: 0.4924\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2011 - acc: 0.4642 - val_loss: 1.3494 - val_acc: 0.5136\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1907 - acc: 0.4882 - val_loss: 1.3441 - val_acc: 0.5015\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1902 - acc: 0.4903 - val_loss: 1.3929 - val_acc: 0.4532\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1940 - acc: 0.4727 - val_loss: 1.5415 - val_acc: 0.3444\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2508 - acc: 0.4202 - val_loss: 1.4363 - val_acc: 0.3988\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1960 - acc: 0.4547 - val_loss: 1.4226 - val_acc: 0.4109\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 31us/step - loss: 1.2013 - acc: 0.4526 - val_loss: 1.3551 - val_acc: 0.4683\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1888 - acc: 0.4579 - val_loss: 1.3588 - val_acc: 0.4713\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1787 - acc: 0.4752 - val_loss: 1.3730 - val_acc: 0.4502\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1849 - acc: 0.4716 - val_loss: 1.4429 - val_acc: 0.4109\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1873 - acc: 0.4470 - val_loss: 1.3959 - val_acc: 0.4290\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.1831 - acc: 0.4678 - val_loss: 1.3977 - val_acc: 0.4350\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1762 - acc: 0.4544 - val_loss: 1.3930 - val_acc: 0.4411\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1763 - acc: 0.4505 - val_loss: 1.3387 - val_acc: 0.4653\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1872 - acc: 0.4709 - val_loss: 1.3722 - val_acc: 0.4653\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1908 - acc: 0.4611 - val_loss: 1.3329 - val_acc: 0.5015\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1943 - acc: 0.4727 - val_loss: 1.2891 - val_acc: 0.5589\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1964 - acc: 0.4967 - val_loss: 1.3186 - val_acc: 0.5076\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1670 - acc: 0.4861 - val_loss: 1.3217 - val_acc: 0.5076\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1605 - acc: 0.4833 - val_loss: 1.3016 - val_acc: 0.5196\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1604 - acc: 0.4886 - val_loss: 1.3098 - val_acc: 0.5166\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1682 - acc: 0.4787 - val_loss: 1.3378 - val_acc: 0.4864\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1679 - acc: 0.4850 - val_loss: 1.2809 - val_acc: 0.5378\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1711 - acc: 0.4822 - val_loss: 1.2608 - val_acc: 0.5378\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1733 - acc: 0.4878 - val_loss: 1.3028 - val_acc: 0.4985\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1597 - acc: 0.4738 - val_loss: 1.2560 - val_acc: 0.5378\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1649 - acc: 0.4900 - val_loss: 1.2808 - val_acc: 0.5287\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 1.1479 - acc: 0.5069 - val_loss: 1.3121 - val_acc: 0.4955\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1404 - acc: 0.4910 - val_loss: 1.3098 - val_acc: 0.5015\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1653 - acc: 0.4889 - val_loss: 1.2450 - val_acc: 0.5619\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 45us/step - loss: 1.1747 - acc: 0.5019 - val_loss: 1.2700 - val_acc: 0.5287\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 58us/step - loss: 1.1626 - acc: 0.5037 - val_loss: 1.2982 - val_acc: 0.5015\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1427 - acc: 0.4914 - val_loss: 1.3064 - val_acc: 0.5076\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.1654 - acc: 0.4882 - val_loss: 1.2712 - val_acc: 0.5136\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1516 - acc: 0.4921 - val_loss: 1.2397 - val_acc: 0.5438\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1474 - acc: 0.5030 - val_loss: 1.2789 - val_acc: 0.5106\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1394 - acc: 0.4794 - val_loss: 1.2532 - val_acc: 0.5317\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1332 - acc: 0.5005 - val_loss: 1.2723 - val_acc: 0.5076\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1142 - acc: 0.5086 - val_loss: 1.2747 - val_acc: 0.4985\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1732 - acc: 0.4931 - val_loss: 1.2693 - val_acc: 0.5045\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1578 - acc: 0.5037 - val_loss: 1.2634 - val_acc: 0.5166\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1217 - acc: 0.4988 - val_loss: 1.2614 - val_acc: 0.5045\n",
      "Epoch 128/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1212 - acc: 0.5012 - val_loss: 1.2627 - val_acc: 0.5166\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1225 - acc: 0.4995 - val_loss: 1.3475 - val_acc: 0.4502\n",
      "Epoch 130/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1492 - acc: 0.4833 - val_loss: 1.3854 - val_acc: 0.4290\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1485 - acc: 0.4597 - val_loss: 1.3150 - val_acc: 0.4864\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1158 - acc: 0.4931 - val_loss: 1.3096 - val_acc: 0.4834\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1143 - acc: 0.5030 - val_loss: 1.3699 - val_acc: 0.4320\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1397 - acc: 0.4716 - val_loss: 1.3812 - val_acc: 0.4320\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1302 - acc: 0.4699 - val_loss: 1.2850 - val_acc: 0.5106\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0972 - acc: 0.4959 - val_loss: 1.2735 - val_acc: 0.4834\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1305 - acc: 0.4956 - val_loss: 1.3059 - val_acc: 0.4653\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1458 - acc: 0.5009 - val_loss: 1.2945 - val_acc: 0.4924\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1101 - acc: 0.5090 - val_loss: 1.2580 - val_acc: 0.4955\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1183 - acc: 0.5016 - val_loss: 1.2291 - val_acc: 0.5106\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1414 - acc: 0.5076 - val_loss: 1.2498 - val_acc: 0.5076\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1122 - acc: 0.4981 - val_loss: 1.2378 - val_acc: 0.5196\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0946 - acc: 0.5097 - val_loss: 1.2434 - val_acc: 0.5015\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0933 - acc: 0.5079 - val_loss: 1.2845 - val_acc: 0.4773\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1086 - acc: 0.5210 - val_loss: 1.2504 - val_acc: 0.4864\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1123 - acc: 0.5132 - val_loss: 1.2292 - val_acc: 0.5045\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1260 - acc: 0.5079 - val_loss: 1.2324 - val_acc: 0.5136\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1035 - acc: 0.5118 - val_loss: 1.2447 - val_acc: 0.4955\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0708 - acc: 0.5336 - val_loss: 1.2574 - val_acc: 0.5106\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0940 - acc: 0.5048 - val_loss: 1.2341 - val_acc: 0.5196\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1037 - acc: 0.5072 - val_loss: 1.2814 - val_acc: 0.5106\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.1101 - acc: 0.5093 - val_loss: 1.3824 - val_acc: 0.4260\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.1252 - acc: 0.4762 - val_loss: 1.3098 - val_acc: 0.4834\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0987 - acc: 0.4921 - val_loss: 1.3197 - val_acc: 0.4713\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0783 - acc: 0.5118 - val_loss: 1.3069 - val_acc: 0.4713\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0848 - acc: 0.5072 - val_loss: 1.2992 - val_acc: 0.4713\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0954 - acc: 0.5086 - val_loss: 1.4118 - val_acc: 0.4169\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1169 - acc: 0.4625 - val_loss: 1.2825 - val_acc: 0.4985\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0878 - acc: 0.5033 - val_loss: 1.2802 - val_acc: 0.5015\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.0890 - acc: 0.4984 - val_loss: 1.2511 - val_acc: 0.5106\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.0769 - acc: 0.5139 - val_loss: 1.2160 - val_acc: 0.5045\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.0778 - acc: 0.5188 - val_loss: 1.2091 - val_acc: 0.4924\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.0798 - acc: 0.5079 - val_loss: 1.2259 - val_acc: 0.5015\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1154 - acc: 0.5319 - val_loss: 1.2609 - val_acc: 0.4804\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.1028 - acc: 0.5280 - val_loss: 1.2992 - val_acc: 0.4773\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.0721 - acc: 0.5104 - val_loss: 1.2194 - val_acc: 0.5106\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0729 - acc: 0.5181 - val_loss: 1.2199 - val_acc: 0.4985\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.0976 - acc: 0.5252 - val_loss: 1.2587 - val_acc: 0.4713\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0704 - acc: 0.5255 - val_loss: 1.2644 - val_acc: 0.4592\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0984 - acc: 0.5262 - val_loss: 1.2656 - val_acc: 0.4804\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 49us/step - loss: 1.0679 - acc: 0.5234 - val_loss: 1.2955 - val_acc: 0.4773\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0618 - acc: 0.5195 - val_loss: 1.2938 - val_acc: 0.4713\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0613 - acc: 0.5217 - val_loss: 1.3722 - val_acc: 0.4048\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0864 - acc: 0.5002 - val_loss: 1.3519 - val_acc: 0.4502\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.0651 - acc: 0.5118 - val_loss: 1.3124 - val_acc: 0.4713\n",
      "3\n",
      "Train on 2839 samples, validate on 331 samples\n",
      "Epoch 1/175\n",
      "2839/2839 [==============================] - 17s 6ms/step - loss: 2.2077 - acc: 0.1800 - val_loss: 1.8305 - val_acc: 0.3323\n",
      "Epoch 2/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.7658 - acc: 0.3142 - val_loss: 1.8176 - val_acc: 0.3323\n",
      "Epoch 3/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.7373 - acc: 0.3029 - val_loss: 1.7625 - val_acc: 0.3323\n",
      "Epoch 4/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.6968 - acc: 0.3554 - val_loss: 1.7973 - val_acc: 0.3323\n",
      "Epoch 5/175\n",
      "2839/2839 [==============================] - 0s 41us/step - loss: 1.6777 - acc: 0.3262 - val_loss: 1.7733 - val_acc: 0.3323\n",
      "Epoch 6/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.6546 - acc: 0.3406 - val_loss: 1.7633 - val_acc: 0.3323\n",
      "Epoch 7/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.6345 - acc: 0.3332 - val_loss: 1.7530 - val_acc: 0.3323\n",
      "Epoch 8/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6391 - acc: 0.3343 - val_loss: 1.7822 - val_acc: 0.3323\n",
      "Epoch 9/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.6155 - acc: 0.3371 - val_loss: 1.7589 - val_acc: 0.3323\n",
      "Epoch 10/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.5981 - acc: 0.3448 - val_loss: 1.7628 - val_acc: 0.3323\n",
      "Epoch 11/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.5963 - acc: 0.3477 - val_loss: 1.7555 - val_acc: 0.3323\n",
      "Epoch 12/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.5849 - acc: 0.3505 - val_loss: 1.7413 - val_acc: 0.3323\n",
      "Epoch 13/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.5604 - acc: 0.3667 - val_loss: 1.7469 - val_acc: 0.3293\n",
      "Epoch 14/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.5636 - acc: 0.3427 - val_loss: 1.7201 - val_acc: 0.3323\n",
      "Epoch 15/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5491 - acc: 0.3656 - val_loss: 1.7264 - val_acc: 0.3293\n",
      "Epoch 16/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5587 - acc: 0.3639 - val_loss: 1.6988 - val_acc: 0.3323\n",
      "Epoch 17/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.5436 - acc: 0.3642 - val_loss: 1.7009 - val_acc: 0.3323\n",
      "Epoch 18/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.5204 - acc: 0.3607 - val_loss: 1.7217 - val_acc: 0.3323\n",
      "Epoch 19/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.5101 - acc: 0.3674 - val_loss: 1.6436 - val_acc: 0.3293\n",
      "Epoch 20/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5081 - acc: 0.3790 - val_loss: 1.6459 - val_acc: 0.3323\n",
      "Epoch 21/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.5028 - acc: 0.3744 - val_loss: 1.6447 - val_acc: 0.3263\n",
      "Epoch 22/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.5071 - acc: 0.3649 - val_loss: 1.6628 - val_acc: 0.3293\n",
      "Epoch 23/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4939 - acc: 0.3491 - val_loss: 1.6320 - val_acc: 0.3293\n",
      "Epoch 24/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4856 - acc: 0.3642 - val_loss: 1.6758 - val_acc: 0.3293\n",
      "Epoch 25/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.4732 - acc: 0.3737 - val_loss: 1.6518 - val_acc: 0.3293\n",
      "Epoch 26/175\n",
      "2839/2839 [==============================] - 0s 59us/step - loss: 1.4674 - acc: 0.3691 - val_loss: 1.6248 - val_acc: 0.3293\n",
      "Epoch 27/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4513 - acc: 0.3748 - val_loss: 1.6696 - val_acc: 0.3172\n",
      "Epoch 28/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.4466 - acc: 0.3586 - val_loss: 1.6253 - val_acc: 0.3293\n",
      "Epoch 29/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4380 - acc: 0.3825 - val_loss: 1.6171 - val_acc: 0.3293\n",
      "Epoch 30/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4286 - acc: 0.3818 - val_loss: 1.5991 - val_acc: 0.3293\n",
      "Epoch 31/175\n",
      "2839/2839 [==============================] - 0s 55us/step - loss: 1.4190 - acc: 0.3808 - val_loss: 1.5490 - val_acc: 0.3293\n",
      "Epoch 32/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.4234 - acc: 0.3853 - val_loss: 1.5828 - val_acc: 0.3293\n",
      "Epoch 33/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.4133 - acc: 0.3885 - val_loss: 1.5925 - val_acc: 0.3202\n",
      "Epoch 34/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4032 - acc: 0.3818 - val_loss: 1.5731 - val_acc: 0.3293\n",
      "Epoch 35/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.4020 - acc: 0.3801 - val_loss: 1.5290 - val_acc: 0.3233\n",
      "Epoch 36/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3976 - acc: 0.3875 - val_loss: 1.5552 - val_acc: 0.3233\n",
      "Epoch 37/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3847 - acc: 0.3882 - val_loss: 1.6109 - val_acc: 0.3172\n",
      "Epoch 38/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3950 - acc: 0.3684 - val_loss: 1.5666 - val_acc: 0.3323\n",
      "Epoch 39/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3658 - acc: 0.3843 - val_loss: 1.5362 - val_acc: 0.3263\n",
      "Epoch 40/175\n",
      "2839/2839 [==============================] - 0s 47us/step - loss: 1.3666 - acc: 0.3857 - val_loss: 1.5149 - val_acc: 0.3414\n",
      "Epoch 41/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.3655 - acc: 0.3910 - val_loss: 1.4848 - val_acc: 0.3323\n",
      "Epoch 42/175\n",
      "2839/2839 [==============================] - 0s 42us/step - loss: 1.3668 - acc: 0.4089 - val_loss: 1.4828 - val_acc: 0.3323\n",
      "Epoch 43/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3570 - acc: 0.4040 - val_loss: 1.5434 - val_acc: 0.3323\n",
      "Epoch 44/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3397 - acc: 0.3980 - val_loss: 1.5203 - val_acc: 0.3233\n",
      "Epoch 45/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.3606 - acc: 0.403 - 0s 35us/step - loss: 1.3423 - acc: 0.4026 - val_loss: 1.5667 - val_acc: 0.3233\n",
      "Epoch 46/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.3380 - acc: 0.3952 - val_loss: 1.5593 - val_acc: 0.3202\n",
      "Epoch 47/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3303 - acc: 0.3864 - val_loss: 1.5549 - val_acc: 0.2961\n",
      "Epoch 48/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3292 - acc: 0.3846 - val_loss: 1.5750 - val_acc: 0.2810\n",
      "Epoch 49/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3282 - acc: 0.3868 - val_loss: 1.5229 - val_acc: 0.3233\n",
      "Epoch 50/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.3318 - acc: 0.396 - 0s 34us/step - loss: 1.3151 - acc: 0.3977 - val_loss: 1.4755 - val_acc: 0.3384\n",
      "Epoch 51/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3191 - acc: 0.4075 - val_loss: 1.4648 - val_acc: 0.3293\n",
      "Epoch 52/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.3098 - acc: 0.4202 - val_loss: 1.5091 - val_acc: 0.3202\n",
      "Epoch 53/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.3082 - acc: 0.3920 - val_loss: 1.5014 - val_acc: 0.3293\n",
      "Epoch 54/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3009 - acc: 0.4079 - val_loss: 1.4726 - val_acc: 0.3474\n",
      "Epoch 55/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.3163 - acc: 0.4125 - val_loss: 1.4616 - val_acc: 0.3595\n",
      "Epoch 56/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.3039 - acc: 0.4118 - val_loss: 1.4578 - val_acc: 0.3414\n",
      "Epoch 57/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2931 - acc: 0.4142 - val_loss: 1.4433 - val_acc: 0.3384\n",
      "Epoch 58/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2809 - acc: 0.4178 - val_loss: 1.4824 - val_acc: 0.3323\n",
      "Epoch 59/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2780 - acc: 0.4107 - val_loss: 1.5537 - val_acc: 0.3021\n",
      "Epoch 60/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2808 - acc: 0.4023 - val_loss: 1.5190 - val_acc: 0.3323\n",
      "Epoch 61/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2730 - acc: 0.4111 - val_loss: 1.4646 - val_acc: 0.3444\n",
      "Epoch 62/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2625 - acc: 0.4114 - val_loss: 1.5035 - val_acc: 0.3565\n",
      "Epoch 63/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2745 - acc: 0.4178 - val_loss: 1.5374 - val_acc: 0.3082\n",
      "Epoch 64/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2807 - acc: 0.3818 - val_loss: 1.4830 - val_acc: 0.3625\n",
      "Epoch 65/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2578 - acc: 0.4206 - val_loss: 1.4918 - val_acc: 0.3444\n",
      "Epoch 66/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2596 - acc: 0.4149 - val_loss: 1.4805 - val_acc: 0.3535\n",
      "Epoch 67/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2547 - acc: 0.4223 - val_loss: 1.4667 - val_acc: 0.3505\n",
      "Epoch 68/175\n",
      "2839/2839 [==============================] - 0s 51us/step - loss: 1.2758 - acc: 0.4139 - val_loss: 1.4305 - val_acc: 0.3807\n",
      "Epoch 69/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.2580 - acc: 0.4304 - val_loss: 1.4279 - val_acc: 0.4320\n",
      "Epoch 70/175\n",
      "2839/2839 [==============================] - 0s 44us/step - loss: 1.2542 - acc: 0.4347 - val_loss: 1.3928 - val_acc: 0.4320\n",
      "Epoch 71/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2539 - acc: 0.4357 - val_loss: 1.4007 - val_acc: 0.4653\n",
      "Epoch 72/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2545 - acc: 0.4385 - val_loss: 1.4639 - val_acc: 0.4199\n",
      "Epoch 73/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2560 - acc: 0.4333 - val_loss: 1.3880 - val_acc: 0.4622\n",
      "Epoch 74/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2414 - acc: 0.4421 - val_loss: 1.3753 - val_acc: 0.4320\n",
      "Epoch 75/175\n",
      "2839/2839 [==============================] - 0s 40us/step - loss: 1.2398 - acc: 0.4498 - val_loss: 1.4218 - val_acc: 0.4169\n",
      "Epoch 76/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2303 - acc: 0.4403 - val_loss: 1.4523 - val_acc: 0.4018\n",
      "Epoch 77/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2430 - acc: 0.4234 - val_loss: 1.4474 - val_acc: 0.4079\n",
      "Epoch 78/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2301 - acc: 0.4259 - val_loss: 1.3992 - val_acc: 0.4562\n",
      "Epoch 79/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2384 - acc: 0.4340 - val_loss: 1.3808 - val_acc: 0.5196\n",
      "Epoch 80/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2428 - acc: 0.4628 - val_loss: 1.3680 - val_acc: 0.4743\n",
      "Epoch 81/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.2391 - acc: 0.4438 - val_loss: 1.4002 - val_acc: 0.4622\n",
      "Epoch 82/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2259 - acc: 0.4459 - val_loss: 1.4133 - val_acc: 0.4562\n",
      "Epoch 83/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.2226 - acc: 0.4385 - val_loss: 1.3753 - val_acc: 0.5287\n",
      "Epoch 84/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.2211 - acc: 0.4572 - val_loss: 1.3492 - val_acc: 0.4713\n",
      "Epoch 85/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2298 - acc: 0.4505 - val_loss: 1.3694 - val_acc: 0.4502\n",
      "Epoch 86/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2078 - acc: 0.4590 - val_loss: 1.3896 - val_acc: 0.4562\n",
      "Epoch 87/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2033 - acc: 0.4477 - val_loss: 1.3687 - val_acc: 0.4864\n",
      "Epoch 88/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1975 - acc: 0.4569 - val_loss: 1.4191 - val_acc: 0.4169\n",
      "Epoch 89/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2033 - acc: 0.4473 - val_loss: 1.4757 - val_acc: 0.3716\n",
      "Epoch 90/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2207 - acc: 0.4248 - val_loss: 1.4063 - val_acc: 0.4169\n",
      "Epoch 91/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2046 - acc: 0.4473 - val_loss: 1.4358 - val_acc: 0.3958\n",
      "Epoch 92/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.2161 - acc: 0.4452 - val_loss: 1.4542 - val_acc: 0.3867\n",
      "Epoch 93/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.2205 - acc: 0.4329 - val_loss: 1.4578 - val_acc: 0.4139\n",
      "Epoch 94/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2052 - acc: 0.4287 - val_loss: 1.4438 - val_acc: 0.4230\n",
      "Epoch 95/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1866 - acc: 0.4340 - val_loss: 1.3818 - val_acc: 0.4864\n",
      "Epoch 96/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1864 - acc: 0.4583 - val_loss: 1.3637 - val_acc: 0.5196\n",
      "Epoch 97/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1928 - acc: 0.4727 - val_loss: 1.3662 - val_acc: 0.5196\n",
      "Epoch 98/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1972 - acc: 0.4762 - val_loss: 1.3554 - val_acc: 0.4804\n",
      "Epoch 99/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1884 - acc: 0.4544 - val_loss: 1.3169 - val_acc: 0.5498\n",
      "Epoch 100/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.2075 - acc: 0.4805 - val_loss: 1.3760 - val_acc: 0.4864\n",
      "Epoch 101/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1718 - acc: 0.4695 - val_loss: 1.4558 - val_acc: 0.4320\n",
      "Epoch 102/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1944 - acc: 0.4442 - val_loss: 1.3491 - val_acc: 0.5287\n",
      "Epoch 103/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1645 - acc: 0.4607 - val_loss: 1.3703 - val_acc: 0.4894\n",
      "Epoch 104/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1589 - acc: 0.4632 - val_loss: 1.3713 - val_acc: 0.4713\n",
      "Epoch 105/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1532 - acc: 0.4614 - val_loss: 1.4008 - val_acc: 0.4562\n",
      "Epoch 106/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1729 - acc: 0.4706 - val_loss: 1.4617 - val_acc: 0.3927\n",
      "Epoch 107/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.2222 - acc: 0.4378 - val_loss: 1.4025 - val_acc: 0.4230\n",
      "Epoch 108/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1652 - acc: 0.4435 - val_loss: 1.3527 - val_acc: 0.4834\n",
      "Epoch 109/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1532 - acc: 0.4586 - val_loss: 1.3637 - val_acc: 0.4743\n",
      "Epoch 110/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1561 - acc: 0.4621 - val_loss: 1.3625 - val_acc: 0.4804\n",
      "Epoch 111/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1479 - acc: 0.4688 - val_loss: 1.4214 - val_acc: 0.4230\n",
      "Epoch 112/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1874 - acc: 0.4526 - val_loss: 1.4000 - val_acc: 0.4502\n",
      "Epoch 113/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1600 - acc: 0.4604 - val_loss: 1.3664 - val_acc: 0.4743\n",
      "Epoch 114/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1544 - acc: 0.4664 - val_loss: 1.3734 - val_acc: 0.4502\n",
      "Epoch 115/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1476 - acc: 0.4625 - val_loss: 1.3390 - val_acc: 0.4924\n",
      "Epoch 116/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1460 - acc: 0.4695 - val_loss: 1.3388 - val_acc: 0.4894\n",
      "Epoch 117/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1355 - acc: 0.4611 - val_loss: 1.3678 - val_acc: 0.4653\n",
      "Epoch 118/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1451 - acc: 0.4748 - val_loss: 1.4606 - val_acc: 0.3867\n",
      "Epoch 119/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1661 - acc: 0.4502 - val_loss: 1.3592 - val_acc: 0.4622\n",
      "Epoch 120/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1512 - acc: 0.4752 - val_loss: 1.3658 - val_acc: 0.4350\n",
      "Epoch 121/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1651 - acc: 0.4621 - val_loss: 1.3395 - val_acc: 0.4834\n",
      "Epoch 122/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1470 - acc: 0.4769 - val_loss: 1.3331 - val_acc: 0.4773\n",
      "Epoch 123/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1391 - acc: 0.4780 - val_loss: 1.3187 - val_acc: 0.4924\n",
      "Epoch 124/175\n",
      "2839/2839 [==============================] - 0s 43us/step - loss: 1.1289 - acc: 0.4836 - val_loss: 1.2483 - val_acc: 0.5680\n",
      "Epoch 125/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1623 - acc: 0.4790 - val_loss: 1.2689 - val_acc: 0.5498\n",
      "Epoch 126/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1580 - acc: 0.5062 - val_loss: 1.3416 - val_acc: 0.4985\n",
      "Epoch 127/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.1489 - acc: 0.4847 - val_loss: 1.3097 - val_acc: 0.5317\n",
      "Epoch 128/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1281 - acc: 0.4984 - val_loss: 1.3147 - val_acc: 0.5166\n",
      "Epoch 129/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1175 - acc: 0.4970 - val_loss: 1.3137 - val_acc: 0.5227\n",
      "Epoch 130/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1129 - acc: 0.4959 - val_loss: 1.2966 - val_acc: 0.5287\n",
      "Epoch 131/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1291 - acc: 0.4868 - val_loss: 1.2690 - val_acc: 0.5468\n",
      "Epoch 132/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1565 - acc: 0.4945 - val_loss: 1.2602 - val_acc: 0.5529\n",
      "Epoch 133/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1334 - acc: 0.4924 - val_loss: 1.2817 - val_acc: 0.5106\n",
      "Epoch 134/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1152 - acc: 0.4871 - val_loss: 1.2982 - val_acc: 0.4985\n",
      "Epoch 135/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1092 - acc: 0.4801 - val_loss: 1.2855 - val_acc: 0.5166\n",
      "Epoch 136/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0920 - acc: 0.4981 - val_loss: 1.2499 - val_acc: 0.5680\n",
      "Epoch 137/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1163 - acc: 0.4921 - val_loss: 1.2521 - val_acc: 0.5498\n",
      "Epoch 138/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1225 - acc: 0.5065 - val_loss: 1.2852 - val_acc: 0.5136\n",
      "Epoch 139/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1372 - acc: 0.4974 - val_loss: 1.3109 - val_acc: 0.5106\n",
      "Epoch 140/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.1402 - acc: 0.5136 - val_loss: 1.3041 - val_acc: 0.5196\n",
      "Epoch 141/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0897 - acc: 0.5132 - val_loss: 1.2678 - val_acc: 0.5287\n",
      "Epoch 142/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1121 - acc: 0.4857 - val_loss: 1.2277 - val_acc: 0.6012\n",
      "Epoch 143/175\n",
      "2839/2839 [==============================] - 0s 46us/step - loss: 1.1287 - acc: 0.4995 - val_loss: 1.2935 - val_acc: 0.5076\n",
      "Epoch 144/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.1001 - acc: 0.4970 - val_loss: 1.3217 - val_acc: 0.4924\n",
      "Epoch 145/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0845 - acc: 0.4984 - val_loss: 1.2681 - val_acc: 0.5196\n",
      "Epoch 146/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1127 - acc: 0.5136 - val_loss: 1.2523 - val_acc: 0.5076\n",
      "Epoch 147/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1460 - acc: 0.5185 - val_loss: 1.2726 - val_acc: 0.5136\n",
      "Epoch 148/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.1156 - acc: 0.520 - 0s 34us/step - loss: 1.1046 - acc: 0.5086 - val_loss: 1.2549 - val_acc: 0.5227\n",
      "Epoch 149/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1013 - acc: 0.5143 - val_loss: 1.2848 - val_acc: 0.5136\n",
      "Epoch 150/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1082 - acc: 0.5100 - val_loss: 1.2852 - val_acc: 0.5076\n",
      "Epoch 151/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0845 - acc: 0.5114 - val_loss: 1.2934 - val_acc: 0.5136\n",
      "Epoch 152/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0850 - acc: 0.4956 - val_loss: 1.3538 - val_acc: 0.4411\n",
      "Epoch 153/175\n",
      "2839/2839 [==============================] - 0s 37us/step - loss: 1.0866 - acc: 0.4991 - val_loss: 1.3272 - val_acc: 0.4864\n",
      "Epoch 154/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0804 - acc: 0.5065 - val_loss: 1.3330 - val_acc: 0.4683\n",
      "Epoch 155/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1128 - acc: 0.4801 - val_loss: 1.3512 - val_acc: 0.4592\n",
      "Epoch 156/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.1137 - acc: 0.4836 - val_loss: 1.3338 - val_acc: 0.4773\n",
      "Epoch 157/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0861 - acc: 0.5044 - val_loss: 1.3668 - val_acc: 0.4532\n",
      "Epoch 158/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0874 - acc: 0.4921 - val_loss: 1.3139 - val_acc: 0.5045\n",
      "Epoch 159/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0638 - acc: 0.5026 - val_loss: 1.2727 - val_acc: 0.5136\n",
      "Epoch 160/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0631 - acc: 0.5097 - val_loss: 1.2753 - val_acc: 0.5045\n",
      "Epoch 161/175\n",
      "2839/2839 [==============================] - 0s 32us/step - loss: 1.0685 - acc: 0.5044 - val_loss: 1.3133 - val_acc: 0.4622\n",
      "Epoch 162/175\n",
      "2839/2839 [==============================] - 0s 39us/step - loss: 1.1132 - acc: 0.4815 - val_loss: 1.3819 - val_acc: 0.4290\n",
      "Epoch 163/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.1298 - acc: 0.4685 - val_loss: 1.3613 - val_acc: 0.4320\n",
      "Epoch 164/175\n",
      "2839/2839 [==============================] - 0s 34us/step - loss: 1.0897 - acc: 0.4868 - val_loss: 1.3643 - val_acc: 0.4562\n",
      "Epoch 165/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.0906 - acc: 0.4808 - val_loss: 1.3412 - val_acc: 0.4471\n",
      "Epoch 166/175\n",
      "2839/2839 [==============================] - ETA: 0s - loss: 1.0745 - acc: 0.485 - 0s 34us/step - loss: 1.0864 - acc: 0.4924 - val_loss: 1.3461 - val_acc: 0.4592\n",
      "Epoch 167/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0763 - acc: 0.4907 - val_loss: 1.3104 - val_acc: 0.4924\n",
      "Epoch 168/175\n",
      "2839/2839 [==============================] - 0s 38us/step - loss: 1.0746 - acc: 0.5090 - val_loss: 1.3875 - val_acc: 0.4290\n",
      "Epoch 169/175\n",
      "2839/2839 [==============================] - 0s 35us/step - loss: 1.1204 - acc: 0.4653 - val_loss: 1.3249 - val_acc: 0.4653\n",
      "Epoch 170/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0760 - acc: 0.4878 - val_loss: 1.2649 - val_acc: 0.5166\n",
      "Epoch 171/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0632 - acc: 0.5107 - val_loss: 1.2883 - val_acc: 0.4924\n",
      "Epoch 172/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0478 - acc: 0.5136 - val_loss: 1.2494 - val_acc: 0.5287\n",
      "Epoch 173/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.0637 - acc: 0.5143 - val_loss: 1.2575 - val_acc: 0.5227\n",
      "Epoch 174/175\n",
      "2839/2839 [==============================] - 0s 36us/step - loss: 1.1215 - acc: 0.5030 - val_loss: 1.2622 - val_acc: 0.5166\n",
      "Epoch 175/175\n",
      "2839/2839 [==============================] - 0s 33us/step - loss: 1.0923 - acc: 0.5153 - val_loss: 1.3007 - val_acc: 0.4985\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.068063</td>\n",
       "      <td>0.497382</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>1.253114</td>\n",
       "      <td>0.474320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>1.237934</td>\n",
       "      <td>0.513595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>1.376934</td>\n",
       "      <td>0.432024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.536765</td>\n",
       "      <td>0.904412</td>\n",
       "      <td>1.312374</td>\n",
       "      <td>0.471299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0.120968</td>\n",
       "      <td>0.701613</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>1.300696</td>\n",
       "      <td>0.498489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       150.0  0.106667  0.653333   0.933333               0.24   \n",
       "1       103.0  0.135922  0.737864   0.970874               0.24   \n",
       "2       121.0  0.115702  0.694215   0.933884               0.20   \n",
       "3       124.0  0.112903  0.685484   0.935484               0.24   \n",
       "4       124.0  0.120968  0.701613   0.959677               0.22   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.86                0.96             0.068063   \n",
       "1              0.88                0.98             0.099174   \n",
       "2              0.88                0.98             0.081481   \n",
       "3              0.88                0.98             0.110294   \n",
       "4              0.88                0.96             0.100000   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.497382              0.879581  1.253114  0.474320  \n",
       "1            0.570248              0.933884  1.237934  0.513595  \n",
       "2            0.548148              0.918519  1.376934  0.432024  \n",
       "3            0.536765              0.904412  1.312374  0.471299  \n",
       "4            0.528571              0.864286  1.300696  0.498489  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business_analysis = pd.DataFrame()\n",
    "#, kernel_regularizer=regularizers.l1(0.0001)\n",
    "for num in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_shape=(130,), activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(25, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    ada = keras.optimizers.Adagrad()\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "    sgd = keras.optimizers.SGD(lr=0.75)\n",
    "    model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    business_model_2 = model.fit(x=X_train_business, y=y_cat_train_business, \n",
    "          batch_size=2000, \n",
    "          epochs=175, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_business, y_cat_test_business),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)\n",
    "    \n",
    "    predictions = model.predict(X_test_business)\n",
    "    loss = business_model_2.history['val_loss'][-1]\n",
    "    acc = business_model_2.history['val_acc'][-1]\n",
    "    gain_pred, gain_true_large, gain_true, gain_stay_true, four_five_split_large, four_five_split, four_five_split_mean, predicted_classes_gain_true, predicted_classes_gain_large_true, predicted_classes_gain_mean, df_metrics_b = model_metrics(predictions, y_cat_test_business, business_test_merge)\n",
    "    df_business_analysis.loc[num,'pred_count'] = gain_pred\n",
    "    df_business_analysis.loc[num,'gain_10%'] = gain_true_large\n",
    "    df_business_analysis.loc[num,'gain_3%'] = gain_true\n",
    "    df_business_analysis.loc[num,'gain_mean'] = gain_stay_true\n",
    "    df_business_analysis.loc[num,'top_pred_prob_10%'] = four_five_split_large\n",
    "    df_business_analysis.loc[num,'top_pred_prob_3%'] = four_five_split\n",
    "    df_business_analysis.loc[num,'top_pred_prob_mean'] = four_five_split_mean\n",
    "    df_business_analysis.loc[num,'model_pred_prob_10%'] = predicted_classes_gain_large_true\n",
    "    df_business_analysis.loc[num,'model_pred_prob_3%'] = predicted_classes_gain_true\n",
    "    df_business_analysis.loc[num,'model_pred_prob_mean'] = predicted_classes_gain_mean\n",
    "    df_business_analysis.loc[num,'loss'] = loss\n",
    "    df_business_analysis.loc[num,'acc'] = acc\n",
    "    print(num)\n",
    "df_175_w_b = df_business_analysis\n",
    "df_business_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>zips</th>\n",
       "      <th>loss</th>\n",
       "      <th>gain</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>top_vs_mean_low_select_true</th>\n",
       "      <th>top_vs_mean_low_select_large</th>\n",
       "      <th>gain_large_true_large</th>\n",
       "      <th>top_vs_mean_low_select_mean</th>\n",
       "      <th>predicted_classes</th>\n",
       "      <th>predicted_classes_gain</th>\n",
       "      <th>predicted_classes_gain_true</th>\n",
       "      <th>predicted_classes_gain_large_true</th>\n",
       "      <th>predicted_classes_gain_mean</th>\n",
       "      <th>gain_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.031247e-16</td>\n",
       "      <td>7.700027e-11</td>\n",
       "      <td>2.984889e-09</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>90210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.455181e-07</td>\n",
       "      <td>1.668296e-04</td>\n",
       "      <td>1.397428e-03</td>\n",
       "      <td>0.052969</td>\n",
       "      <td>0.945467</td>\n",
       "      <td>85119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3.420597e-06</td>\n",
       "      <td>3.465159e-04</td>\n",
       "      <td>3.888561e-03</td>\n",
       "      <td>0.109646</td>\n",
       "      <td>0.886116</td>\n",
       "      <td>85387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.868299e-04</td>\n",
       "      <td>5.019592e-03</td>\n",
       "      <td>3.028309e-03</td>\n",
       "      <td>0.030608</td>\n",
       "      <td>0.961057</td>\n",
       "      <td>44119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.827243e-04</td>\n",
       "      <td>6.607884e-03</td>\n",
       "      <td>5.591956e-03</td>\n",
       "      <td>0.051575</td>\n",
       "      <td>0.935842</td>\n",
       "      <td>44123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4.407305e-04</td>\n",
       "      <td>8.681367e-03</td>\n",
       "      <td>1.378230e-02</td>\n",
       "      <td>0.119696</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>28501</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.769189e-06</td>\n",
       "      <td>3.046874e-04</td>\n",
       "      <td>2.769239e-02</td>\n",
       "      <td>0.533417</td>\n",
       "      <td>0.438585</td>\n",
       "      <td>85201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4.122561e-06</td>\n",
       "      <td>9.443685e-04</td>\n",
       "      <td>3.141423e-02</td>\n",
       "      <td>0.491226</td>\n",
       "      <td>0.476412</td>\n",
       "      <td>85262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2.502714e-03</td>\n",
       "      <td>2.149867e-02</td>\n",
       "      <td>1.974948e-02</td>\n",
       "      <td>0.108461</td>\n",
       "      <td>0.847788</td>\n",
       "      <td>44128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5.928108e-04</td>\n",
       "      <td>9.287618e-03</td>\n",
       "      <td>3.917357e-02</td>\n",
       "      <td>0.267041</td>\n",
       "      <td>0.683905</td>\n",
       "      <td>44028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.702452e-04</td>\n",
       "      <td>5.701867e-03</td>\n",
       "      <td>4.908513e-02</td>\n",
       "      <td>0.347809</td>\n",
       "      <td>0.597034</td>\n",
       "      <td>89115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>3.655296e-03</td>\n",
       "      <td>2.929348e-02</td>\n",
       "      <td>2.509974e-02</td>\n",
       "      <td>0.122833</td>\n",
       "      <td>0.819118</td>\n",
       "      <td>21211</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.058911e-05</td>\n",
       "      <td>2.504396e-03</td>\n",
       "      <td>5.536310e-02</td>\n",
       "      <td>0.522986</td>\n",
       "      <td>0.419106</td>\n",
       "      <td>89145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>5.882598e-03</td>\n",
       "      <td>3.676715e-02</td>\n",
       "      <td>2.871185e-02</td>\n",
       "      <td>0.124161</td>\n",
       "      <td>0.804477</td>\n",
       "      <td>44135</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2.154201e-03</td>\n",
       "      <td>2.629616e-02</td>\n",
       "      <td>4.421640e-02</td>\n",
       "      <td>0.204398</td>\n",
       "      <td>0.722935</td>\n",
       "      <td>22827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.869278e-05</td>\n",
       "      <td>3.596188e-03</td>\n",
       "      <td>8.933006e-02</td>\n",
       "      <td>0.600741</td>\n",
       "      <td>0.306254</td>\n",
       "      <td>89149</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.542025e-05</td>\n",
       "      <td>2.899625e-03</td>\n",
       "      <td>9.864748e-02</td>\n",
       "      <td>0.660353</td>\n",
       "      <td>0.238045</td>\n",
       "      <td>89142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.770015e-04</td>\n",
       "      <td>1.002675e-02</td>\n",
       "      <td>9.414382e-02</td>\n",
       "      <td>0.496719</td>\n",
       "      <td>0.398533</td>\n",
       "      <td>89147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.161580e-04</td>\n",
       "      <td>4.305468e-03</td>\n",
       "      <td>1.030151e-01</td>\n",
       "      <td>0.613076</td>\n",
       "      <td>0.279487</td>\n",
       "      <td>89121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.832869e-05</td>\n",
       "      <td>3.563060e-03</td>\n",
       "      <td>1.061949e-01</td>\n",
       "      <td>0.673377</td>\n",
       "      <td>0.216807</td>\n",
       "      <td>85705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.884772e-03</td>\n",
       "      <td>2.355230e-02</td>\n",
       "      <td>8.608635e-02</td>\n",
       "      <td>0.341184</td>\n",
       "      <td>0.545292</td>\n",
       "      <td>95966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.141472e-04</td>\n",
       "      <td>1.120085e-02</td>\n",
       "      <td>1.021525e-01</td>\n",
       "      <td>0.494183</td>\n",
       "      <td>0.391950</td>\n",
       "      <td>89032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.873421e-04</td>\n",
       "      <td>6.960469e-03</td>\n",
       "      <td>1.076484e-01</td>\n",
       "      <td>0.575461</td>\n",
       "      <td>0.309643</td>\n",
       "      <td>89156</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7.994366e-05</td>\n",
       "      <td>4.073570e-03</td>\n",
       "      <td>1.150403e-01</td>\n",
       "      <td>0.660674</td>\n",
       "      <td>0.220132</td>\n",
       "      <td>89052</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8.662057e-03</td>\n",
       "      <td>4.181749e-02</td>\n",
       "      <td>7.477394e-02</td>\n",
       "      <td>0.262195</td>\n",
       "      <td>0.612552</td>\n",
       "      <td>53714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.571422e-04</td>\n",
       "      <td>4.977447e-03</td>\n",
       "      <td>1.179284e-01</td>\n",
       "      <td>0.632853</td>\n",
       "      <td>0.244084</td>\n",
       "      <td>89110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.602040e-05</td>\n",
       "      <td>4.633715e-03</td>\n",
       "      <td>1.231910e-01</td>\n",
       "      <td>0.662729</td>\n",
       "      <td>0.209350</td>\n",
       "      <td>89113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3.533683e-06</td>\n",
       "      <td>7.581667e-04</td>\n",
       "      <td>1.277204e-01</td>\n",
       "      <td>0.786062</td>\n",
       "      <td>0.085456</td>\n",
       "      <td>85374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.405113e-06</td>\n",
       "      <td>1.001870e-03</td>\n",
       "      <td>1.279665e-01</td>\n",
       "      <td>0.771512</td>\n",
       "      <td>0.099513</td>\n",
       "      <td>85375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>6.450700e-03</td>\n",
       "      <td>4.042833e-02</td>\n",
       "      <td>9.635779e-02</td>\n",
       "      <td>0.326796</td>\n",
       "      <td>0.529967</td>\n",
       "      <td>28012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.628112e-01</td>\n",
       "      <td>4.249763e-01</td>\n",
       "      <td>2.597947e-01</td>\n",
       "      <td>0.114923</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>53589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.217894e-01</td>\n",
       "      <td>4.104198e-01</td>\n",
       "      <td>2.957675e-01</td>\n",
       "      <td>0.135020</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>44240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.236217e-01</td>\n",
       "      <td>4.154737e-01</td>\n",
       "      <td>2.910894e-01</td>\n",
       "      <td>0.132156</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>28211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2.219667e-02</td>\n",
       "      <td>2.509042e-01</td>\n",
       "      <td>5.081251e-01</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>44023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.194333e-01</td>\n",
       "      <td>4.206696e-01</td>\n",
       "      <td>2.908073e-01</td>\n",
       "      <td>0.132399</td>\n",
       "      <td>0.036690</td>\n",
       "      <td>85087</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1.127439e-01</td>\n",
       "      <td>4.079893e-01</td>\n",
       "      <td>3.076535e-01</td>\n",
       "      <td>0.136220</td>\n",
       "      <td>0.035393</td>\n",
       "      <td>15057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.932248e-01</td>\n",
       "      <td>4.582112e-01</td>\n",
       "      <td>2.214753e-01</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>15131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.440521e-01</td>\n",
       "      <td>4.254101e-01</td>\n",
       "      <td>2.801602e-01</td>\n",
       "      <td>0.116829</td>\n",
       "      <td>0.033549</td>\n",
       "      <td>61853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1.812551e-01</td>\n",
       "      <td>4.523243e-01</td>\n",
       "      <td>2.364223e-01</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>15238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>5.651072e-02</td>\n",
       "      <td>3.522030e-01</td>\n",
       "      <td>4.020002e-01</td>\n",
       "      <td>0.162592</td>\n",
       "      <td>0.026694</td>\n",
       "      <td>28803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1.072432e-01</td>\n",
       "      <td>4.144029e-01</td>\n",
       "      <td>3.150887e-01</td>\n",
       "      <td>0.131370</td>\n",
       "      <td>0.031895</td>\n",
       "      <td>15090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7.491967e-02</td>\n",
       "      <td>3.908614e-01</td>\n",
       "      <td>3.552610e-01</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>28270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1.634481e-01</td>\n",
       "      <td>4.552634e-01</td>\n",
       "      <td>2.533953e-01</td>\n",
       "      <td>0.099819</td>\n",
       "      <td>0.028074</td>\n",
       "      <td>61801</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.390730e-01</td>\n",
       "      <td>4.451164e-01</td>\n",
       "      <td>2.777622e-01</td>\n",
       "      <td>0.109874</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>15367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.703121e-01</td>\n",
       "      <td>4.708211e-01</td>\n",
       "      <td>2.371019e-01</td>\n",
       "      <td>0.092668</td>\n",
       "      <td>0.029097</td>\n",
       "      <td>60007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.032095e-01</td>\n",
       "      <td>4.267220e-01</td>\n",
       "      <td>3.209422e-01</td>\n",
       "      <td>0.120951</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>28203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.574856e-01</td>\n",
       "      <td>4.668054e-01</td>\n",
       "      <td>2.583092e-01</td>\n",
       "      <td>0.092433</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>53711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>6.361578e-02</td>\n",
       "      <td>3.858707e-01</td>\n",
       "      <td>3.937069e-01</td>\n",
       "      <td>0.136747</td>\n",
       "      <td>0.020059</td>\n",
       "      <td>19355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>9.889349e-02</td>\n",
       "      <td>4.454283e-01</td>\n",
       "      <td>3.173799e-01</td>\n",
       "      <td>0.114599</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>16901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.123933e-01</td>\n",
       "      <td>4.647112e-01</td>\n",
       "      <td>2.963032e-01</td>\n",
       "      <td>0.103243</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>8054</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1.632874e-01</td>\n",
       "      <td>4.957275e-01</td>\n",
       "      <td>2.428022e-01</td>\n",
       "      <td>0.077909</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>19401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>9.062677e-02</td>\n",
       "      <td>4.438909e-01</td>\n",
       "      <td>3.312093e-01</td>\n",
       "      <td>0.113264</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>44236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1.136420e-01</td>\n",
       "      <td>4.717093e-01</td>\n",
       "      <td>2.945755e-01</td>\n",
       "      <td>0.099442</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>15241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.807597e-02</td>\n",
       "      <td>3.032218e-01</td>\n",
       "      <td>5.261689e-01</td>\n",
       "      <td>0.142642</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>85935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>5.596453e-02</td>\n",
       "      <td>4.091778e-01</td>\n",
       "      <td>4.016577e-01</td>\n",
       "      <td>0.118717</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>15044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5.412810e-02</td>\n",
       "      <td>4.200129e-01</td>\n",
       "      <td>4.061523e-01</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>85014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>9.253535e-02</td>\n",
       "      <td>4.950413e-01</td>\n",
       "      <td>3.125507e-01</td>\n",
       "      <td>0.086257</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>60031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5.203200e-02</td>\n",
       "      <td>4.498133e-01</td>\n",
       "      <td>3.853534e-01</td>\n",
       "      <td>0.101509</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>44022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.828063e-02</td>\n",
       "      <td>6.500644e-01</td>\n",
       "      <td>2.218307e-01</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>91950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.866763e-03</td>\n",
       "      <td>4.278426e-01</td>\n",
       "      <td>5.232871e-01</td>\n",
       "      <td>0.040362</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>90720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2         3         4   zips  \\\n",
       "6    3.031247e-16  7.700027e-11  2.984889e-09  0.000034  0.999966  90210   \n",
       "117  6.455181e-07  1.668296e-04  1.397428e-03  0.052969  0.945467  85119   \n",
       "58   3.420597e-06  3.465159e-04  3.888561e-03  0.109646  0.886116  85387   \n",
       "200  2.868299e-04  5.019592e-03  3.028309e-03  0.030608  0.961057  44119   \n",
       "197  3.827243e-04  6.607884e-03  5.591956e-03  0.051575  0.935842  44123   \n",
       "238  4.407305e-04  8.681367e-03  1.378230e-02  0.119696  0.857400  28501   \n",
       "112  1.769189e-06  3.046874e-04  2.769239e-02  0.533417  0.438585  85201   \n",
       "91   4.122561e-06  9.443685e-04  3.141423e-02  0.491226  0.476412  85262   \n",
       "193  2.502714e-03  2.149867e-02  1.974948e-02  0.108461  0.847788  44128   \n",
       "220  5.928108e-04  9.287618e-03  3.917357e-02  0.267041  0.683905  44028   \n",
       "34   3.702452e-04  5.701867e-03  4.908513e-02  0.347809  0.597034  89115   \n",
       "283  3.655296e-03  2.929348e-02  2.509974e-02  0.122833  0.819118  21211   \n",
       "17   4.058911e-05  2.504396e-03  5.536310e-02  0.522986  0.419106  89145   \n",
       "187  5.882598e-03  3.676715e-02  2.871185e-02  0.124161  0.804477  44135   \n",
       "282  2.154201e-03  2.629616e-02  4.421640e-02  0.204398  0.722935  22827   \n",
       "14   7.869278e-05  3.596188e-03  8.933006e-02  0.600741  0.306254  89149   \n",
       "19   5.542025e-05  2.899625e-03  9.864748e-02  0.660353  0.238045  89142   \n",
       "16   5.770015e-04  1.002675e-02  9.414382e-02  0.496719  0.398533  89147   \n",
       "31   1.161580e-04  4.305468e-03  1.030151e-01  0.613076  0.279487  89121   \n",
       "54   5.832869e-05  3.563060e-03  1.061949e-01  0.673377  0.216807  85705   \n",
       "0    3.884772e-03  2.355230e-02  8.608635e-02  0.341184  0.545292  95966   \n",
       "46   5.141472e-04  1.120085e-02  1.021525e-01  0.494183  0.391950  89032   \n",
       "13   2.873421e-04  6.960469e-03  1.076484e-01  0.575461  0.309643  89156   \n",
       "44   7.994366e-05  4.073570e-03  1.150403e-01  0.660674  0.220132  89052   \n",
       "151  8.662057e-03  4.181749e-02  7.477394e-02  0.262195  0.612552  53714   \n",
       "36   1.571422e-04  4.977447e-03  1.179284e-01  0.632853  0.244084  89110   \n",
       "35   9.602040e-05  4.633715e-03  1.231910e-01  0.662729  0.209350  89113   \n",
       "66   3.533683e-06  7.581667e-04  1.277204e-01  0.786062  0.085456  85374   \n",
       "65   6.405113e-06  1.001870e-03  1.279665e-01  0.771512  0.099513  85375   \n",
       "277  6.450700e-03  4.042833e-02  9.635779e-02  0.326796  0.529967  28012   \n",
       "..            ...           ...           ...       ...       ...    ...   \n",
       "158  1.628112e-01  4.249763e-01  2.597947e-01  0.114923  0.037495  53589   \n",
       "170  1.217894e-01  4.104198e-01  2.957675e-01  0.135020  0.037003  44240   \n",
       "253  1.236217e-01  4.154737e-01  2.910894e-01  0.132156  0.037659  28211   \n",
       "221  2.219667e-02  2.509042e-01  5.081251e-01  0.198659  0.020115  44023   \n",
       "119  1.194333e-01  4.206696e-01  2.908073e-01  0.132399  0.036690  85087   \n",
       "327  1.127439e-01  4.079893e-01  3.076535e-01  0.136220  0.035393  15057   \n",
       "317  1.932248e-01  4.582112e-01  2.214753e-01  0.092069  0.035020  15131   \n",
       "140  1.440521e-01  4.254101e-01  2.801602e-01  0.116829  0.033549  61853   \n",
       "295  1.812551e-01  4.523243e-01  2.364223e-01  0.096603  0.033395  15238   \n",
       "234  5.651072e-02  3.522030e-01  4.020002e-01  0.162592  0.026694  28803   \n",
       "326  1.072432e-01  4.144029e-01  3.150887e-01  0.131370  0.031895  15090   \n",
       "243  7.491967e-02  3.908614e-01  3.552610e-01  0.149397  0.029561  28270   \n",
       "144  1.634481e-01  4.552634e-01  2.533953e-01  0.099819  0.028074  61801   \n",
       "289  1.390730e-01  4.451164e-01  2.777622e-01  0.109874  0.028174  15367   \n",
       "147  1.703121e-01  4.708211e-01  2.371019e-01  0.092668  0.029097  60007   \n",
       "258  1.032095e-01  4.267220e-01  3.209422e-01  0.120951  0.028176  28203   \n",
       "152  1.574856e-01  4.668054e-01  2.583092e-01  0.092433  0.024966  53711   \n",
       "286  6.361578e-02  3.858707e-01  3.937069e-01  0.136747  0.020059  19355   \n",
       "287  9.889349e-02  4.454283e-01  3.173799e-01  0.114599  0.023700  16901   \n",
       "138  1.123933e-01  4.647112e-01  2.963032e-01  0.103243  0.023349   8054   \n",
       "285  1.632874e-01  4.957275e-01  2.428022e-01  0.077909  0.020274  19401   \n",
       "171  9.062677e-02  4.438909e-01  3.312093e-01  0.113264  0.021009  44236   \n",
       "293  1.136420e-01  4.717093e-01  2.945755e-01  0.099442  0.020631  15241   \n",
       "53   1.807597e-02  3.032218e-01  5.261689e-01  0.142642  0.009891  85935   \n",
       "328  5.596453e-02  4.091778e-01  4.016577e-01  0.118717  0.014483  15044   \n",
       "134  5.412810e-02  4.200129e-01  4.061523e-01  0.107960  0.011747  85014   \n",
       "146  9.253535e-02  4.950413e-01  3.125507e-01  0.086257  0.013615  60031   \n",
       "222  5.203200e-02  4.498133e-01  3.853534e-01  0.101509  0.011293  44022   \n",
       "4    9.828063e-02  6.500644e-01  2.218307e-01  0.027162  0.002663  91950   \n",
       "5    7.866763e-03  4.278426e-01  5.232871e-01  0.040362  0.000641  90720   \n",
       "\n",
       "     loss  gain  1  2    ...      top_vs_mean_low_select_true  \\\n",
       "6       0     1  0  0    ...                                1   \n",
       "117     0     1  0  0    ...                                1   \n",
       "58      0     1  0  0    ...                                1   \n",
       "200     0     1  0  1    ...                                0   \n",
       "197     0     1  0  0    ...                                0   \n",
       "238     0     1  0  0    ...                                0   \n",
       "112     0     1  0  0    ...                                1   \n",
       "91      0     1  0  0    ...                                1   \n",
       "193     0     1  0  0    ...                                1   \n",
       "220     0     1  0  0    ...                                1   \n",
       "34      0     1  0  0    ...                                1   \n",
       "283     0     1  0  0    ...                                1   \n",
       "17      0     1  0  0    ...                                1   \n",
       "187     0     1  0  0    ...                                1   \n",
       "282     0     1  0  0    ...                                1   \n",
       "14      0     1  0  0    ...                                1   \n",
       "19      0     1  0  0    ...                                1   \n",
       "16      0     1  0  0    ...                                1   \n",
       "31      0     1  0  0    ...                                1   \n",
       "54      0     1  0  0    ...                                1   \n",
       "0       0     1  0  0    ...                                1   \n",
       "46      0     1  0  0    ...                                1   \n",
       "13      0     1  0  0    ...                                1   \n",
       "44      0     1  0  0    ...                                1   \n",
       "151     0     1  0  0    ...                                0   \n",
       "36      0     1  0  0    ...                                1   \n",
       "35      0     1  0  0    ...                                1   \n",
       "66      0     1  0  0    ...                                1   \n",
       "65      0     1  0  0    ...                                1   \n",
       "277     0     1  0  0    ...                                1   \n",
       "..    ...   ... .. ..    ...                              ...   \n",
       "158     1     0  0  0    ...                                0   \n",
       "170     0     0  0  0    ...                                0   \n",
       "253     0     0  0  0    ...                                0   \n",
       "221     0     0  0  0    ...                                0   \n",
       "119     0     0  0  0    ...                                0   \n",
       "327     0     0  0  0    ...                                0   \n",
       "317     1     0  0  1    ...                                0   \n",
       "140     1     0  0  0    ...                                0   \n",
       "295     1     0  0  0    ...                                0   \n",
       "234     0     0  0  0    ...                                0   \n",
       "326     0     0  0  0    ...                                0   \n",
       "243     0     0  0  0    ...                                0   \n",
       "144     1     0  0  1    ...                                0   \n",
       "289     1     0  0  0    ...                                0   \n",
       "147     1     0  0  1    ...                                0   \n",
       "258     0     0  0  0    ...                                0   \n",
       "152     1     0  0  1    ...                                0   \n",
       "286     0     0  0  0    ...                                0   \n",
       "287     0     0  0  0    ...                                0   \n",
       "138     1     0  0  0    ...                                0   \n",
       "285     1     0  0  1    ...                                0   \n",
       "171     0     0  0  0    ...                                0   \n",
       "293     1     0  0  0    ...                                0   \n",
       "53      0     0  0  0    ...                                0   \n",
       "328     0     0  0  0    ...                                0   \n",
       "134     0     0  0  0    ...                                0   \n",
       "146     1     0  0  1    ...                                0   \n",
       "222     0     0  0  1    ...                                0   \n",
       "4       1     0  0  0    ...                                0   \n",
       "5       0     0  0  0    ...                                0   \n",
       "\n",
       "     top_vs_mean_low_select_large  gain_large_true_large  \\\n",
       "6                               0                      0   \n",
       "117                             1                      1   \n",
       "58                              0                      0   \n",
       "200                             0                      0   \n",
       "197                             0                      0   \n",
       "238                             0                      0   \n",
       "112                             0                      0   \n",
       "91                              0                      0   \n",
       "193                             1                      1   \n",
       "220                             0                      0   \n",
       "34                              1                      1   \n",
       "283                             0                      0   \n",
       "17                              1                      1   \n",
       "187                             1                      1   \n",
       "282                             0                      0   \n",
       "14                              0                      0   \n",
       "19                              1                      1   \n",
       "16                              0                      0   \n",
       "31                              1                      1   \n",
       "54                              0                      0   \n",
       "0                               0                      0   \n",
       "46                              0                      0   \n",
       "13                              1                      1   \n",
       "44                              0                      0   \n",
       "151                             0                      0   \n",
       "36                              0                      0   \n",
       "35                              0                      0   \n",
       "66                              0                      0   \n",
       "65                              0                      0   \n",
       "277                             0                      0   \n",
       "..                            ...                    ...   \n",
       "158                             0                      0   \n",
       "170                             0                      0   \n",
       "253                             0                      0   \n",
       "221                             0                      0   \n",
       "119                             0                      0   \n",
       "327                             0                      0   \n",
       "317                             0                      0   \n",
       "140                             0                      0   \n",
       "295                             0                      0   \n",
       "234                             0                      0   \n",
       "326                             0                      0   \n",
       "243                             0                      0   \n",
       "144                             0                      0   \n",
       "289                             0                      0   \n",
       "147                             0                      0   \n",
       "258                             0                      0   \n",
       "152                             0                      0   \n",
       "286                             0                      0   \n",
       "287                             0                      0   \n",
       "138                             0                      0   \n",
       "285                             0                      0   \n",
       "171                             0                      0   \n",
       "293                             0                      0   \n",
       "53                              0                      0   \n",
       "328                             0                      0   \n",
       "134                             0                      0   \n",
       "146                             0                      0   \n",
       "222                             0                      0   \n",
       "4                               0                      0   \n",
       "5                               0                      0   \n",
       "\n",
       "     top_vs_mean_low_select_mean  predicted_classes  predicted_classes_gain  \\\n",
       "6                              0                  4                       1   \n",
       "117                            0                  3                       1   \n",
       "58                             0                  3                       1   \n",
       "200                            0                  3                       1   \n",
       "197                            1                  1                       0   \n",
       "238                            1                  2                       0   \n",
       "112                            0                  4                       1   \n",
       "91                             0                  4                       1   \n",
       "193                            0                  1                       0   \n",
       "220                            0                  2                       0   \n",
       "34                             0                  3                       1   \n",
       "283                            0                  3                       1   \n",
       "17                             0                  3                       1   \n",
       "187                            0                  3                       1   \n",
       "282                            0                  3                       1   \n",
       "14                             0                  3                       1   \n",
       "19                             0                  3                       1   \n",
       "16                             0                  3                       1   \n",
       "31                             0                  2                       0   \n",
       "54                             0                  3                       1   \n",
       "0                              0                  3                       1   \n",
       "46                             0                  3                       1   \n",
       "13                             0                  2                       0   \n",
       "44                             0                  2                       0   \n",
       "151                            1                  2                       0   \n",
       "36                             0                  3                       1   \n",
       "35                             0                  3                       1   \n",
       "66                             0                  3                       1   \n",
       "65                             0                  3                       1   \n",
       "277                            0                  3                       1   \n",
       "..                           ...                ...                     ...   \n",
       "158                            0                  1                       0   \n",
       "170                            0                  1                       0   \n",
       "253                            0                  1                       0   \n",
       "221                            0                  1                       0   \n",
       "119                            0                  1                       0   \n",
       "327                            0                  1                       0   \n",
       "317                            0                  1                       0   \n",
       "140                            0                  1                       0   \n",
       "295                            0                  1                       0   \n",
       "234                            0                  1                       0   \n",
       "326                            0                  1                       0   \n",
       "243                            0                  3                       1   \n",
       "144                            0                  1                       0   \n",
       "289                            0                  2                       0   \n",
       "147                            0                  1                       0   \n",
       "258                            0                  1                       0   \n",
       "152                            0                  1                       0   \n",
       "286                            0                  1                       0   \n",
       "287                            0                  3                       1   \n",
       "138                            0                  1                       0   \n",
       "285                            0                  4                       1   \n",
       "171                            0                  1                       0   \n",
       "293                            0                  1                       0   \n",
       "53                             0                  1                       0   \n",
       "328                            0                  1                       0   \n",
       "134                            0                  1                       0   \n",
       "146                            0                  1                       0   \n",
       "222                            0                  1                       0   \n",
       "4                              0                  1                       0   \n",
       "5                              0                  1                       0   \n",
       "\n",
       "     predicted_classes_gain_true  predicted_classes_gain_large_true  \\\n",
       "6                              1                                  0   \n",
       "117                            1                                  1   \n",
       "58                             1                                  0   \n",
       "200                            0                                  0   \n",
       "197                            0                                  0   \n",
       "238                            0                                  0   \n",
       "112                            1                                  0   \n",
       "91                             1                                  0   \n",
       "193                            0                                  0   \n",
       "220                            0                                  0   \n",
       "34                             1                                  1   \n",
       "283                            1                                  0   \n",
       "17                             1                                  1   \n",
       "187                            1                                  1   \n",
       "282                            1                                  0   \n",
       "14                             1                                  0   \n",
       "19                             1                                  1   \n",
       "16                             1                                  0   \n",
       "31                             0                                  0   \n",
       "54                             1                                  0   \n",
       "0                              1                                  0   \n",
       "46                             1                                  0   \n",
       "13                             0                                  0   \n",
       "44                             0                                  0   \n",
       "151                            0                                  0   \n",
       "36                             1                                  0   \n",
       "35                             1                                  0   \n",
       "66                             1                                  0   \n",
       "65                             1                                  0   \n",
       "277                            1                                  0   \n",
       "..                           ...                                ...   \n",
       "158                            0                                  0   \n",
       "170                            0                                  0   \n",
       "253                            0                                  0   \n",
       "221                            0                                  0   \n",
       "119                            0                                  0   \n",
       "327                            0                                  0   \n",
       "317                            0                                  0   \n",
       "140                            0                                  0   \n",
       "295                            0                                  0   \n",
       "234                            0                                  0   \n",
       "326                            0                                  0   \n",
       "243                            0                                  0   \n",
       "144                            0                                  0   \n",
       "289                            0                                  0   \n",
       "147                            0                                  0   \n",
       "258                            0                                  0   \n",
       "152                            0                                  0   \n",
       "286                            0                                  0   \n",
       "287                            1                                  0   \n",
       "138                            0                                  0   \n",
       "285                            0                                  0   \n",
       "171                            0                                  0   \n",
       "293                            0                                  0   \n",
       "53                             0                                  0   \n",
       "328                            0                                  0   \n",
       "134                            0                                  0   \n",
       "146                            0                                  0   \n",
       "222                            0                                  0   \n",
       "4                              0                                  0   \n",
       "5                              0                                  0   \n",
       "\n",
       "     predicted_classes_gain_mean  gain_true  \n",
       "6                              0          1  \n",
       "117                            0          1  \n",
       "58                             0          1  \n",
       "200                            0          0  \n",
       "197                            0          0  \n",
       "238                            0          0  \n",
       "112                            0          1  \n",
       "91                             0          1  \n",
       "193                            0          1  \n",
       "220                            0          1  \n",
       "34                             0          1  \n",
       "283                            0          1  \n",
       "17                             0          1  \n",
       "187                            0          1  \n",
       "282                            0          1  \n",
       "14                             0          1  \n",
       "19                             0          1  \n",
       "16                             0          1  \n",
       "31                             0          1  \n",
       "54                             0          1  \n",
       "0                              0          1  \n",
       "46                             0          1  \n",
       "13                             0          1  \n",
       "44                             0          1  \n",
       "151                            0          0  \n",
       "36                             0          1  \n",
       "35                             0          1  \n",
       "66                             0          1  \n",
       "65                             0          1  \n",
       "277                            0          1  \n",
       "..                           ...        ...  \n",
       "158                            0          0  \n",
       "170                            0          0  \n",
       "253                            0          0  \n",
       "221                            0          0  \n",
       "119                            0          1  \n",
       "327                            0          0  \n",
       "317                            0          0  \n",
       "140                            0          0  \n",
       "295                            0          0  \n",
       "234                            0          1  \n",
       "326                            0          0  \n",
       "243                            1          0  \n",
       "144                            0          0  \n",
       "289                            0          0  \n",
       "147                            0          0  \n",
       "258                            0          0  \n",
       "152                            0          0  \n",
       "286                            0          0  \n",
       "287                            0          1  \n",
       "138                            0          0  \n",
       "285                            0          0  \n",
       "171                            0          0  \n",
       "293                            0          0  \n",
       "53                             0          0  \n",
       "328                            0          0  \n",
       "134                            0          1  \n",
       "146                            0          0  \n",
       "222                            0          0  \n",
       "4                              0          1  \n",
       "5                              0          0  \n",
       "\n",
       "[331 rows x 36 columns]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_400_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.373044</td>\n",
       "      <td>0.543807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.604796</td>\n",
       "      <td>0.477341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.558559</td>\n",
       "      <td>0.882883</td>\n",
       "      <td>1.497453</td>\n",
       "      <td>0.486405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>0.503876</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>1.519598</td>\n",
       "      <td>0.441088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>1.441763</td>\n",
       "      <td>0.510574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        79.0  0.094972  0.810127   0.987342           0.272727   \n",
       "1        53.0  0.094972  0.830189   0.981132           0.303030   \n",
       "2        79.0  0.094972  0.848101   0.987342           0.212121   \n",
       "3       108.0  0.094972  0.731481   0.953704           0.272727   \n",
       "4       102.0  0.094972  0.754902   0.950980           0.303030   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.787879            0.969697             0.117117   \n",
       "1          0.848485            1.000000             0.098765   \n",
       "2          0.818182            1.000000             0.099099   \n",
       "3          0.848485            0.969697             0.100775   \n",
       "4          0.757576            0.939394             0.062500   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.549550              0.864865  1.373044  0.543807  \n",
       "1            0.604938              0.888889  1.604796  0.477341  \n",
       "2            0.558559              0.882883  1.497453  0.486405  \n",
       "3            0.503876              0.883721  1.519598  0.441088  \n",
       "4            0.506944              0.847222  1.441763  0.510574  "
      ]
     },
     "execution_count": 1151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_400_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>1.312308</td>\n",
       "      <td>0.486405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>1.336576</td>\n",
       "      <td>0.483384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>1.291740</td>\n",
       "      <td>0.498489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.541353</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>1.287987</td>\n",
       "      <td>0.486405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.278520</td>\n",
       "      <td>0.507553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        76.0  0.094972  0.789474   0.973684           0.242424   \n",
       "1       120.0  0.094972  0.700000   0.950000           0.272727   \n",
       "2        88.0  0.094972  0.795455   0.977273           0.242424   \n",
       "3       113.0  0.094972  0.707965   0.946903           0.242424   \n",
       "4       100.0  0.094972  0.750000   0.960000           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.969697             0.142857   \n",
       "1          0.818182            0.939394             0.105960   \n",
       "2          0.848485            0.969697             0.094340   \n",
       "3          0.848485            0.969697             0.090226   \n",
       "4          0.848485            0.969697             0.100000   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.604396              0.879121  1.312308  0.486405  \n",
       "1            0.543046              0.913907  1.336576  0.483384  \n",
       "2            0.575472              0.924528  1.291740  0.498489  \n",
       "3            0.541353              0.879699  1.287987  0.486405  \n",
       "4            0.558333              0.916667  1.278520  0.507553  "
      ]
     },
     "execution_count": 1141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_300_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.099291</td>\n",
       "      <td>0.560284</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>1.383570</td>\n",
       "      <td>0.429003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>1.445286</td>\n",
       "      <td>0.477341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.424749</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>1.346164</td>\n",
       "      <td>0.429003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>1.408535</td>\n",
       "      <td>0.444109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       113.0  0.094972  0.699115   0.955752           0.242424   \n",
       "1        70.0  0.094972  0.800000   0.971429           0.303030   \n",
       "2        47.0  0.094972  0.851064   0.978723           0.242424   \n",
       "3        54.0  0.094972  0.851852   0.981481           0.242424   \n",
       "4       120.0  0.094972  0.700000   0.950000           0.333333   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.878788            0.969697             0.099291   \n",
       "1          0.878788            1.000000             0.101124   \n",
       "2          0.878788            1.000000             0.077922   \n",
       "3          0.878788            0.969697             0.123077   \n",
       "4          0.878788            0.969697             0.096774   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.560284              0.886525  1.383570  0.429003  \n",
       "1            0.573034              0.898876  1.445286  0.477341  \n",
       "2            0.571429              0.857143  1.424749  0.480363  \n",
       "3            0.553846              0.907692  1.346164  0.429003  \n",
       "4            0.522581              0.851613  1.408535  0.444109  "
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_300_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>1.359825</td>\n",
       "      <td>0.435045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>1.311240</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>1.358138</td>\n",
       "      <td>0.447130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>1.275713</td>\n",
       "      <td>0.516616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>1.231637</td>\n",
       "      <td>0.522659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        94.0  0.094972  0.744681   0.957447           0.212121   \n",
       "1       149.0  0.094972  0.644295   0.939597           0.272727   \n",
       "2        79.0  0.094972  0.797468   0.974684           0.212121   \n",
       "3       122.0  0.094972  0.704918   0.959016           0.242424   \n",
       "4        87.0  0.094972  0.793103   0.965517           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.818182            0.939394             0.089109   \n",
       "1          0.878788            0.969697             0.080000   \n",
       "2          0.878788            0.969697             0.111111   \n",
       "3          0.787879            0.939394             0.106667   \n",
       "4          0.818182            0.939394             0.092437   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.584158              0.900990  1.359825  0.435045  \n",
       "1            0.520000              0.891429  1.311240  0.459215  \n",
       "2            0.604938              0.950617  1.358138  0.447130  \n",
       "3            0.533333              0.886667  1.275713  0.516616  \n",
       "4            0.554622              0.890756  1.231637  0.522659  "
      ]
     },
     "execution_count": 1165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_250_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>1.310063</td>\n",
       "      <td>0.462236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>1.340102</td>\n",
       "      <td>0.465257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>1.218421</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>1.308485</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>1.210499</td>\n",
       "      <td>0.504532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       100.0  0.094972  0.740000   0.970000           0.242424   \n",
       "1        82.0  0.094972  0.768293   0.975610           0.242424   \n",
       "2        90.0  0.094972  0.800000   0.966667           0.272727   \n",
       "3        59.0  0.094972  0.813559   0.966102           0.272727   \n",
       "4        60.0  0.094972  0.833333   0.966667           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.878788            0.969697             0.094017   \n",
       "1          0.818182            0.939394             0.097087   \n",
       "2          0.848485            0.939394             0.134615   \n",
       "3          0.848485            0.969697             0.074468   \n",
       "4          0.878788            0.969697             0.072289   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.564103              0.880342  1.310063  0.462236  \n",
       "1            0.572816              0.902913  1.340102  0.465257  \n",
       "2            0.605769              0.903846  1.218421  0.495468  \n",
       "3            0.521277              0.851064  1.308485  0.495468  \n",
       "4            0.530120              0.903614  1.210499  0.504532  "
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_250_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.716814</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.527559</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>1.344561</td>\n",
       "      <td>0.416918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.296870</td>\n",
       "      <td>0.486405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.089655</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>1.373079</td>\n",
       "      <td>0.422961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.077844</td>\n",
       "      <td>0.508982</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.287742</td>\n",
       "      <td>0.474320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.932836</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>1.338315</td>\n",
       "      <td>0.453172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       113.0  0.094972  0.716814   0.955752           0.272727   \n",
       "1       109.0  0.094972  0.733945   0.972477           0.212121   \n",
       "2       129.0  0.094972  0.697674   0.953488           0.272727   \n",
       "3       129.0  0.094972  0.666667   0.945736           0.272727   \n",
       "4       134.0  0.094972  0.649254   0.932836           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.818182            0.939394             0.094488   \n",
       "1          0.848485            0.969697             0.108333   \n",
       "2          0.878788            0.969697             0.089655   \n",
       "3          0.848485            0.969697             0.077844   \n",
       "4          0.878788            0.969697             0.085366   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.527559              0.897638  1.344561  0.416918  \n",
       "1            0.575000              0.900000  1.296870  0.486405  \n",
       "2            0.551724              0.882759  1.373079  0.422961  \n",
       "3            0.508982              0.862275  1.287742  0.474320  \n",
       "4            0.536585              0.926829  1.338315  0.453172  "
      ]
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>1.344601</td>\n",
       "      <td>0.416918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>1.417642</td>\n",
       "      <td>0.365559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>1.303192</td>\n",
       "      <td>0.444109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>1.126423</td>\n",
       "      <td>0.534743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.243225</td>\n",
       "      <td>0.462236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        94.0  0.094972  0.776596   0.957447           0.303030   \n",
       "1       116.0  0.094972  0.715517   0.956897           0.333333   \n",
       "2        95.0  0.094972  0.757895   0.968421           0.333333   \n",
       "3        73.0  0.094972  0.808219   0.972603           0.242424   \n",
       "4        75.0  0.094972  0.813333   0.973333           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.878788            0.969697             0.114583   \n",
       "1          0.818182            0.939394             0.102362   \n",
       "2          0.848485            0.969697             0.097087   \n",
       "3          0.848485            0.939394             0.101124   \n",
       "4          0.848485            0.939394             0.125000   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.552083              0.854167  1.344601  0.416918  \n",
       "1            0.566929              0.897638  1.417642  0.365559  \n",
       "2            0.563107              0.893204  1.303192  0.444109  \n",
       "3            0.629213              0.898876  1.126423  0.534743  \n",
       "4            0.650000              0.950000  1.243225  0.462236  "
      ]
     },
     "execution_count": 1155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.681481</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.865031</td>\n",
       "      <td>1.162874</td>\n",
       "      <td>0.501511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>1.105068</td>\n",
       "      <td>0.525680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>1.147732</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127.0</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>1.108600</td>\n",
       "      <td>0.525680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.0</td>\n",
       "      <td>0.130841</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>1.234723</td>\n",
       "      <td>0.435045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       135.0  0.103704  0.681481   0.955556               0.28   \n",
       "1        75.0  0.173333  0.826667   0.973333               0.20   \n",
       "2        87.0  0.126437  0.781609   0.977011               0.16   \n",
       "3       127.0  0.110236  0.700787   0.952756               0.20   \n",
       "4       107.0  0.130841  0.738318   0.953271               0.24   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.86                0.96             0.098160   \n",
       "1              0.86                0.96             0.112245   \n",
       "2              0.82                0.96             0.094737   \n",
       "3              0.82                0.96             0.103226   \n",
       "4              0.84                0.94             0.114035   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.539877              0.865031  1.162874  0.501511  \n",
       "1            0.561224              0.867347  1.105068  0.525680  \n",
       "2            0.578947              0.905263  1.147732  0.480363  \n",
       "3            0.567742              0.935484  1.108600  0.525680  \n",
       "4            0.614035              0.885965  1.234723  0.435045  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>1.239896</td>\n",
       "      <td>0.489426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.083799</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>1.240350</td>\n",
       "      <td>0.477341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.0</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>1.227754</td>\n",
       "      <td>0.549849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.971154</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.576577</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.230924</td>\n",
       "      <td>0.501511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>1.199325</td>\n",
       "      <td>0.510574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       111.0  0.126126  0.720721   0.963964               0.20   \n",
       "1       145.0  0.103448  0.655172   0.944828               0.22   \n",
       "2       112.0  0.133929  0.732143   0.973214               0.24   \n",
       "3       104.0  0.134615  0.721154   0.971154               0.20   \n",
       "4       108.0  0.138889  0.740741   0.962963               0.22   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.86                0.96             0.063492   \n",
       "1              0.84                0.96             0.083799   \n",
       "2              0.88                0.96             0.095238   \n",
       "3              0.86                0.96             0.108108   \n",
       "4              0.86                0.96             0.090164   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.539683              0.873016  1.239896  0.489426  \n",
       "1            0.541899              0.877095  1.240350  0.477341  \n",
       "2            0.603175              0.880952  1.227754  0.549849  \n",
       "3            0.576577              0.864865  1.230924  0.501511  \n",
       "4            0.508197              0.909836  1.199325  0.510574  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>zips</th>\n",
       "      <th>loss</th>\n",
       "      <th>gain</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>top_vs_mean_low_select_true</th>\n",
       "      <th>top_vs_mean_low_select_large</th>\n",
       "      <th>gain_large_true_large</th>\n",
       "      <th>top_vs_mean_low_select_mean</th>\n",
       "      <th>predicted_classes</th>\n",
       "      <th>predicted_classes_gain</th>\n",
       "      <th>predicted_classes_gain_true</th>\n",
       "      <th>predicted_classes_gain_large_true</th>\n",
       "      <th>predicted_classes_gain_mean</th>\n",
       "      <th>gain_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.459190e-13</td>\n",
       "      <td>1.339439e-10</td>\n",
       "      <td>7.183982e-08</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.670842e-06</td>\n",
       "      <td>8.583022e-05</td>\n",
       "      <td>1.606960e-03</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.923240</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3.795354e-05</td>\n",
       "      <td>5.469620e-04</td>\n",
       "      <td>8.432047e-03</td>\n",
       "      <td>0.200195</td>\n",
       "      <td>0.790788</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2.533946e-05</td>\n",
       "      <td>5.845839e-04</td>\n",
       "      <td>1.899284e-02</td>\n",
       "      <td>0.436160</td>\n",
       "      <td>0.544238</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.416628e-03</td>\n",
       "      <td>7.835551e-03</td>\n",
       "      <td>1.484125e-02</td>\n",
       "      <td>0.084817</td>\n",
       "      <td>0.890089</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.197447e-03</td>\n",
       "      <td>6.929632e-03</td>\n",
       "      <td>1.777581e-02</td>\n",
       "      <td>0.113021</td>\n",
       "      <td>0.860076</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.517126e-04</td>\n",
       "      <td>5.556580e-03</td>\n",
       "      <td>3.883893e-02</td>\n",
       "      <td>0.349491</td>\n",
       "      <td>0.605161</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4.715793e-03</td>\n",
       "      <td>1.376569e-02</td>\n",
       "      <td>3.650714e-02</td>\n",
       "      <td>0.202793</td>\n",
       "      <td>0.742218</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5.197521e-03</td>\n",
       "      <td>1.658601e-02</td>\n",
       "      <td>4.149340e-02</td>\n",
       "      <td>0.189145</td>\n",
       "      <td>0.747579</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.734561e-04</td>\n",
       "      <td>4.532652e-03</td>\n",
       "      <td>6.209535e-02</td>\n",
       "      <td>0.537148</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3.122277e-03</td>\n",
       "      <td>1.332220e-02</td>\n",
       "      <td>5.982962e-02</td>\n",
       "      <td>0.330458</td>\n",
       "      <td>0.593268</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.838732e-04</td>\n",
       "      <td>3.723274e-03</td>\n",
       "      <td>8.088547e-02</td>\n",
       "      <td>0.674961</td>\n",
       "      <td>0.240246</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2.759518e-04</td>\n",
       "      <td>4.482441e-03</td>\n",
       "      <td>8.095810e-02</td>\n",
       "      <td>0.638122</td>\n",
       "      <td>0.276161</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.227722e-04</td>\n",
       "      <td>6.742783e-03</td>\n",
       "      <td>7.987913e-02</td>\n",
       "      <td>0.516831</td>\n",
       "      <td>0.395924</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.106496e-03</td>\n",
       "      <td>1.538315e-02</td>\n",
       "      <td>8.513473e-02</td>\n",
       "      <td>0.437839</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.161234e-03</td>\n",
       "      <td>1.016846e-02</td>\n",
       "      <td>9.670360e-02</td>\n",
       "      <td>0.559286</td>\n",
       "      <td>0.332681</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.835097e-03</td>\n",
       "      <td>1.306650e-02</td>\n",
       "      <td>9.558450e-02</td>\n",
       "      <td>0.518315</td>\n",
       "      <td>0.371199</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.135497e-03</td>\n",
       "      <td>1.030237e-02</td>\n",
       "      <td>1.032419e-01</td>\n",
       "      <td>0.573741</td>\n",
       "      <td>0.311579</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.015657e-03</td>\n",
       "      <td>1.033567e-02</td>\n",
       "      <td>1.145111e-01</td>\n",
       "      <td>0.586365</td>\n",
       "      <td>0.287773</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.139484e-02</td>\n",
       "      <td>3.471914e-02</td>\n",
       "      <td>9.503350e-02</td>\n",
       "      <td>0.323181</td>\n",
       "      <td>0.535672</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>9.284713e-03</td>\n",
       "      <td>3.274773e-02</td>\n",
       "      <td>9.933559e-02</td>\n",
       "      <td>0.362889</td>\n",
       "      <td>0.495743</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.675350e-02</td>\n",
       "      <td>4.236059e-02</td>\n",
       "      <td>9.721889e-02</td>\n",
       "      <td>0.287029</td>\n",
       "      <td>0.556638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.291950e-03</td>\n",
       "      <td>1.321630e-02</td>\n",
       "      <td>1.341532e-01</td>\n",
       "      <td>0.577771</td>\n",
       "      <td>0.273568</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2.235545e-02</td>\n",
       "      <td>5.699635e-02</td>\n",
       "      <td>8.929031e-02</td>\n",
       "      <td>0.217567</td>\n",
       "      <td>0.613791</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9.243285e-04</td>\n",
       "      <td>1.145600e-02</td>\n",
       "      <td>1.515237e-01</td>\n",
       "      <td>0.651481</td>\n",
       "      <td>0.184614</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.046547e-03</td>\n",
       "      <td>2.100313e-02</td>\n",
       "      <td>1.428357e-01</td>\n",
       "      <td>0.550398</td>\n",
       "      <td>0.282717</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.947260e-03</td>\n",
       "      <td>2.844668e-02</td>\n",
       "      <td>1.448437e-01</td>\n",
       "      <td>0.478524</td>\n",
       "      <td>0.343239</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.756248e-03</td>\n",
       "      <td>2.833412e-02</td>\n",
       "      <td>1.516487e-01</td>\n",
       "      <td>0.520831</td>\n",
       "      <td>0.294430</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1.775828e-02</td>\n",
       "      <td>5.059949e-02</td>\n",
       "      <td>1.242806e-01</td>\n",
       "      <td>0.346378</td>\n",
       "      <td>0.460983</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.897404e-03</td>\n",
       "      <td>1.721425e-02</td>\n",
       "      <td>1.675089e-01</td>\n",
       "      <td>0.621584</td>\n",
       "      <td>0.191796</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.358302e-01</td>\n",
       "      <td>4.553418e-01</td>\n",
       "      <td>2.517807e-01</td>\n",
       "      <td>0.108510</td>\n",
       "      <td>0.048538</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2.754863e-02</td>\n",
       "      <td>2.988531e-01</td>\n",
       "      <td>4.662085e-01</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>9.326784e-02</td>\n",
       "      <td>4.276908e-01</td>\n",
       "      <td>3.055875e-01</td>\n",
       "      <td>0.138176</td>\n",
       "      <td>0.035279</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.225796e-01</td>\n",
       "      <td>4.697762e-01</td>\n",
       "      <td>2.508799e-01</td>\n",
       "      <td>0.113404</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.402419e-01</td>\n",
       "      <td>4.846105e-01</td>\n",
       "      <td>2.301522e-01</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.047654</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>8.775865e-02</td>\n",
       "      <td>4.286960e-01</td>\n",
       "      <td>3.128779e-01</td>\n",
       "      <td>0.136134</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.865153e-02</td>\n",
       "      <td>3.926346e-01</td>\n",
       "      <td>3.586591e-01</td>\n",
       "      <td>0.148023</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1.481791e-01</td>\n",
       "      <td>5.030540e-01</td>\n",
       "      <td>2.113388e-01</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>0.047804</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1.432313e-01</td>\n",
       "      <td>5.000812e-01</td>\n",
       "      <td>2.196652e-01</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.045435</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.430750e-01</td>\n",
       "      <td>5.098780e-01</td>\n",
       "      <td>2.111027e-01</td>\n",
       "      <td>0.089969</td>\n",
       "      <td>0.045975</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.109331e-01</td>\n",
       "      <td>4.864694e-01</td>\n",
       "      <td>2.586757e-01</td>\n",
       "      <td>0.107847</td>\n",
       "      <td>0.036074</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>8.801384e-02</td>\n",
       "      <td>4.568240e-01</td>\n",
       "      <td>3.034566e-01</td>\n",
       "      <td>0.121563</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.484025e-02</td>\n",
       "      <td>2.798627e-01</td>\n",
       "      <td>5.170567e-01</td>\n",
       "      <td>0.177435</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1.373523e-01</td>\n",
       "      <td>5.273945e-01</td>\n",
       "      <td>2.150543e-01</td>\n",
       "      <td>0.081641</td>\n",
       "      <td>0.038558</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.086136e-01</td>\n",
       "      <td>5.055384e-01</td>\n",
       "      <td>2.567061e-01</td>\n",
       "      <td>0.096658</td>\n",
       "      <td>0.032484</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1.142055e-01</td>\n",
       "      <td>5.099567e-01</td>\n",
       "      <td>2.507291e-01</td>\n",
       "      <td>0.094248</td>\n",
       "      <td>0.030860</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>8.757050e-02</td>\n",
       "      <td>4.877237e-01</td>\n",
       "      <td>2.869124e-01</td>\n",
       "      <td>0.111481</td>\n",
       "      <td>0.026313</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>5.649425e-02</td>\n",
       "      <td>4.324875e-01</td>\n",
       "      <td>3.595371e-01</td>\n",
       "      <td>0.132726</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>7.983490e-02</td>\n",
       "      <td>4.806279e-01</td>\n",
       "      <td>3.014271e-01</td>\n",
       "      <td>0.113214</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.235624e-01</td>\n",
       "      <td>5.356058e-01</td>\n",
       "      <td>2.252400e-01</td>\n",
       "      <td>0.083505</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1.269159e-01</td>\n",
       "      <td>5.508341e-01</td>\n",
       "      <td>2.128270e-01</td>\n",
       "      <td>0.076452</td>\n",
       "      <td>0.032971</td>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5.893540e-02</td>\n",
       "      <td>4.439982e-01</td>\n",
       "      <td>3.540618e-01</td>\n",
       "      <td>0.125016</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.233998e-01</td>\n",
       "      <td>5.455791e-01</td>\n",
       "      <td>2.216453e-01</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>9.660497e-02</td>\n",
       "      <td>5.323394e-01</td>\n",
       "      <td>2.566967e-01</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>0.025501</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7.200707e-02</td>\n",
       "      <td>5.027918e-01</td>\n",
       "      <td>3.050674e-01</td>\n",
       "      <td>0.100865</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>9.745269e-02</td>\n",
       "      <td>5.534727e-01</td>\n",
       "      <td>2.432973e-01</td>\n",
       "      <td>0.081697</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>4.685505e-02</td>\n",
       "      <td>4.732583e-01</td>\n",
       "      <td>3.616242e-01</td>\n",
       "      <td>0.104565</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1.078045e-01</td>\n",
       "      <td>6.082356e-01</td>\n",
       "      <td>2.053191e-01</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>0.019692</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.999259e-02</td>\n",
       "      <td>7.268361e-01</td>\n",
       "      <td>1.805120e-01</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.284624e-03</td>\n",
       "      <td>4.404040e-01</td>\n",
       "      <td>4.957895e-01</td>\n",
       "      <td>0.055466</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2         3         4  zips  loss  \\\n",
       "6    2.459190e-13  1.339439e-10  7.183982e-08  0.000712  0.999288     6     0   \n",
       "117  4.670842e-06  8.583022e-05  1.606960e-03  0.075062  0.923240   117     0   \n",
       "58   3.795354e-05  5.469620e-04  8.432047e-03  0.200195  0.790788    58     0   \n",
       "112  2.533946e-05  5.845839e-04  1.899284e-02  0.436160  0.544238   112     0   \n",
       "200  2.416628e-03  7.835551e-03  1.484125e-02  0.084817  0.890089   200     0   \n",
       "197  2.197447e-03  6.929632e-03  1.777581e-02  0.113021  0.860076   197     0   \n",
       "34   9.517126e-04  5.556580e-03  3.883893e-02  0.349491  0.605161    34     0   \n",
       "238  4.715793e-03  1.376569e-02  3.650714e-02  0.202793  0.742218   238     0   \n",
       "193  5.197521e-03  1.658601e-02  4.149340e-02  0.189145  0.747579   193     0   \n",
       "19   3.734561e-04  4.532652e-03  6.209535e-02  0.537148  0.395851    19     0   \n",
       "220  3.122277e-03  1.332220e-02  5.982962e-02  0.330458  0.593268   220     0   \n",
       "91   1.838732e-04  3.723274e-03  8.088547e-02  0.674961  0.240246    91     0   \n",
       "54   2.759518e-04  4.482441e-03  8.095810e-02  0.638122  0.276161    54     0   \n",
       "17   6.227722e-04  6.742783e-03  7.987913e-02  0.516831  0.395924    17     0   \n",
       "16   3.106496e-03  1.538315e-02  8.513473e-02  0.437839  0.458537    16     0   \n",
       "36   1.161234e-03  1.016846e-02  9.670360e-02  0.559286  0.332681    36     0   \n",
       "13   1.835097e-03  1.306650e-02  9.558450e-02  0.518315  0.371199    13     0   \n",
       "47   1.135497e-03  1.030237e-02  1.032419e-01  0.573741  0.311579    47     0   \n",
       "31   1.015657e-03  1.033567e-02  1.145111e-01  0.586365  0.287773    31     0   \n",
       "151  1.139484e-02  3.471914e-02  9.503350e-02  0.323181  0.535672   151     0   \n",
       "251  9.284713e-03  3.274773e-02  9.933559e-02  0.362889  0.495743   251     0   \n",
       "0    1.675350e-02  4.236059e-02  9.721889e-02  0.287029  0.556638     0     0   \n",
       "14   1.291950e-03  1.321630e-02  1.341532e-01  0.577771  0.273568    14     0   \n",
       "283  2.235545e-02  5.699635e-02  8.929031e-02  0.217567  0.613791   283     0   \n",
       "44   9.243285e-04  1.145600e-02  1.515237e-01  0.651481  0.184614    44     0   \n",
       "41   3.046547e-03  2.100313e-02  1.428357e-01  0.550398  0.282717    41     0   \n",
       "46   4.947260e-03  2.844668e-02  1.448437e-01  0.478524  0.343239    46     0   \n",
       "40   4.756248e-03  2.833412e-02  1.516487e-01  0.520831  0.294430    40     0   \n",
       "245  1.775828e-02  5.059949e-02  1.242806e-01  0.346378  0.460983   245     0   \n",
       "70   1.897404e-03  1.721425e-02  1.675089e-01  0.621584  0.191796    70     0   \n",
       "..            ...           ...           ...       ...       ...   ...   ...   \n",
       "140  1.358302e-01  4.553418e-01  2.517807e-01  0.108510  0.048538   140     1   \n",
       "221  2.754863e-02  2.988531e-01  4.662085e-01  0.189734  0.017656   221     0   \n",
       "264  9.326784e-02  4.276908e-01  3.055875e-01  0.138176  0.035279   264     0   \n",
       "158  1.225796e-01  4.697762e-01  2.508799e-01  0.113404  0.043360   158     1   \n",
       "154  1.402419e-01  4.846105e-01  2.301522e-01  0.097341  0.047654   154     1   \n",
       "288  8.775865e-02  4.286960e-01  3.128779e-01  0.136134  0.034534   288     0   \n",
       "119  6.865153e-02  3.926346e-01  3.586591e-01  0.148023  0.032032   119     0   \n",
       "215  1.481791e-01  5.030540e-01  2.113388e-01  0.089624  0.047804   215     1   \n",
       "233  1.432313e-01  5.000812e-01  2.196652e-01  0.091587  0.045435   233     1   \n",
       "317  1.430750e-01  5.098780e-01  2.111027e-01  0.089969  0.045975   317     1   \n",
       "289  1.109331e-01  4.864694e-01  2.586757e-01  0.107847  0.036074   289     1   \n",
       "253  8.801384e-02  4.568240e-01  3.034566e-01  0.121563  0.030143   253     0   \n",
       "53   1.484025e-02  2.798627e-01  5.170567e-01  0.177435  0.010805    53     0   \n",
       "284  1.373523e-01  5.273945e-01  2.150543e-01  0.081641  0.038558   284     1   \n",
       "258  1.086136e-01  5.055384e-01  2.567061e-01  0.096658  0.032484   258     1   \n",
       "144  1.142055e-01  5.099567e-01  2.507291e-01  0.094248  0.030860   144     1   \n",
       "293  8.757050e-02  4.877237e-01  2.869124e-01  0.111481  0.026313   293     0   \n",
       "328  5.649425e-02  4.324875e-01  3.595371e-01  0.132726  0.018755   328     0   \n",
       "171  7.983490e-02  4.806279e-01  3.014271e-01  0.113214  0.024896   171     0   \n",
       "152  1.235624e-01  5.356058e-01  2.252400e-01  0.083505  0.032087   152     1   \n",
       "295  1.269159e-01  5.508341e-01  2.128270e-01  0.076452  0.032971   295     1   \n",
       "134  5.893540e-02  4.439982e-01  3.540618e-01  0.125016  0.017989   134     0   \n",
       "147  1.233998e-01  5.455791e-01  2.216453e-01  0.079051  0.030325   147     1   \n",
       "138  9.660497e-02  5.323394e-01  2.566967e-01  0.088858  0.025501   138     1   \n",
       "146  7.200707e-02  5.027918e-01  3.050674e-01  0.100865  0.019269   146     0   \n",
       "287  9.745269e-02  5.534727e-01  2.432973e-01  0.081697  0.024081   287     1   \n",
       "222  4.685505e-02  4.732583e-01  3.616242e-01  0.104565  0.013698   222     0   \n",
       "285  1.078045e-01  6.082356e-01  2.053191e-01  0.058949  0.019692   285     1   \n",
       "4    5.999259e-02  7.268361e-01  1.805120e-01  0.027860  0.004800     4     1   \n",
       "5    7.284624e-03  4.404040e-01  4.957895e-01  0.055466  0.001055     5     0   \n",
       "\n",
       "     gain  1  2    ...      top_vs_mean_low_select_true  \\\n",
       "6       1  0  0    ...                                1   \n",
       "117     1  0  0    ...                                1   \n",
       "58      1  0  0    ...                                1   \n",
       "112     1  0  0    ...                                1   \n",
       "200     1  0  1    ...                                0   \n",
       "197     1  0  0    ...                                0   \n",
       "34      1  0  0    ...                                1   \n",
       "238     1  0  0    ...                                0   \n",
       "193     1  0  0    ...                                1   \n",
       "19      1  0  0    ...                                1   \n",
       "220     1  0  0    ...                                1   \n",
       "91      1  0  0    ...                                1   \n",
       "54      1  0  0    ...                                1   \n",
       "17      1  0  0    ...                                1   \n",
       "16      1  0  0    ...                                1   \n",
       "36      1  0  0    ...                                1   \n",
       "13      1  0  0    ...                                1   \n",
       "47      1  0  0    ...                                1   \n",
       "31      1  0  0    ...                                1   \n",
       "151     1  0  0    ...                                0   \n",
       "251     1  0  0    ...                                1   \n",
       "0       1  0  0    ...                                1   \n",
       "14      1  0  0    ...                                1   \n",
       "283     1  0  0    ...                                1   \n",
       "44      1  0  0    ...                                1   \n",
       "41      1  0  0    ...                                1   \n",
       "46      1  0  0    ...                                1   \n",
       "40      1  0  0    ...                                1   \n",
       "245     1  0  0    ...                                0   \n",
       "70      1  0  0    ...                                1   \n",
       "..    ... .. ..    ...                              ...   \n",
       "140     0  0  0    ...                                0   \n",
       "221     0  0  0    ...                                0   \n",
       "264     0  0  0    ...                                0   \n",
       "158     0  0  0    ...                                0   \n",
       "154     0  0  1    ...                                0   \n",
       "288     0  0  0    ...                                0   \n",
       "119     0  0  0    ...                                0   \n",
       "215     0  0  1    ...                                0   \n",
       "233     0  0  1    ...                                0   \n",
       "317     0  0  1    ...                                0   \n",
       "289     0  0  0    ...                                0   \n",
       "253     0  0  0    ...                                0   \n",
       "53      0  0  0    ...                                0   \n",
       "284     0  0  1    ...                                0   \n",
       "258     0  0  0    ...                                0   \n",
       "144     0  0  1    ...                                0   \n",
       "293     0  0  0    ...                                0   \n",
       "328     0  0  0    ...                                0   \n",
       "171     0  0  0    ...                                0   \n",
       "152     0  0  1    ...                                0   \n",
       "295     0  0  0    ...                                0   \n",
       "134     0  0  0    ...                                0   \n",
       "147     0  0  1    ...                                0   \n",
       "138     0  0  0    ...                                0   \n",
       "146     0  0  1    ...                                0   \n",
       "287     0  0  0    ...                                0   \n",
       "222     0  0  1    ...                                0   \n",
       "285     0  0  1    ...                                0   \n",
       "4       0  0  0    ...                                0   \n",
       "5       0  0  0    ...                                0   \n",
       "\n",
       "     top_vs_mean_low_select_large  gain_large_true_large  \\\n",
       "6                               0                      0   \n",
       "117                             1                      1   \n",
       "58                              0                      0   \n",
       "112                             0                      0   \n",
       "200                             0                      0   \n",
       "197                             0                      0   \n",
       "34                              1                      1   \n",
       "238                             0                      0   \n",
       "193                             1                      1   \n",
       "19                              1                      1   \n",
       "220                             0                      0   \n",
       "91                              0                      0   \n",
       "54                              0                      0   \n",
       "17                              1                      1   \n",
       "16                              0                      0   \n",
       "36                              0                      0   \n",
       "13                              1                      1   \n",
       "47                              0                      0   \n",
       "31                              1                      1   \n",
       "151                             0                      0   \n",
       "251                             0                      0   \n",
       "0                               0                      0   \n",
       "14                              0                      0   \n",
       "283                             0                      0   \n",
       "44                              0                      0   \n",
       "41                              0                      0   \n",
       "46                              0                      0   \n",
       "40                              1                      1   \n",
       "245                             0                      0   \n",
       "70                              0                      0   \n",
       "..                            ...                    ...   \n",
       "140                             0                      0   \n",
       "221                             0                      0   \n",
       "264                             0                      0   \n",
       "158                             0                      0   \n",
       "154                             0                      0   \n",
       "288                             0                      0   \n",
       "119                             0                      0   \n",
       "215                             0                      0   \n",
       "233                             0                      0   \n",
       "317                             0                      0   \n",
       "289                             0                      0   \n",
       "253                             0                      0   \n",
       "53                              0                      0   \n",
       "284                             0                      0   \n",
       "258                             0                      0   \n",
       "144                             0                      0   \n",
       "293                             0                      0   \n",
       "328                             0                      0   \n",
       "171                             0                      0   \n",
       "152                             0                      0   \n",
       "295                             0                      0   \n",
       "134                             0                      0   \n",
       "147                             0                      0   \n",
       "138                             0                      0   \n",
       "146                             0                      0   \n",
       "287                             0                      0   \n",
       "222                             0                      0   \n",
       "285                             0                      0   \n",
       "4                               0                      0   \n",
       "5                               0                      0   \n",
       "\n",
       "     top_vs_mean_low_select_mean  predicted_classes  predicted_classes_gain  \\\n",
       "6                              0                  4                       1   \n",
       "117                            0                  3                       1   \n",
       "58                             0                  2                       0   \n",
       "112                            0                  3                       1   \n",
       "200                            0                  1                       0   \n",
       "197                            1                  2                       0   \n",
       "34                             0                  4                       1   \n",
       "238                            1                  1                       0   \n",
       "193                            0                  1                       0   \n",
       "19                             0                  1                       0   \n",
       "220                            0                  3                       1   \n",
       "91                             0                  3                       1   \n",
       "54                             0                  3                       1   \n",
       "17                             0                  3                       1   \n",
       "16                             0                  3                       1   \n",
       "36                             0                  3                       1   \n",
       "13                             0                  4                       1   \n",
       "47                             0                  3                       1   \n",
       "31                             0                  2                       0   \n",
       "151                            1                  3                       1   \n",
       "251                            0                  3                       1   \n",
       "0                              0                  3                       1   \n",
       "14                             0                  2                       0   \n",
       "283                            0                  2                       0   \n",
       "44                             0                  2                       0   \n",
       "41                             0                  2                       0   \n",
       "46                             0                  3                       1   \n",
       "40                             0                  3                       1   \n",
       "245                            1                  3                       1   \n",
       "70                             0                  3                       1   \n",
       "..                           ...                ...                     ...   \n",
       "140                            0                  1                       0   \n",
       "221                            0                  1                       0   \n",
       "264                            0                  1                       0   \n",
       "158                            0                  1                       0   \n",
       "154                            0                  1                       0   \n",
       "288                            0                  1                       0   \n",
       "119                            0                  1                       0   \n",
       "215                            0                  1                       0   \n",
       "233                            0                  1                       0   \n",
       "317                            0                  1                       0   \n",
       "289                            0                  1                       0   \n",
       "253                            0                  1                       0   \n",
       "53                             0                  1                       0   \n",
       "284                            0                  1                       0   \n",
       "258                            0                  1                       0   \n",
       "144                            0                  1                       0   \n",
       "293                            0                  1                       0   \n",
       "328                            0                  1                       0   \n",
       "171                            0                  2                       0   \n",
       "152                            0                  1                       0   \n",
       "295                            0                  4                       1   \n",
       "134                            0                  1                       0   \n",
       "147                            0                  1                       0   \n",
       "138                            0                  1                       0   \n",
       "146                            0                  1                       0   \n",
       "287                            0                  1                       0   \n",
       "222                            0                  1                       0   \n",
       "285                            0                  1                       0   \n",
       "4                              0                  1                       0   \n",
       "5                              0                  1                       0   \n",
       "\n",
       "     predicted_classes_gain_true  predicted_classes_gain_large_true  \\\n",
       "6                              1                                  0   \n",
       "117                            1                                  1   \n",
       "58                             0                                  0   \n",
       "112                            1                                  0   \n",
       "200                            0                                  0   \n",
       "197                            0                                  0   \n",
       "34                             1                                  1   \n",
       "238                            0                                  0   \n",
       "193                            0                                  0   \n",
       "19                             0                                  0   \n",
       "220                            1                                  0   \n",
       "91                             1                                  0   \n",
       "54                             1                                  0   \n",
       "17                             1                                  1   \n",
       "16                             1                                  0   \n",
       "36                             1                                  0   \n",
       "13                             1                                  1   \n",
       "47                             1                                  0   \n",
       "31                             0                                  0   \n",
       "151                            0                                  0   \n",
       "251                            1                                  0   \n",
       "0                              1                                  0   \n",
       "14                             0                                  0   \n",
       "283                            0                                  0   \n",
       "44                             0                                  0   \n",
       "41                             0                                  0   \n",
       "46                             1                                  0   \n",
       "40                             1                                  1   \n",
       "245                            0                                  0   \n",
       "70                             1                                  0   \n",
       "..                           ...                                ...   \n",
       "140                            0                                  0   \n",
       "221                            0                                  0   \n",
       "264                            0                                  0   \n",
       "158                            0                                  0   \n",
       "154                            0                                  0   \n",
       "288                            0                                  0   \n",
       "119                            0                                  0   \n",
       "215                            0                                  0   \n",
       "233                            0                                  0   \n",
       "317                            0                                  0   \n",
       "289                            0                                  0   \n",
       "253                            0                                  0   \n",
       "53                             0                                  0   \n",
       "284                            0                                  0   \n",
       "258                            0                                  0   \n",
       "144                            0                                  0   \n",
       "293                            0                                  0   \n",
       "328                            0                                  0   \n",
       "171                            0                                  0   \n",
       "152                            0                                  0   \n",
       "295                            0                                  0   \n",
       "134                            0                                  0   \n",
       "147                            0                                  0   \n",
       "138                            0                                  0   \n",
       "146                            0                                  0   \n",
       "287                            0                                  0   \n",
       "222                            0                                  0   \n",
       "285                            0                                  0   \n",
       "4                              0                                  0   \n",
       "5                              0                                  0   \n",
       "\n",
       "     predicted_classes_gain_mean  gain_true  \n",
       "6                              0          1  \n",
       "117                            0          1  \n",
       "58                             0          1  \n",
       "112                            0          1  \n",
       "200                            0          0  \n",
       "197                            0          0  \n",
       "34                             0          1  \n",
       "238                            0          0  \n",
       "193                            0          1  \n",
       "19                             0          1  \n",
       "220                            0          1  \n",
       "91                             0          1  \n",
       "54                             0          1  \n",
       "17                             0          1  \n",
       "16                             0          1  \n",
       "36                             0          1  \n",
       "13                             0          1  \n",
       "47                             0          1  \n",
       "31                             0          1  \n",
       "151                            1          0  \n",
       "251                            0          1  \n",
       "0                              0          1  \n",
       "14                             0          1  \n",
       "283                            0          1  \n",
       "44                             0          1  \n",
       "41                             0          1  \n",
       "46                             0          1  \n",
       "40                             0          1  \n",
       "245                            1          0  \n",
       "70                             0          1  \n",
       "..                           ...        ...  \n",
       "140                            0          0  \n",
       "221                            0          0  \n",
       "264                            0          0  \n",
       "158                            0          0  \n",
       "154                            0          0  \n",
       "288                            0          0  \n",
       "119                            0          1  \n",
       "215                            0          0  \n",
       "233                            0          0  \n",
       "317                            0          0  \n",
       "289                            0          0  \n",
       "253                            0          0  \n",
       "53                             0          0  \n",
       "284                            0          0  \n",
       "258                            0          0  \n",
       "144                            0          0  \n",
       "293                            0          0  \n",
       "328                            0          0  \n",
       "171                            0          0  \n",
       "152                            0          0  \n",
       "295                            1          0  \n",
       "134                            0          1  \n",
       "147                            0          0  \n",
       "138                            0          0  \n",
       "146                            0          0  \n",
       "287                            0          1  \n",
       "222                            0          0  \n",
       "285                            0          0  \n",
       "4                              0          1  \n",
       "5                              0          0  \n",
       "\n",
       "[331 rows x 36 columns]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>zips</th>\n",
       "      <th>loss</th>\n",
       "      <th>gain</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>top_vs_mean_low_select_true</th>\n",
       "      <th>top_vs_mean_low_select_large</th>\n",
       "      <th>gain_large_true_large</th>\n",
       "      <th>top_vs_mean_low_select_mean</th>\n",
       "      <th>predicted_classes</th>\n",
       "      <th>predicted_classes_gain</th>\n",
       "      <th>predicted_classes_gain_true</th>\n",
       "      <th>predicted_classes_gain_large_true</th>\n",
       "      <th>predicted_classes_gain_mean</th>\n",
       "      <th>gain_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.123152e-20</td>\n",
       "      <td>1.994228e-12</td>\n",
       "      <td>4.905951e-09</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.939950e-09</td>\n",
       "      <td>2.583653e-05</td>\n",
       "      <td>6.679239e-04</td>\n",
       "      <td>0.046662</td>\n",
       "      <td>0.952644</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.453703e-07</td>\n",
       "      <td>1.861113e-04</td>\n",
       "      <td>3.937508e-03</td>\n",
       "      <td>0.137719</td>\n",
       "      <td>0.858158</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.831715e-05</td>\n",
       "      <td>1.385983e-03</td>\n",
       "      <td>6.881033e-03</td>\n",
       "      <td>0.061505</td>\n",
       "      <td>0.930200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1.489586e-05</td>\n",
       "      <td>1.508566e-03</td>\n",
       "      <td>7.686182e-03</td>\n",
       "      <td>0.107026</td>\n",
       "      <td>0.883764</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.108082e-05</td>\n",
       "      <td>1.928392e-03</td>\n",
       "      <td>9.159067e-03</td>\n",
       "      <td>0.091042</td>\n",
       "      <td>0.897840</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.007706e-08</td>\n",
       "      <td>1.766906e-04</td>\n",
       "      <td>1.973090e-02</td>\n",
       "      <td>0.533130</td>\n",
       "      <td>0.446962</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.524232e-04</td>\n",
       "      <td>5.990736e-03</td>\n",
       "      <td>2.151701e-02</td>\n",
       "      <td>0.162266</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.222820e-05</td>\n",
       "      <td>2.777602e-03</td>\n",
       "      <td>2.623559e-02</td>\n",
       "      <td>0.307115</td>\n",
       "      <td>0.663849</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.299357e-06</td>\n",
       "      <td>7.622365e-04</td>\n",
       "      <td>3.866262e-02</td>\n",
       "      <td>0.514127</td>\n",
       "      <td>0.446447</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.285546e-05</td>\n",
       "      <td>2.596335e-03</td>\n",
       "      <td>5.126296e-02</td>\n",
       "      <td>0.467338</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.572909e-05</td>\n",
       "      <td>2.860115e-03</td>\n",
       "      <td>5.692171e-02</td>\n",
       "      <td>0.536112</td>\n",
       "      <td>0.404090</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1.293477e-04</td>\n",
       "      <td>8.331210e-03</td>\n",
       "      <td>5.922468e-02</td>\n",
       "      <td>0.402833</td>\n",
       "      <td>0.529482</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.644691e-03</td>\n",
       "      <td>2.094296e-02</td>\n",
       "      <td>4.720977e-02</td>\n",
       "      <td>0.196331</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.786141e-05</td>\n",
       "      <td>3.054191e-03</td>\n",
       "      <td>7.179769e-02</td>\n",
       "      <td>0.556076</td>\n",
       "      <td>0.369054</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.822986e-04</td>\n",
       "      <td>1.228888e-02</td>\n",
       "      <td>6.244562e-02</td>\n",
       "      <td>0.383361</td>\n",
       "      <td>0.541622</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.384518e-05</td>\n",
       "      <td>5.221861e-03</td>\n",
       "      <td>7.348978e-02</td>\n",
       "      <td>0.531263</td>\n",
       "      <td>0.389972</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.306905e-05</td>\n",
       "      <td>4.083330e-03</td>\n",
       "      <td>7.989099e-02</td>\n",
       "      <td>0.565197</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2.715240e-03</td>\n",
       "      <td>2.807488e-02</td>\n",
       "      <td>5.616768e-02</td>\n",
       "      <td>0.197622</td>\n",
       "      <td>0.715420</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.131456e-06</td>\n",
       "      <td>1.703005e-03</td>\n",
       "      <td>8.897822e-02</td>\n",
       "      <td>0.703712</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.593240e-04</td>\n",
       "      <td>9.825117e-03</td>\n",
       "      <td>8.781170e-02</td>\n",
       "      <td>0.494129</td>\n",
       "      <td>0.408075</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.061795e-05</td>\n",
       "      <td>6.397825e-03</td>\n",
       "      <td>9.468759e-02</td>\n",
       "      <td>0.555350</td>\n",
       "      <td>0.343484</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.391178e-03</td>\n",
       "      <td>2.399775e-02</td>\n",
       "      <td>7.948395e-02</td>\n",
       "      <td>0.317307</td>\n",
       "      <td>0.577820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.687721e-03</td>\n",
       "      <td>2.763486e-02</td>\n",
       "      <td>7.639885e-02</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>0.568160</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2.257301e-03</td>\n",
       "      <td>3.047185e-02</td>\n",
       "      <td>7.615155e-02</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.621119</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.488746e-05</td>\n",
       "      <td>4.924249e-03</td>\n",
       "      <td>1.033057e-01</td>\n",
       "      <td>0.607122</td>\n",
       "      <td>0.284603</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1.202585e-03</td>\n",
       "      <td>2.444785e-02</td>\n",
       "      <td>8.724531e-02</td>\n",
       "      <td>0.376237</td>\n",
       "      <td>0.510867</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.112447e-05</td>\n",
       "      <td>4.697893e-03</td>\n",
       "      <td>1.096378e-01</td>\n",
       "      <td>0.596863</td>\n",
       "      <td>0.288760</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.795266e-04</td>\n",
       "      <td>1.465189e-02</td>\n",
       "      <td>1.053100e-01</td>\n",
       "      <td>0.477685</td>\n",
       "      <td>0.401873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.232191e-04</td>\n",
       "      <td>8.178671e-03</td>\n",
       "      <td>1.129318e-01</td>\n",
       "      <td>0.581226</td>\n",
       "      <td>0.297540</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2.392519e-01</td>\n",
       "      <td>4.847708e-01</td>\n",
       "      <td>1.848212e-01</td>\n",
       "      <td>0.076467</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2.387448e-01</td>\n",
       "      <td>4.870071e-01</td>\n",
       "      <td>1.843908e-01</td>\n",
       "      <td>0.075902</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.850352e-01</td>\n",
       "      <td>4.761027e-01</td>\n",
       "      <td>2.229833e-01</td>\n",
       "      <td>0.100315</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1.554954e-01</td>\n",
       "      <td>4.667670e-01</td>\n",
       "      <td>2.472949e-01</td>\n",
       "      <td>0.115932</td>\n",
       "      <td>0.014510</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1.845998e-01</td>\n",
       "      <td>4.771326e-01</td>\n",
       "      <td>2.229029e-01</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>304</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>9.201788e-02</td>\n",
       "      <td>4.338970e-01</td>\n",
       "      <td>3.136441e-01</td>\n",
       "      <td>0.149605</td>\n",
       "      <td>0.010836</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1.779045e-01</td>\n",
       "      <td>4.785112e-01</td>\n",
       "      <td>2.269369e-01</td>\n",
       "      <td>0.101268</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1.842447e-01</td>\n",
       "      <td>4.653028e-01</td>\n",
       "      <td>2.370155e-01</td>\n",
       "      <td>0.098407</td>\n",
       "      <td>0.015030</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2.951042e-02</td>\n",
       "      <td>2.667226e-01</td>\n",
       "      <td>5.147403e-01</td>\n",
       "      <td>0.184207</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>4.506023e-02</td>\n",
       "      <td>3.837333e-01</td>\n",
       "      <td>3.944792e-01</td>\n",
       "      <td>0.171016</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.821136e-01</td>\n",
       "      <td>4.832354e-01</td>\n",
       "      <td>2.269637e-01</td>\n",
       "      <td>0.093584</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>9.658518e-02</td>\n",
       "      <td>4.334142e-01</td>\n",
       "      <td>3.206338e-01</td>\n",
       "      <td>0.138460</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2.031958e-01</td>\n",
       "      <td>4.986449e-01</td>\n",
       "      <td>2.028238e-01</td>\n",
       "      <td>0.083836</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2.247869e-01</td>\n",
       "      <td>5.118252e-01</td>\n",
       "      <td>1.846148e-01</td>\n",
       "      <td>0.068488</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2.143321e-01</td>\n",
       "      <td>5.166345e-01</td>\n",
       "      <td>1.874302e-01</td>\n",
       "      <td>0.071752</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.751440e-01</td>\n",
       "      <td>4.996326e-01</td>\n",
       "      <td>2.254813e-01</td>\n",
       "      <td>0.088507</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1.881418e-01</td>\n",
       "      <td>5.135359e-01</td>\n",
       "      <td>2.098757e-01</td>\n",
       "      <td>0.079427</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2.116627e-01</td>\n",
       "      <td>5.264133e-01</td>\n",
       "      <td>1.854616e-01</td>\n",
       "      <td>0.067777</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.206522e-01</td>\n",
       "      <td>4.948262e-01</td>\n",
       "      <td>2.632644e-01</td>\n",
       "      <td>0.111398</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.203872e-01</td>\n",
       "      <td>5.069382e-01</td>\n",
       "      <td>2.567557e-01</td>\n",
       "      <td>0.107644</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.455172e-01</td>\n",
       "      <td>5.208745e-01</td>\n",
       "      <td>2.410649e-01</td>\n",
       "      <td>0.085657</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.980300e-01</td>\n",
       "      <td>5.546854e-01</td>\n",
       "      <td>1.822681e-01</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>8.836378e-02</td>\n",
       "      <td>5.091430e-01</td>\n",
       "      <td>2.922416e-01</td>\n",
       "      <td>0.105628</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>6.167826e-02</td>\n",
       "      <td>4.916108e-01</td>\n",
       "      <td>3.285900e-01</td>\n",
       "      <td>0.114852</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1.407189e-01</td>\n",
       "      <td>5.657042e-01</td>\n",
       "      <td>2.154588e-01</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.195444e-01</td>\n",
       "      <td>5.474794e-01</td>\n",
       "      <td>2.443270e-01</td>\n",
       "      <td>0.084181</td>\n",
       "      <td>0.004468</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>6.348996e-02</td>\n",
       "      <td>4.705890e-01</td>\n",
       "      <td>3.501054e-01</td>\n",
       "      <td>0.112488</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1.987355e-01</td>\n",
       "      <td>5.886300e-01</td>\n",
       "      <td>1.661664e-01</td>\n",
       "      <td>0.043284</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.706664e-01</td>\n",
       "      <td>6.742959e-01</td>\n",
       "      <td>1.352088e-01</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.140842e-02</td>\n",
       "      <td>4.477644e-01</td>\n",
       "      <td>4.837892e-01</td>\n",
       "      <td>0.056969</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2         3         4  zips  loss  \\\n",
       "6    1.123152e-20  1.994228e-12  4.905951e-09  0.000122  0.999877     6     0   \n",
       "117  6.939950e-09  2.583653e-05  6.679239e-04  0.046662  0.952644   117     0   \n",
       "58   1.453703e-07  1.861113e-04  3.937508e-03  0.137719  0.858158    58     0   \n",
       "200  2.831715e-05  1.385983e-03  6.881033e-03  0.061505  0.930200   200     0   \n",
       "238  1.489586e-05  1.508566e-03  7.686182e-03  0.107026  0.883764   238     0   \n",
       "197  3.108082e-05  1.928392e-03  9.159067e-03  0.091042  0.897840   197     0   \n",
       "112  6.007706e-08  1.766906e-04  1.973090e-02  0.533130  0.446962   112     0   \n",
       "193  1.524232e-04  5.990736e-03  2.151701e-02  0.162266  0.810074   193     0   \n",
       "34   2.222820e-05  2.777602e-03  2.623559e-02  0.307115  0.663849    34     0   \n",
       "91   1.299357e-06  7.622365e-04  3.866262e-02  0.514127  0.446447    91     0   \n",
       "17   1.285546e-05  2.596335e-03  5.126296e-02  0.467338  0.478790    17     0   \n",
       "19   1.572909e-05  2.860115e-03  5.692171e-02  0.536112  0.404090    19     0   \n",
       "220  1.293477e-04  8.331210e-03  5.922468e-02  0.402833  0.529482   220     0   \n",
       "187  1.644691e-03  2.094296e-02  4.720977e-02  0.196331  0.733871   187     0   \n",
       "31   1.786141e-05  3.054191e-03  7.179769e-02  0.556076  0.369054    31     0   \n",
       "16   2.822986e-04  1.228888e-02  6.244562e-02  0.383361  0.541622    16     0   \n",
       "13   5.384518e-05  5.221861e-03  7.348978e-02  0.531263  0.389972    13     0   \n",
       "36   3.306905e-05  4.083330e-03  7.989099e-02  0.565197  0.350796    36     0   \n",
       "283  2.715240e-03  2.807488e-02  5.616768e-02  0.197622  0.715420   283     0   \n",
       "54   6.131456e-06  1.703005e-03  8.897822e-02  0.703712  0.205600    54     0   \n",
       "28   1.593240e-04  9.825117e-03  8.781170e-02  0.494129  0.408075    28     0   \n",
       "41   8.061795e-05  6.397825e-03  9.468759e-02  0.555350  0.343484    41     0   \n",
       "0    1.391178e-03  2.399775e-02  7.948395e-02  0.317307  0.577820     0     0   \n",
       "151  1.687721e-03  2.763486e-02  7.639885e-02  0.326118  0.568160   151     0   \n",
       "282  2.257301e-03  3.047185e-02  7.615155e-02  0.270000  0.621119   282     0   \n",
       "47   4.488746e-05  4.924249e-03  1.033057e-01  0.607122  0.284603    47     0   \n",
       "251  1.202585e-03  2.444785e-02  8.724531e-02  0.376237  0.510867   251     0   \n",
       "14   4.112447e-05  4.697893e-03  1.096378e-01  0.596863  0.288760    14     0   \n",
       "1    4.795266e-04  1.465189e-02  1.053100e-01  0.477685  0.401873     1     0   \n",
       "70   1.232191e-04  8.178671e-03  1.129318e-01  0.581226  0.297540    70     0   \n",
       "..            ...           ...           ...       ...       ...   ...   ...   \n",
       "317  2.392519e-01  4.847708e-01  1.848212e-01  0.076467  0.014690   317     1   \n",
       "233  2.387448e-01  4.870071e-01  1.843908e-01  0.075902  0.013955   233     1   \n",
       "201  1.850352e-01  4.761027e-01  2.229833e-01  0.100315  0.015564   201     1   \n",
       "292  1.554954e-01  4.667670e-01  2.472949e-01  0.115932  0.014510   292     1   \n",
       "304  1.845998e-01  4.771326e-01  2.229029e-01  0.100409  0.014956   304     1   \n",
       "264  9.201788e-02  4.338970e-01  3.136441e-01  0.149605  0.010836   264     0   \n",
       "325  1.779045e-01  4.785112e-01  2.269369e-01  0.101268  0.015379   325     1   \n",
       "287  1.842447e-01  4.653028e-01  2.370155e-01  0.098407  0.015030   287     1   \n",
       "221  2.951042e-02  2.667226e-01  5.147403e-01  0.184207  0.004820   221     0   \n",
       "286  4.506023e-02  3.837333e-01  3.944792e-01  0.171016  0.005711   286     0   \n",
       "258  1.821136e-01  4.832354e-01  2.269637e-01  0.093584  0.014103   258     1   \n",
       "288  9.658518e-02  4.334142e-01  3.206338e-01  0.138460  0.010907   288     0   \n",
       "158  2.031958e-01  4.986449e-01  2.028238e-01  0.083836  0.011500   158     1   \n",
       "284  2.247869e-01  5.118252e-01  1.846148e-01  0.068488  0.010285   284     1   \n",
       "147  2.143321e-01  5.166345e-01  1.874302e-01  0.071752  0.009851   147     1   \n",
       "289  1.751440e-01  4.996326e-01  2.254813e-01  0.088507  0.011236   289     1   \n",
       "144  1.881418e-01  5.135359e-01  2.098757e-01  0.079427  0.009019   144     1   \n",
       "295  2.116627e-01  5.264133e-01  1.854616e-01  0.067777  0.008686   295     1   \n",
       "253  1.206522e-01  4.948262e-01  2.632644e-01  0.111398  0.009859   253     1   \n",
       "171  1.203872e-01  5.069382e-01  2.567557e-01  0.107644  0.008275   171     1   \n",
       "138  1.455172e-01  5.208745e-01  2.410649e-01  0.085657  0.006887   138     1   \n",
       "152  1.980300e-01  5.546854e-01  1.822681e-01  0.059465  0.005552   152     1   \n",
       "134  8.836378e-02  5.091430e-01  2.922416e-01  0.105628  0.004624   134     0   \n",
       "328  6.167826e-02  4.916108e-01  3.285900e-01  0.114852  0.003269   328     0   \n",
       "293  1.407189e-01  5.657042e-01  2.154588e-01  0.073370  0.004748   293     1   \n",
       "146  1.195444e-01  5.474794e-01  2.443270e-01  0.084181  0.004468   146     1   \n",
       "222  6.348996e-02  4.705890e-01  3.501054e-01  0.112488  0.003328   222     0   \n",
       "285  1.987355e-01  5.886300e-01  1.661664e-01  0.043284  0.003184   285     1   \n",
       "4    1.706664e-01  6.742959e-01  1.352088e-01  0.019294  0.000535     4     1   \n",
       "5    1.140842e-02  4.477644e-01  4.837892e-01  0.056969  0.000069     5     0   \n",
       "\n",
       "     gain  1  2    ...      top_vs_mean_low_select_true  \\\n",
       "6       1  0  0    ...                                1   \n",
       "117     1  0  0    ...                                1   \n",
       "58      1  0  0    ...                                1   \n",
       "200     1  0  1    ...                                0   \n",
       "238     1  0  0    ...                                0   \n",
       "197     1  0  0    ...                                0   \n",
       "112     1  0  0    ...                                1   \n",
       "193     1  0  0    ...                                1   \n",
       "34      1  0  0    ...                                1   \n",
       "91      1  0  0    ...                                1   \n",
       "17      1  0  0    ...                                1   \n",
       "19      1  0  0    ...                                1   \n",
       "220     1  0  0    ...                                1   \n",
       "187     1  0  0    ...                                1   \n",
       "31      1  0  0    ...                                1   \n",
       "16      1  0  0    ...                                1   \n",
       "13      1  0  0    ...                                1   \n",
       "36      1  0  0    ...                                1   \n",
       "283     1  0  0    ...                                1   \n",
       "54      1  0  0    ...                                1   \n",
       "28      1  0  0    ...                                1   \n",
       "41      1  0  0    ...                                1   \n",
       "0       1  0  0    ...                                1   \n",
       "151     1  0  0    ...                                0   \n",
       "282     1  0  0    ...                                1   \n",
       "47      1  0  0    ...                                1   \n",
       "251     1  0  0    ...                                1   \n",
       "14      1  0  0    ...                                1   \n",
       "1       1  0  0    ...                                1   \n",
       "70      1  0  0    ...                                1   \n",
       "..    ... .. ..    ...                              ...   \n",
       "317     0  0  1    ...                                0   \n",
       "233     0  0  1    ...                                0   \n",
       "201     0  0  1    ...                                0   \n",
       "292     0  0  1    ...                                0   \n",
       "304     0  0  1    ...                                0   \n",
       "264     0  0  0    ...                                0   \n",
       "325     0  0  0    ...                                0   \n",
       "287     0  0  0    ...                                0   \n",
       "221     0  0  0    ...                                0   \n",
       "286     0  0  0    ...                                0   \n",
       "258     0  0  0    ...                                0   \n",
       "288     0  0  0    ...                                0   \n",
       "158     0  0  0    ...                                0   \n",
       "284     0  0  1    ...                                0   \n",
       "147     0  0  1    ...                                0   \n",
       "289     0  0  0    ...                                0   \n",
       "144     0  0  1    ...                                0   \n",
       "295     0  0  0    ...                                0   \n",
       "253     0  0  0    ...                                0   \n",
       "171     0  0  0    ...                                0   \n",
       "138     0  0  0    ...                                0   \n",
       "152     0  0  1    ...                                0   \n",
       "134     0  0  0    ...                                0   \n",
       "328     0  0  0    ...                                0   \n",
       "293     0  0  0    ...                                0   \n",
       "146     0  0  1    ...                                0   \n",
       "222     0  0  1    ...                                0   \n",
       "285     0  0  1    ...                                0   \n",
       "4       0  0  0    ...                                0   \n",
       "5       0  0  0    ...                                0   \n",
       "\n",
       "     top_vs_mean_low_select_large  gain_large_true_large  \\\n",
       "6                               0                      0   \n",
       "117                             1                      1   \n",
       "58                              0                      0   \n",
       "200                             0                      0   \n",
       "238                             0                      0   \n",
       "197                             0                      0   \n",
       "112                             0                      0   \n",
       "193                             1                      1   \n",
       "34                              1                      1   \n",
       "91                              0                      0   \n",
       "17                              1                      1   \n",
       "19                              1                      1   \n",
       "220                             0                      0   \n",
       "187                             1                      1   \n",
       "31                              1                      1   \n",
       "16                              0                      0   \n",
       "13                              1                      1   \n",
       "36                              0                      0   \n",
       "283                             0                      0   \n",
       "54                              0                      0   \n",
       "28                              0                      0   \n",
       "41                              0                      0   \n",
       "0                               0                      0   \n",
       "151                             0                      0   \n",
       "282                             0                      0   \n",
       "47                              0                      0   \n",
       "251                             0                      0   \n",
       "14                              0                      0   \n",
       "1                               0                      0   \n",
       "70                              0                      0   \n",
       "..                            ...                    ...   \n",
       "317                             0                      0   \n",
       "233                             0                      0   \n",
       "201                             0                      0   \n",
       "292                             0                      0   \n",
       "304                             0                      0   \n",
       "264                             0                      0   \n",
       "325                             0                      0   \n",
       "287                             0                      0   \n",
       "221                             0                      0   \n",
       "286                             0                      0   \n",
       "258                             0                      0   \n",
       "288                             0                      0   \n",
       "158                             0                      0   \n",
       "284                             0                      0   \n",
       "147                             0                      0   \n",
       "289                             0                      0   \n",
       "144                             0                      0   \n",
       "295                             0                      0   \n",
       "253                             0                      0   \n",
       "171                             0                      0   \n",
       "138                             0                      0   \n",
       "152                             0                      0   \n",
       "134                             0                      0   \n",
       "328                             0                      0   \n",
       "293                             0                      0   \n",
       "146                             0                      0   \n",
       "222                             0                      0   \n",
       "285                             0                      0   \n",
       "4                               0                      0   \n",
       "5                               0                      0   \n",
       "\n",
       "     top_vs_mean_low_select_mean  predicted_classes  predicted_classes_gain  \\\n",
       "6                              0                  4                       1   \n",
       "117                            0                  3                       1   \n",
       "58                             0                  3                       1   \n",
       "200                            0                  3                       1   \n",
       "238                            1                  1                       0   \n",
       "197                            1                  2                       0   \n",
       "112                            0                  4                       1   \n",
       "193                            0                  4                       1   \n",
       "34                             0                  1                       0   \n",
       "91                             0                  2                       0   \n",
       "17                             0                  3                       1   \n",
       "19                             0                  3                       1   \n",
       "220                            0                  3                       1   \n",
       "187                            0                  3                       1   \n",
       "31                             0                  3                       1   \n",
       "16                             0                  3                       1   \n",
       "13                             0                  4                       1   \n",
       "36                             0                  4                       1   \n",
       "283                            0                  2                       0   \n",
       "54                             0                  3                       1   \n",
       "28                             0                  3                       1   \n",
       "41                             0                  3                       1   \n",
       "0                              0                  2                       0   \n",
       "151                            1                  2                       0   \n",
       "282                            0                  2                       0   \n",
       "47                             0                  3                       1   \n",
       "251                            0                  3                       1   \n",
       "14                             0                  3                       1   \n",
       "1                              0                  3                       1   \n",
       "70                             0                  3                       1   \n",
       "..                           ...                ...                     ...   \n",
       "317                            0                  1                       0   \n",
       "233                            0                  1                       0   \n",
       "201                            0                  1                       0   \n",
       "292                            0                  1                       0   \n",
       "304                            0                  1                       0   \n",
       "264                            0                  1                       0   \n",
       "325                            0                  1                       0   \n",
       "287                            0                  1                       0   \n",
       "221                            0                  1                       0   \n",
       "286                            0                  1                       0   \n",
       "258                            0                  1                       0   \n",
       "288                            0                  1                       0   \n",
       "158                            0                  1                       0   \n",
       "284                            0                  2                       0   \n",
       "147                            0                  1                       0   \n",
       "289                            0                  1                       0   \n",
       "144                            0                  1                       0   \n",
       "295                            0                  1                       0   \n",
       "253                            0                  3                       1   \n",
       "171                            0                  1                       0   \n",
       "138                            0                  4                       1   \n",
       "152                            0                  1                       0   \n",
       "134                            0                  1                       0   \n",
       "328                            0                  1                       0   \n",
       "293                            0                  1                       0   \n",
       "146                            0                  1                       0   \n",
       "222                            0                  1                       0   \n",
       "285                            0                  1                       0   \n",
       "4                              0                  1                       0   \n",
       "5                              0                  1                       0   \n",
       "\n",
       "     predicted_classes_gain_true  predicted_classes_gain_large_true  \\\n",
       "6                              1                                  0   \n",
       "117                            1                                  1   \n",
       "58                             1                                  0   \n",
       "200                            0                                  0   \n",
       "238                            0                                  0   \n",
       "197                            0                                  0   \n",
       "112                            1                                  0   \n",
       "193                            1                                  1   \n",
       "34                             0                                  0   \n",
       "91                             0                                  0   \n",
       "17                             1                                  1   \n",
       "19                             1                                  1   \n",
       "220                            1                                  0   \n",
       "187                            1                                  1   \n",
       "31                             1                                  1   \n",
       "16                             1                                  0   \n",
       "13                             1                                  1   \n",
       "36                             1                                  0   \n",
       "283                            0                                  0   \n",
       "54                             1                                  0   \n",
       "28                             1                                  0   \n",
       "41                             1                                  0   \n",
       "0                              0                                  0   \n",
       "151                            0                                  0   \n",
       "282                            0                                  0   \n",
       "47                             1                                  0   \n",
       "251                            1                                  0   \n",
       "14                             1                                  0   \n",
       "1                              1                                  0   \n",
       "70                             1                                  0   \n",
       "..                           ...                                ...   \n",
       "317                            0                                  0   \n",
       "233                            0                                  0   \n",
       "201                            0                                  0   \n",
       "292                            0                                  0   \n",
       "304                            0                                  0   \n",
       "264                            0                                  0   \n",
       "325                            0                                  0   \n",
       "287                            0                                  0   \n",
       "221                            0                                  0   \n",
       "286                            0                                  0   \n",
       "258                            0                                  0   \n",
       "288                            0                                  0   \n",
       "158                            0                                  0   \n",
       "284                            0                                  0   \n",
       "147                            0                                  0   \n",
       "289                            0                                  0   \n",
       "144                            0                                  0   \n",
       "295                            0                                  0   \n",
       "253                            0                                  0   \n",
       "171                            0                                  0   \n",
       "138                            0                                  0   \n",
       "152                            0                                  0   \n",
       "134                            0                                  0   \n",
       "328                            0                                  0   \n",
       "293                            0                                  0   \n",
       "146                            0                                  0   \n",
       "222                            0                                  0   \n",
       "285                            0                                  0   \n",
       "4                              0                                  0   \n",
       "5                              0                                  0   \n",
       "\n",
       "     predicted_classes_gain_mean  gain_true  \n",
       "6                              0          1  \n",
       "117                            0          1  \n",
       "58                             0          1  \n",
       "200                            0          0  \n",
       "238                            0          0  \n",
       "197                            0          0  \n",
       "112                            0          1  \n",
       "193                            0          1  \n",
       "34                             0          1  \n",
       "91                             0          1  \n",
       "17                             0          1  \n",
       "19                             0          1  \n",
       "220                            0          1  \n",
       "187                            0          1  \n",
       "31                             0          1  \n",
       "16                             0          1  \n",
       "13                             0          1  \n",
       "36                             0          1  \n",
       "283                            0          1  \n",
       "54                             0          1  \n",
       "28                             0          1  \n",
       "41                             0          1  \n",
       "0                              0          1  \n",
       "151                            0          0  \n",
       "282                            0          1  \n",
       "47                             0          1  \n",
       "251                            0          1  \n",
       "14                             0          1  \n",
       "1                              0          1  \n",
       "70                             0          1  \n",
       "..                           ...        ...  \n",
       "317                            0          0  \n",
       "233                            0          0  \n",
       "201                            0          0  \n",
       "292                            0          0  \n",
       "304                            0          0  \n",
       "264                            0          0  \n",
       "325                            0          0  \n",
       "287                            0          1  \n",
       "221                            0          0  \n",
       "286                            0          0  \n",
       "258                            0          0  \n",
       "288                            0          0  \n",
       "158                            0          0  \n",
       "284                            0          0  \n",
       "147                            0          0  \n",
       "289                            0          0  \n",
       "144                            0          0  \n",
       "295                            0          0  \n",
       "253                            1          0  \n",
       "171                            0          0  \n",
       "138                            1          0  \n",
       "152                            0          0  \n",
       "134                            0          1  \n",
       "328                            0          0  \n",
       "293                            0          0  \n",
       "146                            0          0  \n",
       "222                            0          0  \n",
       "285                            0          0  \n",
       "4                              0          1  \n",
       "5                              0          0  \n",
       "\n",
       "[331 rows x 36 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>1.122820</td>\n",
       "      <td>0.510574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>0.889908</td>\n",
       "      <td>1.209980</td>\n",
       "      <td>0.465257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.925234</td>\n",
       "      <td>1.187737</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.091603</td>\n",
       "      <td>0.595420</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>1.238466</td>\n",
       "      <td>0.425982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>1.262683</td>\n",
       "      <td>0.432024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        88.0  0.094972  0.750000   0.977273           0.212121   \n",
       "1        84.0  0.094972  0.797619   0.976190           0.303030   \n",
       "2        83.0  0.094972  0.795181   0.975904           0.242424   \n",
       "3       118.0  0.094972  0.703390   0.949153           0.272727   \n",
       "4        86.0  0.094972  0.790698   0.976744           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.909091            0.969697             0.085470   \n",
       "1          0.878788            0.969697             0.091743   \n",
       "2          0.878788            0.969697             0.102804   \n",
       "3          0.909091            0.969697             0.091603   \n",
       "4          0.878788            0.969697             0.086022   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.547009              0.880342  1.122820  0.510574  \n",
       "1            0.596330              0.889908  1.209980  0.465257  \n",
       "2            0.672897              0.925234  1.187737  0.495468  \n",
       "3            0.595420              0.870229  1.238466  0.425982  \n",
       "4            0.602151              0.924731  1.262683  0.432024  "
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>1.287202</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>1.296553</td>\n",
       "      <td>0.486405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>1.235172</td>\n",
       "      <td>0.477341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.628743</td>\n",
       "      <td>0.940120</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.469072</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>1.307907</td>\n",
       "      <td>0.468278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.880240</td>\n",
       "      <td>1.262887</td>\n",
       "      <td>0.492447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       100.0  0.094972  0.770000   0.960000           0.272727   \n",
       "1       121.0  0.094972  0.694215   0.958678           0.242424   \n",
       "2        78.0  0.094972  0.769231   0.961538           0.242424   \n",
       "3       167.0  0.094972  0.628743   0.940120           0.242424   \n",
       "4       144.0  0.094972  0.673611   0.958333           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.878788            0.969697             0.095652   \n",
       "1          0.909091            0.969697             0.086667   \n",
       "2          0.878788            0.969697             0.097087   \n",
       "3          0.878788            0.969697             0.061856   \n",
       "4          0.878788            0.969697             0.095808   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.565217              0.895652  1.287202  0.480363  \n",
       "1            0.500000              0.873333  1.296553  0.486405  \n",
       "2            0.582524              0.912621  1.235172  0.477341  \n",
       "3            0.469072              0.855670  1.307907  0.468278  \n",
       "4            0.550898              0.880240  1.262887  0.492447  "
      ]
     },
     "execution_count": 1145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_150_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.911504</td>\n",
       "      <td>1.193644</td>\n",
       "      <td>0.462236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>1.160346</td>\n",
       "      <td>0.471299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.125869</td>\n",
       "      <td>0.507553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>1.230654</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.121495</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>1.229660</td>\n",
       "      <td>0.422961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       101.0  0.094972  0.762376   0.960396           0.272727   \n",
       "1        95.0  0.094972  0.768421   0.978947           0.272727   \n",
       "2        97.0  0.094972  0.731959   0.969072           0.242424   \n",
       "3        99.0  0.094972  0.787879   0.969697           0.242424   \n",
       "4        99.0  0.094972  0.767677   0.959596           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.939394             0.097345   \n",
       "1          0.909091            0.969697             0.102804   \n",
       "2          0.878788            0.969697             0.099099   \n",
       "3          0.848485            0.969697             0.091743   \n",
       "4          0.818182            0.939394             0.121495   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.566372              0.911504  1.193644  0.462236  \n",
       "1            0.514019              0.850467  1.160346  0.471299  \n",
       "2            0.567568              0.891892  1.125869  0.507553  \n",
       "3            0.568807              0.871560  1.230654  0.459215  \n",
       "4            0.598131              0.887850  1.229660  0.422961  "
      ]
     },
     "execution_count": 1159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_150_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.512658</td>\n",
       "      <td>0.879747</td>\n",
       "      <td>1.287235</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.069519</td>\n",
       "      <td>0.497326</td>\n",
       "      <td>0.877005</td>\n",
       "      <td>1.263305</td>\n",
       "      <td>0.501511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.074890</td>\n",
       "      <td>0.462555</td>\n",
       "      <td>0.859031</td>\n",
       "      <td>1.357800</td>\n",
       "      <td>0.404834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.321788</td>\n",
       "      <td>0.477341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.895604</td>\n",
       "      <td>1.252489</td>\n",
       "      <td>0.507553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       109.0  0.094972  0.715596   0.963303           0.272727   \n",
       "1       175.0  0.094972  0.594286   0.942857           0.242424   \n",
       "2       200.0  0.094972  0.570000   0.910000           0.272727   \n",
       "3       155.0  0.094972  0.651613   0.941935           0.242424   \n",
       "4       130.0  0.094972  0.676923   0.953846           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.878788            0.969697             0.088608   \n",
       "1          0.848485            0.969697             0.069519   \n",
       "2          0.848485            0.969697             0.074890   \n",
       "3          0.878788            0.969697             0.091954   \n",
       "4          0.909091            0.969697             0.071429   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.512658              0.879747  1.287235  0.495468  \n",
       "1            0.497326              0.877005  1.263305  0.501511  \n",
       "2            0.462555              0.859031  1.357800  0.404834  \n",
       "3            0.500000              0.862069  1.321788  0.477341  \n",
       "4            0.494505              0.895604  1.252489  0.507553  "
      ]
     },
     "execution_count": 1149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_125_w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>0.878307</td>\n",
       "      <td>1.159453</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>1.137560</td>\n",
       "      <td>0.492447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.065054</td>\n",
       "      <td>0.549849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>1.223903</td>\n",
       "      <td>0.447130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.592920</td>\n",
       "      <td>0.911504</td>\n",
       "      <td>1.195224</td>\n",
       "      <td>0.465257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       161.0  0.094972  0.621118   0.925466           0.242424   \n",
       "1       101.0  0.094972  0.762376   0.980198           0.272727   \n",
       "2        95.0  0.094972  0.789474   0.978947           0.272727   \n",
       "3       186.0  0.094972  0.591398   0.919355           0.303030   \n",
       "4       101.0  0.094972  0.722772   0.960396           0.242424   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.969697             0.074074   \n",
       "1          0.878788            0.969697             0.093023   \n",
       "2          0.878788            0.969697             0.117647   \n",
       "3          0.848485            0.969697             0.080000   \n",
       "4          0.818182            0.969697             0.106195   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.486772              0.878307  1.159453  0.480363  \n",
       "1            0.558140              0.906977  1.137560  0.492447  \n",
       "2            0.588235              0.882353  1.065054  0.549849  \n",
       "3            0.485000              0.870000  1.223903  0.447130  \n",
       "4            0.592920              0.911504  1.195224  0.465257  "
      ]
     },
     "execution_count": 1161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_125_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2831 samples, validate on 330 samples\n",
      "Epoch 1/300\n",
      "2831/2831 [==============================] - 18s 6ms/step - loss: 2.3538 - acc: 0.3179 - val_loss: 2.2389 - val_acc: 0.3303\n",
      "Epoch 2/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 2.2132 - acc: 0.3575 - val_loss: 2.2645 - val_acc: 0.3303\n",
      "Epoch 3/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 2.1534 - acc: 0.3349 - val_loss: 2.2347 - val_acc: 0.3303\n",
      "Epoch 4/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 2.1152 - acc: 0.3578 - val_loss: 2.2203 - val_acc: 0.3242\n",
      "Epoch 5/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 2.0767 - acc: 0.3606 - val_loss: 2.1927 - val_acc: 0.3212\n",
      "Epoch 6/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 2.0539 - acc: 0.3681 - val_loss: 2.1976 - val_acc: 0.3212\n",
      "Epoch 7/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 2.0219 - acc: 0.3705 - val_loss: 2.2071 - val_acc: 0.3242\n",
      "Epoch 8/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 2.0227 - acc: 0.3681 - val_loss: 2.1055 - val_acc: 0.3273\n",
      "Epoch 9/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.9865 - acc: 0.3822 - val_loss: 2.1098 - val_acc: 0.3303\n",
      "Epoch 10/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.9733 - acc: 0.3758 - val_loss: 2.0889 - val_acc: 0.3242\n",
      "Epoch 11/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.9532 - acc: 0.3635 - val_loss: 2.0586 - val_acc: 0.3273\n",
      "Epoch 12/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.9400 - acc: 0.3712 - val_loss: 2.0520 - val_acc: 0.3273\n",
      "Epoch 13/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.9017 - acc: 0.3741 - val_loss: 2.0405 - val_acc: 0.3242\n",
      "Epoch 14/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8977 - acc: 0.3737 - val_loss: 2.0912 - val_acc: 0.3303\n",
      "Epoch 15/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8882 - acc: 0.3677 - val_loss: 2.0376 - val_acc: 0.3242\n",
      "Epoch 16/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8539 - acc: 0.3617 - val_loss: 1.9464 - val_acc: 0.3242\n",
      "Epoch 17/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8489 - acc: 0.3787 - val_loss: 2.0182 - val_acc: 0.3273\n",
      "Epoch 18/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8355 - acc: 0.3783 - val_loss: 1.9260 - val_acc: 0.3273\n",
      "Epoch 19/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8177 - acc: 0.3797 - val_loss: 1.8975 - val_acc: 0.3242\n",
      "Epoch 20/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8000 - acc: 0.3773 - val_loss: 1.8996 - val_acc: 0.3212\n",
      "Epoch 21/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7717 - acc: 0.3780 - val_loss: 1.8523 - val_acc: 0.3242\n",
      "Epoch 22/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.7806 - acc: 0.3716 - val_loss: 1.8393 - val_acc: 0.3273\n",
      "Epoch 23/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.7713 - acc: 0.3974 - val_loss: 1.8464 - val_acc: 0.3242\n",
      "Epoch 24/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.7218 - acc: 0.3822 - val_loss: 1.8586 - val_acc: 0.3152\n",
      "Epoch 25/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.7142 - acc: 0.4041 - val_loss: 1.8841 - val_acc: 0.3212\n",
      "Epoch 26/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7124 - acc: 0.3709 - val_loss: 1.8611 - val_acc: 0.3273\n",
      "Epoch 27/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7202 - acc: 0.3801 - val_loss: 1.7644 - val_acc: 0.3242\n",
      "Epoch 28/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.7224 - acc: 0.3992 - val_loss: 1.8334 - val_acc: 0.3212\n",
      "Epoch 29/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6743 - acc: 0.3861 - val_loss: 1.9551 - val_acc: 0.3152\n",
      "Epoch 30/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6745 - acc: 0.3857 - val_loss: 1.7872 - val_acc: 0.3242\n",
      "Epoch 31/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.6661 - acc: 0.3727 - val_loss: 1.7354 - val_acc: 0.3242\n",
      "Epoch 32/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.6339 - acc: 0.3907 - val_loss: 1.7918 - val_acc: 0.3212\n",
      "Epoch 33/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.6167 - acc: 0.3921 - val_loss: 1.8052 - val_acc: 0.3121\n",
      "Epoch 34/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6144 - acc: 0.4052 - val_loss: 1.9052 - val_acc: 0.3030\n",
      "Epoch 35/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6369 - acc: 0.3628 - val_loss: 1.7595 - val_acc: 0.3333\n",
      "Epoch 36/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.6093 - acc: 0.4119 - val_loss: 1.8208 - val_acc: 0.3030\n",
      "Epoch 37/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.6242 - acc: 0.3780 - val_loss: 1.7007 - val_acc: 0.3303\n",
      "Epoch 38/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6052 - acc: 0.3864 - val_loss: 1.6881 - val_acc: 0.3303\n",
      "Epoch 39/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.5757 - acc: 0.4055 - val_loss: 1.7322 - val_acc: 0.3242\n",
      "Epoch 40/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5682 - acc: 0.4013 - val_loss: 1.8423 - val_acc: 0.3121\n",
      "Epoch 41/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.5735 - acc: 0.3836 - val_loss: 1.7813 - val_acc: 0.2879\n",
      "Epoch 42/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5660 - acc: 0.3730 - val_loss: 1.7490 - val_acc: 0.3152\n",
      "Epoch 43/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5403 - acc: 0.3949 - val_loss: 1.8087 - val_acc: 0.2879\n",
      "Epoch 44/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5633 - acc: 0.3575 - val_loss: 1.7857 - val_acc: 0.3212\n",
      "Epoch 45/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.5226 - acc: 0.4059 - val_loss: 1.8263 - val_acc: 0.3121\n",
      "Epoch 46/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5499 - acc: 0.3967 - val_loss: 1.6859 - val_acc: 0.3121\n",
      "Epoch 47/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5031 - acc: 0.3910 - val_loss: 1.6512 - val_acc: 0.3273\n",
      "Epoch 48/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4868 - acc: 0.4150 - val_loss: 1.6260 - val_acc: 0.3303\n",
      "Epoch 49/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.5065 - acc: 0.4136 - val_loss: 1.6240 - val_acc: 0.3394\n",
      "Epoch 50/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5317 - acc: 0.4246 - val_loss: 1.7617 - val_acc: 0.2848\n",
      "Epoch 51/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5077 - acc: 0.3829 - val_loss: 1.7159 - val_acc: 0.3212\n",
      "Epoch 52/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5038 - acc: 0.4108 - val_loss: 1.6461 - val_acc: 0.3212\n",
      "Epoch 53/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4925 - acc: 0.4136 - val_loss: 1.6772 - val_acc: 0.3061\n",
      "Epoch 54/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4930 - acc: 0.3889 - val_loss: 1.7588 - val_acc: 0.2515\n",
      "Epoch 55/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4962 - acc: 0.3628 - val_loss: 1.7273 - val_acc: 0.3061\n",
      "Epoch 56/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4621 - acc: 0.3970 - val_loss: 1.9202 - val_acc: 0.2939\n",
      "Epoch 57/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5075 - acc: 0.3917 - val_loss: 1.6103 - val_acc: 0.3333\n",
      "Epoch 58/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4459 - acc: 0.4203 - val_loss: 1.6518 - val_acc: 0.3273\n",
      "Epoch 59/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4367 - acc: 0.4203 - val_loss: 1.7314 - val_acc: 0.3303\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4444 - acc: 0.4108 - val_loss: 1.7420 - val_acc: 0.3091\n",
      "Epoch 61/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4523 - acc: 0.3928 - val_loss: 1.6681 - val_acc: 0.3212\n",
      "Epoch 62/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4177 - acc: 0.4186 - val_loss: 1.6871 - val_acc: 0.3212\n",
      "Epoch 63/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4534 - acc: 0.3992 - val_loss: 1.6340 - val_acc: 0.3212\n",
      "Epoch 64/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4058 - acc: 0.4193 - val_loss: 1.5796 - val_acc: 0.3333\n",
      "Epoch 65/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4181 - acc: 0.4193 - val_loss: 1.5366 - val_acc: 0.3455\n",
      "Epoch 66/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4805 - acc: 0.4309 - val_loss: 1.7074 - val_acc: 0.3152\n",
      "Epoch 67/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4184 - acc: 0.4006 - val_loss: 1.7040 - val_acc: 0.3030\n",
      "Epoch 68/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4220 - acc: 0.3917 - val_loss: 1.6946 - val_acc: 0.2970\n",
      "Epoch 69/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4340 - acc: 0.3864 - val_loss: 1.6419 - val_acc: 0.3152\n",
      "Epoch 70/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3950 - acc: 0.4041 - val_loss: 1.5438 - val_acc: 0.3364\n",
      "Epoch 71/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4411 - acc: 0.4232 - val_loss: 1.6327 - val_acc: 0.3152\n",
      "Epoch 72/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3750 - acc: 0.4239 - val_loss: 1.6153 - val_acc: 0.3364\n",
      "Epoch 73/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3870 - acc: 0.4066 - val_loss: 1.5304 - val_acc: 0.3455\n",
      "Epoch 74/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4271 - acc: 0.4101 - val_loss: 1.5013 - val_acc: 0.3485\n",
      "Epoch 75/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4479 - acc: 0.4165 - val_loss: 1.6773 - val_acc: 0.3242\n",
      "Epoch 76/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3956 - acc: 0.4211 - val_loss: 1.6284 - val_acc: 0.3212\n",
      "Epoch 77/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3870 - acc: 0.4143 - val_loss: 1.7430 - val_acc: 0.3061\n",
      "Epoch 78/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4037 - acc: 0.3999 - val_loss: 1.5870 - val_acc: 0.3364\n",
      "Epoch 79/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3676 - acc: 0.4207 - val_loss: 1.5758 - val_acc: 0.3455\n",
      "Epoch 80/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3750 - acc: 0.4239 - val_loss: 1.5695 - val_acc: 0.3242\n",
      "Epoch 81/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3619 - acc: 0.4246 - val_loss: 1.6098 - val_acc: 0.3091\n",
      "Epoch 82/300\n",
      "2831/2831 [==============================] - 0s 92us/step - loss: 1.3629 - acc: 0.4313 - val_loss: 1.7175 - val_acc: 0.2667\n",
      "Epoch 83/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.4001 - acc: 0.3787 - val_loss: 1.6640 - val_acc: 0.3212\n",
      "Epoch 84/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3574 - acc: 0.4186 - val_loss: 1.7404 - val_acc: 0.3303\n",
      "Epoch 85/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3905 - acc: 0.4097 - val_loss: 1.6385 - val_acc: 0.3091\n",
      "Epoch 86/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3398 - acc: 0.4172 - val_loss: 1.6520 - val_acc: 0.3242\n",
      "Epoch 87/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.3514 - acc: 0.4218 - val_loss: 1.7798 - val_acc: 0.3030\n",
      "Epoch 88/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.3865 - acc: 0.4006 - val_loss: 1.5777 - val_acc: 0.3273\n",
      "Epoch 89/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3377 - acc: 0.4306 - val_loss: 1.6657 - val_acc: 0.2697\n",
      "Epoch 90/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3732 - acc: 0.3963 - val_loss: 1.6278 - val_acc: 0.3000\n",
      "Epoch 91/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.3384 - acc: 0.4066 - val_loss: 1.5364 - val_acc: 0.3333\n",
      "Epoch 92/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3467 - acc: 0.4419 - val_loss: 1.4757 - val_acc: 0.3606\n",
      "Epoch 93/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3642 - acc: 0.4532 - val_loss: 1.5057 - val_acc: 0.3545\n",
      "Epoch 94/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3192 - acc: 0.4348 - val_loss: 1.5077 - val_acc: 0.3606\n",
      "Epoch 95/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.3204 - acc: 0.4384 - val_loss: 1.4558 - val_acc: 0.3758\n",
      "Epoch 96/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3527 - acc: 0.4472 - val_loss: 1.5051 - val_acc: 0.3697\n",
      "Epoch 97/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.3286 - acc: 0.4394 - val_loss: 1.4867 - val_acc: 0.3394\n",
      "Epoch 98/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.3206 - acc: 0.4384 - val_loss: 1.4583 - val_acc: 0.3636\n",
      "Epoch 99/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.3379 - acc: 0.4567 - val_loss: 1.6362 - val_acc: 0.3030\n",
      "Epoch 100/300\n",
      "2831/2831 [==============================] - 0s 92us/step - loss: 1.3445 - acc: 0.4006 - val_loss: 1.6750 - val_acc: 0.2909\n",
      "Epoch 101/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3464 - acc: 0.3988 - val_loss: 1.5211 - val_acc: 0.3697\n",
      "Epoch 102/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.3500 - acc: 0.4415 - val_loss: 1.4963 - val_acc: 0.3606\n",
      "Epoch 103/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.3563 - acc: 0.4567 - val_loss: 1.4960 - val_acc: 0.3455\n",
      "Epoch 104/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.2953 - acc: 0.4292 - val_loss: 1.4581 - val_acc: 0.3455\n",
      "Epoch 105/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3328 - acc: 0.4444 - val_loss: 1.5098 - val_acc: 0.3697\n",
      "Epoch 106/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2890 - acc: 0.4437 - val_loss: 1.5295 - val_acc: 0.3606\n",
      "Epoch 107/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.3411 - acc: 0.4440 - val_loss: 1.4729 - val_acc: 0.3667\n",
      "Epoch 108/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3067 - acc: 0.4454 - val_loss: 1.4448 - val_acc: 0.3606\n",
      "Epoch 109/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.3297 - acc: 0.4479 - val_loss: 1.5129 - val_acc: 0.3333\n",
      "Epoch 110/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.2657 - acc: 0.4504 - val_loss: 1.6493 - val_acc: 0.3273\n",
      "Epoch 111/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2983 - acc: 0.4422 - val_loss: 1.5929 - val_acc: 0.3273\n",
      "Epoch 112/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2651 - acc: 0.4401 - val_loss: 1.5167 - val_acc: 0.3515\n",
      "Epoch 113/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.3333 - acc: 0.4122 - val_loss: 1.4524 - val_acc: 0.3576\n",
      "Epoch 114/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.3185 - acc: 0.4490 - val_loss: 1.4653 - val_acc: 0.3727\n",
      "Epoch 115/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.2679 - acc: 0.4514 - val_loss: 1.4238 - val_acc: 0.3970\n",
      "Epoch 116/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3222 - acc: 0.4468 - val_loss: 1.4758 - val_acc: 0.4091\n",
      "Epoch 117/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.3299 - acc: 0.4624 - val_loss: 1.6189 - val_acc: 0.2788\n",
      "Epoch 118/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.2899 - acc: 0.4087 - val_loss: 1.6290 - val_acc: 0.3152\n",
      "Epoch 119/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2841 - acc: 0.4267 - val_loss: 1.6356 - val_acc: 0.3424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.3059 - acc: 0.4454 - val_loss: 1.6351 - val_acc: 0.3121\n",
      "Epoch 121/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2776 - acc: 0.4320 - val_loss: 1.5785 - val_acc: 0.3182\n",
      "Epoch 122/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2496 - acc: 0.4398 - val_loss: 1.5435 - val_acc: 0.3394\n",
      "Epoch 123/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2347 - acc: 0.4571 - val_loss: 1.6721 - val_acc: 0.3212\n",
      "Epoch 124/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.3044 - acc: 0.4419 - val_loss: 1.5268 - val_acc: 0.3212\n",
      "Epoch 125/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2580 - acc: 0.4225 - val_loss: 1.4822 - val_acc: 0.3424\n",
      "Epoch 126/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2843 - acc: 0.4253 - val_loss: 1.4781 - val_acc: 0.3606\n",
      "Epoch 127/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2520 - acc: 0.4514 - val_loss: 1.5081 - val_acc: 0.3606\n",
      "Epoch 128/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.2436 - acc: 0.4507 - val_loss: 1.6129 - val_acc: 0.3515\n",
      "Epoch 129/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2537 - acc: 0.4461 - val_loss: 1.6107 - val_acc: 0.3364\n",
      "Epoch 130/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2695 - acc: 0.4288 - val_loss: 1.5994 - val_acc: 0.3152\n",
      "Epoch 131/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.2481 - acc: 0.4369 - val_loss: 1.6033 - val_acc: 0.3333\n",
      "Epoch 132/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2749 - acc: 0.4324 - val_loss: 1.4827 - val_acc: 0.3424\n",
      "Epoch 133/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2972 - acc: 0.4105 - val_loss: 1.4033 - val_acc: 0.3727\n",
      "Epoch 134/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3013 - acc: 0.4518 - val_loss: 1.4520 - val_acc: 0.4394\n",
      "Epoch 135/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2700 - acc: 0.4603 - val_loss: 1.5153 - val_acc: 0.3909\n",
      "Epoch 136/300\n",
      "2831/2831 [==============================] - 0s 93us/step - loss: 1.2459 - acc: 0.4341 - val_loss: 1.5097 - val_acc: 0.3667\n",
      "Epoch 137/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2038 - acc: 0.4557 - val_loss: 1.5463 - val_acc: 0.3606\n",
      "Epoch 138/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2323 - acc: 0.4511 - val_loss: 1.8759 - val_acc: 0.2848\n",
      "Epoch 139/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.3848 - acc: 0.3836 - val_loss: 1.4545 - val_acc: 0.3545\n",
      "Epoch 140/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.2562 - acc: 0.4528 - val_loss: 1.4987 - val_acc: 0.3697\n",
      "Epoch 141/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2156 - acc: 0.4631 - val_loss: 1.5661 - val_acc: 0.3303\n",
      "Epoch 142/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.2232 - acc: 0.4359 - val_loss: 1.5924 - val_acc: 0.3455\n",
      "Epoch 143/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.2442 - acc: 0.4288 - val_loss: 1.5450 - val_acc: 0.3636\n",
      "Epoch 144/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2289 - acc: 0.4458 - val_loss: 1.5896 - val_acc: 0.3515\n",
      "Epoch 145/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.2314 - acc: 0.4355 - val_loss: 1.6177 - val_acc: 0.3576\n",
      "Epoch 146/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2839 - acc: 0.4377 - val_loss: 1.5970 - val_acc: 0.3182\n",
      "Epoch 147/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2684 - acc: 0.4306 - val_loss: 1.4930 - val_acc: 0.3545\n",
      "Epoch 148/300\n",
      "2831/2831 [==============================] - 0s 98us/step - loss: 1.2115 - acc: 0.4479 - val_loss: 1.5252 - val_acc: 0.3636\n",
      "Epoch 149/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2115 - acc: 0.4493 - val_loss: 1.5854 - val_acc: 0.3485\n",
      "Epoch 150/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2551 - acc: 0.4430 - val_loss: 1.5816 - val_acc: 0.3364\n",
      "Epoch 151/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2242 - acc: 0.4394 - val_loss: 1.6068 - val_acc: 0.3333\n",
      "Epoch 152/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2530 - acc: 0.4172 - val_loss: 1.5723 - val_acc: 0.3576\n",
      "Epoch 153/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.2163 - acc: 0.4475 - val_loss: 1.4475 - val_acc: 0.4061\n",
      "Epoch 154/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.1899 - acc: 0.4666 - val_loss: 1.3829 - val_acc: 0.4182\n",
      "Epoch 155/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2546 - acc: 0.4603 - val_loss: 1.5057 - val_acc: 0.4030\n",
      "Epoch 156/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2480 - acc: 0.4546 - val_loss: 1.7430 - val_acc: 0.3182\n",
      "Epoch 157/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.3494 - acc: 0.4161 - val_loss: 1.5153 - val_acc: 0.3576\n",
      "Epoch 158/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2265 - acc: 0.4454 - val_loss: 1.4927 - val_acc: 0.4273\n",
      "Epoch 159/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2196 - acc: 0.4638 - val_loss: 1.4197 - val_acc: 0.4303\n",
      "Epoch 160/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.1933 - acc: 0.4779 - val_loss: 1.3768 - val_acc: 0.4303\n",
      "Epoch 161/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2158 - acc: 0.4712 - val_loss: 1.3978 - val_acc: 0.4394\n",
      "Epoch 162/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1966 - acc: 0.4800 - val_loss: 1.3735 - val_acc: 0.4424\n",
      "Epoch 163/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2100 - acc: 0.4730 - val_loss: 1.4071 - val_acc: 0.4212\n",
      "Epoch 164/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2000 - acc: 0.4677 - val_loss: 1.3767 - val_acc: 0.4545\n",
      "Epoch 165/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.1880 - acc: 0.4719 - val_loss: 1.3368 - val_acc: 0.4939\n",
      "Epoch 166/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2480 - acc: 0.4751 - val_loss: 1.4941 - val_acc: 0.4333\n",
      "Epoch 167/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2881 - acc: 0.4412 - val_loss: 1.5248 - val_acc: 0.3576\n",
      "Epoch 168/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.2022 - acc: 0.4341 - val_loss: 1.4846 - val_acc: 0.4455\n",
      "Epoch 169/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1818 - acc: 0.4641 - val_loss: 1.4828 - val_acc: 0.4394\n",
      "Epoch 170/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.1859 - acc: 0.4733 - val_loss: 1.5043 - val_acc: 0.3970\n",
      "Epoch 171/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.1731 - acc: 0.4641 - val_loss: 1.5443 - val_acc: 0.3758\n",
      "Epoch 172/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1917 - acc: 0.4649 - val_loss: 1.6463 - val_acc: 0.3667\n",
      "Epoch 173/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2718 - acc: 0.4352 - val_loss: 1.4848 - val_acc: 0.3515\n",
      "Epoch 174/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1912 - acc: 0.4588 - val_loss: 1.4368 - val_acc: 0.4030\n",
      "Epoch 175/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1794 - acc: 0.4638 - val_loss: 1.3977 - val_acc: 0.4152\n",
      "Epoch 176/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2359 - acc: 0.4596 - val_loss: 1.4795 - val_acc: 0.4242\n",
      "Epoch 177/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.1752 - acc: 0.4790 - val_loss: 1.6600 - val_acc: 0.3485\n",
      "Epoch 178/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2548 - acc: 0.4398 - val_loss: 1.4635 - val_acc: 0.3727\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1640 - acc: 0.4649 - val_loss: 1.4447 - val_acc: 0.4212\n",
      "Epoch 180/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1600 - acc: 0.4786 - val_loss: 1.5707 - val_acc: 0.3909\n",
      "Epoch 181/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.2535 - acc: 0.4302 - val_loss: 1.4905 - val_acc: 0.4394\n",
      "Epoch 182/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1776 - acc: 0.4603 - val_loss: 1.3342 - val_acc: 0.5303\n",
      "Epoch 183/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.2412 - acc: 0.4680 - val_loss: 1.3599 - val_acc: 0.4394\n",
      "Epoch 184/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.2219 - acc: 0.4804 - val_loss: 1.4354 - val_acc: 0.4242\n",
      "Epoch 185/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1436 - acc: 0.4984 - val_loss: 1.4662 - val_acc: 0.4182\n",
      "Epoch 186/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1704 - acc: 0.4822 - val_loss: 1.6442 - val_acc: 0.3576\n",
      "Epoch 187/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2495 - acc: 0.4398 - val_loss: 1.5294 - val_acc: 0.4000\n",
      "Epoch 188/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1786 - acc: 0.4610 - val_loss: 1.4291 - val_acc: 0.4636\n",
      "Epoch 189/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.1476 - acc: 0.4860 - val_loss: 1.4219 - val_acc: 0.4606\n",
      "Epoch 190/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1747 - acc: 0.4857 - val_loss: 1.4088 - val_acc: 0.4636\n",
      "Epoch 191/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1870 - acc: 0.5009 - val_loss: 1.3431 - val_acc: 0.4939\n",
      "Epoch 192/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1737 - acc: 0.4913 - val_loss: 1.3537 - val_acc: 0.4606\n",
      "Epoch 193/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1710 - acc: 0.4868 - val_loss: 1.3554 - val_acc: 0.4636\n",
      "Epoch 194/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1744 - acc: 0.4913 - val_loss: 1.4018 - val_acc: 0.4727\n",
      "Epoch 195/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2121 - acc: 0.4726 - val_loss: 1.4248 - val_acc: 0.4424\n",
      "Epoch 196/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1779 - acc: 0.4917 - val_loss: 1.3628 - val_acc: 0.4576\n",
      "Epoch 197/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1357 - acc: 0.5026 - val_loss: 1.3514 - val_acc: 0.4455\n",
      "Epoch 198/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.1994 - acc: 0.4641 - val_loss: 1.3401 - val_acc: 0.4606\n",
      "Epoch 199/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1842 - acc: 0.4966 - val_loss: 1.4287 - val_acc: 0.4455\n",
      "Epoch 200/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1681 - acc: 0.5023 - val_loss: 1.4499 - val_acc: 0.4273\n",
      "Epoch 201/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1614 - acc: 0.4921 - val_loss: 1.4657 - val_acc: 0.4242\n",
      "Epoch 202/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1500 - acc: 0.4910 - val_loss: 1.4978 - val_acc: 0.4182\n",
      "Epoch 203/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1674 - acc: 0.4613 - val_loss: 1.5337 - val_acc: 0.3909\n",
      "Epoch 204/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2014 - acc: 0.4387 - val_loss: 1.5995 - val_acc: 0.3788\n",
      "Epoch 205/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2118 - acc: 0.4475 - val_loss: 1.4620 - val_acc: 0.4061\n",
      "Epoch 206/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1370 - acc: 0.4709 - val_loss: 1.4779 - val_acc: 0.4000\n",
      "Epoch 207/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1576 - acc: 0.4779 - val_loss: 1.5884 - val_acc: 0.3606\n",
      "Epoch 208/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2173 - acc: 0.4468 - val_loss: 1.4791 - val_acc: 0.4061\n",
      "Epoch 209/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1337 - acc: 0.4857 - val_loss: 1.4288 - val_acc: 0.4424\n",
      "Epoch 210/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1153 - acc: 0.4896 - val_loss: 1.5640 - val_acc: 0.3818\n",
      "Epoch 211/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1832 - acc: 0.4539 - val_loss: 1.3942 - val_acc: 0.4667\n",
      "Epoch 212/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1295 - acc: 0.4995 - val_loss: 1.3473 - val_acc: 0.4879\n",
      "Epoch 213/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1540 - acc: 0.4921 - val_loss: 1.3267 - val_acc: 0.4727\n",
      "Epoch 214/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1796 - acc: 0.4800 - val_loss: 1.3541 - val_acc: 0.4636\n",
      "Epoch 215/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1394 - acc: 0.4850 - val_loss: 1.3170 - val_acc: 0.4909\n",
      "Epoch 216/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1772 - acc: 0.5037 - val_loss: 1.3587 - val_acc: 0.4515\n",
      "Epoch 217/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1219 - acc: 0.5005 - val_loss: 1.3705 - val_acc: 0.4576\n",
      "Epoch 218/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1176 - acc: 0.4998 - val_loss: 1.4532 - val_acc: 0.4394\n",
      "Epoch 219/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1841 - acc: 0.4882 - val_loss: 1.5404 - val_acc: 0.3879\n",
      "Epoch 220/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2257 - acc: 0.4454 - val_loss: 1.4940 - val_acc: 0.3848\n",
      "Epoch 221/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1198 - acc: 0.4846 - val_loss: 1.4427 - val_acc: 0.4273\n",
      "Epoch 222/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0999 - acc: 0.4935 - val_loss: 1.5350 - val_acc: 0.3848\n",
      "Epoch 223/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1806 - acc: 0.4606 - val_loss: 1.4754 - val_acc: 0.4152\n",
      "Epoch 224/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1246 - acc: 0.4875 - val_loss: 1.4567 - val_acc: 0.4030\n",
      "Epoch 225/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1132 - acc: 0.5009 - val_loss: 1.5801 - val_acc: 0.3485\n",
      "Epoch 226/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1927 - acc: 0.4440 - val_loss: 1.5220 - val_acc: 0.3939\n",
      "Epoch 227/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1821 - acc: 0.4712 - val_loss: 1.4282 - val_acc: 0.4242\n",
      "Epoch 228/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1391 - acc: 0.4779 - val_loss: 1.4480 - val_acc: 0.4273\n",
      "Epoch 229/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1311 - acc: 0.4882 - val_loss: 1.3744 - val_acc: 0.4576\n",
      "Epoch 230/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1024 - acc: 0.4988 - val_loss: 1.3426 - val_acc: 0.4758\n",
      "Epoch 231/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0986 - acc: 0.5104 - val_loss: 1.2902 - val_acc: 0.5152\n",
      "Epoch 232/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1662 - acc: 0.5051 - val_loss: 1.3792 - val_acc: 0.4424\n",
      "Epoch 233/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1871 - acc: 0.4892 - val_loss: 1.4126 - val_acc: 0.4485\n",
      "Epoch 234/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1049 - acc: 0.5087 - val_loss: 1.4742 - val_acc: 0.4182\n",
      "Epoch 235/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1640 - acc: 0.4730 - val_loss: 1.3449 - val_acc: 0.4909\n",
      "Epoch 236/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1613 - acc: 0.4988 - val_loss: 1.3367 - val_acc: 0.4455\n",
      "Epoch 237/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1572 - acc: 0.5037 - val_loss: 1.3604 - val_acc: 0.4576\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0803 - acc: 0.5129 - val_loss: 1.3451 - val_acc: 0.4727\n",
      "Epoch 239/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1101 - acc: 0.4998 - val_loss: 1.3353 - val_acc: 0.4697\n",
      "Epoch 240/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1885 - acc: 0.5041 - val_loss: 1.4153 - val_acc: 0.4242\n",
      "Epoch 241/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0914 - acc: 0.5132 - val_loss: 1.3506 - val_acc: 0.4455\n",
      "Epoch 242/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1005 - acc: 0.5037 - val_loss: 1.3127 - val_acc: 0.4727\n",
      "Epoch 243/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1352 - acc: 0.4970 - val_loss: 1.3511 - val_acc: 0.4606\n",
      "Epoch 244/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.1268 - acc: 0.490 - 0s 72us/step - loss: 1.1323 - acc: 0.4889 - val_loss: 1.4920 - val_acc: 0.4182\n",
      "Epoch 245/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.1542 - acc: 0.4769 - val_loss: 1.4976 - val_acc: 0.3939\n",
      "Epoch 246/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1083 - acc: 0.4875 - val_loss: 1.4716 - val_acc: 0.4061\n",
      "Epoch 247/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.0892 - acc: 0.4981 - val_loss: 1.5250 - val_acc: 0.3848\n",
      "Epoch 248/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.1232 - acc: 0.4702 - val_loss: 1.4857 - val_acc: 0.4121\n",
      "Epoch 249/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.1058 - acc: 0.4928 - val_loss: 1.4371 - val_acc: 0.4182\n",
      "Epoch 250/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.1096 - acc: 0.5009 - val_loss: 1.7034 - val_acc: 0.3606\n",
      "Epoch 251/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2764 - acc: 0.4271 - val_loss: 1.3779 - val_acc: 0.4242\n",
      "Epoch 252/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1005 - acc: 0.4959 - val_loss: 1.3586 - val_acc: 0.4576\n",
      "Epoch 253/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.0811 - acc: 0.5072 - val_loss: 1.3617 - val_acc: 0.4515\n",
      "Epoch 254/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.0921 - acc: 0.5012 - val_loss: 1.3525 - val_acc: 0.4727\n",
      "Epoch 255/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.0662 - acc: 0.5044 - val_loss: 1.3565 - val_acc: 0.4848\n",
      "Epoch 256/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.0879 - acc: 0.4981 - val_loss: 1.4349 - val_acc: 0.4333\n",
      "Epoch 257/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1297 - acc: 0.5026 - val_loss: 1.5380 - val_acc: 0.3939\n",
      "Epoch 258/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.1978 - acc: 0.4557 - val_loss: 1.4987 - val_acc: 0.4030\n",
      "Epoch 259/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.1127 - acc: 0.4811 - val_loss: 1.3758 - val_acc: 0.4545\n",
      "Epoch 260/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.0812 - acc: 0.5238 - val_loss: 1.3783 - val_acc: 0.4576\n",
      "Epoch 261/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.0913 - acc: 0.5221 - val_loss: 1.3441 - val_acc: 0.4727\n",
      "Epoch 262/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0696 - acc: 0.5245 - val_loss: 1.3081 - val_acc: 0.4788\n",
      "Epoch 263/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1631 - acc: 0.5058 - val_loss: 1.3481 - val_acc: 0.4606\n",
      "Epoch 264/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.0537 - acc: 0.5253 - val_loss: 1.3495 - val_acc: 0.4606\n",
      "Epoch 265/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0753 - acc: 0.4998 - val_loss: 1.3428 - val_acc: 0.4697\n",
      "Epoch 266/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1063 - acc: 0.5048 - val_loss: 1.4181 - val_acc: 0.4394\n",
      "Epoch 267/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1333 - acc: 0.4931 - val_loss: 1.5431 - val_acc: 0.4030\n",
      "Epoch 268/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2112 - acc: 0.4475 - val_loss: 1.5276 - val_acc: 0.3939\n",
      "Epoch 269/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1061 - acc: 0.4910 - val_loss: 1.3917 - val_acc: 0.4636\n",
      "Epoch 270/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0420 - acc: 0.5355 - val_loss: 1.3549 - val_acc: 0.4606\n",
      "Epoch 271/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0400 - acc: 0.5351 - val_loss: 1.3163 - val_acc: 0.4909\n",
      "Epoch 272/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0884 - acc: 0.5076 - val_loss: 1.2922 - val_acc: 0.4970\n",
      "Epoch 273/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1887 - acc: 0.5097 - val_loss: 1.3994 - val_acc: 0.4485\n",
      "Epoch 274/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.0789 - acc: 0.5348 - val_loss: 1.4497 - val_acc: 0.4364\n",
      "Epoch 275/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1670 - acc: 0.4910 - val_loss: 1.3858 - val_acc: 0.4727\n",
      "Epoch 276/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0903 - acc: 0.5461 - val_loss: 1.3306 - val_acc: 0.4879\n",
      "Epoch 277/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.0583 - acc: 0.5221 - val_loss: 1.2998 - val_acc: 0.5030\n",
      "Epoch 278/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1161 - acc: 0.5132 - val_loss: 1.3148 - val_acc: 0.4818\n",
      "Epoch 279/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1075 - acc: 0.5277 - val_loss: 1.3892 - val_acc: 0.4576\n",
      "Epoch 280/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.0419 - acc: 0.5334 - val_loss: 1.3573 - val_acc: 0.4727\n",
      "Epoch 281/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1065 - acc: 0.5270 - val_loss: 1.3390 - val_acc: 0.4576\n",
      "Epoch 282/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1689 - acc: 0.5143 - val_loss: 1.3559 - val_acc: 0.4606\n",
      "Epoch 283/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.0516 - acc: 0.5178 - val_loss: 1.3420 - val_acc: 0.4727\n",
      "Epoch 284/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1761 - acc: 0.4755 - val_loss: 1.3686 - val_acc: 0.4758\n",
      "Epoch 285/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.0607 - acc: 0.5185 - val_loss: 1.3422 - val_acc: 0.4636\n",
      "Epoch 286/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.0386 - acc: 0.5450 - val_loss: 1.4083 - val_acc: 0.4545\n",
      "Epoch 287/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.0434 - acc: 0.5182 - val_loss: 1.5356 - val_acc: 0.4030\n",
      "Epoch 288/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.1060 - acc: 0.4779 - val_loss: 1.4715 - val_acc: 0.4212\n",
      "Epoch 289/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.0713 - acc: 0.5076 - val_loss: 1.5125 - val_acc: 0.4152\n",
      "Epoch 290/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1482 - acc: 0.4868 - val_loss: 1.4348 - val_acc: 0.4364\n",
      "Epoch 291/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.0865 - acc: 0.4864 - val_loss: 1.3643 - val_acc: 0.4697\n",
      "Epoch 292/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.0495 - acc: 0.5048 - val_loss: 1.3071 - val_acc: 0.4758\n",
      "Epoch 293/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1573 - acc: 0.4779 - val_loss: 1.3320 - val_acc: 0.4576\n",
      "Epoch 294/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.0777 - acc: 0.5323 - val_loss: 1.4159 - val_acc: 0.4394\n",
      "Epoch 295/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.0967 - acc: 0.5147 - val_loss: 1.3955 - val_acc: 0.4636\n",
      "Epoch 296/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1126 - acc: 0.5175 - val_loss: 1.3433 - val_acc: 0.4818\n",
      "Epoch 297/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.0721 - acc: 0.5429 - val_loss: 1.3413 - val_acc: 0.4848\n",
      "Epoch 298/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.0351 - acc: 0.5330 - val_loss: 1.3007 - val_acc: 0.4879\n",
      "Epoch 299/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1662 - acc: 0.5048 - val_loss: 1.3763 - val_acc: 0.4515\n",
      "Epoch 300/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.0311 - acc: 0.5380 - val_loss: 1.4089 - val_acc: 0.4515\n",
      "0\n",
      "Train on 2831 samples, validate on 330 samples\n",
      "Epoch 1/300\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 2.7163 - acc: 0.2017 - val_loss: 2.3464 - val_acc: 0.3333\n",
      "Epoch 2/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 2.2635 - acc: 0.3603 - val_loss: 2.3795 - val_acc: 0.3303\n",
      "Epoch 3/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 2.2000 - acc: 0.3780 - val_loss: 2.3030 - val_acc: 0.3303\n",
      "Epoch 4/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 2.1783 - acc: 0.3755 - val_loss: 2.2630 - val_acc: 0.3303\n",
      "Epoch 5/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 2.1493 - acc: 0.3758 - val_loss: 2.2553 - val_acc: 0.3303\n",
      "Epoch 6/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 2.1194 - acc: 0.3737 - val_loss: 2.2204 - val_acc: 0.3303\n",
      "Epoch 7/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 2.1064 - acc: 0.3822 - val_loss: 2.2120 - val_acc: 0.3303\n",
      "Epoch 8/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 2.0716 - acc: 0.3949 - val_loss: 2.1829 - val_acc: 0.3303\n",
      "Epoch 9/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 2.0528 - acc: 0.3931 - val_loss: 2.1533 - val_acc: 0.3303\n",
      "Epoch 10/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 2.0409 - acc: 0.3907 - val_loss: 2.1899 - val_acc: 0.3303\n",
      "Epoch 11/300\n",
      "2831/2831 [==============================] - 0s 92us/step - loss: 2.0036 - acc: 0.4013 - val_loss: 2.1620 - val_acc: 0.3303\n",
      "Epoch 12/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.9887 - acc: 0.3999 - val_loss: 2.1136 - val_acc: 0.3303\n",
      "Epoch 13/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.9646 - acc: 0.3963 - val_loss: 2.1215 - val_acc: 0.3303\n",
      "Epoch 14/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.9675 - acc: 0.3783 - val_loss: 2.0945 - val_acc: 0.3303\n",
      "Epoch 15/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.9362 - acc: 0.3981 - val_loss: 2.0574 - val_acc: 0.3333\n",
      "Epoch 16/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.9265 - acc: 0.3886 - val_loss: 2.0570 - val_acc: 0.3303\n",
      "Epoch 17/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.9265 - acc: 0.3889 - val_loss: 2.0648 - val_acc: 0.3364\n",
      "Epoch 18/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8811 - acc: 0.3939 - val_loss: 1.9965 - val_acc: 0.3333\n",
      "Epoch 19/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8628 - acc: 0.4073 - val_loss: 2.0137 - val_acc: 0.3333\n",
      "Epoch 20/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.8285 - acc: 0.3974 - val_loss: 1.9811 - val_acc: 0.3333\n",
      "Epoch 21/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.8554 - acc: 0.3931 - val_loss: 2.1088 - val_acc: 0.3242\n",
      "Epoch 22/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.8480 - acc: 0.3720 - val_loss: 2.0072 - val_acc: 0.3182\n",
      "Epoch 23/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.8120 - acc: 0.3857 - val_loss: 1.9795 - val_acc: 0.3242\n",
      "Epoch 24/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.7979 - acc: 0.3886 - val_loss: 2.0177 - val_acc: 0.3242\n",
      "Epoch 25/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.7756 - acc: 0.3967 - val_loss: 1.9762 - val_acc: 0.3273\n",
      "Epoch 26/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.7773 - acc: 0.4009 - val_loss: 1.9164 - val_acc: 0.3273\n",
      "Epoch 27/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.7386 - acc: 0.3875 - val_loss: 2.0395 - val_acc: 0.3152\n",
      "Epoch 28/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.7641 - acc: 0.3931 - val_loss: 1.8750 - val_acc: 0.3273\n",
      "Epoch 29/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.7131 - acc: 0.4006 - val_loss: 1.8340 - val_acc: 0.3303\n",
      "Epoch 30/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.7380 - acc: 0.4009 - val_loss: 1.8849 - val_acc: 0.3182\n",
      "Epoch 31/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.6816 - acc: 0.398 - 0s 70us/step - loss: 1.6903 - acc: 0.3995 - val_loss: 1.8804 - val_acc: 0.3182\n",
      "Epoch 32/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.6762 - acc: 0.3977 - val_loss: 1.8976 - val_acc: 0.3121\n",
      "Epoch 33/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.6759 - acc: 0.3942 - val_loss: 1.9015 - val_acc: 0.3121\n",
      "Epoch 34/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6518 - acc: 0.4097 - val_loss: 1.9058 - val_acc: 0.2636\n",
      "Epoch 35/300\n",
      "2831/2831 [==============================] - 0s 115us/step - loss: 1.6875 - acc: 0.3624 - val_loss: 1.8139 - val_acc: 0.3152\n",
      "Epoch 36/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6355 - acc: 0.4108 - val_loss: 1.7277 - val_acc: 0.3091\n",
      "Epoch 37/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6339 - acc: 0.4133 - val_loss: 1.7175 - val_acc: 0.3152\n",
      "Epoch 38/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6358 - acc: 0.4221 - val_loss: 1.7783 - val_acc: 0.3121\n",
      "Epoch 39/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6021 - acc: 0.4034 - val_loss: 1.8586 - val_acc: 0.3121\n",
      "Epoch 40/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.5939 - acc: 0.4055 - val_loss: 1.8257 - val_acc: 0.3091\n",
      "Epoch 41/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.6018 - acc: 0.4037 - val_loss: 1.7735 - val_acc: 0.3182\n",
      "Epoch 42/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.6589 - acc: 0.3670 - val_loss: 1.7556 - val_acc: 0.3242\n",
      "Epoch 43/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5913 - acc: 0.4143 - val_loss: 1.7833 - val_acc: 0.3152\n",
      "Epoch 44/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.5642 - acc: 0.4165 - val_loss: 1.7825 - val_acc: 0.3121\n",
      "Epoch 45/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.5662 - acc: 0.4140 - val_loss: 1.8018 - val_acc: 0.3152\n",
      "Epoch 46/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5558 - acc: 0.4052 - val_loss: 1.7566 - val_acc: 0.3182\n",
      "Epoch 47/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5427 - acc: 0.4154 - val_loss: 1.9828 - val_acc: 0.1909\n",
      "Epoch 48/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6232 - acc: 0.3264 - val_loss: 1.8020 - val_acc: 0.3152\n",
      "Epoch 49/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5604 - acc: 0.3995 - val_loss: 1.7597 - val_acc: 0.2788\n",
      "Epoch 50/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5560 - acc: 0.3992 - val_loss: 1.6984 - val_acc: 0.3061\n",
      "Epoch 51/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.4955 - acc: 0.4143 - val_loss: 1.7023 - val_acc: 0.3091\n",
      "Epoch 52/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5081 - acc: 0.4108 - val_loss: 1.8369 - val_acc: 0.2758\n",
      "Epoch 53/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5371 - acc: 0.3928 - val_loss: 1.7414 - val_acc: 0.2970\n",
      "Epoch 54/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5245 - acc: 0.3984 - val_loss: 1.7566 - val_acc: 0.2485\n",
      "Epoch 55/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.5332 - acc: 0.3868 - val_loss: 1.7322 - val_acc: 0.2939\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4916 - acc: 0.4069 - val_loss: 1.7385 - val_acc: 0.3061\n",
      "Epoch 57/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.4659 - acc: 0.4108 - val_loss: 1.7572 - val_acc: 0.3030\n",
      "Epoch 58/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.4776 - acc: 0.4140 - val_loss: 1.7652 - val_acc: 0.3091\n",
      "Epoch 59/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4911 - acc: 0.4115 - val_loss: 1.7658 - val_acc: 0.2788\n",
      "Epoch 60/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.4772 - acc: 0.3857 - val_loss: 1.7997 - val_acc: 0.2424\n",
      "Epoch 61/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.4891 - acc: 0.3702 - val_loss: 1.6187 - val_acc: 0.3121\n",
      "Epoch 62/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.4681 - acc: 0.4228 - val_loss: 1.7342 - val_acc: 0.2273\n",
      "Epoch 63/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.5019 - acc: 0.3797 - val_loss: 1.8926 - val_acc: 0.1848\n",
      "Epoch 64/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.4975 - acc: 0.3504 - val_loss: 1.6833 - val_acc: 0.3121\n",
      "Epoch 65/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.4343 - acc: 0.4232 - val_loss: 1.7134 - val_acc: 0.2848\n",
      "Epoch 66/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.4397 - acc: 0.4165 - val_loss: 1.7272 - val_acc: 0.3121\n",
      "Epoch 67/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4414 - acc: 0.4200 - val_loss: 1.7247 - val_acc: 0.2848\n",
      "Epoch 68/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4386 - acc: 0.4119 - val_loss: 1.7440 - val_acc: 0.2758\n",
      "Epoch 69/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.4468 - acc: 0.3864 - val_loss: 1.7012 - val_acc: 0.2636\n",
      "Epoch 70/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.4173 - acc: 0.3999 - val_loss: 1.6797 - val_acc: 0.2909\n",
      "Epoch 71/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4183 - acc: 0.4041 - val_loss: 1.8915 - val_acc: 0.2303\n",
      "Epoch 72/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.4733 - acc: 0.3730 - val_loss: 1.6272 - val_acc: 0.3061\n",
      "Epoch 73/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.4050 - acc: 0.4232 - val_loss: 1.6774 - val_acc: 0.3121\n",
      "Epoch 74/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.4351 - acc: 0.427 - 0s 70us/step - loss: 1.4348 - acc: 0.4253 - val_loss: 1.5949 - val_acc: 0.3121\n",
      "Epoch 75/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.3979 - acc: 0.4299 - val_loss: 1.5575 - val_acc: 0.3121\n",
      "Epoch 76/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3782 - acc: 0.4207 - val_loss: 1.5244 - val_acc: 0.3242\n",
      "Epoch 77/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.4040 - acc: 0.4119 - val_loss: 1.5616 - val_acc: 0.3152\n",
      "Epoch 78/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3939 - acc: 0.4246 - val_loss: 1.6334 - val_acc: 0.3182\n",
      "Epoch 79/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3731 - acc: 0.4302 - val_loss: 1.7589 - val_acc: 0.3091\n",
      "Epoch 80/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.4046 - acc: 0.4189 - val_loss: 1.7318 - val_acc: 0.2636\n",
      "Epoch 81/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.3902 - acc: 0.3967 - val_loss: 1.6508 - val_acc: 0.3000\n",
      "Epoch 82/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.3738 - acc: 0.4069 - val_loss: 1.5442 - val_acc: 0.3182\n",
      "Epoch 83/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.3801 - acc: 0.4334 - val_loss: 1.4904 - val_acc: 0.3212\n",
      "Epoch 84/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.4331 - acc: 0.4490 - val_loss: 1.6286 - val_acc: 0.3182\n",
      "Epoch 85/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.3799 - acc: 0.4203 - val_loss: 1.5190 - val_acc: 0.3273\n",
      "Epoch 86/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.4090 - acc: 0.4232 - val_loss: 1.5347 - val_acc: 0.3182\n",
      "Epoch 87/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3614 - acc: 0.4338 - val_loss: 1.5034 - val_acc: 0.3182\n",
      "Epoch 88/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3779 - acc: 0.4306 - val_loss: 1.5009 - val_acc: 0.3091\n",
      "Epoch 89/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.3515 - acc: 0.4359 - val_loss: 1.5390 - val_acc: 0.3242\n",
      "Epoch 90/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3865 - acc: 0.4158 - val_loss: 1.6114 - val_acc: 0.3182\n",
      "Epoch 91/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3326 - acc: 0.4461 - val_loss: 1.8436 - val_acc: 0.2667\n",
      "Epoch 92/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4092 - acc: 0.3900 - val_loss: 1.5702 - val_acc: 0.3121\n",
      "Epoch 93/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3359 - acc: 0.4264 - val_loss: 1.5856 - val_acc: 0.3182\n",
      "Epoch 94/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3293 - acc: 0.4366 - val_loss: 1.6027 - val_acc: 0.3182\n",
      "Epoch 95/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.3656 - acc: 0.4267 - val_loss: 1.5950 - val_acc: 0.3121\n",
      "Epoch 96/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3238 - acc: 0.4285 - val_loss: 1.5357 - val_acc: 0.3061\n",
      "Epoch 97/300\n",
      "2831/2831 [==============================] - 0s 140us/step - loss: 1.3358 - acc: 0.4285 - val_loss: 1.5356 - val_acc: 0.3212\n",
      "Epoch 98/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3257 - acc: 0.4415 - val_loss: 1.4441 - val_acc: 0.3364\n",
      "Epoch 99/300\n",
      "2831/2831 [==============================] - 0s 101us/step - loss: 1.3704 - acc: 0.4475 - val_loss: 1.4855 - val_acc: 0.3212\n",
      "Epoch 100/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.3394 - acc: 0.4278 - val_loss: 1.4602 - val_acc: 0.3212\n",
      "Epoch 101/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.3680 - acc: 0.4447 - val_loss: 1.6122 - val_acc: 0.3030\n",
      "Epoch 102/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3050 - acc: 0.4285 - val_loss: 1.5924 - val_acc: 0.2818\n",
      "Epoch 103/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3418 - acc: 0.4179 - val_loss: 1.7104 - val_acc: 0.2121\n",
      "Epoch 104/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3593 - acc: 0.3794 - val_loss: 1.6449 - val_acc: 0.3182\n",
      "Epoch 105/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3158 - acc: 0.4285 - val_loss: 1.7063 - val_acc: 0.3242\n",
      "Epoch 106/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3323 - acc: 0.4271 - val_loss: 1.6301 - val_acc: 0.3030\n",
      "Epoch 107/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3131 - acc: 0.4179 - val_loss: 1.6730 - val_acc: 0.2909\n",
      "Epoch 108/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3048 - acc: 0.4278 - val_loss: 1.6132 - val_acc: 0.2970\n",
      "Epoch 109/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2905 - acc: 0.4274 - val_loss: 1.6809 - val_acc: 0.3121\n",
      "Epoch 110/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3195 - acc: 0.4267 - val_loss: 1.6238 - val_acc: 0.3182\n",
      "Epoch 111/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3138 - acc: 0.4189 - val_loss: 1.5845 - val_acc: 0.3242\n",
      "Epoch 112/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3097 - acc: 0.4373 - val_loss: 1.4909 - val_acc: 0.3152\n",
      "Epoch 113/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3190 - acc: 0.4168 - val_loss: 1.4377 - val_acc: 0.3424\n",
      "Epoch 114/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3186 - acc: 0.4497 - val_loss: 1.4707 - val_acc: 0.3303\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2933 - acc: 0.4535 - val_loss: 1.4714 - val_acc: 0.3515\n",
      "Epoch 116/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.3114 - acc: 0.4369 - val_loss: 1.4325 - val_acc: 0.3394\n",
      "Epoch 117/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2954 - acc: 0.4638 - val_loss: 1.5421 - val_acc: 0.3121\n",
      "Epoch 118/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2649 - acc: 0.4430 - val_loss: 1.5277 - val_acc: 0.3424\n",
      "Epoch 119/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2673 - acc: 0.4408 - val_loss: 1.5095 - val_acc: 0.3667\n",
      "Epoch 120/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2853 - acc: 0.4384 - val_loss: 1.4441 - val_acc: 0.3636\n",
      "Epoch 121/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3019 - acc: 0.4472 - val_loss: 1.4180 - val_acc: 0.3364\n",
      "Epoch 122/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3460 - acc: 0.4380 - val_loss: 1.4896 - val_acc: 0.3242\n",
      "Epoch 123/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3022 - acc: 0.4437 - val_loss: 1.5942 - val_acc: 0.3424\n",
      "Epoch 124/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2671 - acc: 0.4355 - val_loss: 1.6112 - val_acc: 0.3030\n",
      "Epoch 125/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2650 - acc: 0.4366 - val_loss: 1.6586 - val_acc: 0.2879\n",
      "Epoch 126/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2767 - acc: 0.4172 - val_loss: 1.5762 - val_acc: 0.3121\n",
      "Epoch 127/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2784 - acc: 0.4355 - val_loss: 1.6229 - val_acc: 0.3091\n",
      "Epoch 128/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3128 - acc: 0.4037 - val_loss: 1.5517 - val_acc: 0.3182\n",
      "Epoch 129/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2422 - acc: 0.4444 - val_loss: 1.5014 - val_acc: 0.3697\n",
      "Epoch 130/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2422 - acc: 0.4557 - val_loss: 1.5229 - val_acc: 0.3848\n",
      "Epoch 131/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2949 - acc: 0.4352 - val_loss: 1.4397 - val_acc: 0.3788\n",
      "Epoch 132/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2751 - acc: 0.4539 - val_loss: 1.3917 - val_acc: 0.3727\n",
      "Epoch 133/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.3367 - acc: 0.4493 - val_loss: 1.5188 - val_acc: 0.3242\n",
      "Epoch 134/300\n",
      "2831/2831 [==============================] - 0s 98us/step - loss: 1.2467 - acc: 0.4366 - val_loss: 1.5445 - val_acc: 0.3303\n",
      "Epoch 135/300\n",
      "2831/2831 [==============================] - 0s 101us/step - loss: 1.2529 - acc: 0.4359 - val_loss: 1.4824 - val_acc: 0.3364\n",
      "Epoch 136/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2402 - acc: 0.4437 - val_loss: 1.3888 - val_acc: 0.3970\n",
      "Epoch 137/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3040 - acc: 0.4627 - val_loss: 1.4333 - val_acc: 0.3545\n",
      "Epoch 138/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.2955 - acc: 0.4571 - val_loss: 1.4147 - val_acc: 0.3697\n",
      "Epoch 139/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2729 - acc: 0.4631 - val_loss: 1.4888 - val_acc: 0.3364\n",
      "Epoch 140/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2148 - acc: 0.4525 - val_loss: 1.6665 - val_acc: 0.2879\n",
      "Epoch 141/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2965 - acc: 0.4161 - val_loss: 1.5751 - val_acc: 0.3242\n",
      "Epoch 142/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2411 - acc: 0.4451 - val_loss: 1.5990 - val_acc: 0.3364\n",
      "Epoch 143/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2538 - acc: 0.4398 - val_loss: 1.6016 - val_acc: 0.3121\n",
      "Epoch 144/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2602 - acc: 0.4518 - val_loss: 1.4687 - val_acc: 0.3242\n",
      "Epoch 145/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2234 - acc: 0.4585 - val_loss: 1.4235 - val_acc: 0.3424\n",
      "Epoch 146/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2209 - acc: 0.4588 - val_loss: 1.3782 - val_acc: 0.3697\n",
      "Epoch 147/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2770 - acc: 0.4437 - val_loss: 1.3988 - val_acc: 0.3939\n",
      "Epoch 148/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2466 - acc: 0.4709 - val_loss: 1.4156 - val_acc: 0.4182\n",
      "Epoch 149/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2533 - acc: 0.4666 - val_loss: 1.4138 - val_acc: 0.3545\n",
      "Epoch 150/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2167 - acc: 0.4666 - val_loss: 1.3997 - val_acc: 0.3970\n",
      "Epoch 151/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2555 - acc: 0.4518 - val_loss: 1.3821 - val_acc: 0.3818\n",
      "Epoch 152/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2452 - acc: 0.4659 - val_loss: 1.5087 - val_acc: 0.3606\n",
      "Epoch 153/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2279 - acc: 0.4592 - val_loss: 1.5749 - val_acc: 0.3303\n",
      "Epoch 154/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2628 - acc: 0.4603 - val_loss: 1.5025 - val_acc: 0.3394\n",
      "Epoch 155/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2030 - acc: 0.4634 - val_loss: 1.5851 - val_acc: 0.3091\n",
      "Epoch 156/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2383 - acc: 0.4405 - val_loss: 1.5915 - val_acc: 0.3182\n",
      "Epoch 157/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2288 - acc: 0.4479 - val_loss: 1.6003 - val_acc: 0.3121\n",
      "Epoch 158/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2149 - acc: 0.4415 - val_loss: 1.5160 - val_acc: 0.3364\n",
      "Epoch 159/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2131 - acc: 0.4553 - val_loss: 1.3987 - val_acc: 0.3667\n",
      "Epoch 160/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2441 - acc: 0.4426 - val_loss: 1.3787 - val_acc: 0.3848\n",
      "Epoch 161/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2225 - acc: 0.4588 - val_loss: 1.4308 - val_acc: 0.3970\n",
      "Epoch 162/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2175 - acc: 0.4631 - val_loss: 1.4407 - val_acc: 0.3970\n",
      "Epoch 163/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2313 - acc: 0.4638 - val_loss: 1.4227 - val_acc: 0.4000\n",
      "Epoch 164/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2072 - acc: 0.4613 - val_loss: 1.3954 - val_acc: 0.3970\n",
      "Epoch 165/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1919 - acc: 0.4747 - val_loss: 1.3659 - val_acc: 0.4000\n",
      "Epoch 166/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2632 - acc: 0.4553 - val_loss: 1.3731 - val_acc: 0.3485\n",
      "Epoch 167/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2586 - acc: 0.4479 - val_loss: 1.4490 - val_acc: 0.3697\n",
      "Epoch 168/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1741 - acc: 0.4836 - val_loss: 1.5920 - val_acc: 0.3182\n",
      "Epoch 169/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2308 - acc: 0.4504 - val_loss: 1.5823 - val_acc: 0.3333\n",
      "Epoch 170/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2080 - acc: 0.4504 - val_loss: 1.5063 - val_acc: 0.3515\n",
      "Epoch 171/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1736 - acc: 0.4557 - val_loss: 1.5492 - val_acc: 0.3758\n",
      "Epoch 172/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1942 - acc: 0.4483 - val_loss: 1.4960 - val_acc: 0.3879\n",
      "Epoch 173/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1650 - acc: 0.4836 - val_loss: 1.5912 - val_acc: 0.3273\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2247 - acc: 0.4419 - val_loss: 1.6025 - val_acc: 0.3333\n",
      "Epoch 175/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2150 - acc: 0.4525 - val_loss: 1.4953 - val_acc: 0.3576\n",
      "Epoch 176/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1714 - acc: 0.4673 - val_loss: 1.4970 - val_acc: 0.3818\n",
      "Epoch 177/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1814 - acc: 0.4673 - val_loss: 1.4884 - val_acc: 0.3636\n",
      "Epoch 178/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2303 - acc: 0.4641 - val_loss: 1.3936 - val_acc: 0.4061\n",
      "Epoch 179/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2018 - acc: 0.4659 - val_loss: 1.3503 - val_acc: 0.4030\n",
      "Epoch 180/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2049 - acc: 0.4769 - val_loss: 1.3631 - val_acc: 0.4212\n",
      "Epoch 181/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.1934 - acc: 0.4892 - val_loss: 1.3626 - val_acc: 0.4030\n",
      "Epoch 182/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1755 - acc: 0.4776 - val_loss: 1.3652 - val_acc: 0.4152\n",
      "Epoch 183/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1521 - acc: 0.4956 - val_loss: 1.4271 - val_acc: 0.3848\n",
      "Epoch 184/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2100 - acc: 0.4610 - val_loss: 1.4678 - val_acc: 0.3939\n",
      "Epoch 185/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2352 - acc: 0.4687 - val_loss: 1.4531 - val_acc: 0.3758\n",
      "Epoch 186/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1508 - acc: 0.4829 - val_loss: 1.4778 - val_acc: 0.3818\n",
      "Epoch 187/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1569 - acc: 0.4793 - val_loss: 1.6237 - val_acc: 0.3273\n",
      "Epoch 188/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2532 - acc: 0.4387 - val_loss: 1.5335 - val_acc: 0.3515\n",
      "Epoch 189/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2230 - acc: 0.4440 - val_loss: 1.4305 - val_acc: 0.4152\n",
      "Epoch 190/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1917 - acc: 0.4755 - val_loss: 1.5048 - val_acc: 0.3848\n",
      "Epoch 191/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1635 - acc: 0.4592 - val_loss: 1.5821 - val_acc: 0.3455\n",
      "Epoch 192/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2152 - acc: 0.4334 - val_loss: 1.5625 - val_acc: 0.3606\n",
      "Epoch 193/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2096 - acc: 0.4603 - val_loss: 1.5094 - val_acc: 0.3697\n",
      "Epoch 194/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1719 - acc: 0.4663 - val_loss: 1.5509 - val_acc: 0.3576\n",
      "Epoch 195/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1768 - acc: 0.4585 - val_loss: 1.5176 - val_acc: 0.3727\n",
      "Epoch 196/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1601 - acc: 0.4726 - val_loss: 1.4782 - val_acc: 0.4091\n",
      "Epoch 197/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1354 - acc: 0.4818 - val_loss: 1.5898 - val_acc: 0.3667\n",
      "Epoch 198/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2165 - acc: 0.4539 - val_loss: 1.5210 - val_acc: 0.3485\n",
      "Epoch 199/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1854 - acc: 0.4610 - val_loss: 1.4660 - val_acc: 0.3758\n",
      "Epoch 200/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1471 - acc: 0.4705 - val_loss: 1.5649 - val_acc: 0.3333\n",
      "Epoch 201/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1840 - acc: 0.4451 - val_loss: 1.4848 - val_acc: 0.4152\n",
      "Epoch 202/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1792 - acc: 0.4705 - val_loss: 1.4375 - val_acc: 0.4121\n",
      "Epoch 203/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2262 - acc: 0.4617 - val_loss: 1.3445 - val_acc: 0.3970\n",
      "Epoch 204/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1971 - acc: 0.4797 - val_loss: 1.3823 - val_acc: 0.3848\n",
      "Epoch 205/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1456 - acc: 0.4913 - val_loss: 1.4385 - val_acc: 0.3909\n",
      "Epoch 206/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1274 - acc: 0.4981 - val_loss: 1.5073 - val_acc: 0.3818\n",
      "Epoch 207/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1498 - acc: 0.4885 - val_loss: 1.5801 - val_acc: 0.3667\n",
      "Epoch 208/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2146 - acc: 0.4624 - val_loss: 1.5206 - val_acc: 0.3515\n",
      "Epoch 209/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1460 - acc: 0.4610 - val_loss: 1.5030 - val_acc: 0.3848\n",
      "Epoch 210/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1560 - acc: 0.4680 - val_loss: 1.5383 - val_acc: 0.3788\n",
      "Epoch 211/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1895 - acc: 0.4387 - val_loss: 1.4196 - val_acc: 0.4242\n",
      "Epoch 212/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1355 - acc: 0.4924 - val_loss: 1.4039 - val_acc: 0.4424\n",
      "Epoch 213/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1881 - acc: 0.4758 - val_loss: 1.3254 - val_acc: 0.4303\n",
      "Epoch 214/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2131 - acc: 0.4875 - val_loss: 1.3810 - val_acc: 0.3818\n",
      "Epoch 215/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1267 - acc: 0.4797 - val_loss: 1.3290 - val_acc: 0.4485\n",
      "Epoch 216/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1942 - acc: 0.4807 - val_loss: 1.3505 - val_acc: 0.4485\n",
      "Epoch 217/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1396 - acc: 0.5009 - val_loss: 1.3736 - val_acc: 0.4273\n",
      "Epoch 218/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1109 - acc: 0.5129 - val_loss: 1.4480 - val_acc: 0.4212\n",
      "Epoch 219/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1410 - acc: 0.4942 - val_loss: 1.5319 - val_acc: 0.3818\n",
      "Epoch 220/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1922 - acc: 0.4447 - val_loss: 1.4062 - val_acc: 0.4364\n",
      "Epoch 221/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1585 - acc: 0.4921 - val_loss: 1.3454 - val_acc: 0.4333\n",
      "Epoch 222/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1878 - acc: 0.4850 - val_loss: 1.3243 - val_acc: 0.4091\n",
      "Epoch 223/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1622 - acc: 0.4875 - val_loss: 1.3344 - val_acc: 0.4182\n",
      "Epoch 224/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1539 - acc: 0.4984 - val_loss: 1.3369 - val_acc: 0.4515\n",
      "Epoch 225/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1642 - acc: 0.4970 - val_loss: 1.3623 - val_acc: 0.3939\n",
      "Epoch 226/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1387 - acc: 0.4882 - val_loss: 1.3293 - val_acc: 0.4576\n",
      "Epoch 227/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1314 - acc: 0.4966 - val_loss: 1.3240 - val_acc: 0.4333\n",
      "Epoch 228/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1599 - acc: 0.4882 - val_loss: 1.3543 - val_acc: 0.3818\n",
      "Epoch 229/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1202 - acc: 0.5009 - val_loss: 1.4025 - val_acc: 0.4455\n",
      "Epoch 230/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0919 - acc: 0.5065 - val_loss: 1.4208 - val_acc: 0.4273\n",
      "Epoch 231/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2347 - acc: 0.4691 - val_loss: 1.4656 - val_acc: 0.4091\n",
      "Epoch 232/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.1633 - acc: 0.4885 - val_loss: 1.5036 - val_acc: 0.3424\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1408 - acc: 0.4719 - val_loss: 1.5287 - val_acc: 0.3545\n",
      "Epoch 234/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1370 - acc: 0.4624 - val_loss: 1.4737 - val_acc: 0.3939\n",
      "Epoch 235/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1232 - acc: 0.4984 - val_loss: 1.5074 - val_acc: 0.3788\n",
      "Epoch 236/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1354 - acc: 0.4913 - val_loss: 1.5269 - val_acc: 0.3545\n",
      "Epoch 237/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1566 - acc: 0.4716 - val_loss: 1.5157 - val_acc: 0.3788\n",
      "Epoch 238/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1189 - acc: 0.4942 - val_loss: 1.3762 - val_acc: 0.4333\n",
      "Epoch 239/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.0787 - acc: 0.5214 - val_loss: 1.3959 - val_acc: 0.4182\n",
      "Epoch 240/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1363 - acc: 0.4839 - val_loss: 1.3550 - val_acc: 0.4455\n",
      "Epoch 241/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1662 - acc: 0.4758 - val_loss: 1.3144 - val_acc: 0.4636\n",
      "Epoch 242/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1203 - acc: 0.5094 - val_loss: 1.3183 - val_acc: 0.4576\n",
      "Epoch 243/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1641 - acc: 0.5076 - val_loss: 1.3361 - val_acc: 0.3909\n",
      "Epoch 244/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.1398 - acc: 0.496 - 0s 71us/step - loss: 1.1275 - acc: 0.4924 - val_loss: 1.3379 - val_acc: 0.4424\n",
      "Epoch 245/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.0905 - acc: 0.5094 - val_loss: 1.3226 - val_acc: 0.4545\n",
      "Epoch 246/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1119 - acc: 0.5136 - val_loss: 1.3271 - val_acc: 0.4606\n",
      "Epoch 247/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1211 - acc: 0.4995 - val_loss: 1.3199 - val_acc: 0.4333\n",
      "Epoch 248/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1759 - acc: 0.5090 - val_loss: 1.4060 - val_acc: 0.4455\n",
      "Epoch 249/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1237 - acc: 0.5101 - val_loss: 1.5761 - val_acc: 0.3515\n",
      "Epoch 250/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1669 - acc: 0.4440 - val_loss: 1.3618 - val_acc: 0.4576\n",
      "Epoch 251/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1355 - acc: 0.5178 - val_loss: 1.3142 - val_acc: 0.4515\n",
      "Epoch 252/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1661 - acc: 0.5140 - val_loss: 1.3452 - val_acc: 0.4273\n",
      "Epoch 253/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0851 - acc: 0.5185 - val_loss: 1.3547 - val_acc: 0.4515\n",
      "Epoch 254/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.0675 - acc: 0.5235 - val_loss: 1.3551 - val_acc: 0.4364\n",
      "Epoch 255/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.0612 - acc: 0.5242 - val_loss: 1.3456 - val_acc: 0.4667\n",
      "Epoch 256/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0856 - acc: 0.5019 - val_loss: 1.2894 - val_acc: 0.4848\n",
      "Epoch 257/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2039 - acc: 0.4839 - val_loss: 1.3514 - val_acc: 0.4455\n",
      "Epoch 258/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0831 - acc: 0.5341 - val_loss: 1.4334 - val_acc: 0.4030\n",
      "Epoch 259/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1142 - acc: 0.5083 - val_loss: 1.5700 - val_acc: 0.3818\n",
      "Epoch 260/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.1883 - acc: 0.4673 - val_loss: 1.3593 - val_acc: 0.3970\n",
      "Epoch 261/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1597 - acc: 0.4716 - val_loss: 1.3119 - val_acc: 0.4485\n",
      "Epoch 262/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1959 - acc: 0.4889 - val_loss: 1.3629 - val_acc: 0.4515\n",
      "Epoch 263/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0771 - acc: 0.5185 - val_loss: 1.3959 - val_acc: 0.4333\n",
      "Epoch 264/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0527 - acc: 0.5175 - val_loss: 1.5425 - val_acc: 0.3667\n",
      "Epoch 265/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1354 - acc: 0.4733 - val_loss: 1.4397 - val_acc: 0.4394\n",
      "Epoch 266/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0785 - acc: 0.5097 - val_loss: 1.3838 - val_acc: 0.4515\n",
      "Epoch 267/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0639 - acc: 0.5185 - val_loss: 1.3852 - val_acc: 0.4364\n",
      "Epoch 268/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0915 - acc: 0.5323 - val_loss: 1.3379 - val_acc: 0.4364\n",
      "Epoch 269/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1694 - acc: 0.5164 - val_loss: 1.3555 - val_acc: 0.4182\n",
      "Epoch 270/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1017 - acc: 0.5115 - val_loss: 1.3380 - val_acc: 0.4545\n",
      "Epoch 271/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0932 - acc: 0.5094 - val_loss: 1.3190 - val_acc: 0.4121\n",
      "Epoch 272/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1289 - acc: 0.5122 - val_loss: 1.3506 - val_acc: 0.4545\n",
      "Epoch 273/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.0486 - acc: 0.5221 - val_loss: 1.3356 - val_acc: 0.4333\n",
      "Epoch 274/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1200 - acc: 0.4836 - val_loss: 1.3889 - val_acc: 0.4333\n",
      "Epoch 275/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1102 - acc: 0.5083 - val_loss: 1.5422 - val_acc: 0.3939\n",
      "Epoch 276/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1660 - acc: 0.4564 - val_loss: 1.4425 - val_acc: 0.3970\n",
      "Epoch 277/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0702 - acc: 0.5090 - val_loss: 1.4911 - val_acc: 0.4000\n",
      "Epoch 278/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0879 - acc: 0.4956 - val_loss: 1.5099 - val_acc: 0.3879\n",
      "Epoch 279/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0960 - acc: 0.4733 - val_loss: 1.4165 - val_acc: 0.4061\n",
      "Epoch 280/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.0496 - acc: 0.5150 - val_loss: 1.4366 - val_acc: 0.4333\n",
      "Epoch 281/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0564 - acc: 0.5154 - val_loss: 1.5501 - val_acc: 0.3909\n",
      "Epoch 282/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1229 - acc: 0.4574 - val_loss: 1.4365 - val_acc: 0.4303\n",
      "Epoch 283/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1032 - acc: 0.5044 - val_loss: 1.4099 - val_acc: 0.4303\n",
      "Epoch 284/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1031 - acc: 0.5189 - val_loss: 1.4357 - val_acc: 0.4303\n",
      "Epoch 285/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.0783 - acc: 0.4956 - val_loss: 1.3824 - val_acc: 0.4394\n",
      "Epoch 286/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1206 - acc: 0.5030 - val_loss: 1.3217 - val_acc: 0.4364\n",
      "Epoch 287/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1877 - acc: 0.5009 - val_loss: 1.3752 - val_acc: 0.4091\n",
      "Epoch 288/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.0705 - acc: 0.5065 - val_loss: 1.4516 - val_acc: 0.4030\n",
      "Epoch 289/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.0694 - acc: 0.5101 - val_loss: 1.4702 - val_acc: 0.3970\n",
      "Epoch 290/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.0912 - acc: 0.4984 - val_loss: 1.5312 - val_acc: 0.3758\n",
      "Epoch 291/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1506 - acc: 0.4617 - val_loss: 1.4351 - val_acc: 0.3909\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0464 - acc: 0.5111 - val_loss: 1.3713 - val_acc: 0.4455\n",
      "Epoch 293/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.0189 - acc: 0.527 - 0s 70us/step - loss: 1.0318 - acc: 0.5274 - val_loss: 1.3854 - val_acc: 0.4030\n",
      "Epoch 294/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0706 - acc: 0.5101 - val_loss: 1.4138 - val_acc: 0.4303\n",
      "Epoch 295/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.0912 - acc: 0.5076 - val_loss: 1.3791 - val_acc: 0.4212\n",
      "Epoch 296/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.0505 - acc: 0.5118 - val_loss: 1.3088 - val_acc: 0.4576\n",
      "Epoch 297/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1208 - acc: 0.4942 - val_loss: 1.3470 - val_acc: 0.4455\n",
      "Epoch 298/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1388 - acc: 0.5108 - val_loss: 1.3758 - val_acc: 0.4424\n",
      "Epoch 299/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.0746 - acc: 0.5231 - val_loss: 1.3229 - val_acc: 0.4152\n",
      "Epoch 300/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1628 - acc: 0.5111 - val_loss: 1.3487 - val_acc: 0.4606\n",
      "1\n",
      "Train on 2831 samples, validate on 330 samples\n",
      "Epoch 1/300\n",
      "2831/2831 [==============================] - 17s 6ms/step - loss: 2.6159 - acc: 0.2695 - val_loss: 2.5367 - val_acc: 0.0667\n",
      "Epoch 2/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 2.3577 - acc: 0.2307 - val_loss: 2.2788 - val_acc: 0.4121\n",
      "Epoch 3/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 2.2442 - acc: 0.3151 - val_loss: 2.2543 - val_acc: 0.3273\n",
      "Epoch 4/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 2.2029 - acc: 0.3384 - val_loss: 2.2218 - val_acc: 0.3273\n",
      "Epoch 5/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 2.1522 - acc: 0.3522 - val_loss: 2.2359 - val_acc: 0.3212\n",
      "Epoch 6/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 2.1537 - acc: 0.3490 - val_loss: 2.2485 - val_acc: 0.3182\n",
      "Epoch 7/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 2.1264 - acc: 0.3384 - val_loss: 2.1158 - val_acc: 0.3273\n",
      "Epoch 8/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 2.0964 - acc: 0.3638 - val_loss: 2.1203 - val_acc: 0.3273\n",
      "Epoch 9/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 2.0676 - acc: 0.3734 - val_loss: 2.0864 - val_acc: 0.3303\n",
      "Epoch 10/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 2.0350 - acc: 0.3691 - val_loss: 2.1566 - val_acc: 0.3212\n",
      "Epoch 11/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 2.0146 - acc: 0.3536 - val_loss: 2.0946 - val_acc: 0.3303\n",
      "Epoch 12/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.9961 - acc: 0.3614 - val_loss: 2.0700 - val_acc: 0.3303\n",
      "Epoch 13/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.9751 - acc: 0.3723 - val_loss: 2.1388 - val_acc: 0.3121\n",
      "Epoch 14/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.9658 - acc: 0.3550 - val_loss: 2.1836 - val_acc: 0.3182\n",
      "Epoch 15/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.9496 - acc: 0.3448 - val_loss: 2.0328 - val_acc: 0.3273\n",
      "Epoch 16/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.9344 - acc: 0.3773 - val_loss: 1.9759 - val_acc: 0.3273\n",
      "Epoch 17/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.8983 - acc: 0.3903 - val_loss: 1.9743 - val_acc: 0.3242\n",
      "Epoch 18/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.8639 - acc: 0.3804 - val_loss: 1.9084 - val_acc: 0.3273\n",
      "Epoch 19/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.9199 - acc: 0.3674 - val_loss: 1.9892 - val_acc: 0.3273\n",
      "Epoch 20/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.8724 - acc: 0.3815 - val_loss: 1.9739 - val_acc: 0.3273\n",
      "Epoch 21/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.8352 - acc: 0.3797 - val_loss: 1.9546 - val_acc: 0.3121\n",
      "Epoch 22/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.8228 - acc: 0.3688 - val_loss: 2.0151 - val_acc: 0.3061\n",
      "Epoch 23/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.8239 - acc: 0.3578 - val_loss: 1.9742 - val_acc: 0.3182\n",
      "Epoch 24/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.7991 - acc: 0.3649 - val_loss: 2.0158 - val_acc: 0.3061\n",
      "Epoch 25/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.7927 - acc: 0.3599 - val_loss: 1.8930 - val_acc: 0.3242\n",
      "Epoch 26/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.7702 - acc: 0.3751 - val_loss: 1.8613 - val_acc: 0.3152\n",
      "Epoch 27/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.7345 - acc: 0.3960 - val_loss: 1.9927 - val_acc: 0.2364\n",
      "Epoch 28/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8006 - acc: 0.3437 - val_loss: 1.9484 - val_acc: 0.3182\n",
      "Epoch 29/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.7595 - acc: 0.3709 - val_loss: 1.8706 - val_acc: 0.3212\n",
      "Epoch 30/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.6909 - acc: 0.3871 - val_loss: 1.8070 - val_acc: 0.3182\n",
      "Epoch 31/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.6892 - acc: 0.3956 - val_loss: 1.8450 - val_acc: 0.3121\n",
      "Epoch 32/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.7068 - acc: 0.3917 - val_loss: 1.8655 - val_acc: 0.3182\n",
      "Epoch 33/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6912 - acc: 0.3808 - val_loss: 1.8382 - val_acc: 0.3212\n",
      "Epoch 34/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6561 - acc: 0.3907 - val_loss: 2.0013 - val_acc: 0.2364\n",
      "Epoch 35/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.6860 - acc: 0.3568 - val_loss: 1.8560 - val_acc: 0.3273\n",
      "Epoch 36/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.6547 - acc: 0.3928 - val_loss: 1.8774 - val_acc: 0.2939\n",
      "Epoch 37/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.6612 - acc: 0.3667 - val_loss: 1.9129 - val_acc: 0.3030\n",
      "Epoch 38/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.6248 - acc: 0.3751 - val_loss: 1.7740 - val_acc: 0.3212\n",
      "Epoch 39/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.6056 - acc: 0.3984 - val_loss: 1.6985 - val_acc: 0.3273\n",
      "Epoch 40/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.6397 - acc: 0.4013 - val_loss: 1.6693 - val_acc: 0.3273\n",
      "Epoch 41/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6688 - acc: 0.4052 - val_loss: 1.8115 - val_acc: 0.3212\n",
      "Epoch 42/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.5895 - acc: 0.3931 - val_loss: 1.8177 - val_acc: 0.2970\n",
      "Epoch 43/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5779 - acc: 0.3984 - val_loss: 1.8596 - val_acc: 0.2879\n",
      "Epoch 44/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5770 - acc: 0.3921 - val_loss: 1.8337 - val_acc: 0.2970\n",
      "Epoch 45/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.6040 - acc: 0.3773 - val_loss: 1.8573 - val_acc: 0.3000\n",
      "Epoch 46/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.5844 - acc: 0.3808 - val_loss: 1.7668 - val_acc: 0.3030\n",
      "Epoch 47/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5817 - acc: 0.3931 - val_loss: 1.9345 - val_acc: 0.2485\n",
      "Epoch 48/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5976 - acc: 0.3497 - val_loss: 1.7582 - val_acc: 0.3182\n",
      "Epoch 49/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5419 - acc: 0.4041 - val_loss: 1.7224 - val_acc: 0.3152\n",
      "Epoch 50/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.5373 - acc: 0.3967 - val_loss: 1.8145 - val_acc: 0.2636\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.5541 - acc: 0.3822 - val_loss: 1.8180 - val_acc: 0.2848\n",
      "Epoch 52/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5450 - acc: 0.3868 - val_loss: 1.8687 - val_acc: 0.2848\n",
      "Epoch 53/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5454 - acc: 0.3645 - val_loss: 1.7248 - val_acc: 0.3212\n",
      "Epoch 54/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4954 - acc: 0.3864 - val_loss: 1.7956 - val_acc: 0.2909\n",
      "Epoch 55/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.4954 - acc: 0.3946 - val_loss: 1.8726 - val_acc: 0.2606\n",
      "Epoch 56/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.5645 - acc: 0.3642 - val_loss: 1.7560 - val_acc: 0.3182\n",
      "Epoch 57/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5248 - acc: 0.3921 - val_loss: 1.6768 - val_acc: 0.3152\n",
      "Epoch 58/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5027 - acc: 0.4052 - val_loss: 1.7290 - val_acc: 0.2909\n",
      "Epoch 59/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.4821 - acc: 0.3921 - val_loss: 1.6569 - val_acc: 0.3091\n",
      "Epoch 60/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.4641 - acc: 0.4087 - val_loss: 1.6018 - val_acc: 0.3152\n",
      "Epoch 61/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.5022 - acc: 0.4020 - val_loss: 1.6060 - val_acc: 0.3273\n",
      "Epoch 62/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.5519 - acc: 0.4161 - val_loss: 1.7623 - val_acc: 0.3121\n",
      "Epoch 63/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.4753 - acc: 0.3999 - val_loss: 1.8198 - val_acc: 0.2879\n",
      "Epoch 64/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.5021 - acc: 0.3702 - val_loss: 1.6950 - val_acc: 0.3061\n",
      "Epoch 65/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.4405 - acc: 0.4076 - val_loss: 1.7418 - val_acc: 0.2879\n",
      "Epoch 66/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4599 - acc: 0.3854 - val_loss: 1.8335 - val_acc: 0.2848\n",
      "Epoch 67/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.4621 - acc: 0.3886 - val_loss: 1.6617 - val_acc: 0.3091\n",
      "Epoch 68/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.4330 - acc: 0.4073 - val_loss: 1.6147 - val_acc: 0.3091\n",
      "Epoch 69/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.4330 - acc: 0.4147 - val_loss: 1.6379 - val_acc: 0.3152\n",
      "Epoch 70/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.4549 - acc: 0.4218 - val_loss: 1.6921 - val_acc: 0.2758\n",
      "Epoch 71/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.4326 - acc: 0.3988 - val_loss: 1.7064 - val_acc: 0.2879\n",
      "Epoch 72/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.4056 - acc: 0.401 - 0s 69us/step - loss: 1.4147 - acc: 0.4080 - val_loss: 1.8697 - val_acc: 0.2303\n",
      "Epoch 73/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.4900 - acc: 0.3610 - val_loss: 1.6751 - val_acc: 0.3121\n",
      "Epoch 74/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4223 - acc: 0.3981 - val_loss: 1.7515 - val_acc: 0.2879\n",
      "Epoch 75/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.4299 - acc: 0.3910 - val_loss: 1.7272 - val_acc: 0.3030\n",
      "Epoch 76/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4138 - acc: 0.3970 - val_loss: 1.7694 - val_acc: 0.2727\n",
      "Epoch 77/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4451 - acc: 0.3741 - val_loss: 1.7446 - val_acc: 0.2909\n",
      "Epoch 78/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4679 - acc: 0.3674 - val_loss: 1.6128 - val_acc: 0.3121\n",
      "Epoch 79/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3997 - acc: 0.4221 - val_loss: 1.6819 - val_acc: 0.2848\n",
      "Epoch 80/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3872 - acc: 0.3988 - val_loss: 1.7778 - val_acc: 0.2879\n",
      "Epoch 81/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.4159 - acc: 0.3815 - val_loss: 1.6770 - val_acc: 0.3182\n",
      "Epoch 82/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3847 - acc: 0.4059 - val_loss: 1.5790 - val_acc: 0.3091\n",
      "Epoch 83/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3707 - acc: 0.4165 - val_loss: 1.5192 - val_acc: 0.3242\n",
      "Epoch 84/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4262 - acc: 0.4087 - val_loss: 1.5935 - val_acc: 0.3152\n",
      "Epoch 85/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3855 - acc: 0.4186 - val_loss: 1.6136 - val_acc: 0.3121\n",
      "Epoch 86/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3455 - acc: 0.4225 - val_loss: 1.6121 - val_acc: 0.3121\n",
      "Epoch 87/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3395 - acc: 0.4186 - val_loss: 1.7932 - val_acc: 0.3061\n",
      "Epoch 88/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4306 - acc: 0.4034 - val_loss: 1.6058 - val_acc: 0.3000\n",
      "Epoch 89/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3693 - acc: 0.4122 - val_loss: 1.5656 - val_acc: 0.3091\n",
      "Epoch 90/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.3897 - acc: 0.4218 - val_loss: 1.5182 - val_acc: 0.3273\n",
      "Epoch 91/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3987 - acc: 0.4228 - val_loss: 1.5440 - val_acc: 0.3242\n",
      "Epoch 92/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.4022 - acc: 0.4094 - val_loss: 1.5434 - val_acc: 0.3242\n",
      "Epoch 93/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3648 - acc: 0.4260 - val_loss: 1.5244 - val_acc: 0.3273\n",
      "Epoch 94/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3781 - acc: 0.4182 - val_loss: 1.5537 - val_acc: 0.3121\n",
      "Epoch 95/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.3471 - acc: 0.4158 - val_loss: 1.4795 - val_acc: 0.3242\n",
      "Epoch 96/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4096 - acc: 0.4108 - val_loss: 1.5587 - val_acc: 0.3273\n",
      "Epoch 97/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3701 - acc: 0.4189 - val_loss: 1.6801 - val_acc: 0.3061\n",
      "Epoch 98/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3440 - acc: 0.4136 - val_loss: 1.6909 - val_acc: 0.3000\n",
      "Epoch 99/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3515 - acc: 0.4179 - val_loss: 1.8448 - val_acc: 0.2545\n",
      "Epoch 100/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.4022 - acc: 0.3624 - val_loss: 1.5835 - val_acc: 0.3212\n",
      "Epoch 101/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3223 - acc: 0.4221 - val_loss: 1.6052 - val_acc: 0.2970\n",
      "Epoch 102/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3221 - acc: 0.4002 - val_loss: 1.5329 - val_acc: 0.3333\n",
      "Epoch 103/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3355 - acc: 0.4126 - val_loss: 1.5485 - val_acc: 0.3212\n",
      "Epoch 104/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.3245 - acc: 0.4182 - val_loss: 1.5187 - val_acc: 0.3303\n",
      "Epoch 105/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.3401 - acc: 0.4034 - val_loss: 1.4777 - val_acc: 0.3333\n",
      "Epoch 106/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.5192 - acc: 0.4256 - val_loss: 1.6671 - val_acc: 0.3152\n",
      "Epoch 107/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.3383 - acc: 0.4221 - val_loss: 1.5972 - val_acc: 0.3273\n",
      "Epoch 108/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2984 - acc: 0.4334 - val_loss: 1.5984 - val_acc: 0.3242\n",
      "Epoch 109/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.3069 - acc: 0.4218 - val_loss: 1.6450 - val_acc: 0.3152\n",
      "Epoch 110/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.3101 - acc: 0.4232 - val_loss: 1.6152 - val_acc: 0.3121\n",
      "Epoch 111/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2881 - acc: 0.4228 - val_loss: 1.6977 - val_acc: 0.2970\n",
      "Epoch 112/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3578 - acc: 0.4097 - val_loss: 1.6923 - val_acc: 0.2879\n",
      "Epoch 113/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3457 - acc: 0.3864 - val_loss: 1.5906 - val_acc: 0.3152\n",
      "Epoch 114/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2731 - acc: 0.4292 - val_loss: 1.6879 - val_acc: 0.2818\n",
      "Epoch 115/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.3498 - acc: 0.3942 - val_loss: 1.6270 - val_acc: 0.3333\n",
      "Epoch 116/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3056 - acc: 0.4154 - val_loss: 1.5099 - val_acc: 0.3333\n",
      "Epoch 117/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2830 - acc: 0.4306 - val_loss: 1.5763 - val_acc: 0.3515\n",
      "Epoch 118/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3189 - acc: 0.4196 - val_loss: 1.5022 - val_acc: 0.3242\n",
      "Epoch 119/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.3001 - acc: 0.4253 - val_loss: 1.4431 - val_acc: 0.3394\n",
      "Epoch 120/300\n",
      "2831/2831 [==============================] - 0s 104us/step - loss: 1.4274 - acc: 0.4324 - val_loss: 1.6461 - val_acc: 0.3152\n",
      "Epoch 121/300\n",
      "2831/2831 [==============================] - 0s 93us/step - loss: 1.3081 - acc: 0.4285 - val_loss: 1.6019 - val_acc: 0.3242\n",
      "Epoch 122/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2731 - acc: 0.4225 - val_loss: 1.5772 - val_acc: 0.3182\n",
      "Epoch 123/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2783 - acc: 0.4264 - val_loss: 1.5220 - val_acc: 0.3303\n",
      "Epoch 124/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2955 - acc: 0.4126 - val_loss: 1.4405 - val_acc: 0.3424\n",
      "Epoch 125/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.3247 - acc: 0.4320 - val_loss: 1.4740 - val_acc: 0.3636\n",
      "Epoch 126/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3210 - acc: 0.4419 - val_loss: 1.4449 - val_acc: 0.3394\n",
      "Epoch 127/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.3033 - acc: 0.4341 - val_loss: 1.4554 - val_acc: 0.3455\n",
      "Epoch 128/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.2812 - acc: 0.4278 - val_loss: 1.4168 - val_acc: 0.3424\n",
      "Epoch 129/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3411 - acc: 0.4309 - val_loss: 1.5913 - val_acc: 0.3333\n",
      "Epoch 130/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2605 - acc: 0.4405 - val_loss: 1.5669 - val_acc: 0.3212\n",
      "Epoch 131/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2729 - acc: 0.4278 - val_loss: 1.4934 - val_acc: 0.3424\n",
      "Epoch 132/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3070 - acc: 0.4129 - val_loss: 1.4246 - val_acc: 0.3515\n",
      "Epoch 133/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3206 - acc: 0.4412 - val_loss: 1.4860 - val_acc: 0.3727\n",
      "Epoch 134/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2472 - acc: 0.4398 - val_loss: 1.4904 - val_acc: 0.3818\n",
      "Epoch 135/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2719 - acc: 0.4437 - val_loss: 1.6685 - val_acc: 0.2606\n",
      "Epoch 136/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.3220 - acc: 0.3889 - val_loss: 1.6542 - val_acc: 0.3273\n",
      "Epoch 137/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.2780 - acc: 0.4161 - val_loss: 1.4995 - val_acc: 0.3606\n",
      "Epoch 138/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2150 - acc: 0.4521 - val_loss: 1.4254 - val_acc: 0.3697\n",
      "Epoch 139/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2619 - acc: 0.4465 - val_loss: 1.4172 - val_acc: 0.3667\n",
      "Epoch 140/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2825 - acc: 0.4369 - val_loss: 1.4567 - val_acc: 0.3515\n",
      "Epoch 141/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.2394 - acc: 0.4444 - val_loss: 1.4126 - val_acc: 0.3848\n",
      "Epoch 142/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.3225 - acc: 0.4324 - val_loss: 1.4705 - val_acc: 0.3455\n",
      "Epoch 143/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.2947 - acc: 0.4355 - val_loss: 1.6503 - val_acc: 0.3303\n",
      "Epoch 144/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2410 - acc: 0.4394 - val_loss: 1.6404 - val_acc: 0.3182\n",
      "Epoch 145/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2508 - acc: 0.4278 - val_loss: 1.6607 - val_acc: 0.3091\n",
      "Epoch 146/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2829 - acc: 0.4168 - val_loss: 1.5700 - val_acc: 0.3364\n",
      "Epoch 147/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2280 - acc: 0.4362 - val_loss: 1.5503 - val_acc: 0.3424\n",
      "Epoch 148/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2142 - acc: 0.4419 - val_loss: 1.7128 - val_acc: 0.2818\n",
      "Epoch 149/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2731 - acc: 0.4055 - val_loss: 1.5751 - val_acc: 0.3485\n",
      "Epoch 150/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2348 - acc: 0.4316 - val_loss: 1.4862 - val_acc: 0.3788\n",
      "Epoch 151/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2586 - acc: 0.4493 - val_loss: 1.5833 - val_acc: 0.3576\n",
      "Epoch 152/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2963 - acc: 0.4267 - val_loss: 1.5578 - val_acc: 0.3212\n",
      "Epoch 153/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2146 - acc: 0.4359 - val_loss: 1.6519 - val_acc: 0.3242\n",
      "Epoch 154/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2705 - acc: 0.4108 - val_loss: 1.5865 - val_acc: 0.3455\n",
      "Epoch 155/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2317 - acc: 0.4331 - val_loss: 1.4817 - val_acc: 0.3697\n",
      "Epoch 156/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1961 - acc: 0.4518 - val_loss: 1.4882 - val_acc: 0.3879\n",
      "Epoch 157/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2324 - acc: 0.4585 - val_loss: 1.4215 - val_acc: 0.3970\n",
      "Epoch 158/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2816 - acc: 0.4465 - val_loss: 1.4048 - val_acc: 0.3667\n",
      "Epoch 159/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2680 - acc: 0.4359 - val_loss: 1.4096 - val_acc: 0.3727\n",
      "Epoch 160/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2498 - acc: 0.4497 - val_loss: 1.4908 - val_acc: 0.3818\n",
      "Epoch 161/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2404 - acc: 0.4447 - val_loss: 1.4767 - val_acc: 0.3939\n",
      "Epoch 162/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2462 - acc: 0.4486 - val_loss: 1.4085 - val_acc: 0.3667\n",
      "Epoch 163/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2242 - acc: 0.4525 - val_loss: 1.3777 - val_acc: 0.3758\n",
      "Epoch 164/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.3025 - acc: 0.4560 - val_loss: 1.5645 - val_acc: 0.3424\n",
      "Epoch 165/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2087 - acc: 0.4532 - val_loss: 1.5712 - val_acc: 0.3424\n",
      "Epoch 166/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2111 - acc: 0.4426 - val_loss: 1.5651 - val_acc: 0.3364\n",
      "Epoch 167/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1792 - acc: 0.4564 - val_loss: 1.5799 - val_acc: 0.3242\n",
      "Epoch 168/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1872 - acc: 0.4532 - val_loss: 1.6119 - val_acc: 0.3242\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2485 - acc: 0.4235 - val_loss: 1.5809 - val_acc: 0.3758\n",
      "Epoch 170/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2334 - acc: 0.4366 - val_loss: 1.4436 - val_acc: 0.3939\n",
      "Epoch 171/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.1925 - acc: 0.4585 - val_loss: 1.4081 - val_acc: 0.3697\n",
      "Epoch 172/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1997 - acc: 0.4564 - val_loss: 1.3794 - val_acc: 0.3758\n",
      "Epoch 173/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2932 - acc: 0.4433 - val_loss: 1.4794 - val_acc: 0.3697\n",
      "Epoch 174/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.2045 - acc: 0.4444 - val_loss: 1.4844 - val_acc: 0.3485\n",
      "Epoch 175/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2281 - acc: 0.4511 - val_loss: 1.4892 - val_acc: 0.3697\n",
      "Epoch 176/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1703 - acc: 0.4673 - val_loss: 1.6741 - val_acc: 0.3212\n",
      "Epoch 177/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2565 - acc: 0.4306 - val_loss: 1.5422 - val_acc: 0.3545\n",
      "Epoch 178/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1868 - acc: 0.4447 - val_loss: 1.5192 - val_acc: 0.3485\n",
      "Epoch 179/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1754 - acc: 0.4493 - val_loss: 1.6064 - val_acc: 0.3576\n",
      "Epoch 180/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2017 - acc: 0.4288 - val_loss: 1.5990 - val_acc: 0.3485\n",
      "Epoch 181/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2234 - acc: 0.4295 - val_loss: 1.5431 - val_acc: 0.3727\n",
      "Epoch 182/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1922 - acc: 0.4405 - val_loss: 1.5433 - val_acc: 0.3727\n",
      "Epoch 183/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1907 - acc: 0.4387 - val_loss: 1.5439 - val_acc: 0.3818\n",
      "Epoch 184/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1927 - acc: 0.4447 - val_loss: 1.5085 - val_acc: 0.4242\n",
      "Epoch 185/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2378 - acc: 0.4532 - val_loss: 1.4043 - val_acc: 0.4152\n",
      "Epoch 186/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2399 - acc: 0.4634 - val_loss: 1.3962 - val_acc: 0.3909\n",
      "Epoch 187/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1626 - acc: 0.4673 - val_loss: 1.3593 - val_acc: 0.4152\n",
      "Epoch 188/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2186 - acc: 0.4581 - val_loss: 1.3889 - val_acc: 0.4091\n",
      "Epoch 189/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1738 - acc: 0.4740 - val_loss: 1.4055 - val_acc: 0.3818\n",
      "Epoch 190/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1920 - acc: 0.4606 - val_loss: 1.5241 - val_acc: 0.3788\n",
      "Epoch 191/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1998 - acc: 0.4528 - val_loss: 1.5415 - val_acc: 0.3667\n",
      "Epoch 192/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1920 - acc: 0.4528 - val_loss: 1.5721 - val_acc: 0.3485\n",
      "Epoch 193/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1781 - acc: 0.4500 - val_loss: 1.5632 - val_acc: 0.3515\n",
      "Epoch 194/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1797 - acc: 0.4373 - val_loss: 1.5856 - val_acc: 0.3545\n",
      "Epoch 195/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1903 - acc: 0.4331 - val_loss: 1.5223 - val_acc: 0.3909\n",
      "Epoch 196/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1705 - acc: 0.4493 - val_loss: 1.4730 - val_acc: 0.4121\n",
      "Epoch 197/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1777 - acc: 0.4588 - val_loss: 1.6162 - val_acc: 0.3455\n",
      "Epoch 198/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1947 - acc: 0.4369 - val_loss: 1.5419 - val_acc: 0.3848\n",
      "Epoch 199/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1699 - acc: 0.4712 - val_loss: 1.5674 - val_acc: 0.3576\n",
      "Epoch 200/300\n",
      "2831/2831 [==============================] - 0s 96us/step - loss: 1.1816 - acc: 0.4543 - val_loss: 1.5145 - val_acc: 0.3667\n",
      "Epoch 201/300\n",
      "2831/2831 [==============================] - 0s 95us/step - loss: 1.1550 - acc: 0.4592 - val_loss: 1.5040 - val_acc: 0.3848\n",
      "Epoch 202/300\n",
      "2831/2831 [==============================] - 0s 96us/step - loss: 1.1385 - acc: 0.4663 - val_loss: 1.6243 - val_acc: 0.3515\n",
      "Epoch 203/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2282 - acc: 0.4150 - val_loss: 1.4976 - val_acc: 0.3727\n",
      "Epoch 204/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1824 - acc: 0.4733 - val_loss: 1.4876 - val_acc: 0.4242\n",
      "Epoch 205/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2233 - acc: 0.4359 - val_loss: 1.3634 - val_acc: 0.4000\n",
      "Epoch 206/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2339 - acc: 0.4687 - val_loss: 1.3939 - val_acc: 0.3848\n",
      "Epoch 207/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1436 - acc: 0.4836 - val_loss: 1.3832 - val_acc: 0.4061\n",
      "Epoch 208/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1455 - acc: 0.4730 - val_loss: 1.3456 - val_acc: 0.4152\n",
      "Epoch 209/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1609 - acc: 0.4793 - val_loss: 1.3800 - val_acc: 0.4091\n",
      "Epoch 210/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1666 - acc: 0.4737 - val_loss: 1.4952 - val_acc: 0.3788\n",
      "Epoch 211/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1627 - acc: 0.4769 - val_loss: 1.5237 - val_acc: 0.3939\n",
      "Epoch 212/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1515 - acc: 0.4694 - val_loss: 1.5542 - val_acc: 0.3636\n",
      "Epoch 213/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1548 - acc: 0.4684 - val_loss: 1.5055 - val_acc: 0.3909\n",
      "Epoch 214/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1263 - acc: 0.4751 - val_loss: 1.6089 - val_acc: 0.3667\n",
      "Epoch 215/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.1872 - acc: 0.4437 - val_loss: 1.4958 - val_acc: 0.3818\n",
      "Epoch 216/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1094 - acc: 0.4793 - val_loss: 1.4398 - val_acc: 0.4091\n",
      "Epoch 217/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1095 - acc: 0.4719 - val_loss: 1.5079 - val_acc: 0.4121\n",
      "Epoch 218/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1866 - acc: 0.4588 - val_loss: 1.6771 - val_acc: 0.3606\n",
      "Epoch 219/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2156 - acc: 0.4218 - val_loss: 1.4461 - val_acc: 0.4394\n",
      "Epoch 220/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1373 - acc: 0.4790 - val_loss: 1.4516 - val_acc: 0.4333\n",
      "Epoch 221/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1697 - acc: 0.4832 - val_loss: 1.3712 - val_acc: 0.4273\n",
      "Epoch 222/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1640 - acc: 0.4928 - val_loss: 1.3582 - val_acc: 0.4242\n",
      "Epoch 223/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1526 - acc: 0.4850 - val_loss: 1.3670 - val_acc: 0.4424\n",
      "Epoch 224/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1326 - acc: 0.5108 - val_loss: 1.3356 - val_acc: 0.4606\n",
      "Epoch 225/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2022 - acc: 0.4790 - val_loss: 1.3867 - val_acc: 0.4061\n",
      "Epoch 226/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1517 - acc: 0.4811 - val_loss: 1.5207 - val_acc: 0.4121\n",
      "Epoch 227/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1713 - acc: 0.4762 - val_loss: 1.4664 - val_acc: 0.3970\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1293 - acc: 0.4758 - val_loss: 1.4816 - val_acc: 0.3909\n",
      "Epoch 229/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1176 - acc: 0.4882 - val_loss: 1.5817 - val_acc: 0.3606\n",
      "Epoch 230/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1875 - acc: 0.4430 - val_loss: 1.5102 - val_acc: 0.3939\n",
      "Epoch 231/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1282 - acc: 0.4783 - val_loss: 1.3772 - val_acc: 0.4818\n",
      "Epoch 232/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1063 - acc: 0.5044 - val_loss: 1.3468 - val_acc: 0.4515\n",
      "Epoch 233/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.1730 - acc: 0.4931 - val_loss: 1.4094 - val_acc: 0.4333\n",
      "Epoch 234/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1260 - acc: 0.5171 - val_loss: 1.4377 - val_acc: 0.4303\n",
      "Epoch 235/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.1243 - acc: 0.4910 - val_loss: 1.5229 - val_acc: 0.3727\n",
      "Epoch 236/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1465 - acc: 0.4603 - val_loss: 1.5535 - val_acc: 0.3970\n",
      "Epoch 237/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1456 - acc: 0.4596 - val_loss: 1.5040 - val_acc: 0.4061\n",
      "Epoch 238/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1250 - acc: 0.4807 - val_loss: 1.4681 - val_acc: 0.4030\n",
      "Epoch 239/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1036 - acc: 0.4889 - val_loss: 1.5565 - val_acc: 0.3939\n",
      "Epoch 240/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.1731 - acc: 0.4649 - val_loss: 1.4856 - val_acc: 0.3788\n",
      "Epoch 241/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1275 - acc: 0.4723 - val_loss: 1.5568 - val_acc: 0.3727\n",
      "Epoch 242/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1788 - acc: 0.4302 - val_loss: 1.5786 - val_acc: 0.3788\n",
      "Epoch 243/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1931 - acc: 0.4567 - val_loss: 1.3901 - val_acc: 0.4545\n",
      "Epoch 244/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1382 - acc: 0.5140 - val_loss: 1.3832 - val_acc: 0.4061\n",
      "Epoch 245/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.0927 - acc: 0.4998 - val_loss: 1.3515 - val_acc: 0.4333\n",
      "Epoch 246/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.1028 - acc: 0.5118 - val_loss: 1.3325 - val_acc: 0.4273\n",
      "Epoch 247/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1477 - acc: 0.4970 - val_loss: 1.3741 - val_acc: 0.4303\n",
      "Epoch 248/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.0914 - acc: 0.4988 - val_loss: 1.3602 - val_acc: 0.4333\n",
      "Epoch 249/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.1381 - acc: 0.4755 - val_loss: 1.3538 - val_acc: 0.4303\n",
      "Epoch 250/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1013 - acc: 0.5016 - val_loss: 1.3346 - val_acc: 0.4727\n",
      "Epoch 251/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1301 - acc: 0.4924 - val_loss: 1.3332 - val_acc: 0.4273\n",
      "Epoch 252/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1424 - acc: 0.4988 - val_loss: 1.4252 - val_acc: 0.4212\n",
      "Epoch 253/300\n",
      "2831/2831 [==============================] - 0s 102us/step - loss: 1.1743 - acc: 0.4776 - val_loss: 1.3942 - val_acc: 0.4455\n",
      "Epoch 254/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.1081 - acc: 0.5122 - val_loss: 1.4027 - val_acc: 0.4000\n",
      "Epoch 255/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.0673 - acc: 0.5143 - val_loss: 1.4056 - val_acc: 0.4242\n",
      "Epoch 256/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.0603 - acc: 0.5178 - val_loss: 1.3334 - val_acc: 0.4727\n",
      "Epoch 257/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1280 - acc: 0.5065 - val_loss: 1.3347 - val_acc: 0.4364\n",
      "Epoch 258/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2052 - acc: 0.4956 - val_loss: 1.4295 - val_acc: 0.4333\n",
      "Epoch 259/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.0974 - acc: 0.5069 - val_loss: 1.5181 - val_acc: 0.4030\n",
      "Epoch 260/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1464 - acc: 0.4871 - val_loss: 1.5271 - val_acc: 0.3970\n",
      "Epoch 261/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.0930 - acc: 0.4751 - val_loss: 1.5089 - val_acc: 0.4091\n",
      "Epoch 262/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.1336 - acc: 0.4659 - val_loss: 1.5735 - val_acc: 0.4061\n",
      "Epoch 263/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1681 - acc: 0.4564 - val_loss: 1.4302 - val_acc: 0.4152\n",
      "Epoch 264/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1229 - acc: 0.5009 - val_loss: 1.3469 - val_acc: 0.4515\n",
      "Epoch 265/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1405 - acc: 0.4974 - val_loss: 1.3411 - val_acc: 0.4182\n",
      "Epoch 266/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.0977 - acc: 0.5083 - val_loss: 1.3636 - val_acc: 0.4545\n",
      "Epoch 267/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.0480 - acc: 0.5348 - val_loss: 1.3405 - val_acc: 0.4424\n",
      "Epoch 268/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1334 - acc: 0.4974 - val_loss: 1.3401 - val_acc: 0.4364\n",
      "Epoch 269/300\n",
      "2831/2831 [==============================] - 0s 106us/step - loss: 1.0768 - acc: 0.5175 - val_loss: 1.3832 - val_acc: 0.4515\n",
      "Epoch 270/300\n",
      "2831/2831 [==============================] - 0s 120us/step - loss: 1.0458 - acc: 0.5281 - val_loss: 1.3435 - val_acc: 0.4576\n",
      "Epoch 271/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1587 - acc: 0.5012 - val_loss: 1.3743 - val_acc: 0.4061\n",
      "Epoch 272/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1561 - acc: 0.4804 - val_loss: 1.4030 - val_acc: 0.4606\n",
      "Epoch 273/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.0562 - acc: 0.5284 - val_loss: 1.5091 - val_acc: 0.4212\n",
      "Epoch 274/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1350 - acc: 0.4853 - val_loss: 1.5036 - val_acc: 0.4303\n",
      "Epoch 275/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.1086 - acc: 0.4885 - val_loss: 1.5139 - val_acc: 0.4273\n",
      "Epoch 276/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1013 - acc: 0.4807 - val_loss: 1.5180 - val_acc: 0.3939\n",
      "Epoch 277/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1061 - acc: 0.4970 - val_loss: 1.5135 - val_acc: 0.4121\n",
      "Epoch 278/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1111 - acc: 0.4790 - val_loss: 1.5057 - val_acc: 0.3818\n",
      "Epoch 279/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.0861 - acc: 0.4903 - val_loss: 1.4742 - val_acc: 0.4303\n",
      "Epoch 280/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0534 - acc: 0.5090 - val_loss: 1.4717 - val_acc: 0.4242\n",
      "Epoch 281/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.0594 - acc: 0.5034 - val_loss: 1.5234 - val_acc: 0.4273\n",
      "Epoch 282/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1217 - acc: 0.4592 - val_loss: 1.5062 - val_acc: 0.4364\n",
      "Epoch 283/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.0978 - acc: 0.4846 - val_loss: 1.4313 - val_acc: 0.4152\n",
      "Epoch 284/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1411 - acc: 0.5005 - val_loss: 1.3255 - val_acc: 0.4515\n",
      "Epoch 285/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1644 - acc: 0.4956 - val_loss: 1.3539 - val_acc: 0.4212\n",
      "Epoch 286/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.0657 - acc: 0.5132 - val_loss: 1.3784 - val_acc: 0.4606\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.0390 - acc: 0.5288 - val_loss: 1.3954 - val_acc: 0.4424\n",
      "Epoch 288/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0453 - acc: 0.5118 - val_loss: 1.4798 - val_acc: 0.4303\n",
      "Epoch 289/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1374 - acc: 0.4860 - val_loss: 1.5188 - val_acc: 0.3848\n",
      "Epoch 290/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1021 - acc: 0.4687 - val_loss: 1.5424 - val_acc: 0.3727\n",
      "Epoch 291/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1093 - acc: 0.4592 - val_loss: 1.4371 - val_acc: 0.4091\n",
      "Epoch 292/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0584 - acc: 0.5051 - val_loss: 1.6086 - val_acc: 0.3515\n",
      "Epoch 293/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1366 - acc: 0.4419 - val_loss: 1.4268 - val_acc: 0.4455\n",
      "Epoch 294/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.0489 - acc: 0.5249 - val_loss: 1.3874 - val_acc: 0.4545\n",
      "Epoch 295/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0245 - acc: 0.5214 - val_loss: 1.3291 - val_acc: 0.4939\n",
      "Epoch 296/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1629 - acc: 0.4843 - val_loss: 1.3869 - val_acc: 0.4182\n",
      "Epoch 297/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1375 - acc: 0.4892 - val_loss: 1.4458 - val_acc: 0.4303\n",
      "Epoch 298/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.0678 - acc: 0.5154 - val_loss: 1.4193 - val_acc: 0.4515\n",
      "Epoch 299/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.0311 - acc: 0.5260 - val_loss: 1.4497 - val_acc: 0.4394\n",
      "Epoch 300/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0337 - acc: 0.5210 - val_loss: 1.5343 - val_acc: 0.4121\n",
      "2\n",
      "Train on 2831 samples, validate on 330 samples\n",
      "Epoch 1/300\n",
      "2831/2831 [==============================] - 18s 7ms/step - loss: 2.6055 - acc: 0.2292 - val_loss: 2.3477 - val_acc: 0.3303\n",
      "Epoch 2/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 2.2413 - acc: 0.3292 - val_loss: 2.2902 - val_acc: 0.3303\n",
      "Epoch 3/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 2.2226 - acc: 0.3267 - val_loss: 2.2672 - val_acc: 0.3303\n",
      "Epoch 4/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 2.1711 - acc: 0.3525 - val_loss: 2.2408 - val_acc: 0.3303\n",
      "Epoch 5/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 2.1455 - acc: 0.3395 - val_loss: 2.2552 - val_acc: 0.3303\n",
      "Epoch 6/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 2.1045 - acc: 0.3462 - val_loss: 2.2501 - val_acc: 0.3273\n",
      "Epoch 7/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 2.0983 - acc: 0.3154 - val_loss: 2.1747 - val_acc: 0.3303\n",
      "Epoch 8/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 2.0797 - acc: 0.3409 - val_loss: 2.1768 - val_acc: 0.3303\n",
      "Epoch 9/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 2.0464 - acc: 0.3476 - val_loss: 2.2106 - val_acc: 0.3303\n",
      "Epoch 10/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 2.0870 - acc: 0.3370 - val_loss: 2.1310 - val_acc: 0.3303\n",
      "Epoch 11/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 2.0119 - acc: 0.3508 - val_loss: 2.1397 - val_acc: 0.3273\n",
      "Epoch 12/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.9823 - acc: 0.3391 - val_loss: 2.1105 - val_acc: 0.3303\n",
      "Epoch 13/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.9680 - acc: 0.3557 - val_loss: 2.1140 - val_acc: 0.3242\n",
      "Epoch 14/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.9566 - acc: 0.3335 - val_loss: 2.0539 - val_acc: 0.3303\n",
      "Epoch 15/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.9200 - acc: 0.3575 - val_loss: 2.0624 - val_acc: 0.3303\n",
      "Epoch 16/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.9014 - acc: 0.3748 - val_loss: 2.0937 - val_acc: 0.3303\n",
      "Epoch 17/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.9207 - acc: 0.3483 - val_loss: 2.0080 - val_acc: 0.3273\n",
      "Epoch 18/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8801 - acc: 0.3532 - val_loss: 2.0044 - val_acc: 0.3242\n",
      "Epoch 19/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.8640 - acc: 0.3769 - val_loss: 1.9595 - val_acc: 0.3273\n",
      "Epoch 20/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8377 - acc: 0.3705 - val_loss: 1.9751 - val_acc: 0.3303\n",
      "Epoch 21/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.8408 - acc: 0.3575 - val_loss: 2.0013 - val_acc: 0.3273\n",
      "Epoch 22/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.8242 - acc: 0.3592 - val_loss: 1.9196 - val_acc: 0.3273\n",
      "Epoch 23/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.7986 - acc: 0.3617 - val_loss: 1.9060 - val_acc: 0.3273\n",
      "Epoch 24/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.7759 - acc: 0.3737 - val_loss: 1.9192 - val_acc: 0.3242\n",
      "Epoch 25/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.7666 - acc: 0.3758 - val_loss: 1.9559 - val_acc: 0.3303\n",
      "Epoch 26/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.7747 - acc: 0.3624 - val_loss: 1.8941 - val_acc: 0.3242\n",
      "Epoch 27/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.7492 - acc: 0.3776 - val_loss: 1.9101 - val_acc: 0.3121\n",
      "Epoch 28/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.7277 - acc: 0.3606 - val_loss: 1.8847 - val_acc: 0.3121\n",
      "Epoch 29/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.7226 - acc: 0.3592 - val_loss: 1.9022 - val_acc: 0.3121\n",
      "Epoch 30/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.7203 - acc: 0.3638 - val_loss: 1.8737 - val_acc: 0.3030\n",
      "Epoch 31/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.7046 - acc: 0.3564 - val_loss: 1.8590 - val_acc: 0.3091\n",
      "Epoch 32/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.6719 - acc: 0.3493 - val_loss: 1.8705 - val_acc: 0.3091\n",
      "Epoch 33/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.6614 - acc: 0.3744 - val_loss: 1.8296 - val_acc: 0.3182\n",
      "Epoch 34/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.6468 - acc: 0.3709 - val_loss: 1.8517 - val_acc: 0.2909\n",
      "Epoch 35/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.6523 - acc: 0.3624 - val_loss: 1.8892 - val_acc: 0.2667\n",
      "Epoch 36/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.6667 - acc: 0.3204 - val_loss: 1.8079 - val_acc: 0.3242\n",
      "Epoch 37/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.6279 - acc: 0.3769 - val_loss: 1.7870 - val_acc: 0.3182\n",
      "Epoch 38/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.5996 - acc: 0.3896 - val_loss: 1.7523 - val_acc: 0.3242\n",
      "Epoch 39/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.6090 - acc: 0.3790 - val_loss: 1.7605 - val_acc: 0.3303\n",
      "Epoch 40/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.6388 - acc: 0.3960 - val_loss: 1.9099 - val_acc: 0.3152\n",
      "Epoch 41/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.6027 - acc: 0.3893 - val_loss: 1.8196 - val_acc: 0.3121\n",
      "Epoch 42/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.5869 - acc: 0.3762 - val_loss: 1.8613 - val_acc: 0.2606\n",
      "Epoch 43/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.5922 - acc: 0.3437 - val_loss: 1.7508 - val_acc: 0.3182\n",
      "Epoch 44/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.5547 - acc: 0.3956 - val_loss: 1.7773 - val_acc: 0.2909\n",
      "Epoch 45/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.5713 - acc: 0.3681 - val_loss: 1.7861 - val_acc: 0.3030\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.5777 - acc: 0.3677 - val_loss: 1.6905 - val_acc: 0.3212\n",
      "Epoch 47/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5694 - acc: 0.3931 - val_loss: 1.6617 - val_acc: 0.3273\n",
      "Epoch 48/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5544 - acc: 0.3977 - val_loss: 1.6969 - val_acc: 0.3212\n",
      "Epoch 49/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.5104 - acc: 0.3999 - val_loss: 1.6941 - val_acc: 0.3182\n",
      "Epoch 50/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5257 - acc: 0.3822 - val_loss: 1.6412 - val_acc: 0.3303\n",
      "Epoch 51/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.5652 - acc: 0.4097 - val_loss: 1.8300 - val_acc: 0.3182\n",
      "Epoch 52/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5378 - acc: 0.3935 - val_loss: 1.7737 - val_acc: 0.3121\n",
      "Epoch 53/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.5145 - acc: 0.3939 - val_loss: 1.8421 - val_acc: 0.3061\n",
      "Epoch 54/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5150 - acc: 0.3850 - val_loss: 1.6895 - val_acc: 0.3152\n",
      "Epoch 55/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4781 - acc: 0.4034 - val_loss: 1.6448 - val_acc: 0.3303\n",
      "Epoch 56/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4841 - acc: 0.4133 - val_loss: 1.6316 - val_acc: 0.3212\n",
      "Epoch 57/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4971 - acc: 0.4027 - val_loss: 1.5926 - val_acc: 0.3333\n",
      "Epoch 58/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.4895 - acc: 0.4136 - val_loss: 1.6226 - val_acc: 0.3212\n",
      "Epoch 59/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.4780 - acc: 0.3963 - val_loss: 1.5921 - val_acc: 0.3364\n",
      "Epoch 60/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.5265 - acc: 0.4073 - val_loss: 1.7370 - val_acc: 0.3212\n",
      "Epoch 61/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.4552 - acc: 0.4168 - val_loss: 1.7125 - val_acc: 0.3212\n",
      "Epoch 62/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4711 - acc: 0.3984 - val_loss: 1.6708 - val_acc: 0.3273\n",
      "Epoch 63/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4290 - acc: 0.4200 - val_loss: 1.7465 - val_acc: 0.3091\n",
      "Epoch 64/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.4560 - acc: 0.4147 - val_loss: 1.7667 - val_acc: 0.3121\n",
      "Epoch 65/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.4676 - acc: 0.3974 - val_loss: 1.7785 - val_acc: 0.2879\n",
      "Epoch 66/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.4660 - acc: 0.3829 - val_loss: 1.6796 - val_acc: 0.3091\n",
      "Epoch 67/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4564 - acc: 0.3886 - val_loss: 1.6414 - val_acc: 0.3091\n",
      "Epoch 68/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4460 - acc: 0.4023 - val_loss: 1.5627 - val_acc: 0.3333\n",
      "Epoch 69/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.4215 - acc: 0.4122 - val_loss: 1.5276 - val_acc: 0.3394\n",
      "Epoch 70/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4542 - acc: 0.4207 - val_loss: 1.6717 - val_acc: 0.3152\n",
      "Epoch 71/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.4176 - acc: 0.4059 - val_loss: 1.6874 - val_acc: 0.3152\n",
      "Epoch 72/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.4319 - acc: 0.4062 - val_loss: 1.6540 - val_acc: 0.3212\n",
      "Epoch 73/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4367 - acc: 0.4020 - val_loss: 1.5595 - val_acc: 0.3333\n",
      "Epoch 74/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.4460 - acc: 0.4030 - val_loss: 1.5140 - val_acc: 0.3364\n",
      "Epoch 75/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4596 - acc: 0.4320 - val_loss: 1.6990 - val_acc: 0.3152\n",
      "Epoch 76/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3963 - acc: 0.4186 - val_loss: 1.6101 - val_acc: 0.3212\n",
      "Epoch 77/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3662 - acc: 0.4186 - val_loss: 1.6431 - val_acc: 0.3333\n",
      "Epoch 78/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.3884 - acc: 0.4253 - val_loss: 1.7841 - val_acc: 0.3152\n",
      "Epoch 79/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.4629 - acc: 0.4143 - val_loss: 1.6925 - val_acc: 0.3000\n",
      "Epoch 80/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3823 - acc: 0.4094 - val_loss: 1.6425 - val_acc: 0.2909\n",
      "Epoch 81/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3830 - acc: 0.4083 - val_loss: 1.7039 - val_acc: 0.2758\n",
      "Epoch 82/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3978 - acc: 0.3871 - val_loss: 1.7413 - val_acc: 0.3091\n",
      "Epoch 83/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.3891 - acc: 0.4189 - val_loss: 1.8263 - val_acc: 0.2818\n",
      "Epoch 84/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.4290 - acc: 0.3720 - val_loss: 1.5894 - val_acc: 0.3273\n",
      "Epoch 85/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3676 - acc: 0.4316 - val_loss: 1.5336 - val_acc: 0.3303\n",
      "Epoch 86/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3537 - acc: 0.4352 - val_loss: 1.6282 - val_acc: 0.3000\n",
      "Epoch 87/300\n",
      "2831/2831 [==============================] - 0s 92us/step - loss: 1.4006 - acc: 0.3977 - val_loss: 1.6844 - val_acc: 0.2606\n",
      "Epoch 88/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3807 - acc: 0.3882 - val_loss: 1.6027 - val_acc: 0.3242\n",
      "Epoch 89/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3479 - acc: 0.4345 - val_loss: 1.4695 - val_acc: 0.3455\n",
      "Epoch 90/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4121 - acc: 0.4090 - val_loss: 1.4732 - val_acc: 0.3303\n",
      "Epoch 91/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4157 - acc: 0.4232 - val_loss: 1.6261 - val_acc: 0.3152\n",
      "Epoch 92/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.3501 - acc: 0.4228 - val_loss: 1.6412 - val_acc: 0.3212\n",
      "Epoch 93/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.3604 - acc: 0.4165 - val_loss: 1.5268 - val_acc: 0.3242\n",
      "Epoch 94/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3663 - acc: 0.3984 - val_loss: 1.4409 - val_acc: 0.3515\n",
      "Epoch 95/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3952 - acc: 0.4507 - val_loss: 1.5395 - val_acc: 0.3242\n",
      "Epoch 96/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.3510 - acc: 0.4260 - val_loss: 1.5330 - val_acc: 0.3333\n",
      "Epoch 97/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3479 - acc: 0.4267 - val_loss: 1.5155 - val_acc: 0.3273\n",
      "Epoch 98/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3300 - acc: 0.4292 - val_loss: 1.4682 - val_acc: 0.3273\n",
      "Epoch 99/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.3665 - acc: 0.4249 - val_loss: 1.4667 - val_acc: 0.3394\n",
      "Epoch 100/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.3787 - acc: 0.4253 - val_loss: 1.5975 - val_acc: 0.3333\n",
      "Epoch 101/300\n",
      "2831/2831 [==============================] - ETA: 0s - loss: 1.3280 - acc: 0.440 - 0s 70us/step - loss: 1.3195 - acc: 0.4401 - val_loss: 1.6186 - val_acc: 0.3212\n",
      "Epoch 102/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3183 - acc: 0.4359 - val_loss: 1.5075 - val_acc: 0.3364\n",
      "Epoch 103/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3681 - acc: 0.4211 - val_loss: 1.4314 - val_acc: 0.3515\n",
      "Epoch 104/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.3560 - acc: 0.4426 - val_loss: 1.5272 - val_acc: 0.3212\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.3044 - acc: 0.4302 - val_loss: 1.5915 - val_acc: 0.3000\n",
      "Epoch 106/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3148 - acc: 0.4165 - val_loss: 1.6577 - val_acc: 0.3152\n",
      "Epoch 107/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.3220 - acc: 0.4246 - val_loss: 1.7953 - val_acc: 0.3212\n",
      "Epoch 108/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.3682 - acc: 0.4158 - val_loss: 1.5311 - val_acc: 0.3242\n",
      "Epoch 109/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2862 - acc: 0.4377 - val_loss: 1.5101 - val_acc: 0.3424\n",
      "Epoch 110/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3032 - acc: 0.4285 - val_loss: 1.4112 - val_acc: 0.3636\n",
      "Epoch 111/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.3540 - acc: 0.4415 - val_loss: 1.4589 - val_acc: 0.3333\n",
      "Epoch 112/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.3100 - acc: 0.4387 - val_loss: 1.4375 - val_acc: 0.3455\n",
      "Epoch 113/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3072 - acc: 0.4391 - val_loss: 1.4514 - val_acc: 0.3576\n",
      "Epoch 114/300\n",
      "2831/2831 [==============================] - 0s 94us/step - loss: 1.3046 - acc: 0.4394 - val_loss: 1.4985 - val_acc: 0.3545\n",
      "Epoch 115/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2724 - acc: 0.4497 - val_loss: 1.5322 - val_acc: 0.3424\n",
      "Epoch 116/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2832 - acc: 0.4426 - val_loss: 1.6826 - val_acc: 0.3333\n",
      "Epoch 117/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3560 - acc: 0.4334 - val_loss: 1.6091 - val_acc: 0.3182\n",
      "Epoch 118/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2877 - acc: 0.4338 - val_loss: 1.8145 - val_acc: 0.2818\n",
      "Epoch 119/300\n",
      "2831/2831 [==============================] - 0s 62us/step - loss: 1.3485 - acc: 0.3942 - val_loss: 1.5433 - val_acc: 0.3303\n",
      "Epoch 120/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2760 - acc: 0.4472 - val_loss: 1.4694 - val_acc: 0.3424\n",
      "Epoch 121/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2556 - acc: 0.4553 - val_loss: 1.5422 - val_acc: 0.3485\n",
      "Epoch 122/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2751 - acc: 0.4511 - val_loss: 1.5592 - val_acc: 0.3576\n",
      "Epoch 123/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3124 - acc: 0.4461 - val_loss: 1.6710 - val_acc: 0.3242\n",
      "Epoch 124/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3222 - acc: 0.4398 - val_loss: 1.6849 - val_acc: 0.3121\n",
      "Epoch 125/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.3048 - acc: 0.4193 - val_loss: 1.5501 - val_acc: 0.3182\n",
      "Epoch 126/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2483 - acc: 0.4391 - val_loss: 1.5092 - val_acc: 0.3333\n",
      "Epoch 127/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2390 - acc: 0.4486 - val_loss: 1.5743 - val_acc: 0.3394\n",
      "Epoch 128/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2727 - acc: 0.4504 - val_loss: 1.7239 - val_acc: 0.2758\n",
      "Epoch 129/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3219 - acc: 0.3924 - val_loss: 1.5711 - val_acc: 0.3394\n",
      "Epoch 130/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2742 - acc: 0.4419 - val_loss: 1.6557 - val_acc: 0.3242\n",
      "Epoch 131/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.3067 - acc: 0.4422 - val_loss: 1.5023 - val_acc: 0.3242\n",
      "Epoch 132/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2543 - acc: 0.4260 - val_loss: 1.3587 - val_acc: 0.3909\n",
      "Epoch 133/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3584 - acc: 0.4486 - val_loss: 1.4539 - val_acc: 0.3424\n",
      "Epoch 134/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2554 - acc: 0.4677 - val_loss: 1.4223 - val_acc: 0.4212\n",
      "Epoch 135/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2785 - acc: 0.4451 - val_loss: 1.4177 - val_acc: 0.3758\n",
      "Epoch 136/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2757 - acc: 0.4546 - val_loss: 1.4240 - val_acc: 0.3394\n",
      "Epoch 137/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.3067 - acc: 0.4444 - val_loss: 1.4662 - val_acc: 0.3424\n",
      "Epoch 138/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2479 - acc: 0.4578 - val_loss: 1.6201 - val_acc: 0.3333\n",
      "Epoch 139/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2535 - acc: 0.4419 - val_loss: 1.5846 - val_acc: 0.3303\n",
      "Epoch 140/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2609 - acc: 0.4465 - val_loss: 1.5492 - val_acc: 0.3394\n",
      "Epoch 141/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2411 - acc: 0.4454 - val_loss: 1.5390 - val_acc: 0.3333\n",
      "Epoch 142/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2236 - acc: 0.4475 - val_loss: 1.6246 - val_acc: 0.3242\n",
      "Epoch 143/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2448 - acc: 0.4458 - val_loss: 1.6219 - val_acc: 0.3091\n",
      "Epoch 144/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2598 - acc: 0.4288 - val_loss: 1.5379 - val_acc: 0.3485\n",
      "Epoch 145/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2371 - acc: 0.4479 - val_loss: 1.5635 - val_acc: 0.3182\n",
      "Epoch 146/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2551 - acc: 0.4274 - val_loss: 1.5606 - val_acc: 0.3182\n",
      "Epoch 147/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2430 - acc: 0.4359 - val_loss: 1.6324 - val_acc: 0.3455\n",
      "Epoch 148/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2670 - acc: 0.4334 - val_loss: 1.6901 - val_acc: 0.3121\n",
      "Epoch 149/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2870 - acc: 0.4338 - val_loss: 1.5354 - val_acc: 0.3364\n",
      "Epoch 150/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2357 - acc: 0.4422 - val_loss: 1.6751 - val_acc: 0.2667\n",
      "Epoch 151/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.2752 - acc: 0.3970 - val_loss: 1.4472 - val_acc: 0.3606\n",
      "Epoch 152/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2065 - acc: 0.4617 - val_loss: 1.5617 - val_acc: 0.3515\n",
      "Epoch 153/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2478 - acc: 0.4560 - val_loss: 1.6331 - val_acc: 0.3303\n",
      "Epoch 154/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2321 - acc: 0.4415 - val_loss: 1.4657 - val_acc: 0.3697\n",
      "Epoch 155/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1852 - acc: 0.4564 - val_loss: 1.4588 - val_acc: 0.3758\n",
      "Epoch 156/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1991 - acc: 0.4691 - val_loss: 1.4508 - val_acc: 0.3576\n",
      "Epoch 157/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2724 - acc: 0.4246 - val_loss: 1.3485 - val_acc: 0.4485\n",
      "Epoch 158/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3358 - acc: 0.4415 - val_loss: 1.4282 - val_acc: 0.3697\n",
      "Epoch 159/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2108 - acc: 0.4634 - val_loss: 1.3765 - val_acc: 0.4152\n",
      "Epoch 160/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2114 - acc: 0.4666 - val_loss: 1.3345 - val_acc: 0.4273\n",
      "Epoch 161/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.2944 - acc: 0.4603 - val_loss: 1.4174 - val_acc: 0.3939\n",
      "Epoch 162/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1960 - acc: 0.4603 - val_loss: 1.4080 - val_acc: 0.4424\n",
      "Epoch 163/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2631 - acc: 0.4472 - val_loss: 1.3604 - val_acc: 0.3909\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2364 - acc: 0.4638 - val_loss: 1.3979 - val_acc: 0.3848\n",
      "Epoch 165/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1853 - acc: 0.4726 - val_loss: 1.3784 - val_acc: 0.3939\n",
      "Epoch 166/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2222 - acc: 0.4588 - val_loss: 1.3595 - val_acc: 0.4121\n",
      "Epoch 167/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.2220 - acc: 0.4603 - val_loss: 1.3642 - val_acc: 0.4576\n",
      "Epoch 168/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2461 - acc: 0.4733 - val_loss: 1.3826 - val_acc: 0.4182\n",
      "Epoch 169/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2057 - acc: 0.4617 - val_loss: 1.3690 - val_acc: 0.3697\n",
      "Epoch 170/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2534 - acc: 0.4483 - val_loss: 1.3903 - val_acc: 0.3788\n",
      "Epoch 171/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1764 - acc: 0.4815 - val_loss: 1.4202 - val_acc: 0.4030\n",
      "Epoch 172/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1589 - acc: 0.4850 - val_loss: 1.6364 - val_acc: 0.3485\n",
      "Epoch 173/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2893 - acc: 0.4267 - val_loss: 1.5404 - val_acc: 0.3242\n",
      "Epoch 174/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2223 - acc: 0.4401 - val_loss: 1.4506 - val_acc: 0.3667\n",
      "Epoch 175/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1708 - acc: 0.4663 - val_loss: 1.5248 - val_acc: 0.3727\n",
      "Epoch 176/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2347 - acc: 0.4528 - val_loss: 1.5363 - val_acc: 0.3455\n",
      "Epoch 177/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1951 - acc: 0.4550 - val_loss: 1.5009 - val_acc: 0.3485\n",
      "Epoch 178/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1966 - acc: 0.4581 - val_loss: 1.5778 - val_acc: 0.3576\n",
      "Epoch 179/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2150 - acc: 0.4264 - val_loss: 1.4339 - val_acc: 0.3909\n",
      "Epoch 180/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1623 - acc: 0.4747 - val_loss: 1.4672 - val_acc: 0.3758\n",
      "Epoch 181/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1865 - acc: 0.4698 - val_loss: 1.7906 - val_acc: 0.3273\n",
      "Epoch 182/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.3175 - acc: 0.4172 - val_loss: 1.4886 - val_acc: 0.3758\n",
      "Epoch 183/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2149 - acc: 0.4490 - val_loss: 1.4506 - val_acc: 0.4121\n",
      "Epoch 184/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2033 - acc: 0.4408 - val_loss: 1.5679 - val_acc: 0.3515\n",
      "Epoch 185/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2179 - acc: 0.4267 - val_loss: 1.4342 - val_acc: 0.4121\n",
      "Epoch 186/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1440 - acc: 0.4793 - val_loss: 1.3976 - val_acc: 0.4545\n",
      "Epoch 187/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1441 - acc: 0.4762 - val_loss: 1.3579 - val_acc: 0.4455\n",
      "Epoch 188/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.2633 - acc: 0.4603 - val_loss: 1.3483 - val_acc: 0.4000\n",
      "Epoch 189/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2616 - acc: 0.4634 - val_loss: 1.4416 - val_acc: 0.3879\n",
      "Epoch 190/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1720 - acc: 0.4737 - val_loss: 1.4988 - val_acc: 0.3848\n",
      "Epoch 191/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1858 - acc: 0.4624 - val_loss: 1.6119 - val_acc: 0.3485\n",
      "Epoch 192/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.2207 - acc: 0.4207 - val_loss: 1.4120 - val_acc: 0.3970\n",
      "Epoch 193/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1617 - acc: 0.4719 - val_loss: 1.3565 - val_acc: 0.4182\n",
      "Epoch 194/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.1821 - acc: 0.4747 - val_loss: 1.3812 - val_acc: 0.4182\n",
      "Epoch 195/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1500 - acc: 0.4836 - val_loss: 1.5042 - val_acc: 0.3909\n",
      "Epoch 196/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2174 - acc: 0.4641 - val_loss: 1.6377 - val_acc: 0.3273\n",
      "Epoch 197/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.2348 - acc: 0.4225 - val_loss: 1.4753 - val_acc: 0.3818\n",
      "Epoch 198/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1792 - acc: 0.4465 - val_loss: 1.3902 - val_acc: 0.4455\n",
      "Epoch 199/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1590 - acc: 0.4786 - val_loss: 1.4116 - val_acc: 0.4424\n",
      "Epoch 200/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1447 - acc: 0.4797 - val_loss: 1.5058 - val_acc: 0.3909\n",
      "Epoch 201/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1778 - acc: 0.4560 - val_loss: 1.5520 - val_acc: 0.3788\n",
      "Epoch 202/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1772 - acc: 0.4666 - val_loss: 1.5028 - val_acc: 0.3909\n",
      "Epoch 203/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1769 - acc: 0.4740 - val_loss: 1.5906 - val_acc: 0.3515\n",
      "Epoch 204/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2330 - acc: 0.4316 - val_loss: 1.4833 - val_acc: 0.3939\n",
      "Epoch 205/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1613 - acc: 0.4670 - val_loss: 1.4111 - val_acc: 0.4485\n",
      "Epoch 206/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1515 - acc: 0.4882 - val_loss: 1.4546 - val_acc: 0.4152\n",
      "Epoch 207/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1932 - acc: 0.4451 - val_loss: 1.3346 - val_acc: 0.4667\n",
      "Epoch 208/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1809 - acc: 0.4860 - val_loss: 1.3167 - val_acc: 0.4242\n",
      "Epoch 209/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2028 - acc: 0.4836 - val_loss: 1.3720 - val_acc: 0.4364\n",
      "Epoch 210/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1223 - acc: 0.5072 - val_loss: 1.3823 - val_acc: 0.4182\n",
      "Epoch 211/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1598 - acc: 0.4744 - val_loss: 1.3611 - val_acc: 0.4364\n",
      "Epoch 212/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1584 - acc: 0.4959 - val_loss: 1.3669 - val_acc: 0.4333\n",
      "Epoch 213/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1303 - acc: 0.4913 - val_loss: 1.4415 - val_acc: 0.4121\n",
      "Epoch 214/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1654 - acc: 0.4797 - val_loss: 1.6426 - val_acc: 0.3485\n",
      "Epoch 215/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2547 - acc: 0.4253 - val_loss: 1.4544 - val_acc: 0.4061\n",
      "Epoch 216/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.1700 - acc: 0.4694 - val_loss: 1.3679 - val_acc: 0.4515\n",
      "Epoch 217/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1354 - acc: 0.4822 - val_loss: 1.3492 - val_acc: 0.4576\n",
      "Epoch 218/300\n",
      "2831/2831 [==============================] - 0s 91us/step - loss: 1.1711 - acc: 0.4875 - val_loss: 1.2968 - val_acc: 0.4606\n",
      "Epoch 219/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2047 - acc: 0.4843 - val_loss: 1.3407 - val_acc: 0.3939\n",
      "Epoch 220/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1382 - acc: 0.4875 - val_loss: 1.3419 - val_acc: 0.4242\n",
      "Epoch 221/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1139 - acc: 0.4945 - val_loss: 1.2965 - val_acc: 0.4697\n",
      "Epoch 222/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1858 - acc: 0.4702 - val_loss: 1.3250 - val_acc: 0.4455\n",
      "Epoch 223/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.2268 - acc: 0.4762 - val_loss: 1.4241 - val_acc: 0.4303\n",
      "Epoch 224/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1535 - acc: 0.4790 - val_loss: 1.3903 - val_acc: 0.4303\n",
      "Epoch 225/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1148 - acc: 0.4942 - val_loss: 1.4373 - val_acc: 0.4152\n",
      "Epoch 226/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.1502 - acc: 0.4659 - val_loss: 1.5372 - val_acc: 0.3727\n",
      "Epoch 227/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1765 - acc: 0.4415 - val_loss: 1.4702 - val_acc: 0.4000\n",
      "Epoch 228/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1550 - acc: 0.4723 - val_loss: 1.6491 - val_acc: 0.3545\n",
      "Epoch 229/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2247 - acc: 0.4295 - val_loss: 1.3607 - val_acc: 0.4091\n",
      "Epoch 230/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1049 - acc: 0.4984 - val_loss: 1.3251 - val_acc: 0.4576\n",
      "Epoch 231/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1161 - acc: 0.4928 - val_loss: 1.3000 - val_acc: 0.4606\n",
      "Epoch 232/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1801 - acc: 0.4882 - val_loss: 1.3413 - val_acc: 0.4273\n",
      "Epoch 233/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.1171 - acc: 0.5055 - val_loss: 1.3611 - val_acc: 0.4515\n",
      "Epoch 234/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1038 - acc: 0.4913 - val_loss: 1.3672 - val_acc: 0.4636\n",
      "Epoch 235/300\n",
      "2831/2831 [==============================] - 0s 92us/step - loss: 1.1707 - acc: 0.4850 - val_loss: 1.3788 - val_acc: 0.4455\n",
      "Epoch 236/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1354 - acc: 0.4952 - val_loss: 1.3254 - val_acc: 0.4485\n",
      "Epoch 237/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1360 - acc: 0.4864 - val_loss: 1.2864 - val_acc: 0.4727\n",
      "Epoch 238/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2378 - acc: 0.4762 - val_loss: 1.4084 - val_acc: 0.4030\n",
      "Epoch 239/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1074 - acc: 0.4906 - val_loss: 1.4804 - val_acc: 0.3970\n",
      "Epoch 240/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.1566 - acc: 0.4680 - val_loss: 1.5375 - val_acc: 0.3758\n",
      "Epoch 241/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1480 - acc: 0.4507 - val_loss: 1.4194 - val_acc: 0.4242\n",
      "Epoch 242/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1019 - acc: 0.4924 - val_loss: 1.5049 - val_acc: 0.3939\n",
      "Epoch 243/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1645 - acc: 0.4740 - val_loss: 1.3721 - val_acc: 0.4121\n",
      "Epoch 244/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0836 - acc: 0.4896 - val_loss: 1.3249 - val_acc: 0.4364\n",
      "Epoch 245/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1347 - acc: 0.4687 - val_loss: 1.2905 - val_acc: 0.4485\n",
      "Epoch 246/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2314 - acc: 0.4793 - val_loss: 1.4078 - val_acc: 0.4212\n",
      "Epoch 247/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1322 - acc: 0.4896 - val_loss: 1.3989 - val_acc: 0.4606\n",
      "Epoch 248/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1373 - acc: 0.4864 - val_loss: 1.3909 - val_acc: 0.4545\n",
      "Epoch 249/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0872 - acc: 0.5009 - val_loss: 1.4153 - val_acc: 0.4333\n",
      "Epoch 250/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.0902 - acc: 0.4921 - val_loss: 1.5143 - val_acc: 0.3970\n",
      "Epoch 251/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1555 - acc: 0.4490 - val_loss: 1.4349 - val_acc: 0.3909\n",
      "Epoch 252/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0860 - acc: 0.5048 - val_loss: 1.4117 - val_acc: 0.3970\n",
      "Epoch 253/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0806 - acc: 0.5090 - val_loss: 1.4655 - val_acc: 0.4182\n",
      "Epoch 254/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1400 - acc: 0.4712 - val_loss: 1.5887 - val_acc: 0.3818\n",
      "Epoch 255/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1828 - acc: 0.4497 - val_loss: 1.3569 - val_acc: 0.4182\n",
      "Epoch 256/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1009 - acc: 0.4829 - val_loss: 1.3282 - val_acc: 0.4364\n",
      "Epoch 257/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1964 - acc: 0.4649 - val_loss: 1.4200 - val_acc: 0.4333\n",
      "Epoch 258/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0992 - acc: 0.5002 - val_loss: 1.4627 - val_acc: 0.4030\n",
      "Epoch 259/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1313 - acc: 0.4924 - val_loss: 1.4431 - val_acc: 0.4152\n",
      "Epoch 260/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1093 - acc: 0.4762 - val_loss: 1.3850 - val_acc: 0.4303\n",
      "Epoch 261/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.0811 - acc: 0.5019 - val_loss: 1.3633 - val_acc: 0.4212\n",
      "Epoch 262/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.0970 - acc: 0.4797 - val_loss: 1.2981 - val_acc: 0.4697\n",
      "Epoch 263/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1195 - acc: 0.4889 - val_loss: 1.3037 - val_acc: 0.4303\n",
      "Epoch 264/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2027 - acc: 0.4860 - val_loss: 1.3900 - val_acc: 0.4606\n",
      "Epoch 265/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.0884 - acc: 0.5231 - val_loss: 1.3744 - val_acc: 0.4333\n",
      "Epoch 266/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0779 - acc: 0.5097 - val_loss: 1.5143 - val_acc: 0.3970\n",
      "Epoch 267/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1401 - acc: 0.4550 - val_loss: 1.4057 - val_acc: 0.4242\n",
      "Epoch 268/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1170 - acc: 0.4970 - val_loss: 1.6725 - val_acc: 0.3576\n",
      "Epoch 269/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.2285 - acc: 0.4239 - val_loss: 1.3516 - val_acc: 0.4152\n",
      "Epoch 270/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.0787 - acc: 0.5136 - val_loss: 1.3541 - val_acc: 0.4667\n",
      "Epoch 271/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0640 - acc: 0.5140 - val_loss: 1.3465 - val_acc: 0.4545\n",
      "Epoch 272/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1235 - acc: 0.4846 - val_loss: 1.3716 - val_acc: 0.4273\n",
      "Epoch 273/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.0932 - acc: 0.4995 - val_loss: 1.4657 - val_acc: 0.3879\n",
      "Epoch 274/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1158 - acc: 0.4797 - val_loss: 1.5657 - val_acc: 0.3727\n",
      "Epoch 275/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.1509 - acc: 0.4532 - val_loss: 1.3759 - val_acc: 0.4364\n",
      "Epoch 276/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.0555 - acc: 0.5224 - val_loss: 1.3642 - val_acc: 0.4303\n",
      "Epoch 277/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0324 - acc: 0.5373 - val_loss: 1.4254 - val_acc: 0.4515\n",
      "Epoch 278/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.0915 - acc: 0.4822 - val_loss: 1.6558 - val_acc: 0.3394\n",
      "Epoch 279/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1891 - acc: 0.4129 - val_loss: 1.3426 - val_acc: 0.4758\n",
      "Epoch 280/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.0518 - acc: 0.5270 - val_loss: 1.3237 - val_acc: 0.4636\n",
      "Epoch 281/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.1007 - acc: 0.5101 - val_loss: 1.3191 - val_acc: 0.4515\n",
      "Epoch 282/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.2341 - acc: 0.4931 - val_loss: 1.3825 - val_acc: 0.4152\n",
      "Epoch 283/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.0644 - acc: 0.5150 - val_loss: 1.3662 - val_acc: 0.4333\n",
      "Epoch 284/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.0465 - acc: 0.5249 - val_loss: 1.3851 - val_acc: 0.4182\n",
      "Epoch 285/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.0848 - acc: 0.5034 - val_loss: 1.5151 - val_acc: 0.4000\n",
      "Epoch 286/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1733 - acc: 0.4726 - val_loss: 1.3533 - val_acc: 0.4485\n",
      "Epoch 287/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.0639 - acc: 0.5041 - val_loss: 1.4095 - val_acc: 0.4394\n",
      "Epoch 288/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.0812 - acc: 0.5065 - val_loss: 1.5982 - val_acc: 0.3758\n",
      "Epoch 289/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1705 - acc: 0.4207 - val_loss: 1.3527 - val_acc: 0.4152\n",
      "Epoch 290/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.0766 - acc: 0.5115 - val_loss: 1.3621 - val_acc: 0.4485\n",
      "Epoch 291/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.0756 - acc: 0.5136 - val_loss: 1.4755 - val_acc: 0.4030\n",
      "Epoch 292/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1180 - acc: 0.4730 - val_loss: 1.4449 - val_acc: 0.4091\n",
      "Epoch 293/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.0638 - acc: 0.5065 - val_loss: 1.3767 - val_acc: 0.4303\n",
      "Epoch 294/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.0438 - acc: 0.5182 - val_loss: 1.3960 - val_acc: 0.4273\n",
      "Epoch 295/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.0686 - acc: 0.5072 - val_loss: 1.4622 - val_acc: 0.4303\n",
      "Epoch 296/300\n",
      "2831/2831 [==============================] - 0s 93us/step - loss: 1.1239 - acc: 0.4913 - val_loss: 1.4581 - val_acc: 0.3909\n",
      "Epoch 297/300\n",
      "2831/2831 [==============================] - 0s 81us/step - loss: 1.0741 - acc: 0.4913 - val_loss: 1.5463 - val_acc: 0.3818\n",
      "Epoch 298/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1581 - acc: 0.4352 - val_loss: 1.4099 - val_acc: 0.4485\n",
      "Epoch 299/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.0639 - acc: 0.5196 - val_loss: 1.4208 - val_acc: 0.4515\n",
      "Epoch 300/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.0707 - acc: 0.4970 - val_loss: 1.5834 - val_acc: 0.3788\n",
      "3\n",
      "Train on 2831 samples, validate on 330 samples\n",
      "Epoch 1/300\n",
      "2831/2831 [==============================] - 17s 6ms/step - loss: 2.5022 - acc: 0.2801 - val_loss: 2.3341 - val_acc: 0.4061\n",
      "Epoch 2/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 2.2710 - acc: 0.3151 - val_loss: 2.2708 - val_acc: 0.3303\n",
      "Epoch 3/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 2.1816 - acc: 0.3794 - val_loss: 2.2903 - val_acc: 0.3212\n",
      "Epoch 4/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 2.1464 - acc: 0.3649 - val_loss: 2.1993 - val_acc: 0.3182\n",
      "Epoch 5/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 2.1115 - acc: 0.3635 - val_loss: 2.2015 - val_acc: 0.3182\n",
      "Epoch 6/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 2.0960 - acc: 0.3928 - val_loss: 2.1728 - val_acc: 0.3303\n",
      "Epoch 7/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 2.0667 - acc: 0.3840 - val_loss: 2.1352 - val_acc: 0.3273\n",
      "Epoch 8/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 2.0447 - acc: 0.3808 - val_loss: 2.1274 - val_acc: 0.3182\n",
      "Epoch 9/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 2.0197 - acc: 0.3691 - val_loss: 2.1124 - val_acc: 0.3242\n",
      "Epoch 10/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.9925 - acc: 0.3794 - val_loss: 2.1207 - val_acc: 0.3152\n",
      "Epoch 11/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.9849 - acc: 0.3695 - val_loss: 2.0834 - val_acc: 0.3242\n",
      "Epoch 12/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.9502 - acc: 0.3931 - val_loss: 2.0358 - val_acc: 0.3182\n",
      "Epoch 13/300\n",
      "2831/2831 [==============================] - 0s 70us/step - loss: 1.9348 - acc: 0.3903 - val_loss: 2.0333 - val_acc: 0.3121\n",
      "Epoch 14/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.9072 - acc: 0.3808 - val_loss: 2.1103 - val_acc: 0.2909\n",
      "Epoch 15/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8995 - acc: 0.3780 - val_loss: 2.0585 - val_acc: 0.3212\n",
      "Epoch 16/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8890 - acc: 0.3935 - val_loss: 2.0149 - val_acc: 0.3242\n",
      "Epoch 17/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.8840 - acc: 0.3893 - val_loss: 1.9513 - val_acc: 0.3152\n",
      "Epoch 18/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.8409 - acc: 0.3921 - val_loss: 1.8948 - val_acc: 0.3242\n",
      "Epoch 19/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8447 - acc: 0.3850 - val_loss: 1.9095 - val_acc: 0.3273\n",
      "Epoch 20/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7896 - acc: 0.4087 - val_loss: 1.8953 - val_acc: 0.3242\n",
      "Epoch 21/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8129 - acc: 0.3737 - val_loss: 1.8527 - val_acc: 0.3273\n",
      "Epoch 22/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.8024 - acc: 0.4087 - val_loss: 1.8956 - val_acc: 0.3121\n",
      "Epoch 23/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7813 - acc: 0.4023 - val_loss: 1.9434 - val_acc: 0.3030\n",
      "Epoch 24/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7847 - acc: 0.3751 - val_loss: 1.9455 - val_acc: 0.2758\n",
      "Epoch 25/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.7635 - acc: 0.3811 - val_loss: 1.9217 - val_acc: 0.2909\n",
      "Epoch 26/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7221 - acc: 0.3956 - val_loss: 1.9407 - val_acc: 0.2848\n",
      "Epoch 27/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6967 - acc: 0.3924 - val_loss: 1.8515 - val_acc: 0.3152\n",
      "Epoch 28/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.6976 - acc: 0.3871 - val_loss: 1.8065 - val_acc: 0.3212\n",
      "Epoch 29/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.7075 - acc: 0.3946 - val_loss: 1.7688 - val_acc: 0.3273\n",
      "Epoch 30/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6944 - acc: 0.4048 - val_loss: 1.7571 - val_acc: 0.3182\n",
      "Epoch 31/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6737 - acc: 0.3988 - val_loss: 1.7595 - val_acc: 0.3242\n",
      "Epoch 32/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.6615 - acc: 0.4080 - val_loss: 1.7740 - val_acc: 0.3091\n",
      "Epoch 33/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6319 - acc: 0.4059 - val_loss: 1.7540 - val_acc: 0.3212\n",
      "Epoch 34/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.6521 - acc: 0.3967 - val_loss: 1.7879 - val_acc: 0.3152\n",
      "Epoch 35/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6258 - acc: 0.4055 - val_loss: 1.7774 - val_acc: 0.3000\n",
      "Epoch 36/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6043 - acc: 0.3953 - val_loss: 1.7087 - val_acc: 0.3273\n",
      "Epoch 37/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.6645 - acc: 0.4094 - val_loss: 1.8243 - val_acc: 0.3091\n",
      "Epoch 38/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.6172 - acc: 0.3984 - val_loss: 1.7826 - val_acc: 0.3152\n",
      "Epoch 39/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5894 - acc: 0.3893 - val_loss: 1.7526 - val_acc: 0.3182\n",
      "Epoch 40/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.6160 - acc: 0.3797 - val_loss: 1.6812 - val_acc: 0.3212\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.5801 - acc: 0.4239 - val_loss: 1.7485 - val_acc: 0.3152\n",
      "Epoch 42/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.5459 - acc: 0.4140 - val_loss: 1.7601 - val_acc: 0.3121\n",
      "Epoch 43/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5660 - acc: 0.3970 - val_loss: 1.6913 - val_acc: 0.3212\n",
      "Epoch 44/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5827 - acc: 0.4016 - val_loss: 1.7214 - val_acc: 0.3242\n",
      "Epoch 45/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5884 - acc: 0.4168 - val_loss: 1.7654 - val_acc: 0.2758\n",
      "Epoch 46/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5343 - acc: 0.4002 - val_loss: 1.8632 - val_acc: 0.2515\n",
      "Epoch 47/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5561 - acc: 0.3783 - val_loss: 1.7151 - val_acc: 0.3152\n",
      "Epoch 48/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5128 - acc: 0.4066 - val_loss: 1.6696 - val_acc: 0.3091\n",
      "Epoch 49/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5121 - acc: 0.4073 - val_loss: 1.6889 - val_acc: 0.3121\n",
      "Epoch 50/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5443 - acc: 0.4158 - val_loss: 1.7938 - val_acc: 0.2606\n",
      "Epoch 51/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5116 - acc: 0.3886 - val_loss: 1.8135 - val_acc: 0.2818\n",
      "Epoch 52/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5133 - acc: 0.3949 - val_loss: 1.7871 - val_acc: 0.3061\n",
      "Epoch 53/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5041 - acc: 0.4020 - val_loss: 1.7019 - val_acc: 0.3121\n",
      "Epoch 54/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5058 - acc: 0.3974 - val_loss: 1.6297 - val_acc: 0.3212\n",
      "Epoch 55/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.5050 - acc: 0.4129 - val_loss: 1.6616 - val_acc: 0.3152\n",
      "Epoch 56/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4597 - acc: 0.4126 - val_loss: 1.6256 - val_acc: 0.3152\n",
      "Epoch 57/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4815 - acc: 0.4055 - val_loss: 1.6083 - val_acc: 0.3303\n",
      "Epoch 58/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.5486 - acc: 0.4143 - val_loss: 1.7973 - val_acc: 0.3091\n",
      "Epoch 59/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4732 - acc: 0.4133 - val_loss: 1.7001 - val_acc: 0.3091\n",
      "Epoch 60/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4607 - acc: 0.4165 - val_loss: 1.7797 - val_acc: 0.2727\n",
      "Epoch 61/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4745 - acc: 0.3963 - val_loss: 1.6590 - val_acc: 0.3061\n",
      "Epoch 62/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4290 - acc: 0.4097 - val_loss: 1.8538 - val_acc: 0.2030\n",
      "Epoch 63/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.5081 - acc: 0.3532 - val_loss: 1.6647 - val_acc: 0.3152\n",
      "Epoch 64/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4587 - acc: 0.4154 - val_loss: 1.6528 - val_acc: 0.3061\n",
      "Epoch 65/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4593 - acc: 0.4288 - val_loss: 1.6998 - val_acc: 0.2758\n",
      "Epoch 66/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4303 - acc: 0.4027 - val_loss: 1.8011 - val_acc: 0.2667\n",
      "Epoch 67/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4561 - acc: 0.3903 - val_loss: 1.7047 - val_acc: 0.3061\n",
      "Epoch 68/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4019 - acc: 0.4037 - val_loss: 1.7610 - val_acc: 0.2848\n",
      "Epoch 69/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4267 - acc: 0.4066 - val_loss: 1.6857 - val_acc: 0.2848\n",
      "Epoch 70/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4460 - acc: 0.3995 - val_loss: 1.7853 - val_acc: 0.2121\n",
      "Epoch 71/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4871 - acc: 0.3638 - val_loss: 1.5595 - val_acc: 0.3212\n",
      "Epoch 72/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4246 - acc: 0.4380 - val_loss: 1.5675 - val_acc: 0.3121\n",
      "Epoch 73/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.4098 - acc: 0.4288 - val_loss: 1.5918 - val_acc: 0.3121\n",
      "Epoch 74/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.3914 - acc: 0.4126 - val_loss: 1.5236 - val_acc: 0.3212\n",
      "Epoch 75/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.4206 - acc: 0.4260 - val_loss: 1.5804 - val_acc: 0.3212\n",
      "Epoch 76/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3889 - acc: 0.4239 - val_loss: 1.5963 - val_acc: 0.3000\n",
      "Epoch 77/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4100 - acc: 0.4232 - val_loss: 1.5967 - val_acc: 0.2970\n",
      "Epoch 78/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.4299 - acc: 0.4302 - val_loss: 1.8939 - val_acc: 0.1606\n",
      "Epoch 79/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4805 - acc: 0.3299 - val_loss: 1.6335 - val_acc: 0.3121\n",
      "Epoch 80/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3782 - acc: 0.4129 - val_loss: 1.6157 - val_acc: 0.3121\n",
      "Epoch 81/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3539 - acc: 0.4253 - val_loss: 1.5384 - val_acc: 0.3182\n",
      "Epoch 82/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3605 - acc: 0.4242 - val_loss: 1.4960 - val_acc: 0.3667\n",
      "Epoch 83/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.4041 - acc: 0.4246 - val_loss: 1.5612 - val_acc: 0.3242\n",
      "Epoch 84/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3639 - acc: 0.4309 - val_loss: 1.6145 - val_acc: 0.3121\n",
      "Epoch 85/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3668 - acc: 0.4207 - val_loss: 1.6941 - val_acc: 0.3121\n",
      "Epoch 86/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3987 - acc: 0.4264 - val_loss: 1.6775 - val_acc: 0.2879\n",
      "Epoch 87/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.3713 - acc: 0.4076 - val_loss: 1.7882 - val_acc: 0.2455\n",
      "Epoch 88/300\n",
      "2831/2831 [==============================] - 0s 69us/step - loss: 1.4071 - acc: 0.3659 - val_loss: 1.5777 - val_acc: 0.3152\n",
      "Epoch 89/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3552 - acc: 0.4338 - val_loss: 1.5776 - val_acc: 0.3242\n",
      "Epoch 90/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3964 - acc: 0.4267 - val_loss: 1.5514 - val_acc: 0.3091\n",
      "Epoch 91/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3390 - acc: 0.4246 - val_loss: 1.4815 - val_acc: 0.3303\n",
      "Epoch 92/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3677 - acc: 0.4150 - val_loss: 1.4738 - val_acc: 0.3576\n",
      "Epoch 93/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3986 - acc: 0.4440 - val_loss: 1.6008 - val_acc: 0.3091\n",
      "Epoch 94/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3433 - acc: 0.4168 - val_loss: 1.5800 - val_acc: 0.3242\n",
      "Epoch 95/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3923 - acc: 0.4115 - val_loss: 1.4899 - val_acc: 0.3303\n",
      "Epoch 96/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3321 - acc: 0.4345 - val_loss: 1.4821 - val_acc: 0.3485\n",
      "Epoch 97/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3264 - acc: 0.4384 - val_loss: 1.4393 - val_acc: 0.3970\n",
      "Epoch 98/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3586 - acc: 0.4500 - val_loss: 1.5590 - val_acc: 0.3242\n",
      "Epoch 99/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3201 - acc: 0.4398 - val_loss: 1.6782 - val_acc: 0.2545\n",
      "Epoch 100/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.4098 - acc: 0.3829 - val_loss: 1.7458 - val_acc: 0.2485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3728 - acc: 0.3886 - val_loss: 1.7608 - val_acc: 0.3000\n",
      "Epoch 102/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3504 - acc: 0.4211 - val_loss: 1.5746 - val_acc: 0.3182\n",
      "Epoch 103/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3255 - acc: 0.4200 - val_loss: 1.5367 - val_acc: 0.3242\n",
      "Epoch 104/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3297 - acc: 0.4249 - val_loss: 1.4746 - val_acc: 0.3667\n",
      "Epoch 105/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.3200 - acc: 0.4472 - val_loss: 1.4486 - val_acc: 0.3636\n",
      "Epoch 106/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3375 - acc: 0.4415 - val_loss: 1.4610 - val_acc: 0.4030\n",
      "Epoch 107/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.3722 - acc: 0.4387 - val_loss: 1.6074 - val_acc: 0.2818\n",
      "Epoch 108/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3371 - acc: 0.4249 - val_loss: 1.6706 - val_acc: 0.2636\n",
      "Epoch 109/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.3499 - acc: 0.4059 - val_loss: 1.6686 - val_acc: 0.3061\n",
      "Epoch 110/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3126 - acc: 0.4221 - val_loss: 1.5990 - val_acc: 0.3273\n",
      "Epoch 111/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2802 - acc: 0.4369 - val_loss: 1.7912 - val_acc: 0.2848\n",
      "Epoch 112/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.3665 - acc: 0.3995 - val_loss: 1.5497 - val_acc: 0.3212\n",
      "Epoch 113/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2786 - acc: 0.4352 - val_loss: 1.4842 - val_acc: 0.3606\n",
      "Epoch 114/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2913 - acc: 0.4560 - val_loss: 1.5004 - val_acc: 0.4273\n",
      "Epoch 115/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3239 - acc: 0.4500 - val_loss: 1.6052 - val_acc: 0.2788\n",
      "Epoch 116/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3107 - acc: 0.4154 - val_loss: 1.7421 - val_acc: 0.2273\n",
      "Epoch 117/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3387 - acc: 0.3723 - val_loss: 1.5712 - val_acc: 0.3303\n",
      "Epoch 118/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2835 - acc: 0.4271 - val_loss: 1.5730 - val_acc: 0.3364\n",
      "Epoch 119/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2525 - acc: 0.4419 - val_loss: 1.5454 - val_acc: 0.3485\n",
      "Epoch 120/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2488 - acc: 0.4557 - val_loss: 1.6444 - val_acc: 0.3364\n",
      "Epoch 121/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3241 - acc: 0.4338 - val_loss: 1.6006 - val_acc: 0.3091\n",
      "Epoch 122/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2807 - acc: 0.4355 - val_loss: 1.6877 - val_acc: 0.2758\n",
      "Epoch 123/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.3246 - acc: 0.3992 - val_loss: 1.6428 - val_acc: 0.2909\n",
      "Epoch 124/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2968 - acc: 0.4186 - val_loss: 1.6405 - val_acc: 0.2818\n",
      "Epoch 125/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2873 - acc: 0.4203 - val_loss: 1.6052 - val_acc: 0.3333\n",
      "Epoch 126/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2772 - acc: 0.4472 - val_loss: 1.6293 - val_acc: 0.3364\n",
      "Epoch 127/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2973 - acc: 0.4412 - val_loss: 1.4921 - val_acc: 0.3485\n",
      "Epoch 128/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2796 - acc: 0.4412 - val_loss: 1.4074 - val_acc: 0.3727\n",
      "Epoch 129/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2987 - acc: 0.4500 - val_loss: 1.4522 - val_acc: 0.4000\n",
      "Epoch 130/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2710 - acc: 0.4677 - val_loss: 1.5079 - val_acc: 0.4061\n",
      "Epoch 131/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2753 - acc: 0.4571 - val_loss: 1.5575 - val_acc: 0.3545\n",
      "Epoch 132/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2700 - acc: 0.4369 - val_loss: 1.6332 - val_acc: 0.3030\n",
      "Epoch 133/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2958 - acc: 0.4295 - val_loss: 1.6394 - val_acc: 0.3152\n",
      "Epoch 134/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2838 - acc: 0.4246 - val_loss: 1.6045 - val_acc: 0.3061\n",
      "Epoch 135/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2574 - acc: 0.4288 - val_loss: 1.5879 - val_acc: 0.3333\n",
      "Epoch 136/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2438 - acc: 0.4391 - val_loss: 1.6775 - val_acc: 0.2970\n",
      "Epoch 137/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2990 - acc: 0.4055 - val_loss: 1.5830 - val_acc: 0.3545\n",
      "Epoch 138/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2470 - acc: 0.4532 - val_loss: 1.6856 - val_acc: 0.3333\n",
      "Epoch 139/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.3055 - acc: 0.4175 - val_loss: 1.4649 - val_acc: 0.3606\n",
      "Epoch 140/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.3082 - acc: 0.4316 - val_loss: 1.4382 - val_acc: 0.3515\n",
      "Epoch 141/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2447 - acc: 0.4521 - val_loss: 1.4675 - val_acc: 0.3939\n",
      "Epoch 142/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2226 - acc: 0.4620 - val_loss: 1.4542 - val_acc: 0.4394\n",
      "Epoch 143/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2505 - acc: 0.4596 - val_loss: 1.4279 - val_acc: 0.4242\n",
      "Epoch 144/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2675 - acc: 0.4645 - val_loss: 1.4291 - val_acc: 0.3606\n",
      "Epoch 145/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2724 - acc: 0.4419 - val_loss: 1.3977 - val_acc: 0.3939\n",
      "Epoch 146/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2445 - acc: 0.4663 - val_loss: 1.4393 - val_acc: 0.4000\n",
      "Epoch 147/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2023 - acc: 0.4613 - val_loss: 1.3987 - val_acc: 0.4242\n",
      "Epoch 148/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2598 - acc: 0.4730 - val_loss: 1.4424 - val_acc: 0.4121\n",
      "Epoch 149/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2761 - acc: 0.4815 - val_loss: 1.5084 - val_acc: 0.3818\n",
      "Epoch 150/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2309 - acc: 0.4497 - val_loss: 1.6058 - val_acc: 0.3061\n",
      "Epoch 151/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2679 - acc: 0.4126 - val_loss: 1.6557 - val_acc: 0.3000\n",
      "Epoch 152/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2680 - acc: 0.4207 - val_loss: 1.5405 - val_acc: 0.3424\n",
      "Epoch 153/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2157 - acc: 0.4525 - val_loss: 1.5314 - val_acc: 0.3515\n",
      "Epoch 154/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2374 - acc: 0.4574 - val_loss: 1.5964 - val_acc: 0.3242\n",
      "Epoch 155/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2317 - acc: 0.4535 - val_loss: 1.5036 - val_acc: 0.3697\n",
      "Epoch 156/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1945 - acc: 0.4557 - val_loss: 1.5234 - val_acc: 0.3818\n",
      "Epoch 157/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2216 - acc: 0.4528 - val_loss: 1.7381 - val_acc: 0.2636\n",
      "Epoch 158/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2979 - acc: 0.3744 - val_loss: 1.5306 - val_acc: 0.3576\n",
      "Epoch 159/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2163 - acc: 0.4649 - val_loss: 1.5527 - val_acc: 0.3515\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2290 - acc: 0.4606 - val_loss: 1.5997 - val_acc: 0.3333\n",
      "Epoch 161/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2462 - acc: 0.4514 - val_loss: 1.5037 - val_acc: 0.3667\n",
      "Epoch 162/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1994 - acc: 0.4603 - val_loss: 1.5266 - val_acc: 0.3727\n",
      "Epoch 163/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2037 - acc: 0.4532 - val_loss: 1.4854 - val_acc: 0.3697\n",
      "Epoch 164/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2274 - acc: 0.4405 - val_loss: 1.3566 - val_acc: 0.4394\n",
      "Epoch 165/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2552 - acc: 0.4627 - val_loss: 1.3980 - val_acc: 0.4091\n",
      "Epoch 166/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2417 - acc: 0.4730 - val_loss: 1.4368 - val_acc: 0.4485\n",
      "Epoch 167/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2171 - acc: 0.4694 - val_loss: 1.5203 - val_acc: 0.3758\n",
      "Epoch 168/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2171 - acc: 0.4444 - val_loss: 1.6126 - val_acc: 0.3455\n",
      "Epoch 169/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2220 - acc: 0.4430 - val_loss: 1.5440 - val_acc: 0.3455\n",
      "Epoch 170/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.2108 - acc: 0.4599 - val_loss: 1.4736 - val_acc: 0.3697\n",
      "Epoch 171/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2044 - acc: 0.4603 - val_loss: 1.3867 - val_acc: 0.4424\n",
      "Epoch 172/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1982 - acc: 0.4613 - val_loss: 1.3522 - val_acc: 0.4545\n",
      "Epoch 173/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2174 - acc: 0.4783 - val_loss: 1.3946 - val_acc: 0.4212\n",
      "Epoch 174/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1960 - acc: 0.4843 - val_loss: 1.4042 - val_acc: 0.4091\n",
      "Epoch 175/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1757 - acc: 0.4949 - val_loss: 1.3604 - val_acc: 0.4364\n",
      "Epoch 176/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2157 - acc: 0.4857 - val_loss: 1.4116 - val_acc: 0.4030\n",
      "Epoch 177/300\n",
      "2831/2831 [==============================] - 0s 90us/step - loss: 1.1791 - acc: 0.4822 - val_loss: 1.4474 - val_acc: 0.3909\n",
      "Epoch 178/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1803 - acc: 0.4698 - val_loss: 1.5992 - val_acc: 0.3515\n",
      "Epoch 179/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.2642 - acc: 0.4154 - val_loss: 1.4683 - val_acc: 0.3970\n",
      "Epoch 180/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1784 - acc: 0.4740 - val_loss: 1.5481 - val_acc: 0.3697\n",
      "Epoch 181/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.2141 - acc: 0.4401 - val_loss: 1.6936 - val_acc: 0.3394\n",
      "Epoch 182/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.2792 - acc: 0.4172 - val_loss: 1.4865 - val_acc: 0.3515\n",
      "Epoch 183/300\n",
      "2831/2831 [==============================] - 0s 74us/step - loss: 1.1680 - acc: 0.4528 - val_loss: 1.4719 - val_acc: 0.3697\n",
      "Epoch 184/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1551 - acc: 0.4712 - val_loss: 1.4157 - val_acc: 0.4030\n",
      "Epoch 185/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2327 - acc: 0.4274 - val_loss: 1.3359 - val_acc: 0.4152\n",
      "Epoch 186/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2434 - acc: 0.4645 - val_loss: 1.3906 - val_acc: 0.4333\n",
      "Epoch 187/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1727 - acc: 0.4903 - val_loss: 1.3383 - val_acc: 0.4364\n",
      "Epoch 188/300\n",
      "2831/2831 [==============================] - 0s 99us/step - loss: 1.2415 - acc: 0.4659 - val_loss: 1.3776 - val_acc: 0.3879\n",
      "Epoch 189/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.1981 - acc: 0.4885 - val_loss: 1.3716 - val_acc: 0.4273\n",
      "Epoch 190/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1489 - acc: 0.4868 - val_loss: 1.3623 - val_acc: 0.4333\n",
      "Epoch 191/300\n",
      "2831/2831 [==============================] - 0s 89us/step - loss: 1.1934 - acc: 0.4875 - val_loss: 1.3780 - val_acc: 0.4606\n",
      "Epoch 192/300\n",
      "2831/2831 [==============================] - 0s 84us/step - loss: 1.2586 - acc: 0.4804 - val_loss: 1.4662 - val_acc: 0.3909\n",
      "Epoch 193/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1474 - acc: 0.4769 - val_loss: 1.4948 - val_acc: 0.3788\n",
      "Epoch 194/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1902 - acc: 0.4415 - val_loss: 1.6298 - val_acc: 0.3242\n",
      "Epoch 195/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.2277 - acc: 0.3995 - val_loss: 1.4506 - val_acc: 0.4030\n",
      "Epoch 196/300\n",
      "2831/2831 [==============================] - 0s 95us/step - loss: 1.1300 - acc: 0.4910 - val_loss: 1.4271 - val_acc: 0.4061\n",
      "Epoch 197/300\n",
      "2831/2831 [==============================] - 0s 94us/step - loss: 1.1368 - acc: 0.4815 - val_loss: 1.4634 - val_acc: 0.4394\n",
      "Epoch 198/300\n",
      "2831/2831 [==============================] - 0s 87us/step - loss: 1.1988 - acc: 0.4649 - val_loss: 1.6116 - val_acc: 0.3697\n",
      "Epoch 199/300\n",
      "2831/2831 [==============================] - 0s 93us/step - loss: 1.2567 - acc: 0.4115 - val_loss: 1.5934 - val_acc: 0.3818\n",
      "Epoch 200/300\n",
      "2831/2831 [==============================] - 0s 86us/step - loss: 1.2071 - acc: 0.4465 - val_loss: 1.4980 - val_acc: 0.3667\n",
      "Epoch 201/300\n",
      "2831/2831 [==============================] - 0s 71us/step - loss: 1.1850 - acc: 0.4571 - val_loss: 1.5064 - val_acc: 0.3788\n",
      "Epoch 202/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1930 - acc: 0.4673 - val_loss: 1.6453 - val_acc: 0.3364\n",
      "Epoch 203/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.2218 - acc: 0.4256 - val_loss: 1.4651 - val_acc: 0.4000\n",
      "Epoch 204/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.1399 - acc: 0.4797 - val_loss: 1.4483 - val_acc: 0.4000\n",
      "Epoch 205/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1199 - acc: 0.4769 - val_loss: 1.4908 - val_acc: 0.3970\n",
      "Epoch 206/300\n",
      "2831/2831 [==============================] - 0s 75us/step - loss: 1.1641 - acc: 0.4677 - val_loss: 1.5551 - val_acc: 0.3848\n",
      "Epoch 207/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1809 - acc: 0.4468 - val_loss: 1.4579 - val_acc: 0.4030\n",
      "Epoch 208/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1179 - acc: 0.4942 - val_loss: 1.5012 - val_acc: 0.4000\n",
      "Epoch 209/300\n",
      "2831/2831 [==============================] - 0s 83us/step - loss: 1.1960 - acc: 0.4624 - val_loss: 1.6339 - val_acc: 0.3424\n",
      "Epoch 210/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2185 - acc: 0.4497 - val_loss: 1.4167 - val_acc: 0.3879\n",
      "Epoch 211/300\n",
      "2831/2831 [==============================] - 0s 73us/step - loss: 1.1511 - acc: 0.4680 - val_loss: 1.3854 - val_acc: 0.4121\n",
      "Epoch 212/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.1442 - acc: 0.4783 - val_loss: 1.3548 - val_acc: 0.4303\n",
      "Epoch 213/300\n",
      "2831/2831 [==============================] - 0s 88us/step - loss: 1.1438 - acc: 0.4836 - val_loss: 1.3540 - val_acc: 0.4212\n",
      "Epoch 214/300\n",
      "2831/2831 [==============================] - 0s 82us/step - loss: 1.1476 - acc: 0.4945 - val_loss: 1.3240 - val_acc: 0.4667\n",
      "Epoch 215/300\n",
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.1765 - acc: 0.4779 - val_loss: 1.3444 - val_acc: 0.4303\n",
      "Epoch 216/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.1347 - acc: 0.4984 - val_loss: 1.3801 - val_acc: 0.4485\n",
      "Epoch 217/300\n",
      "2831/2831 [==============================] - 0s 85us/step - loss: 1.2237 - acc: 0.4910 - val_loss: 1.3546 - val_acc: 0.4545\n",
      "Epoch 218/300\n",
      "2831/2831 [==============================] - 0s 103us/step - loss: 1.1539 - acc: 0.5072 - val_loss: 1.3922 - val_acc: 0.4061\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 76us/step - loss: 1.1131 - acc: 0.4875 - val_loss: 1.4102 - val_acc: 0.4242\n",
      "Epoch 220/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1351 - acc: 0.4896 - val_loss: 1.5721 - val_acc: 0.3758\n",
      "Epoch 221/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.2144 - acc: 0.4514 - val_loss: 1.5910 - val_acc: 0.3636\n",
      "Epoch 222/300\n",
      "2831/2831 [==============================] - 0s 72us/step - loss: 1.2047 - acc: 0.4150 - val_loss: 1.4730 - val_acc: 0.4212\n",
      "Epoch 223/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1480 - acc: 0.4857 - val_loss: 1.4065 - val_acc: 0.4515\n",
      "Epoch 224/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1234 - acc: 0.4995 - val_loss: 1.3568 - val_acc: 0.4455\n",
      "Epoch 225/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1370 - acc: 0.5079 - val_loss: 1.3363 - val_acc: 0.4606\n",
      "Epoch 226/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1475 - acc: 0.4860 - val_loss: 1.3375 - val_acc: 0.4152\n",
      "Epoch 227/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1318 - acc: 0.5030 - val_loss: 1.3697 - val_acc: 0.4182\n",
      "Epoch 228/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1085 - acc: 0.4963 - val_loss: 1.4140 - val_acc: 0.4182\n",
      "Epoch 229/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1560 - acc: 0.4744 - val_loss: 1.3604 - val_acc: 0.4545\n",
      "Epoch 230/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1324 - acc: 0.4913 - val_loss: 1.3748 - val_acc: 0.4424\n",
      "Epoch 231/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0931 - acc: 0.5041 - val_loss: 1.3137 - val_acc: 0.4606\n",
      "Epoch 232/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.2035 - acc: 0.4758 - val_loss: 1.3826 - val_acc: 0.4152\n",
      "Epoch 233/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.2122 - acc: 0.4758 - val_loss: 1.4135 - val_acc: 0.4455\n",
      "Epoch 234/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1262 - acc: 0.5030 - val_loss: 1.4528 - val_acc: 0.4515\n",
      "Epoch 235/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1260 - acc: 0.4910 - val_loss: 1.4125 - val_acc: 0.4576\n",
      "Epoch 236/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0917 - acc: 0.5079 - val_loss: 1.3361 - val_acc: 0.4576\n",
      "Epoch 237/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1287 - acc: 0.4956 - val_loss: 1.3186 - val_acc: 0.4333\n",
      "Epoch 238/300\n",
      "2831/2831 [==============================] - 0s 77us/step - loss: 1.2202 - acc: 0.4931 - val_loss: 1.4128 - val_acc: 0.4061\n",
      "Epoch 239/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0924 - acc: 0.5055 - val_loss: 1.3762 - val_acc: 0.4576\n",
      "Epoch 240/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0785 - acc: 0.5189 - val_loss: 1.3864 - val_acc: 0.4364\n",
      "Epoch 241/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1867 - acc: 0.4793 - val_loss: 1.3963 - val_acc: 0.4485\n",
      "Epoch 242/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1362 - acc: 0.5118 - val_loss: 1.3977 - val_acc: 0.4455\n",
      "Epoch 243/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1033 - acc: 0.5016 - val_loss: 1.4117 - val_acc: 0.4485\n",
      "Epoch 244/300\n",
      "2831/2831 [==============================] - 0s 80us/step - loss: 1.0978 - acc: 0.5034 - val_loss: 1.6779 - val_acc: 0.3182\n",
      "Epoch 245/300\n",
      "2831/2831 [==============================] - 0s 78us/step - loss: 1.2778 - acc: 0.3946 - val_loss: 1.5332 - val_acc: 0.3909\n",
      "Epoch 246/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1667 - acc: 0.4772 - val_loss: 1.4657 - val_acc: 0.4091\n",
      "Epoch 247/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1367 - acc: 0.4818 - val_loss: 1.5485 - val_acc: 0.3788\n",
      "Epoch 248/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1429 - acc: 0.4603 - val_loss: 1.4388 - val_acc: 0.4061\n",
      "Epoch 249/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0908 - acc: 0.4931 - val_loss: 1.5357 - val_acc: 0.4000\n",
      "Epoch 250/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1460 - acc: 0.4610 - val_loss: 1.4851 - val_acc: 0.4091\n",
      "Epoch 251/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0922 - acc: 0.4913 - val_loss: 1.3959 - val_acc: 0.4545\n",
      "Epoch 252/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0871 - acc: 0.4977 - val_loss: 1.3789 - val_acc: 0.4364\n",
      "Epoch 253/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1914 - acc: 0.4843 - val_loss: 1.3387 - val_acc: 0.4303\n",
      "Epoch 254/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1864 - acc: 0.4935 - val_loss: 1.3916 - val_acc: 0.4091\n",
      "Epoch 255/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0976 - acc: 0.4963 - val_loss: 1.3847 - val_acc: 0.4242\n",
      "Epoch 256/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.1002 - acc: 0.4984 - val_loss: 1.4132 - val_acc: 0.4364\n",
      "Epoch 257/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1238 - acc: 0.4970 - val_loss: 1.4294 - val_acc: 0.4030\n",
      "Epoch 258/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0903 - acc: 0.5002 - val_loss: 1.5636 - val_acc: 0.3697\n",
      "Epoch 259/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1572 - acc: 0.4437 - val_loss: 1.4740 - val_acc: 0.4091\n",
      "Epoch 260/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0778 - acc: 0.5062 - val_loss: 1.4702 - val_acc: 0.4121\n",
      "Epoch 261/300\n",
      "2831/2831 [==============================] - 0s 63us/step - loss: 1.1121 - acc: 0.5009 - val_loss: 1.7199 - val_acc: 0.3242\n",
      "Epoch 262/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.2269 - acc: 0.4030 - val_loss: 1.4053 - val_acc: 0.3939\n",
      "Epoch 263/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1065 - acc: 0.5069 - val_loss: 1.4067 - val_acc: 0.4333\n",
      "Epoch 264/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1089 - acc: 0.4921 - val_loss: 1.4615 - val_acc: 0.4121\n",
      "Epoch 265/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1195 - acc: 0.4906 - val_loss: 1.3979 - val_acc: 0.4545\n",
      "Epoch 266/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0613 - acc: 0.5136 - val_loss: 1.4946 - val_acc: 0.4030\n",
      "Epoch 267/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1249 - acc: 0.4719 - val_loss: 1.6131 - val_acc: 0.3606\n",
      "Epoch 268/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1267 - acc: 0.4649 - val_loss: 1.3980 - val_acc: 0.4273\n",
      "Epoch 269/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0591 - acc: 0.5224 - val_loss: 1.4786 - val_acc: 0.4091\n",
      "Epoch 270/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0949 - acc: 0.4829 - val_loss: 1.5720 - val_acc: 0.3788\n",
      "Epoch 271/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1615 - acc: 0.4638 - val_loss: 1.4343 - val_acc: 0.4030\n",
      "Epoch 272/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1245 - acc: 0.4617 - val_loss: 1.3543 - val_acc: 0.4485\n",
      "Epoch 273/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1864 - acc: 0.4666 - val_loss: 1.3597 - val_acc: 0.4303\n",
      "Epoch 274/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0895 - acc: 0.5090 - val_loss: 1.3475 - val_acc: 0.4758\n",
      "Epoch 275/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1035 - acc: 0.5228 - val_loss: 1.3645 - val_acc: 0.4424\n",
      "Epoch 276/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0987 - acc: 0.5196 - val_loss: 1.3895 - val_acc: 0.4667\n",
      "Epoch 277/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0685 - acc: 0.5277 - val_loss: 1.3755 - val_acc: 0.4424\n",
      "Epoch 278/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1428 - acc: 0.5019 - val_loss: 1.3740 - val_acc: 0.4273\n",
      "Epoch 279/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0971 - acc: 0.5231 - val_loss: 1.3637 - val_acc: 0.4576\n",
      "Epoch 280/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0553 - acc: 0.5189 - val_loss: 1.3546 - val_acc: 0.4333\n",
      "Epoch 281/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0748 - acc: 0.5062 - val_loss: 1.2974 - val_acc: 0.4606\n",
      "Epoch 282/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1844 - acc: 0.4913 - val_loss: 1.3901 - val_acc: 0.4242\n",
      "Epoch 283/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0577 - acc: 0.5200 - val_loss: 1.4000 - val_acc: 0.4242\n",
      "Epoch 284/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0575 - acc: 0.5016 - val_loss: 1.3790 - val_acc: 0.4606\n",
      "Epoch 285/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1519 - acc: 0.4680 - val_loss: 1.3201 - val_acc: 0.4970\n",
      "Epoch 286/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0849 - acc: 0.5136 - val_loss: 1.3219 - val_acc: 0.4758\n",
      "Epoch 287/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0672 - acc: 0.5175 - val_loss: 1.3561 - val_acc: 0.4667\n",
      "Epoch 288/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1575 - acc: 0.5048 - val_loss: 1.3996 - val_acc: 0.4455\n",
      "Epoch 289/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0601 - acc: 0.5355 - val_loss: 1.5074 - val_acc: 0.4303\n",
      "Epoch 290/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0921 - acc: 0.4871 - val_loss: 1.5018 - val_acc: 0.4455\n",
      "Epoch 291/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.0722 - acc: 0.4949 - val_loss: 1.4336 - val_acc: 0.4515\n",
      "Epoch 292/300\n",
      "2831/2831 [==============================] - 0s 79us/step - loss: 1.0447 - acc: 0.5214 - val_loss: 1.5693 - val_acc: 0.3879\n",
      "Epoch 293/300\n",
      "2831/2831 [==============================] - 0s 68us/step - loss: 1.1756 - acc: 0.4610 - val_loss: 1.4526 - val_acc: 0.3939\n",
      "Epoch 294/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.1284 - acc: 0.4822 - val_loss: 1.3809 - val_acc: 0.4455\n",
      "Epoch 295/300\n",
      "2831/2831 [==============================] - 0s 66us/step - loss: 1.0571 - acc: 0.5076 - val_loss: 1.3414 - val_acc: 0.4515\n",
      "Epoch 296/300\n",
      "2831/2831 [==============================] - 0s 67us/step - loss: 1.0427 - acc: 0.5185 - val_loss: 1.3148 - val_acc: 0.4939\n",
      "Epoch 297/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.1051 - acc: 0.5143 - val_loss: 1.3556 - val_acc: 0.4212\n",
      "Epoch 298/300\n",
      "2831/2831 [==============================] - 0s 64us/step - loss: 1.0689 - acc: 0.5147 - val_loss: 1.3494 - val_acc: 0.4485\n",
      "Epoch 299/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.0383 - acc: 0.5249 - val_loss: 1.3253 - val_acc: 0.4636\n",
      "Epoch 300/300\n",
      "2831/2831 [==============================] - 0s 65us/step - loss: 1.1410 - acc: 0.5097 - val_loss: 1.4635 - val_acc: 0.4273\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>1.348672</td>\n",
       "      <td>0.460606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>1.534324</td>\n",
       "      <td>0.412121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.490066</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>1.583446</td>\n",
       "      <td>0.378788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>1.463503</td>\n",
       "      <td>0.427273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        89.0  0.146067  0.741573   0.966292               0.22   \n",
       "1       120.0  0.116667  0.658333   0.925000               0.22   \n",
       "2        83.0  0.168675  0.710843   0.939759               0.22   \n",
       "3       122.0  0.122951  0.672131   0.934426               0.24   \n",
       "4        81.0  0.160494  0.728395   0.962963               0.26   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.78                0.96             0.095652   \n",
       "1              0.80                0.96             0.076433   \n",
       "2              0.76                0.96             0.080357   \n",
       "3              0.84                0.96             0.092715   \n",
       "4              0.84                0.96             0.082090   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.521739              0.843478  1.408911  0.451515  \n",
       "1            0.452229              0.866242  1.348672  0.460606  \n",
       "2            0.508929              0.848214  1.534324  0.412121  \n",
       "3            0.490066              0.887417  1.583446  0.378788  \n",
       "4            0.514925              0.895522  1.463503  0.427273  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_cluster_models = []\n",
    "df_w2v_analysis = pd.DataFrame()\n",
    "#, kernel_regularizer=regularizers.l1(0.0001)\n",
    "for num in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_shape=(631,), activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(25, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.add(Dropout(.35))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    ada = keras.optimizers.Adagrad()\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "    sgd = keras.optimizers.SGD(lr=0.75)\n",
    "    model.compile(optimizer=rms,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    w2v_model_2 = model.fit(x=X_train_w2v, y=y_cat_train_w2v, \n",
    "          batch_size=2000, \n",
    "          epochs=300, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test_w2v, y_cat_test_w2v),\n",
    "          callbacks=None,\n",
    "          class_weight = class_weight)\n",
    "    \n",
    "    predictions = model.predict(X_test_w2v)\n",
    "    loss = w2v_model_2.history['val_loss'][-1]\n",
    "    acc = w2v_model_2.history['val_acc'][-1]\n",
    "    gain_pred, gain_true_large, gain_true, gain_stay_true, four_five_split_large, four_five_split, four_five_split_mean, predicted_classes_gain_true, predicted_classes_gain_large_true, predicted_classes_gain_mean, df_metrics_w2v = model_metrics(predictions, y_cat_test_w2v, w2v_test_merge)\n",
    "    df_w2v_analysis.loc[num,'pred_count'] = gain_pred\n",
    "    df_w2v_analysis.loc[num,'gain_10%'] = gain_true_large\n",
    "    df_w2v_analysis.loc[num,'gain_3%'] = gain_true\n",
    "    df_w2v_analysis.loc[num,'gain_mean'] = gain_stay_true\n",
    "    df_w2v_analysis.loc[num,'top_pred_prob_10%'] = four_five_split_large\n",
    "    df_w2v_analysis.loc[num,'top_pred_prob_3%'] = four_five_split\n",
    "    df_w2v_analysis.loc[num,'top_pred_prob_mean'] = four_five_split_mean\n",
    "    df_w2v_analysis.loc[num,'model_pred_prob_10%'] = predicted_classes_gain_large_true\n",
    "    df_w2v_analysis.loc[num,'model_pred_prob_3%'] = predicted_classes_gain_true\n",
    "    df_w2v_analysis.loc[num,'model_pred_prob_mean'] = predicted_classes_gain_mean\n",
    "    df_w2v_analysis.loc[num,'loss'] = loss\n",
    "    df_w2v_analysis.loc[num,'acc'] = acc\n",
    "    print(num)\n",
    "df_300_w = df_w2v_analysis\n",
    "df_w2v_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>1.485391</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>1.418552</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.932692</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>1.582820</td>\n",
       "      <td>0.381818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.445205</td>\n",
       "      <td>0.883562</td>\n",
       "      <td>1.391745</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>1.708369</td>\n",
       "      <td>0.381818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        40.0  0.200000  0.825000   0.950000               0.18   \n",
       "1        73.0  0.178082  0.753425   0.958904               0.22   \n",
       "2       104.0  0.134615  0.711538   0.932692               0.22   \n",
       "3        83.0  0.156627  0.722892   0.963855               0.24   \n",
       "4        99.0  0.131313  0.707071   0.959596               0.20   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.84                0.96             0.076087   \n",
       "1              0.84                0.96             0.099174   \n",
       "2              0.84                0.96             0.075472   \n",
       "3              0.80                0.96             0.089041   \n",
       "4              0.80                0.96             0.086614   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.510870              0.902174  1.485391  0.451515  \n",
       "1            0.504132              0.859504  1.418552  0.451515  \n",
       "2            0.509434              0.830189  1.582820  0.381818  \n",
       "3            0.445205              0.883562  1.391745  0.484848  \n",
       "4            0.496063              0.874016  1.708369  0.381818  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_500_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>1.521373</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>1.509003</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.879747</td>\n",
       "      <td>1.464449</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>1.489063</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.103175</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.368972</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        80.0  0.175000  0.762500   0.962500               0.22   \n",
       "1        49.0  0.204082  0.816327   0.959184               0.22   \n",
       "2       109.0  0.137615  0.715596   0.963303               0.22   \n",
       "3        41.0  0.219512  0.804878   0.951220               0.22   \n",
       "4        86.0  0.162791  0.709302   0.953488               0.24   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.80                0.96             0.091743   \n",
       "1              0.84                0.96             0.093023   \n",
       "2              0.80                0.96             0.088608   \n",
       "3              0.84                0.96             0.112500   \n",
       "4              0.82                0.96             0.103175   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.550459              0.834862  1.521373  0.424242  \n",
       "1            0.593023              0.906977  1.509003  0.451515  \n",
       "2            0.443038              0.879747  1.464449  0.451515  \n",
       "3            0.625000              0.925000  1.489063  0.451515  \n",
       "4            0.539683              0.928571  1.368972  0.515152  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_450_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.414496</td>\n",
       "      <td>0.432024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.069519</td>\n",
       "      <td>0.491979</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>1.475380</td>\n",
       "      <td>0.416918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.539130</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>1.399635</td>\n",
       "      <td>0.459215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>0.496403</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>1.491990</td>\n",
       "      <td>0.438066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.854015</td>\n",
       "      <td>1.385046</td>\n",
       "      <td>0.471299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        87.0  0.094972  0.758621   0.977011           0.303030   \n",
       "1       137.0  0.094972  0.671533   0.948905           0.303030   \n",
       "2        54.0  0.094972  0.777778   0.962963           0.242424   \n",
       "3       100.0  0.094972  0.720000   0.960000           0.272727   \n",
       "4       111.0  0.094972  0.684685   0.945946           0.303030   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.939394             0.087302   \n",
       "1          0.848485            0.939394             0.069519   \n",
       "2          0.818182            0.939394             0.069565   \n",
       "3          0.787879            0.939394             0.086331   \n",
       "4          0.787879            0.939394             0.072993   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.539683              0.904762  1.414496  0.432024  \n",
       "1            0.491979              0.866310  1.475380  0.416918  \n",
       "2            0.539130              0.886957  1.399635  0.459215  \n",
       "3            0.496403              0.848921  1.491990  0.438066  \n",
       "4            0.481752              0.854015  1.385046  0.471299  "
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_400_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>1.543366</td>\n",
       "      <td>0.450151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.486957</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>1.527017</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>1.605956</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.634043</td>\n",
       "      <td>0.444109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>1.477137</td>\n",
       "      <td>0.471299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        52.0  0.094972  0.788462   0.961538           0.272727   \n",
       "1        45.0  0.094972  0.755556   0.955556           0.272727   \n",
       "2        44.0  0.094972  0.772727   0.954545           0.272727   \n",
       "3        47.0  0.094972  0.872340   0.978723           0.242424   \n",
       "4        70.0  0.094972  0.771429   0.971429           0.212121   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.969697             0.090164   \n",
       "1          0.787879            0.939394             0.095652   \n",
       "2          0.757576            0.939394             0.105263   \n",
       "3          0.787879            0.969697             0.064103   \n",
       "4          0.787879            0.969697             0.085714   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.557377              0.877049  1.543366  0.450151  \n",
       "1            0.486957              0.878261  1.527017  0.456193  \n",
       "2            0.526316              0.921053  1.605956  0.456193  \n",
       "3            0.615385              0.923077  1.634043  0.444109  \n",
       "4            0.528571              0.878571  1.477137  0.471299  "
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without weights, 400 epochs\n",
    "df_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>1.348672</td>\n",
       "      <td>0.460606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>1.534324</td>\n",
       "      <td>0.412121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.490066</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>1.583446</td>\n",
       "      <td>0.378788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>1.463503</td>\n",
       "      <td>0.427273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        89.0  0.146067  0.741573   0.966292               0.22   \n",
       "1       120.0  0.116667  0.658333   0.925000               0.22   \n",
       "2        83.0  0.168675  0.710843   0.939759               0.22   \n",
       "3       122.0  0.122951  0.672131   0.934426               0.24   \n",
       "4        81.0  0.160494  0.728395   0.962963               0.26   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.78                0.96             0.095652   \n",
       "1              0.80                0.96             0.076433   \n",
       "2              0.76                0.96             0.080357   \n",
       "3              0.84                0.96             0.092715   \n",
       "4              0.84                0.96             0.082090   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.521739              0.843478  1.408911  0.451515  \n",
       "1            0.452229              0.866242  1.348672  0.460606  \n",
       "2            0.508929              0.848214  1.534324  0.412121  \n",
       "3            0.490066              0.887417  1.583446  0.378788  \n",
       "4            0.514925              0.895522  1.463503  0.427273  "
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best\n",
    "df_300_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.459854</td>\n",
       "      <td>0.868613</td>\n",
       "      <td>1.530630</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>1.518007</td>\n",
       "      <td>0.418182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>1.780207</td>\n",
       "      <td>0.430303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>1.715226</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.168831</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>1.582686</td>\n",
       "      <td>0.463636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        62.0  0.193548  0.790323   0.951613               0.20   \n",
       "1        99.0  0.141414  0.717172   0.949495               0.20   \n",
       "2        89.0  0.146067  0.741573   0.943820               0.22   \n",
       "3        44.0  0.181818  0.818182   0.954545               0.18   \n",
       "4        77.0  0.168831  0.779221   0.961039               0.24   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.76                0.98             0.087591   \n",
       "1              0.86                1.00             0.069149   \n",
       "2              0.78                0.96             0.118182   \n",
       "3              0.82                0.96             0.074627   \n",
       "4              0.84                0.96             0.105691   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.459854              0.868613  1.530630  0.500000  \n",
       "1            0.468085              0.851064  1.518007  0.418182  \n",
       "2            0.490909              0.845455  1.780207  0.430303  \n",
       "3            0.552239              0.880597  1.715226  0.400000  \n",
       "4            0.528455              0.878049  1.582686  0.463636  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>1.230999</td>\n",
       "      <td>0.447130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.086294</td>\n",
       "      <td>0.477157</td>\n",
       "      <td>0.832487</td>\n",
       "      <td>1.229504</td>\n",
       "      <td>0.447130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.064220</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.857798</td>\n",
       "      <td>1.281605</td>\n",
       "      <td>0.398792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.268600</td>\n",
       "      <td>0.416918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.282214</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        85.0  0.094972  0.705882   0.941176           0.242424   \n",
       "1       123.0  0.094972  0.674797   0.934959           0.272727   \n",
       "2       112.0  0.094972  0.678571   0.928571           0.272727   \n",
       "3        61.0  0.094972  0.819672   0.967213           0.242424   \n",
       "4        60.0  0.094972  0.783333   0.966667           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.757576            0.939394             0.081522   \n",
       "1          0.727273            0.939394             0.086294   \n",
       "2          0.848485            0.969697             0.064220   \n",
       "3          0.787879            0.939394             0.092308   \n",
       "4          0.757576            0.939394             0.090909   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.434783              0.847826  1.230999  0.447130  \n",
       "1            0.477157              0.832487  1.229504  0.447130  \n",
       "2            0.440367              0.857798  1.281605  0.398792  \n",
       "3            0.507692              0.846154  1.268600  0.416918  \n",
       "4            0.484848              0.863636  1.282214  0.456193  "
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without weights, 225 epochs\n",
    "df_225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.570681</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.088372</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>1.429407</td>\n",
       "      <td>0.410876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>1.344073</td>\n",
       "      <td>0.471299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>1.387137</td>\n",
       "      <td>0.429003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>1.544066</td>\n",
       "      <td>0.380665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>1.357028</td>\n",
       "      <td>0.465257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       191.0  0.094972  0.570681   0.926702           0.272727   \n",
       "1        71.0  0.094972  0.732394   0.957746           0.303030   \n",
       "2        59.0  0.094972  0.796610   0.966102           0.303030   \n",
       "3       119.0  0.094972  0.663866   0.941176           0.303030   \n",
       "4       142.0  0.094972  0.640845   0.929577           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.757576            0.909091             0.088372   \n",
       "1          0.818182            0.939394             0.071429   \n",
       "2          0.818182            0.939394             0.125000   \n",
       "3          0.818182            0.969697             0.083916   \n",
       "4          0.787879            0.969697             0.078125   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.488372              0.879070  1.429407  0.410876  \n",
       "1            0.428571              0.842857  1.344073  0.471299  \n",
       "2            0.556818              0.840909  1.387137  0.429003  \n",
       "3            0.496503              0.860140  1.544066  0.380665  \n",
       "4            0.447917              0.843750  1.357028  0.465257  "
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights, 225 epochs\n",
    "df_225_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>1.198510</td>\n",
       "      <td>0.407855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.068293</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>1.237291</td>\n",
       "      <td>0.429003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.408088</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>1.319757</td>\n",
       "      <td>0.386707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.584699</td>\n",
       "      <td>0.923497</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>0.433180</td>\n",
       "      <td>0.843318</td>\n",
       "      <td>1.329758</td>\n",
       "      <td>0.371601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.524038</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.331992</td>\n",
       "      <td>0.419940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0       128.0  0.094972  0.664062   0.937500           0.242424   \n",
       "1       154.0  0.094972  0.597403   0.909091           0.272727   \n",
       "2       249.0  0.094972  0.469880   0.867470           0.303030   \n",
       "3       183.0  0.094972  0.584699   0.923497           0.242424   \n",
       "4       208.0  0.094972  0.524038   0.913462           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.757576            0.939394             0.061404   \n",
       "1          0.727273            0.939394             0.068293   \n",
       "2          0.787879            0.969697             0.066176   \n",
       "3          0.818182            0.969697             0.073733   \n",
       "4          0.757576            0.909091             0.065041   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.421053              0.850877  1.198510  0.407855  \n",
       "1            0.448780              0.863415  1.237291  0.429003  \n",
       "2            0.408088              0.845588  1.319757  0.386707  \n",
       "3            0.433180              0.843318  1.329758  0.371601  \n",
       "4            0.439024              0.833333  1.331992  0.419940  "
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.059113</td>\n",
       "      <td>0.394089</td>\n",
       "      <td>0.832512</td>\n",
       "      <td>1.342970</td>\n",
       "      <td>0.456193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.434389</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>1.422866</td>\n",
       "      <td>0.432024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.575269</td>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.073913</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>1.432149</td>\n",
       "      <td>0.404834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.435424</td>\n",
       "      <td>0.837638</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.402685</td>\n",
       "      <td>0.828859</td>\n",
       "      <td>1.555367</td>\n",
       "      <td>0.344411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211.0</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.082251</td>\n",
       "      <td>0.471861</td>\n",
       "      <td>0.852814</td>\n",
       "      <td>1.608255</td>\n",
       "      <td>0.350453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        62.0  0.094972  0.741935   0.951613           0.272727   \n",
       "1       179.0  0.094972  0.569832   0.927374           0.272727   \n",
       "2       186.0  0.094972  0.575269   0.930108           0.272727   \n",
       "3       271.0  0.094972  0.435424   0.837638           0.272727   \n",
       "4       211.0  0.094972  0.530806   0.914692           0.272727   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0          0.848485            0.969697             0.059113   \n",
       "1          0.727273            0.939394             0.063348   \n",
       "2          0.727273            0.878788             0.073913   \n",
       "3          0.818182            0.969697             0.060403   \n",
       "4          0.818182            0.969697             0.082251   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.394089              0.832512  1.342970  0.456193  \n",
       "1            0.434389              0.837104  1.422866  0.432024  \n",
       "2            0.426087              0.843478  1.432149  0.404834  \n",
       "3            0.402685              0.828859  1.555367  0.344411  \n",
       "4            0.471861              0.852814  1.608255  0.350453  "
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_175_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean metrics and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ = df_300_w.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_count</th>\n",
       "      <th>gain_10%</th>\n",
       "      <th>gain_3%</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>0.451515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>1.348672</td>\n",
       "      <td>0.460606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>1.534324</td>\n",
       "      <td>0.412121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.490066</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>1.583446</td>\n",
       "      <td>0.378788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>1.463503</td>\n",
       "      <td>0.427273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_count  gain_10%   gain_3%  gain_mean  top_pred_prob_10%  \\\n",
       "0        89.0  0.146067  0.741573   0.966292               0.22   \n",
       "1       120.0  0.116667  0.658333   0.925000               0.22   \n",
       "2        83.0  0.168675  0.710843   0.939759               0.22   \n",
       "3       122.0  0.122951  0.672131   0.934426               0.24   \n",
       "4        81.0  0.160494  0.728395   0.962963               0.26   \n",
       "\n",
       "   top_pred_prob_3%  top_pred_prob_mean  model_pred_prob_10%  \\\n",
       "0              0.78                0.96             0.095652   \n",
       "1              0.80                0.96             0.076433   \n",
       "2              0.76                0.96             0.080357   \n",
       "3              0.84                0.96             0.092715   \n",
       "4              0.84                0.96             0.082090   \n",
       "\n",
       "   model_pred_prob_3%  model_pred_prob_mean      loss       acc  \n",
       "0            0.521739              0.843478  1.408911  0.451515  \n",
       "1            0.452229              0.866242  1.348672  0.460606  \n",
       "2            0.508929              0.848214  1.534324  0.412121  \n",
       "3            0.490066              0.887417  1.583446  0.378788  \n",
       "4            0.514925              0.895522  1.463503  0.427273  "
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_300_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_count              99.000000\n",
       "gain_10%                 0.142971\n",
       "gain_3%                  0.702255\n",
       "gain_mean                0.945688\n",
       "top_pred_prob_10%        0.232000\n",
       "top_pred_prob_3%         0.804000\n",
       "top_pred_prob_mean       0.960000\n",
       "model_pred_prob_10%      0.085449\n",
       "model_pred_prob_3%       0.497578\n",
       "model_pred_prob_mean     0.868175\n",
       "loss                     1.467771\n",
       "acc                      0.426061\n",
       "dtype: float64"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_ = pd.DataFrame(w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_.columns=['w2v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred_count</th>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_10%</th>\n",
       "      <td>0.142971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_3%</th>\n",
       "      <td>0.702255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_mean</th>\n",
       "      <td>0.945688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <td>0.085449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <td>0.497578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <td>0.868175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>1.467771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.426061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            w2v\n",
       "pred_count            99.000000\n",
       "gain_10%               0.142971\n",
       "gain_3%                0.702255\n",
       "gain_mean              0.945688\n",
       "top_pred_prob_10%      0.232000\n",
       "top_pred_prob_3%       0.804000\n",
       "top_pred_prob_mean     0.960000\n",
       "model_pred_prob_10%    0.085449\n",
       "model_pred_prob_3%     0.497578\n",
       "model_pred_prob_mean   0.868175\n",
       "loss                   1.467771\n",
       "acc                    0.426061"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics_tvm = df_metrics_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics_tvm.to_csv('tvm_metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x150417f60>"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14b94eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics_w2v['y_true'] = y_test_w2v\n",
    "data_for_model = df_metrics_w2v[['top_vs_mean_low', 'y_true']]\n",
    "ax_sca_w2v = sns.regplot(data_for_model['top_vs_mean_low'], data_for_model['y_true'], fit_reg=False, color='purple')\n",
    "ax_sca_w2v.set_title('w2v') \n",
    "ax_sca_w2v.set(xlabel='Prediction Certainty', ylabel='Growth')\n",
    "ax_sca_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1d51fc748>, <matplotlib.text.Text at 0x1d51f22b0>]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d45fc780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_classes = y_cat_test_w2v.values.argmax(axis=1)\n",
    "ax_w2v = sns.violinplot(x=true_classes, y=df_metrics_w2v['top_vs_mean_low'], palette=\"plasma\") \n",
    "ax_w2v.set_title('w2v') \n",
    "ax_w2v.set(xlabel='True classes', ylabel='Positive prediction difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1d3607f28>, <matplotlib.text.Text at 0x1d37e2a58>]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7t1KEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d5561e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_w2v_kde = sns.kdeplot(df_metrics_w2v['gain_true'], df_metrics_w2v['top_vs_mean_low'], n_levels=90, cmap=\"Purples_d\")\n",
    "ax_w2v_kde.set_title('w2v')\n",
    "ax_w2v_kde.set(xlabel='Loss vs Gain', ylabel='Positive prediction difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_b = df_175_w_b.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_b = pd.DataFrame(w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_b.columns=['business']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred_count</th>\n",
       "      <td>124.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_10%</th>\n",
       "      <td>0.118432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_3%</th>\n",
       "      <td>0.694502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_mean</th>\n",
       "      <td>0.946651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <td>0.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <td>0.091802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <td>0.536223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <td>0.900136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>1.296210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.477946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        business\n",
       "pred_count            124.400000\n",
       "gain_10%                0.118432\n",
       "gain_3%                 0.694502\n",
       "gain_mean               0.946651\n",
       "top_pred_prob_10%       0.228000\n",
       "top_pred_prob_3%        0.876000\n",
       "top_pred_prob_mean      0.972000\n",
       "model_pred_prob_10%     0.091802\n",
       "model_pred_prob_3%      0.536223\n",
       "model_pred_prob_mean    0.900136\n",
       "loss                    1.296210\n",
       "acc                     0.477946"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cd1525f8>"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncK4HAqA25KEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cd141240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics_b['y_true'] = y_test_business\n",
    "data_for_model = df_metrics_b[['top_vs_mean_low', 'y_true']]\n",
    "ax_sca_b = sns.regplot(data_for_model['top_vs_mean_low'], data_for_model['y_true'], fit_reg=False, color='purple')\n",
    "ax_sca_b.set_title('Business') \n",
    "ax_sca_b.set(xlabel='Prediction Certainty', ylabel='Growth')\n",
    "ax_sca_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1d465d748>, <matplotlib.text.Text at 0x1d4669898>]"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d35d62b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_classes = y_cat_test.values.argmax(axis=1)\n",
    "ax_business = sns.violinplot(x=true_classes, y=df_metrics_b['top_vs_mean_low'], palette=\"plasma\")\n",
    "ax_business.set_title('business')\n",
    "ax_business.set(xlabel='True classes', ylabel='Positive prediction difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1d5555f60>, <matplotlib.text.Text at 0x1d66570b8>]"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noQmHhoaGhkab+P8tfc5hMn+P/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d661b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_business_kde = sns.kdeplot(df_metrics_b['gain_true'], df_metrics_b['top_vs_mean_low'], n_levels=90, cmap=\"Purples_d\")\n",
    "ax_business_kde.set_title('business')\n",
    "ax_business_kde.set(xlabel='Loss vs Gain', ylabel='Positive prediction difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zillow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred_count</th>\n",
       "      <td>126.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_10%</th>\n",
       "      <td>0.133799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_3%</th>\n",
       "      <td>0.709302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_mean</th>\n",
       "      <td>0.951756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <td>0.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <td>0.087084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <td>0.491733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <td>0.874210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>1.356700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.504532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Zillow\n",
       "pred_count            126.800000\n",
       "gain_10%                0.133799\n",
       "gain_3%                 0.709302\n",
       "gain_mean               0.951756\n",
       "top_pred_prob_10%       0.228000\n",
       "top_pred_prob_3%        0.796000\n",
       "top_pred_prob_mean      0.940000\n",
       "model_pred_prob_10%     0.087084\n",
       "model_pred_prob_3%      0.491733\n",
       "model_pred_prob_mean    0.874210\n",
       "loss                    1.356700\n",
       "acc                     0.504532"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_z = df_175_w_z.mean()\n",
    "w_z = pd.DataFrame(w_z)\n",
    "w_z.columns=['Zillow']\n",
    "w_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_merge_1 = pd.merge(w_z, w_b, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zillow</th>\n",
       "      <th>business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred_count</th>\n",
       "      <td>126.800000</td>\n",
       "      <td>124.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_10%</th>\n",
       "      <td>0.133799</td>\n",
       "      <td>0.118432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_3%</th>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.694502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_mean</th>\n",
       "      <td>0.951756</td>\n",
       "      <td>0.946651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <td>0.087084</td>\n",
       "      <td>0.091802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <td>0.491733</td>\n",
       "      <td>0.536223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <td>0.874210</td>\n",
       "      <td>0.900136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>1.356700</td>\n",
       "      <td>1.296210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.504532</td>\n",
       "      <td>0.477946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Zillow    business\n",
       "pred_count            126.800000  124.400000\n",
       "gain_10%                0.133799    0.118432\n",
       "gain_3%                 0.709302    0.694502\n",
       "gain_mean               0.951756    0.946651\n",
       "top_pred_prob_10%       0.228000    0.228000\n",
       "top_pred_prob_3%        0.796000    0.876000\n",
       "top_pred_prob_mean      0.940000    0.972000\n",
       "model_pred_prob_10%     0.087084    0.091802\n",
       "model_pred_prob_3%      0.491733    0.536223\n",
       "model_pred_prob_mean    0.874210    0.900136\n",
       "loss                    1.356700    1.296210\n",
       "acc                     0.504532    0.477946"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_merge_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_merge_2 = pd.merge(metrics_merge_1, w_, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zillow</th>\n",
       "      <th>business</th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred_count</th>\n",
       "      <td>126.800000</td>\n",
       "      <td>124.400000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_10%</th>\n",
       "      <td>0.133799</td>\n",
       "      <td>0.118432</td>\n",
       "      <td>0.142971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_3%</th>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.694502</td>\n",
       "      <td>0.702255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain_mean</th>\n",
       "      <td>0.951756</td>\n",
       "      <td>0.946651</td>\n",
       "      <td>0.945688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_10%</th>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_3%</th>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_pred_prob_mean</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_10%</th>\n",
       "      <td>0.087084</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>0.085449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_3%</th>\n",
       "      <td>0.491733</td>\n",
       "      <td>0.536223</td>\n",
       "      <td>0.497578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_prob_mean</th>\n",
       "      <td>0.874210</td>\n",
       "      <td>0.900136</td>\n",
       "      <td>0.868175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>1.356700</td>\n",
       "      <td>1.296210</td>\n",
       "      <td>1.467771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.504532</td>\n",
       "      <td>0.477946</td>\n",
       "      <td>0.426061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Zillow    business        w2v\n",
       "pred_count            126.800000  124.400000  99.000000\n",
       "gain_10%                0.133799    0.118432   0.142971\n",
       "gain_3%                 0.709302    0.694502   0.702255\n",
       "gain_mean               0.951756    0.946651   0.945688\n",
       "top_pred_prob_10%       0.228000    0.228000   0.232000\n",
       "top_pred_prob_3%        0.796000    0.876000   0.804000\n",
       "top_pred_prob_mean      0.940000    0.972000   0.960000\n",
       "model_pred_prob_10%     0.087084    0.091802   0.085449\n",
       "model_pred_prob_3%      0.491733    0.536223   0.497578\n",
       "model_pred_prob_mean    0.874210    0.900136   0.868175\n",
       "loss                    1.356700    1.296210   1.467771\n",
       "acc                     0.504532    0.477946   0.426061"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_merge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d318a278>"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1612ae7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics_z['y_true'] = y_test\n",
    "data_for_model = df_metrics_z[['top_vs_mean_low', 'y_true']]\n",
    "ax_sca_z = sns.regplot(data_for_model['top_vs_mean_low'], data_for_model['y_true'], fit_reg=False, color='purple')\n",
    "ax_sca_z.set_title('Zillow') \n",
    "ax_sca_z.set(xlabel='Prediction Certainty', ylabel='Growth')\n",
    "ax_sca_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1d3601a20>, <matplotlib.text.Text at 0x1d31973c8>]"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXmYZGV59/+5T+3dXb0v07MvDDszKsOiASUCKkhgEtEI\nqGgQTKJEfoY3JiYur75ZjIm+Ku6JCwFZ3AaMQxCQoLxBZICBmWGZfenpnt67q7r2qvP8/qg6vcx0\nLd1Ty6mq53NddVWfOqfr3NNTdb7nvp97EaUUGo1Go9EUilFpAzQajUZTXWjh0Gg0Gs2C0MKh0Wg0\nmgWhhUOj0Wg0C0ILh0aj0WgWhBYOjUaj0SwILRwaTZEQkYdE5MbMz+8XkSdn7VMickrlrNNoioez\n0gZoNNWCiNwAfGueXY3Ap5VSV5TZJI2mImiPQ6MpEKXU3UqpptkP4DZgEPhOhc3TaMqGFg6NZpGI\nyGuB/wu8Wyk1ICL/LSIfLOD3WkTkThEZFpFDIvJ3ImJk9h0SkXMzP9+QCXGdldm+SUS2lPLfpNEU\nghYOjWYRiEgr8GPgc0qp/17gr38VaAHWAm8C3gd8ILPvCeCSzM9vAvYDb5y1/cSijdZoioQWDo1m\ngYiIAHcCO4F/XuDvOoB3A3+jlAoqpQ4C/wq8N3PIE6QFAuBi4B9nbWvh0NgCLRwazcL5OHAWcKNa\neJfQTsAFHJr12iFgWebnJ4CLRaQXcAD3A78nIqtJeynbF2+2RlMctHBoNAtARC4B/ha4Vik1sYi3\nGAESwKpZr60EjgIopfYCYeBW4NdKqQBwDLgFeFIpZS7eeo2mOGjh0GgKJOMF3AvcppR6fjHvoZRK\nkfYi/l5E/CKyCvgYcNesw54APsJMWOq/j9vWaCqKFg6NpnBuBnqAL4vI1HGPby7gfW4FQqQXvp8E\nfgh8d9b+JwA/8Oss2xpNRRE9yEmj0Wg0C0F7HBqNRqNZEFo4NBqNRrMgtHBoNBqNZkFo4dBoNBrN\ngqjJ7ridnZ1q9erVlTZDo9FoqoZnn312RCnVVcixNSkcq1evZtu2bZU2Q6PRaKoGETmU/6g0OlSl\n0Wg0mgWhhUOj0Wg0C0ILh0aj0WgWhBYOjUaj0SwILRwajUajWRBaODQajUazILRwaDQajWZBaOHQ\naDSaCqKUwjSraz5XRYVDRL4rIkMisjPL/ktEZFJEtmcenyq3jRqNRlNKPvnJT3Leeedxzz33VNqU\ngql05fj3gTuAO3Mc8xul1FXlMUej0WjKyyuvvATAnj17KmxJ4VTU41BK/RoYq6QNGo1GU0mikQgA\noVCowpYUTjWscbxBRF4UkYdE5KxsB4nILSKyTUS2DQ8Pl9M+jUajWTShUBiAcDhcYUsKx+7C8Ryw\nUim1AfgqsCXbgUqpbyulNimlNnV1FdTgUaPRaCqKUopQOO1xTE1NVdiawrG1cCilAkqpqczPWwGX\niHRW2CyNRqMpCtFolFQqBUBoKlhhawrH1sIhIktERDI/n0/a3tHKWqXRaDTFIRicEYtAMFBBSxZG\nRbOqROQe4BKgU0T6gE8DLgCl1DeBa4E/E5EkEAHerZRSFTJXo9FoikogkBaLzmaDYLB6QlUVFQ6l\n1HV59t9BOl1Xo9HUEMeOHeOhhx7iHe94B83NzZU2p2JYwtHb5mDHoRixWAyPx1Nhq/Jj61CVRqOp\nTe68807uuOMOnnzyyUqbUlEmJiYAWN6RvoefnJyspDkFo4VDo9GUHSu2H41GK2xJZRkfHwdmhMPa\ntjtaODQaTcWod+EYG0vXP6/sdMzZtjtaODQaTcWIZKqm65Xx8XEavQ46m7VwaDQaTU7i8ThQXW02\nSsHIyAhtTQ7amtKX4tHR6qg20MKh0ZSJXbt2ce2117Jv375Km1JxLMGopmrpUjAyMkxbo6LBY+B1\nG1RLuyQtHBpNmXj44Yc5cOAATz31VKVNqTiBTPZQvQvH0NAgHf50mKrd79DCodFo5kfXsEIgkBaO\nakk/LQWmaTI8PEKHP30Z7mgUBgePVdiqwtDCodGUmUwXnbrGSjudqJL001IwNjZGMpmiM+NxdDYb\nDGnh0Gg081HvHkc8Hmcq00p8ZGSkwtZUjmPH0iLR2Zy+DHc1OxgeHiWZTFbSrILQwqHRaMqKFcdv\n87oYHx+f7g5bbwwMDADQ3Zr2OLpaDFKmWRXrHFo4NJoyU+8ex9DQEACntDWSMs2qSUEtNtPCkanh\nsASkv7+/YjYVihYOTUk5cuQIH7zpgxw4cKDSptiGWCxWaRMqinXBPKPDP2e73jh69ChNPgeN3vRl\nuKdFC4dGA8AjjzzC89ufZ+vWrZU2peIkEglAC0dfXx8AZ3SmhePo0aOVNKdi9Pf309MycwnuanFg\nyMzfx85o4dCUBdM0K21CxbHaa9R7m43Dhw/T2ehlud+LIcLhw4crbVJFOHL4EEtaZy7BLofQ0eyq\nCiHVwqEpC/Ue1wctHBYHDx6gt8GNy2HQ1ejh4MGDlTap7KRSKQaOHWNJm2PO60tahSNH7C+kWjg0\nmjKhhSPteR7Yf4DlzV4Aljd52Ld3b4WtKj8DAwMkkyl62+bO0uttc9B35EiFrCocLRyasqCL3mb6\nM9VzY7++vj6isRgr/D4AVjT7OHToUN2t+1jhuaXtcz2Ope0OJiYDc2aR2xEtHJqyoIUDpjIXg3oW\njldeeQWANa0NAKxuaSBlmnXX+PFIxqs4QTgyoSu7r/vkFQ4R6RGRfxeRhzLbZ4rITaU3TVNL6DUO\nCE2lBSMYsPfdZCl56aWXcBoGyzMex9rWRiDdObieOHz4MF63QVvj3Evw0nbn9H47U4jH8X3gYWBp\nZns3cFupDNLUFlYIQmdVwVQo3Qk2VMcdYXfu2MHq1gZcjkybjQY3zV43O3furLBl5eXw4cMsbXOc\n4IkvaXMgMuOR2JVChKNTKXU/YAIopZJAffYI0CwYSzjqLYZ9PEopQuF0fyZLQOqNRCLBrpdeYn1b\nw/RrIsKprQ28sH17BS0rP0cOH6S37cTLr9spdDa7asLjCIlIB6AARORCoH57IWsWhBaONJFIBNM0\ncSCEw5G69MBefvll4vE4p7f757x+WkcTR/r66qbhYSKRoL//2HRY6niWtgmHDx8qs1ULoxDh+Bjw\nILBORP4fcCdwa0mt0tQMWjjSWAOL2lw+TGXWZUrutm3bADi9s2nO62dktp977rmy21QJBgYGSJnm\nCQvjFr1tDg4fqnLhUEo9B7wJeAPwIeAspdSLpTZMUxtEo1FAC4eVXtnq8s3Zrie2bdvGiuYGWjyu\nOa+vaWnE53JOC0utY61f9LbNLxxL2x0Ep0K2HnJVSFbVh4EmpdQupdROoElE/rwYJxeR74rIkIjM\nuzImab4iIntF5EUReV0xzqspH9rjSDPtcTgb5mzXC/F4nO3PP89Zx3kbAA5DOL29kd89/XQFLCs/\n+YXD/plVhYSqblZKTVgbSqlx4OYinf/7wNty7L8CWJ953AJ8o0jn1ZQJ3dgvjSUUrS7vnO164YUX\nXiAWj3N2V/O8+8/pauZIX19ddMo9cuQIPrdBa+P8l98lmfbqdm52WIhwOGRWzpiIOAB3MU6ulPo1\nMJbjkGuAO1Wa3wKtItJbjHNrykM8HgcgEU9U2JLKMi0czvoMVT399NMYIpyZ6Yj7gxcP84MXZ+6o\nz+lOC8pvf/vbithXTvr6+uhpc2Ytiu2pEeH4L+A+EblURC4F7sm8Vg6WAbMTmvsyr52AiNwiIttE\nZFs1TNCqFyzhsJ7rFata/OXQ4JzteuG3v32K9e2NNLjSF8WDk2EOToan9y/3e2n3eepCOI4ePcKS\nluydFDwuod3vtPVcjkKE4+PA48CfZR6PAX9VSqMWg1Lq20qpTUqpTV1dXZU2R5PBClUlE/afo1xK\nLI9jIhGds10PjI+P88orr7IhS5gK0vUcZ3c28bunn67pUbJKKQYGjk17FdnobhFbt1cvJKvKVEp9\nQyl1bebxLaVUuf5njwIrZm0vz7ymqRLMVLpeoZYvBoVgCYVT0l+5cDic6/Ca4plnnkEpNR2OysaG\n7mYCweB0P6taZGJigmg0RldzHuFodnBsoIo9DhH5PRF5RER2i8h+ETkgIvvLYRzp+pH3ZbKrLgQm\nlVK1v3pWQ1iCkTLrWzhCoRCCICIIUlcex+9+9zsaXE7WZfpSZcNaOH+6hrOrjh07BkBXS+5Lb1eL\nweDQkG0LRQsJVf078EXgIuA8YFPm+aQRkXuAp4DTRKRPRG4SkT8VkT/NHLIV2A/sBb4DFCUNWFN+\n6r3JYSgUwhBBAK/TVVdrHL97+rec0dGEw8jdIbnV62JlSwPPPPNMmSwrP4OD6TWuzjweR6ffQTKZ\nYmwsV+5Q5Zi/5n0uk0qph0pxcqXUdXn2K+DDpTi3przUe1v1cDiMQfpv4DGcdSMcAwMDHO0f4NJz\nVuQ/GDizo4nHt28nHo/jdhcledNWDA0NAdDhz33Pbu0fHh6ms7Oz5HYtlEI8jsdF5Asi8noReZ31\nKLllmprAEgzDqO/RL2mPI/2zx3DUzRqH1UbkrE5/niPTnNnpJxaP8/LLL5fSrIoxOjqKIdDSkPv7\n0O5PeyR27d9ViMdxQeZ506zXFPDm4pujqTUcjvQXQAtHaMbjEEfdeBzbt2+nwe1kRbOvoONP70hX\nlj///PNs3LixlKZVhNHRUZobnHPCdt95JF3Tc/PlM+JqzemoWuFQSv1+OQzR1CYOZ1o4LAGpV0LB\nKSQjHG5x1M1MjhdffIFTWhswCgxVNntc9Pp9NTufY2JigpbjKsYPDJ5YHNuc8UgmJiZO2GcH9ARA\nTUlxOtL3Jk5nIc5t7TIVmpq+eHoN5/Q0wFomEolwYP+BvNlUx7OuxcfOF2uzj+rExDh+b/5EEY9L\n8LgMxsfHy2DVwtETADUlxenSwgFzQ1Vew1UX6bj79u0jZZrT88ULZXVLA8Ojo7a9aJ4MgclJmryF\nhW2bvA7bfk70BEBNSbEEwxKQesQ0TcKRyByPox6mAO7duxeAlS2FrW9YrGpJC82ePXuKblOlCQaD\nNHoLC9s1esW2Pc30BEBNSbHWNurZ4wiFQiilMDJV416Hi3AkQjJZ221YDh06hMth0N3gWdDv9Tal\nOwjbua34YolEIjS4CxMOr9u+HQYK+TYfPwGwC7i2pFZpaoZpj6OOhSMQCABMh6p8RvpvEQwGaWtr\nq5hdpebw4cP0NHoLXhi3aPe5cDuM6bkVtUQ4EsXjnhHS7zwSZP9g+gbiE3eNsabHNZ1d5XVi20mR\nOb/NImIAXtITAE8DBHhVKVXfPbI1BaPTcWeEw5G5gDY43NOv17JwDB47Rod34TcMhggdDZ7pKuta\nIZlMkkqlcDtmhPTAYIJwLL1YvvPw3Muq2wmhWLSsNhZKzm+zUsoEvqaUSloTALVoaBaCJRj1nI5r\nLfLOCEd6dKqdR4MWg+GhIdq8i6v+bvM4Gc5UWdcKVqdol7MwD8zpENsOQCvkNvAxEXmH1HvPCM2i\nsISjnj8+Vi6+kfm6NWU8Drv2ISoGSikCwSB+z4kexw9ePMyhyTCHJsP879+8Mmegk0WT22nbGobF\nYq1pOQp0vp0O+3aVLsSP/BDpdY6UiERIh6uUUip3j2SNhhnBqGfhGB0dBcAhlnCkY9y1LBzxeJx4\nIkGD80RP8+BkmHAy3fX15dH5s8saXQ6mbJpRtFisRp+FfhUMEUybdpUupHK8sCYzGs08WF+Weu6O\nOzY2htNwTC8SNznTwmEJSi1iTXz0FHp7fRxuwyAWt2d8v1woFGDPG65CKsdFRN4jIp/MbK8QkfNL\nb5qmFtDCke5w2uLyTl8CnGLQ6PLYtg9RMbDCMkaeVurZcBpSc+nKC/a6lX099UJuB74OvB64PrM9\nBXytZBZpagprEI1dB9KUg+HhYZqMuYvEzQ4Pw8PDFbLI/qSLxiptRXGxEkRSBX4VUuZMrze7UYhw\nXKCU+jAQBVBKjQO11yhfUxKmJwDadJGvHBwbGKDF6Z3zWrPhmZ4GV4tYdTupRd4wpEw13eesVrD+\nJslUYd530gSn01VKkxZNIcKREBEHM5XjXWTaj2g0+ah34VBKMTg0ROtxwtHq8jJYw8Lh8aTXceIF\nXiSPJ26a0+9RK7hcLkSERIERuERS2fZvUIhwfAX4GdAtIn8PPAn8Q0mt0tQMVpy61uLVhTI2NkYi\nkaDNObdfU6vTx8TkpG0rg08Wl8uF0+kgklzcDUMkkaKpcWFdde2OiOB2u4gnCxPTWFLhdttTOLL6\ngiKyRil1QCl1t4g8C1xKOuq4WSlVm+O5NEVn2uNY5AWk2hkYGACg1TVXONoy28eOHWPNmjVlt6vU\niAj+Jj+hQm+vjyOUSOJvr72Mf5/XSzRRWA11LCG0Nyyss3C5yBVE/DFwrog8ppS6FHilTDZpaohk\n5sKRSNZnw4H+/n5gRigsrO3+/v6aFA6A1tZWgrHFFfEFEyYrarAdi8/nJZpJVc5HLAk+38I6C5eL\nXMJhiMgngFNF5GPH71RKfbF0ZmlqhelQ1SLvPKsdSzjaXXPvHNucDXP21yLtHR1MHlhcyvFkLMnG\n9vYiW1R5GhubiMQLazUTiSsabRquy7XG8W7SczecgH+eh0aTF0s46nVxvL+/nwanB48x9x7N7/Tg\nNIyaFo6uri7G4wv/f0+ZislonM7OzhJYVVkam/zTTQ3zEYqmbCscuTyOtymlPi8iHqXUZ8tmkaam\nsOo36lU4BgYGaDsuowrS7SRaXQ01LRzd3d2MhWOYSi2otfpkLIGpFN3d3SW0rjL4/X6OFdC7MWUq\nonETv9+e9+i5PI4PZJ43l8MQTW1S7wWA/UePziscAK0OD8cyi+e1yJIlS0iaJoHYwsKUI5H49O/X\nGn6/n6lofo8jlDmmqamp1CYtilzC8bKI7AFOE5EXZz12iEhRJsmLyNtE5FUR2Ssifz3P/ktEZFJE\ntmcenyrGeTXlo55bjSilOHZskFbn/AucbU4f/f21LRwAI5GFtQYfCdeucDQ3NzMVzX8TZR3T3GzP\nzLKsoSql1HUisgR4GLi62CfOFBV+Dbgc6AOeEZEHlVIvHXfob5RSVxX7/BpNqQkEAkRjUVqb5xeO\nFpeP8bGjJBIJXC57VgifDL29vUBaCE5ZQILUcDg25/drCb/fTyiayhu+s7wSu4aqctb0K6WOARtL\ndO7zgb1Kqf0AInIvcA1wvHBoqhhrHkc9TgAcygwias4SqmpxelFKMTw8zNKlS8tpWlmwLvzD4cLS\nTy2Gw3Ga/X7bLgyfDC0tLSgF4aiiyZdLOMzp4+1I1m+ziNyfed5RolDVMmD2UOG+zGvH84bMeR8S\nkbNy2HuLiGwTkW26eZx9sBq7OQx7NmsrJdbnsNk5f/Vvc2YuR61+Xv1+P/6mxmkPolCGwzGWLas9\nIYWZ0FMgkjtcFYxUaagK+GjmuZJhoueAlUqpKRG5EtgCrJ/vQKXUt4FvA2zatKl+A+s2Y1o4bNrl\ns5RYg5r8jvmFw++s/YFOvb1LGQ4sbATsSDTJaUvnu4esfiwhCOVZIA9G0vurzuNQSg1kng/N9yjC\nuY8CK2ZtL8+8NtuGgFJqKvPzVsAlIrWX3F3DuNyuOc/1hCUIjY75m0lbr1szyWuR3qVLGYkW3jVA\nKcVIOFaT6xswIwT5PI6pzH67rnHkClUFRSSQ7VGEcz8DrBeRNSLiJl1w+OBxNiyxZp1nhkcZQO2O\nTatBrEVft7v+OvEHAgEMEbzG/I59Q0Y4JicLqySuRnp7e6ezpAohGE8SS6ZqMqMKZjyOfJlVwaii\nsdFn26SJXFlVfgAR+RwwAPwH6SaHNwAnfTuglEqKyEdIZ205gO8qpXaJyJ9m9n8TuBb4MxFJAhHg\n3aqe8zurEEsw7PoFKCXBYBCf0511iptLDJyGQbDGZmvPpqenh0giSSiepNGdf77GaCTtndSqcFge\nhxWKysZUxKTZb8/1DShg5jhwtVJqdmbVN0TkBeCkayoy4aetx732zVk/3wHccbLn0VQOSzjq0eOI\nRCJZvQ1Id5D1OFyEw+EyWlVeenp6ABiLJgoUjrR3UotV4zATesrncUxFTfzN9lzfgMLmcYRE5AYR\ncYiIISI3AKFSG6apDaxBNHYdSFNKotEoLsmdFOASR83O5IAZARiLFhauso6zBKfWcLlc+LyevIvj\noaiiucqF43rgXcBg5vFOZuaPazQ5qec1jlgshiPP4GyXGCQKnM9QjViNCicKXCCfjCYwDKG9Bjvj\nWjT5mwjFcnscobjYdmEcCghVKaUOki7M02gWTD2vcSSTSRyS+97MEKOmpyN2dHQAhQvHRCxBS3PL\ndBp3LeJv8hOKTuU8JhRVtu1TBYV5HBrNoqln4TBNM4+/kf4C1nLn4IaGBjxud8GNDgOxJO3ttTfA\naTZNBbRWD8VMLRya+sXpTDu19SgcQF7hALJmXdUKbW1tBOKFC0drW+2GqQAam5qIxLMLh6kU0XiK\nBpuOjQUtHJoSM105XsOhh2yICPlyx+sht7ylpYWpWcIRTqTw+Xxcd911+Hw+wokZj2sqadLa2loJ\nM8tGQ0MD0UT2m4VYQqGUfVuqQwFrHCLiAd4BrJ59vB7upCkE6266HpscGoaBmUcaFKrm/zYtra2M\nj8wMrAonU2ze/A5uv/12AB594CfT+0KJpG37MxULn8+X0+OIZvbZdd44FFbH8QAwCTwLLKxbmUaT\noR7rNh0OR16PwlRqOpxXqzQ1NdGfnMkianA62LJlCwBbtmyh2zXjjYbjSVtnExUDn89HLJH9k2Ht\nq3bhWK6UelvJLdHUJPU8c9zhcJDKI5gmqubDeE1NTYSTM///DS4HkcAU99xzT3q7IR2SSZom8ZRZ\nk+3UZ+P1eoklsqfjxjIJaHaufSrER/4fETmn5JZoahJLOOLxhc1kqAWcTicmufP1U3XgcTQ0NBBN\n5r9xiGS8kloXDrfbTTxpZvXC46n063YWjkI+sRcB7xeRA6RDVQIopdSGklqmqQmsquharo7OhtPp\n1B4HaSGIJlIopXJmkFniYudsomLgdrtRClJZ7ikSSTV9nF0pRDiuKLkVmprFauA3NZW74KkWSXsc\nuYUjpcya9zi8Xi+mUiRMhduRI5so43HYObZfDKzU9GxOmJVkZucU9ryhqszsjVbgDzKP1iLN49DU\nAdasifGx2p05kQ3DMFAZ4Xhw6CX6YwH6YwG+deS3PDiUnpBsqtrPqrKEIF+4Kpa5Bfd65x+1WytY\nNwrJ1Pw3FSlTzTnOjuT9xIrIR4G7ge7M4y4RubXUhmlqg6Fj6elvQ4MLmwJXCxiGgZkJVQ3EAkTN\nJFEzyf7IGAOx9EgbpWo/VGUJQTxbbCZDvQiH9f9tZnFGrT+TnT8XhUjaTcAFSqkQgIh8HngK+Gop\nDdNUP6ZpMnBsAIChkSESiYSt3e/SkL8qvNYrx61F3niWO2yLehEOy8NMZVEOa1nMzp5oIZYJMNvH\nTFFYJwVNnTMwMEAimaAr1YVpmvT19VXapAqQp5JD0gJbyxTqcSTqTDiyYXmpdr6hKMTj+B7wtIj8\nLLO9Gfj30pmkqRV2794NwOrUGoYdw+zevZs1a9ZU2KrykUql8nfHRepHOPL8O+N1IhyWIGQLVR1/\nnB0pZHH8i8AHgLHM4wNKqf9basM01c+OHTswMFiVXI1TnOzYsaPSJpWVZDKJkcc5d9R4W3WYEYJY\ngWscdq5fKAZq2qMo7Dg7ktXjEJFmpVRARNqBg5mHta9dKTVWevM01cwzv3uGDrMDFy46Up0887tn\nKm1SWUkkEjjzeBwOMWq+OHJmjaMwj6NuhCPLfvv6GTPkClX9ELiKdI+q2dInme21JbRLU+WMj4/z\n8isvc3Yy3XRgSXIJL+zbztDQUM3Okz6eaDSaVzhchoNoNFomiyrDtMeR1MIBM2taRhaXwzBkznF2\nJOunWil1VeZ5jVJq7azHGqWUFg1NTh5//HGUUixLLQNgWWo5AL/61a8qaVZZiYTDuPNEg90YNV9V\nX+jieDRpIiI1v8Zh9W0zDAjHzLkt5mMmGd2oTuGwEJHHCnlNo5nNQ1sfopkWWlV6mluLaqGNNh7a\n+lCFLSsfU1NTeIzc+ScecRAOhcpkUWWwCgDzrXHEUyZej8fWi8LFwBIOh5EeEbt582Zuv/12Nm/e\nTCiqsJKu7Lz2lWuNwws0AJ0i0sZM6K0ZWFYG2zRVyuHDh3nu+efYEN+IzIrYro6v4fldz7Fv3z7W\nrVtXQQvLQzAQZEke4fAaLiYnA2WyqDJYwlFIAWCtexswIwgOQ2j0ypwW873NgjPjcthZOHJ5HB8i\nvb5xeubZejwA3FF60zTVyv33348hBmuTc8VhTXINDnFw3333Vciy8hIIBmhw5G5U53M4CQZqWzis\nNYt8LUeiyRQ+X/0Ih9MBDZ50qPKee+4hEonQ4DFwOuYeZ0dyrXF8WSm1Brh91trGGqXURqWUFg7N\nvASDQbb8bAsrEivxMbdZnQcvKxOr+M+f/+d0D6taJZFIEAqHaXDkrpRvcLiZmJy0derlyWIYBj6v\nl2gBHketd8aF9GdDJO1xzIcz0wgykUiU06wFUUjluCki00OARaRNRP68GCcXkbeJyKsisldE/nqe\n/SIiX8nsf1FEXleM82pKx/33308kGuGMxBnz7j8jcQaxeIx77723zJaVl4mJCQAa83gcTQ438USc\ncDhcDrMqhs/nLdDjqH3hiMfjuBzZL72Wx2HnNO1ChONmpdSEtaGUGgduPtkTi4gD+Brptu1nAteJ\nyJnHHXYFsD7zuAX4xsmeV1M6QqEQd/3HXSxNLaVNtc97TItqZXlqOff88J7pluu1yOjoKAB+R+7U\nUmv/2Fhtl0U1+BrypuNGU4qGGh/iBBnhcGZPALBaz1e7cDhkVppD5oJfjAkj5wN7lVL7lVJx4F7g\nmuOOuQa4U6X5LdAqIr1FOLemBNx3330EggHOTuQeGHlW/BxC4RB33313mSwrPyMjIwD4nXmEI7N/\neHi45DZVEl9Dw/SEv2xEU2bNz+KAdAjK7cohHM7aCFX9F3CfiFwqIpcC92ReO1mWAUdmbfdxYrZW\nIccAICJT13Y9AAAgAElEQVS3iMg2EdlW619COxIMBrnz+3eyNLWMDrMz57Htqp3lyRXc9R93T4d0\nao2hoXQb+WZn7sVea3+tf2YbGhsLmsdR62NjAWKxGK4cA60sbyQWi5XLpAVTiHB8HHgc+LPM4zHg\nr0pp1GJQSn1bKbVJKbWpq6ur0ubUHXfddRfBUJBz4oVNFN6Q2EAkGubOO+8ssWWVYXBwEAGa83gc\nLRnhGBwcLINVlcPn8+Wt44gm6yMdNxaLTXsV8+F2zhxnVwppcmgqpb6hlLo28/iWUir/5Pn8HAVW\nzNpennltocdoKsz4+Dh333U3K5IraT9ubeNZ1zaedW074XdaVCurk6u59557a/Jue3BwkGa3L293\nXK/hxOtw1Ydw5GkHG02m6iKrKi0c2fdXtcchIvdnnndkMprmPIpw7meA9SKyRkTcwLuBB4875kHg\nfZnsqguBSaXUQBHOrSkiP/jBD4hGo5yTONHbmDDGmTDmT709O7GBeDzO9773vVKbWHYGBgZodeS/\nexYRWl0+BgZq+2Od9jiyC4epFPFkqi7WOGKxGG5H9r+F0wBD7C0cucpaP5p5vqoUJ1ZKJUXkI8DD\ngAP4rlJql4j8aWb/N4GtwJXAXiBMur27xkaMjIxw/333syq5mhbVsqDf9Ss/a5Pr+MlPfsKNN95I\nT09PiawsP0eP9NGTZ33Dos3h5WiND7nyer3Ecqxx1MsQJ0g3v8wVqhIR3C6jOoXDurNXSh0q1cmV\nUltJi8Ps174562cFfLhU59ecPHfeeSfxeDxvJlU2zkqcxQHnfr7//e/z8Y9/vMjWVYZEIsHg0BBn\ntBXWC7Td1cBzR/tRStVsnyaPx0MiR9O+eCaMVeudcQFi0Qj+PBOUPS7D1l2Tc4WqgiISyPYop5Ea\nezI+Ps6Pf/RjViVX4Vf+Rb1Ho2pidXINP/vpz6ZTWKudgYEBTGXS4SosXt/haiASjUzXftQibreb\neI50XMvjcLuLkelvb/ItjkM6JdfOHkeuliN+pVQz8GXgr0mnwS4nnWWlJwBquO+++4jFY5yZOPuk\n3ufMxFkkk0l++MMfFsmyynLoUNpJ73QXJhyd7nQK6pEjR/IcWb24XC6Sppm1tUoy43G4XHluxWuA\nWCyKJ0cdB4DHVaXCMYurlVJfV0oFlVIBpdQ3OLFQT1NnRCIR7rv3Ppalli94beN4/MrP8uQKfvyj\nHxOqgRbjlnB0uZsKOr4rIxwHDx4slUkVx+lMR8VT2YQj87rD4SibTZUiGovhyetxUJ2hqlmEROQG\nEXGIiCEiNwDV/+3WnBQPPfQQgWCA0xOnF+X9Tk+eQSgc4he/+EVR3q+SHDhwgCaXJ2+fKotWpw+X\n4eDAgQMltqxyWIKQrZejqiPhiMXi+UNVDlX1LUeuB94FDGYe78y8pqlTlFLcd+99tNFGl5l9DOyz\nrm2MG+OMG+M85nlk3noOi06zkw7Vyb333Fv1nWL37dtHl7PwCmhDhC53E/v37SuhVZXFWvTP9j9r\n/ZfXanLAbNK9qnIf43ZKdXscSqmDSqlrlFKdSqkupdRmpdTBMtimsSk7d+5k7769nBJbP2dQ0/FM\nGOMkJEFCEgw5hrLWc1icEj+FQ4cP8fzzzxfb5LKhlGL/vn30FBimsuhxNbJnz54SWVV5qv1moFik\nUimSyVRBoap4rIqFQ0ROFZHHRGRnZnuDiPxd6U3T2JUHHngApzhZlVpd1PddmVqFW9w88MADRX3f\ncjIwMEAoHKbX07yg3+v1NDMyOlqzvbss4cgyggLL0bDznO1iYIWfcnXHhYzHUc3CAXwH+BsgAaCU\nepF0lbemDonFYvzy4V+yPLECF8XNgHHiZEViJY8+8iiRSKSo710uXnnlFQB6PQtLT7aO3717d9Ft\nsgPTc7azhKKsoUbWcbWKlSmVb43D5RQSVb7G0aCU+t1xr9l3pmGF2b17Nx/72Mf46Ec/ym233cYz\nzzxTaZOKyv/8z/8QCodYnVxTkvdfnVxNNBbl17/+dUnev9S8+uqrCLJgj2OZN52ZZglPrZFIJDBE\nsq5hOMX+rcSLwbTHkScHwOWEmI2FI88SDQAjIrKOzLqWiFwL1HZjnZPga1/7Gk8++SS+ZAcR5yiD\nxwb54T0/rJlFv1/96ld4xEOPWZr2IJ1mFw3SwOOPP85b3/rWkpyjlLz00kss8fpxGwvLDmp0uGlz\nN/Dyyy+XyLLKEo/HceeYemdNxLNzJlExsIQxX6jKaQhJG4toIR7Hh4FvAaeLyFHgNuBPS2pVlbJ9\n+3aefPJJOidfw6qBq1gy+nvs3rObRx55pNKmFYVUKsVvfv0behNLMQr66CwcA4PexFKe/M3/q7q7\nT6UUu3buYpl7Yd6GxTJ3Mztf3FFkq+xBuj9TdjF1G8b0cbWM9ZnO8acA0sISt/HnP+e3X0QMYJNS\n6jKgCzhdKXVRKftXVSuRSITP/u/P4VZNtAfTE3BbwmvxJjv458//M+PjuTOKqoFXX32V4FSQ3tTS\nkp6nN9VLJBrmpZdeKul5ik1/fz+TgUlWeBdXELnC20L/sYGa+KwcTyQSwZPD4/A460w4smUJZHAa\nkMwz+KqS5BQOpZRJZmiTUiqklKrdIdEngVKKz33ucxw6fIie4ddjqPSisWCwZOQNTE4E+PjHP151\nd9DH89xzzwHQkyptF9vuzPs/++yzJT1Psdm5cycAK7ytJ+yLphL4fD6uu+46fD4f0dSJn4WVmd/b\ntWtXaQ2tAOFwGK8z++XGEMHtdBAOh8toVflJJtPLw/nqHJ0OIZmw71JyIfGGR0XkdhFZISLt1qPk\nllUJSim+9KUv8fDDD9M18VoaY3Pvxr2JdnpGX8+zzz7Lpz71qarOGnnppZdokiZ8lHZmggcPzdJc\ndR7Hzp07cRkOlsyTURUxk2zevJnbb7+dzZs3EzFPvCgs97YgCDt21F64KhQK4c0xLhWgweWsiZYz\nubC+//k8DocBqRy9vSpNIYvjf5x5nt3eXAGF9YyuYUzT5F//9V+59957aQueQXtw/mZ/LeF1JB0R\nfvnLX2Kaiv/zfz5Xlc3c9u3dR3NycfH7hdKcaGH/3v1lOVexePHFF1nuaZl36p/PcLJlyxYAtmzZ\nQptx4lfPbTjp9TZPey61RGhqioZMYH91SwOHJtOexaqWBla3pJtB+pxG3QiHkeeW3dqfSqWm+3zZ\nibwWKaVKk3dZ5cRiMT796U/zyCOP0BY8k+6JTTmrqDsyovLoo48wOTHBF/7lC/j9i2tFXimOHj3K\nCnNlWc7VpJrYO7CnamZUJBIJXn31VV7ftHze/V6Hi0gkyD333ANAr29+p325J71AbpomRr6rSxUx\nNRWkNyMcN25YycGMcHz64pleZz6nwdTUVEXsKxcz9Sy5jzMyn3m7FkQWUjnuFZGPichPReQnInKb\niNT+mK4cjIyMcPPNt/DII4/QNXFuXtGw6AieTe/oRWzb9izve9+NHD58uAzWFodYLEYkGsGryvNf\n71U+kslk1VxI9uzZQyKRmHd9YyGs9LYyFQ5V1WejEKampmjIU7zgcxgEg7W9jGoJQb6bIccsj8OO\nFHJLcydwFvBV4I7Mz/9RSqPszK5du7jh+ht4ZderLBu5hI7g2QWJhkVLeB0rhi6n//Ag77nhvTz1\n1FMltLZ4WNkuzoKimyePE8ec89oda0H7ZIVjeSYjq9rWd/IRCoXx5clBbXA5mKoT4cizxGF7ChGO\ns5VSNymlHs88biYtHnXH1q1buelPbiIwHGPFsbfhj6xa1Ps0xJawsv9KUgE3t956K3fddZdtF8Es\nFmNfgrmZRAkKzypbiBjbgVdeeYVGp4fWAueMZ6Pb3YTLcNRUBXkymSQai+X3OJwOwjW+xjFNno+3\n5ZDY9bpQiHA8JyIXWhsicgGQvT92DWKaJl//+tf55Cc/iSvcwcqBK/EmTi6xzJ3ys/LY22gKreRL\nX/oSn/vc52ydrtvQkF7ATC6g20xc4nMyieJSeFVwInMen6+0GVzFYverr9Lrbjrp9RiHGCzx+NlT\nQz2rrBTbQjyOWl8cnyaPHti9zXwhcYdzgf8RESvouhJ4VUR2AEoptaFk1tmARCLBZz/7WbZu3UrL\n1HqWjF+IFKlq2lAulo6+iZHEdh544AGGBof4wr98wZYXS7fbTYOvgWii8NCRW7nnZBItZH0kKhHc\nLjeNjYXPtagUpmmyf/9+zvX1FuX9elxNNdVi3RKOXHUc1v5wlYQmF0u+uSTVQiHC8baSW2FTkskk\nf/uJv+WxXz1G5+Rr6AhsKCiEMtia7gnZM3F+3mMFoSvwWlypJn7726f4yEdu5Y47vmpL8ejp6SEU\nLHyx2oWL8cj4dCaRn8KzyEISoru727Z3XLMZGhoiGovR3VIcket2N7FtpI9gMFh1mXfzYXU69uQR\nDo/DQSqVIpFIVGW6eiFYEw4zI9ZZ0+Ni/2Dau17b42RNj2vOfrtORCxkkNOhXI9yGFkJlFL8/d//\nPY/96jG6xzfRGdhYcNw96hoj6hpb0PlaQ+vpHbmYF7Zv53/9r7+arjC1E2vXrSXoKs/iZdAZZM3a\n6sgEP3r0KADtroaivF9H5n36+vqK8n6VZrqVeJ70YncmR9U6vhaxboTMTCzq5sv9rO1xsrbHyT+8\np52bL0/fKJgZ5bDrjVPtJIoXmR/96Ec8+OCDdExuoH2qPLkAzZE1dI9dwFNP/Q/f+MY3ynLOhXDK\nKacQUIEFLXIvhhQpAkxyyimnlPQ8xWJwcBCANldxvMQWl3fO+1Y7M439cl9unEbtd8i1ivnyZdmm\nzLnH242KCEembckjIrIn89yW5biDIrJDRLaLSNkW5A8dOsQXv/glmqLL6Qy8plynBaAtdBotU+v5\nwQ9+wPbt28t67nycfnq6WCvfCNiTZcKYwMScPp/dsZoSNjk8RXk/631qpdnhdH+mPDfP1pAnu9Yu\nFANLCJJm7lWOpKlwOBzV7XGIyCoRuSzzs09ETjbw+tfAY0qp9cBjme1s/L5S6jVKqU0nec6C+eIX\nv4iZgCWjr69IWmjPxHm4zEY+/0+ft1Xl6FlnpT2vUWO0pOcZNUbmnM/uWEVrnnnaiCwGX+Z9aq0Y\nLu93qQ7Gx7rdbgDyRaKTKXC57OltQGGV4zcDPyY9kwNgObDlJM97DfCDzM8/ADaf5PsVjR07dvDk\nk0/SPnE2TrM4MeuFYigXHWOvYfee3Tz++OMVsWE+Ojo66Onumb6wl4pRY4T2tnaWLFlS0vMUi0Qi\ngUOM6TYRJ4sz0+vKjutci2E6rp8nl2h6LnkNtVo5Hks44qncf4tEUuG2cYJAoYOcfg8IACil9gDd\nJ3neHqWUNUXwGJCtT7ci3Z33WRG55STPWRDf//73ceKhdWpxYZLB1t8Rc48Rc49xqOu/pjOsFkpz\neA0es5nvfvd7tioC2rBxA2MLXPhfKGOuMc7ZcI5t3fTjKdX/j53+308GKzxj5gnPpDL7azWjCsDj\nSYch48ncf4t4UuHxuMth0qIoRDhiSqnp1SoRcVJAGrKIPCoiO+d5XDP7OJX+dmR7v4uUUq8BrgA+\nLCJvzHG+W0Rkm4hsGx4eLuCfdSIHDhzgiSeeoGXyNBxqcR/eqGsM00hgGgki3sEFZ1dZCAatE2fy\nyisv22pu+VlnncWUmiJKafLt48QJqABnnz1/p2E74vV6SSmTlCpOiCWReR+vtzZawk1fLPPdZWeE\nw7orr0Wsv0UskU84Zo61I4UIxxMi8gnAJyKXAz8Cfp7vl5RSlymlzp7n8QAwKCK9AJnnoSzvcTTz\nPAT8DMhaGKGU+rZSapNSalNXV1cB/6wT+eY3v4WhnLRNnbGo3y82LaFTcKlGvv71b9jm7vPMM9PT\nDcdKtM4xZqSF9owz7PF/UAhWrUVknuFMiyGceZ9aqOGAmer/aJ5F72gyhYjUjGDOh/W3iOX5qEQT\nCp+vMqHyQihEOP4aGAZ2AB8CtgJ/d5LnfRC4MfPzjcADxx8gIo3WIryINAJvAUo2qOCpp57i0Ucf\noXXyTJymPT64Bg46xjewY8eL/PznebW6LJx66qkAjJcos8rK2KqWjCoA60YlkCpO/UEgmfbmOjs7\ni/J+laapqQmAUCK3cIQTKRp8vppe43C5XDgcDqKJ3N5pNF79wrEZuFMp9U6l1LVKqe+ok7/9/Sfg\nchHZA1yW2UZElorI1swxPcCTIvIC8DvgF0qp/zrJ887L8PAwn/zkp/CkWqfnZtiFltB6GuI9fP7z\n/8yBAwcqbQ5+v5+e7h4mjYmSvP+EMUFHWwdtbfNmaNuS5cvTMzhG49n7LPV6mvEaTryGk7W+dno9\n2QdijSTS77NixYriGloh/H4/IsJUPPdifzCepKWlPIPCKoWI0NjgIxLLfQkNx6HJxh5nIcLxB8Bu\nEfkPEbkqs8ZxUiilRpVSlyql1mdCWmOZ1/uVUldmft6vlNqYeZyllPr7kz3vfASDQf7i1r8gMB6k\nd/iNGMpeKXCC0DtyMakofOTDt7LY9ZticupppxJwBkry3pOOSdatX1eS9y4Vq1atQkQ4Fs/ejuXq\n7jNZ6mlmqaeZD624kKu7z8x67GB8CpfLRW9vcXpfVRqHw0FLczOBWG7hmIwlaGur/anUjY0NhOO5\nhSMSV9ONRe1IIS1HPgCcQnpt4zpgn4j8W6kNKwfBYJAP//mH2bNnL73Db8SbsOddrivVyNLBNzM8\nOMLNH7yZoaF5l4TKxtq1awlIAJPi5tsrFAFjkrVrq2sqsc/nY83q1fRFi+OF9UUnOe2002xbNbwY\nurq6GI/mrggfj6Xo7smWYFk7NDX5CefxOEIxZes1roKCiUqpBPAQcC/wLDaqu1gso6Oj3PzBm3np\npZdZOvImmqLzj/y0C754J8sGL6W/b5APvP8DHDlypGK2rF27lpRKMSXFLVALSYikSrJuXXV5HAAb\nNm7kUGxyugfRYkmYKY7EJtm4cWORLLMHPUuWMBrN7nEopRiNxOnuPtlMf/vjb24mFM190xWKmNNr\nQ3akkALAK0Tk+8Ae4B3AvwHVUZmVhYGBAT7w/j9h/96DLB96M/5IeeZonywN8R6WH7uckcEJPvD+\nD1Ss9bZ1YZ8wJov6vta6STUKx3nnnUckGedo7OT+Joei4yTNFJs2la1RQllYunQpQ+HsyQOhRIpI\nIsnSpUvLaFVl8PubmYplr1GKJRTxpElzs33XewrxON5HulL8NKXU+5VSW5VSVVvSOjg4yAdv+iCD\n/cMsH7yMxtiySpu0IHyJTlYMvJXQeJxbbr6FvXv3lt2GtWvXYhgGE0ZxCwHHZRwRqZrmhrO54IIL\nEBFemTq5MOLLU0O4nM6aE45ly5YRjicJZlkgHwzFpo+rdVpaWghGsnumUxlvpKWlpVwmLZhC1jiu\nU0ptUUpVfa/jaDTKX9z6UYYHx1h+7HJ88ep0iz3JVpYPvIVoIMWtH/kLJiZKk+GU9fweD+vWrmO0\nyMIx6hhlxfIVVTG86Xja2trYcM45vBRevHAopXg5PMx5551n64XRxbByZdqrPzY1f+HoQOb1VasW\nN465mmhtbSUYTmWtzQpEzOnj7EpW4RCRJzPPQREJzHoERaQ0KTUl5s4772Tvvj30Dl+MN9FRaXNO\nCneqmaWDv8/w8DB33HFH2c+/YeMGRp2jORfIW802XMqFS7noTnXTamZPPlAoxpyjbHxN9cb2L73s\nMvqjAYZzZFfl4mgswGg8xKWXXVZkyyqPJRz9OYTDMKRuPI540iSapXo8EFbTx9mVrMKhlLoo8+xX\nSjXPeviVUvYNvuXggS0P0BhZVtKF8JTE8fl8XHfddfh8PlILmLO9ULyJDlqmTuEXv9ha9nnlmzZt\nIqHi05Xe83FuYhNtZhttZhuXxi7n3ET28Mu4jBNVUc4777xSmFsWLr/8ckSE7YH+Rf3+9mA/ToeT\n3//93y+yZZVn+fLlOJ0OjgbnF46jwShLl/Taus1GsbBqlCbD8wvHZMicc5wdKWRx/D8Kea0amJiY\nwJ0sbYqbaSTYvHkzt99+O5s3b8Y0SntBdyX9xOMxomWe1Xz++edjGAZHHcWZUnfU0YeIcOGFFxbl\n/SpBd3c35557Ls+HBhbcIialTF6YGuCiiy+y9Z3mYnE6naxcsZKjwci8+4+GYqypwqSIxTAtHKH5\nvfXJcPr19nb71rQUsjg+ZyhCpgDw3NKYU1pe+9rXMuU/RNKY/8NbDAzTxZYtW/iXf/kXtmzZgmGW\nrtNnShIE/HtZs2Zt2XO+W1tbOfd159LnOoLK3/MyJwpFn/sIGzZsoKOjukOIV111FaOxEAcjC2vJ\nsic0QiAR5e1vf3uJLKs8p6xfz+HgiUulSdOkPxipyqSIxWB9xidC87dgmQiZOAzD1jcQudY4/kZE\ngsCG2esbwCDz9JaqBj5620cRt0nfkl8Sd5RmmaYxvoRoKM69d99HasJLY7w0mctJI8LRnkdJuIL8\n1V/9r5KcIx9Xvv1KAgQYNk6umn3MGGOCCa666qoiWVY5LrvsMnxeH88EFlZnsy3QR0tzCxdffHGJ\nLKs869atYzgUJZqce8HsD0ZJmarqCj8Xy4xwzO9xTIRStLa22LpnV641jn9USvmBLxy3vtGhlPqb\nMtpYNNavX88dd3wVZ3OKQ0v/k7Gml1FFrn7umTif1tCptIZOY+3Q1fRMZG3ouygUismGfRxa9nOS\nDZP80z/9E+efX9xzFMpll11Gg6+BPc7dJ/U+e5y78Xq8XH755UWyrHL4fD7e8ta3sDM0SMwsLGt9\nKhnjpdAQV/3BVTU9i8KqzzkSmOvxH8mEr9avX192myqBFYIazwjHmh4Xa3pm/t8nQiYdNm9wmcvj\nsNqT/khEXnf8o0z2FZ1zzz2Xe++7h00XvI6htt9xaOnPCfgOnXS4ZTY9E+eXRDBCnn4OL9nKQMeT\nrD9jDXf/8C4uvfTSop5nITQ0NPCHf/SH9DmPEJLFZRKFJcxh1yGuvuZqW7dYWAibN28mlkryQnAg\n/8HA88F+Usrk6quvLrFllcUKRR0vHIcDERwOB6tXr66AVeXH7XbT3NzE+FRaOG6+3M/Nl8989sdD\n0Nm5uNEQ5SJXM5yPAbcA/zrPPgW8uSQWlYHe3l6+9rWv8fjjj/OVr3yVI47/xptqo23iLJrDa5DC\nOrGUBYViyneEsZadRFzDdHV181d//mmuuuoqW7iy1113Hffdex8vO19mU+LEjKhcKbgArzhfRoni\nhhtuKJWJZeecc85h1cpVbBvu4/yW3B1ulVI8GzzKmWecUfMx/mXLluH1eE4Qjr5AhFUrV9a0t3U8\nXZ1djE/Nn303PqU4a5EzhcpFVuFQSt2Sea693EDS7Y3f/OY386Y3vYmHH36Y7/77dzlw8ElG25+n\nZfI0WkOn4jArlxpoSoLJxn1MtLxMzAiwpKeX2/7kb7j66qttNSGtt7eXP7j6D3hwy4OckTyTRjW3\neC9XCm6ECPvce3nb29423Zq8FhARrtl8DV/5ylcYjk/R5c7ec6g/FmAgGuDGa/68jBZWBsMwWLN2\nLX0jR+e8fmQqxms21EeYyqKru4fRwydmJKZMxfhUwvazWApJx33nrIFKfyciPxWR15betPLgcDi4\n8soruf9H9/PlL3+ZDZvOYLj1OfYv+wnH2p4i5ixuP6Z8JBxTDLVsY//ynzDY9jTrzlrOP/7jP/LA\ng1u49tprbSUaFjfddBNiCLtcC5uztcu1E1NMbrmlLOPky8qVV16JIcJzgaM5j3s2cBSX08lb3/rW\nMllWWdatW0ff1ExmVTSZYmgqypo1aypoVfnp6upifJ7o7kTIxFQzw8HsSiF9mz+plPqRiFxEeujS\nF4BvAheU1LIyYxgGF110ERdddBF79uzh7rvv5r8e+i8mmnbTGF1Ge+AsGmJLELI3JzsZIu4Rxvy7\nmGo4hBhpb+j6669nw4YNiJTmnMWit7eXd1z7Du6/735OT5xBcwH1oVMyxT73Xq655pqaGVg0m66u\nLs47/3y2P7+Tt3ScOu//YUqZvBA6xsVvfKOtG9oVkzVr1vCfkRjdPieGyHSrkXrJqLLo6upibCpJ\nylQ4jJnPxljQnN5vZwoJklu5c28Hvq2U+gVgv9veIrJ+/Xo+85nPsPWhrXzoQx/C1RPmSPcvObxk\nK0Hf4aItpKcXvAc40v0wh3p+QapzmPe89z08+OCDfP7zn2fjxo22Fw2LD37wg3g8Hl50vVDQ8Ttc\nL+B0OmvS27C44oorGIuHOJyZ09HraZ4z+W9feJSpRJQrrriiUiaWHcuziKXSF0irkrwePQ7TVNPF\nfhajwfTl1u7t5QvxOI6KyLeAy4HPi4iHAud4VDvt7e3ccsst3HjjjfziF7/ge9/9PkcHHseb7KBz\n/DU0Rpct2gMJu4cYaXuOsHuQjvZObrnx/+MP//APq7LBH6T/Vu9933v5zne+w1hilHaVvZBvQsY5\n6DzIjdffaPsvyMlwySWX4HQ42TF1jFW+thOm/r0YPIbP6+MNb3hDhSwsP1YTw3jKxOd0MDAVRURq\n0uvMheVRjAZN2psc06+P1pDH8S7gYeCtSqkJoB2oTMVZhfB4PPzRH/0RP9vyUz772c/StsJDX9dj\n9HU9SnyBayAJR4ijHU9wuOchPD0JPv7xj/Pz/3yQ97znPVUrGhbvec978Df5edH9Ys7jdrh30OBr\n4MYbbyyTZZXB7/dzwYUXsCs0eEILElMpXo4McfEbL8br9VbIwvKzbNkyHIZBPJX+ewyEYizp6bHl\n2l0psW6YLA/DYnQqhcMwbN1uBAprqx4G9gFvFZGPAN1KqV+W3DIb4nQ6efvb387PfvZT/vIv/xLV\nPsnB3p8z1rSroPDVZMM+Di59kGhLP7fccgs///mDvOtd76qZxm5NTU3c+P4bGXD0M2qMznvMuIzT\n5zjCe9/3Xlu3VCgWl1xyCWPxMMfic6clHo5OMJWIcckll1TGsArhcrlYsqSHeCZUNRSKsWJldQxS\nKzvJIgQAAA6YSURBVCaWcFhrGhajQZOOjnYcDsd8v2YbCsmq+ihwN9CdedwlIreW2jA743K5uP76\n6/npT3/CRW/8PYbattHf+d+YMn+lsMLkWNtTDHQ8yTkbz+RHP7qfD33oQ/h8vjJbXnre+c534m/0\n81KWDKuXXLvweRt497vfXWbLKoPVQuTV0Ny2LK+GhjEMo67CVBbLlq8gbmaEI5Koi1bqx9Pe3o7D\nMKZDUxZjQZOeHvsPWC0kVHUTcIFS6lNKqU8BFwI3l9as6qCrq4svfvGLfOxjH2Oq4Qh93Y9iytxu\nuAqT/s4nmGjazfvf/36+/Z1v13Q8t6mpiXe9+130OfpOmEkekhBHnId5x7V/VDdZRF1dXZyydh27\nwyNzXt8TGeHss86qmWr5hdDb20vCVJgKAtF4XYyLPR6Hw0FnZwcjJ4SqFN09PRWyqnAKEQ5hJrOK\nzM/VkepTBkSEG264gX/4h38g4hmiv+M3pCSBmXkMtj1N0HeYv/zLv+TWW2+1vQtaDN75znfiMBzs\ncc6dib7PuRcE/viP/7hCllWG8y44n8PRCZJm+msUTSXoi0xy/gU1ldFeMEuWLCFlKhIZr6OnCi6U\npaCru3veUJXdF8ahMOH4HvC0iHxGRD4D/Bb495JaVYW85S1v4bbbbmPKd4Q9y3/I7sxjomk3N9xw\nA9dff32lTSwbXV1dXHTxRRxyH5yeEKhQHHQf4MILL6y7O8zXve51JMwUfbF0R+ZD0QkUite9rmpb\nvp0UVny/wZm+iapX4eju7mFsVhFgOGYSiaWqItMwbzquUuqLIvLfwEWZlz6glHq+pFZVKddffz0d\nHR0MD8/Es1taWrjyyisraFVluOqqq3jiiScYMoZYYi5hxBgmpEI10Tp9oZxzzjkAHI6Os9rXxuHo\nBCLC2WefXWHLKoN1R73U72XnSND27TVKRVdXF09PzQRzxqaqIxUXcgiHiHiBPwVOAXYAX1dKFdYn\nOg8i8k7gM8AZwPlKqW1Zjnsb8GXAAfybUuqfinH+UmEYRl0Vc+Xi9a9/PR63h77EEZaYSzjiOILT\n6azpeRPZ6Orqoruzi6PRtMdxNDrJ6lWrqj79erFY8ygOTobnbNcbXV1dhKIponGF1y3TYatqENJc\noaofAJtIi8YVwL8U8bw7gT8Cfp3tABFxAF/LnPtM4DoROTPb8Rp74fP52HTeJgZdxwAYdB3jta99\nbd1eLE8743QGEulkgYHEFKedfnqe36hdrBqFvkAUl9NJU1P2JpC1jOVZjGW8Duu5GkJVuYTjTKXU\ne5RS3wKuBd5YrJMqpV5WSr2a57Dzgb1Kqf1KqThwL3BNsWzQlJ5NmzYRIEBAJplggvPOO7Hter2w\nfv16hmMhQqk4E/FwzbdQz0VraysA4WSKlpaWqmmrU2wsz8IKUVnzOard45jOKy1WiGqBLANmz9/s\ny7w2LyJyi4hsE5Fts9cYNJXDiu3vzkwItLbrkdWrV2Mqk1dCQ0D99Waajdvtxpspem1trf0i0GxY\nAjGREYyxKROv11MVXnmuxfGNImIN5hbAl9kWQCmVuwWqiDwKzFfJ8rdKqaLPLFdKfRv4NsCmTZuK\nN85Ps2isUaCHnAcBOPXUUytoTWVZmamO3h1K13PUci1PIfj9fqKxGM3N9Ssc1tqO5XFMhEw62tur\nwgPLNcjppAoOlFKXnczvA0eB2d+u5ZnXNFVCU1MTXR1dDI8O09LcOh2iqEesFOT94dE52/VKU1MT\nwyMjNNVhAaRFS0sLDsNgIpxe2xifMunosH+YCuzd5fYZYL2IrBERN/Bu4MEK26RZIKvWpLuhrlpd\nf/2IZtPW1obL6SSQitHs99dku5mFYFXMV0NYplQYhkFbW+v02sZEWNFeJRlmhbRVLzoi8ofAV4Eu\n4Bcisl0p9VYRWUo67fZKpVQy01TxYdLpuN9VSu2qhL2axfOJT3yC559/no0bN1balIpiZDqeDg4N\n0dVp/zz9UuNraACgIfNcr7R3dBAIp6sAJ8OqalKTKyIcSqmfAT+b5/V+4MpZ21uBrWU0TVNkVq1a\nNT2Dod7p6OhkcGiIjq7qCEeUEksw6t3zam/vYOzwQVKmIhBOVk04186hKo2mpmhrbwOomotDKbFG\nCdS7cLS2thKIQCiqUCod0qwGtHBoNGXC6ghcjx1xj8dq9llvA5yOp62tjcmwOT1CtlpuKrRwaDRl\nwloIrtdK6dlYExHrafrhfLS0tBCJpaYXyLVwaDSaOVh311o4mK5VcLlcFbakslhTMPvH0zXWWjg0\nGs28OJ0VyUmxFZbHUe+hKks4jo2nazmqZcCZFg6NpsxUQ2VwuTCM+r4EWetdWjg0Gs28bNq0Cbfb\nzel13BnXQotnGksohgIpRKRqCiK1z6zRlIk3velNPPXUU5U2w1bUu4BY611DEykaG3xV44FVh5Ua\njaYmsdY66hVLOAIRRVNTdXgboIVDo9FUkHr3OGaHphobqyfbTguHRqOpGPXucXi9XgwjLZ5aODQa\njaYA6t3jEBEaMm1XfFXU8FELh0ajqRj17nEA+Hzp6vlq6hSshUOj0VSMevc4ALzejMdRRQ0ftXBo\nNJqKoT2OmRCVFg6NRqPJgSUY1VK3UEq8nnSoymo1Xw3o/zWNRlMxtMcBHq8WDo1Go8mL9jRmsBo9\nauHQaDSaHFx33XWcun49F1xwQaVNqTiW11VNwqF7VWk0mrJz+umnc8+991baDFtQjbNJtMeh0Wg0\nNqCaZpNo4dBoNJoKsmrVKgA6OjoqbEnhSC1mNWzatElt27at0mZoNBpNXpLJJAMDAyxfvryiBZEi\n8qxSalMhx+o1Do1Go6kgTqeTFStWVNqMBVGRUJWIvFNEdomIKSL/f3t3G2NHVcdx/PuDAm0UfKwK\nLeUhNmg1oSRmJeILRCy1Eg0mJm0iJkZttDVBMVGM8emFL0ADRGOwa30IsWpQiyi+gFY3MRqrtnVZ\nW4oJGog04irQAMYoLT9fzFnvFHfrnfbunrvs75Nsdmbu7Mx/T/be/54zM/8zY4aT9ICk30sal5Qu\nRETEEKjV49gHvB3Y0se+b7D991mOJyIi+lQlcdg+AClwFhExHw37XVUGdkraI2lj7WAiImIWexyS\ndgIvm+alT9i+o8/DvN72QUkvAXZIus/2z2c430ZgI8CKFSuOK+aIiPj/Zi1x2L58AMc4WL5PSrod\nGAGmTRy2R4FRaG7HPdFzR0TE9IZ2qErScySdPrUMrKG5qB4RERVVeQBQ0lXAl4ClwCFg3PYVks4C\nttpeJ+l84PbyI4uAb9v+XJ/H/xvw4CyE3sWLgdwN1khb9KQtetIWPcPQFufYXtrPjs/KJ8eHgaTd\n/T6F+WyXtuhJW/SkLXrmW1sM7VBVREQMpySOiIjoJIlj9ozWDmCIpC160hY9aYueedUWucYRERGd\npMcRERGdJHFEREQnSRwDJmmtpD9Iul/SdbXjqUnS1yVNSlrwD25KOlvSmKR7y5QC19SOqQZJiyX9\nRtI9pR0+Wzum2iSdLOl3ku6sHUu/kjgGSNLJwJeBNwOrgA2SVtWNqqpvAmtrBzEkDgMfsb0KuBjY\nvED/Nv4FXGb7QmA1sFbSxZVjqu0a4EDtILpI4hisEeB+23+y/W/gu8DbKsdUTSlI+WjtOIaB7b/Y\n3luWn6D5oFhWN6q558aTZfWU8rVg79CRtBx4C7C1dixdJHEM1jLgz631h1iAHw5xbJLOBS4Cfl03\nkjrK0Mw4MAnssL0g26G4Gfgo8HTtQLpI4oiYQ5KeC/wA+JDtx2vHU4PtI7ZXA8uBEUmvrh1TDZKu\nBCZt76kdS1dJHIN1EGjPOr+8bItA0ik0SWOb7e2146nN9iFgjIV7HewS4K2SHqAZ1r5M0rfqhtSf\nJI7B+i2wUtJ5kk4F1gM/qhxTDAE18yR/DThg+8ba8dQiaamk55flJcCbgPvqRlWH7Y/bXm77XJrP\nip/ZfmflsPqSxDFAtg8DHwTuorn4eZvt/XWjqkfSd4BfARdIekjSe2rHVNElwNU0/1WOl691tYOq\n4ExgTNIEzT9aO2zPm9tQo5GSIxER0Ul6HBER0UkSR0REdJLEERERnSRxREREJ0kcERHRSRJHLDiS\nXtS6JfZhSQdb66fOwfl/IWn1bJ8nYrYsqh1AxFyz/QhNZVYkfQZ40vYX2vuUB/Zke17VEIqYC+lx\nRBSSXl7my9gG7AfOlnSo9fp6SVvL8kslbZe0u8wv8T+lwSUtknSTpH2SJiRtmmaf0XKM/ZI+1dr+\n+RLLhKTrW+ffV+ayGGud48YSw4Sk95bty0rPZrz8zOsG3V6xcKXHEXG0VwDvsr1b0rHeH18EbrC9\nq1S7vRN4ZrG+DwBnARfaPiLphdMc5zrbj5ZzjUn6PvAIsA54lW1PlegAPg1cavuvrW0baQrljUg6\nDdgl6W5gA/Bj29eXeWKWdGyHiBklcUQc7Y+2d/ex3+U0pVSm1l8gaYntfz5jn5ttHwGwPd3cJBtK\nKZZFNElmFXAHTZntr0r6CU1SAvglcKuk7wFTRRLXAK+UtL6sPw9YSVPOY4ukxcAPbd/Tx+8U0Zck\njoij/aO1/DSg1vri1rKAkTJh13GRtJJm9rcR24dKZdTFtp+S9BqaAoDvoOm5rAHeB7wWuBLYK+mi\nEscm2z+d5viX0kwSdKukG2xvO95YI9pyjSNiBuXC+GOSVko6Cbiq9fJOYPPUygx3Se0A3l+Giphm\nqOoM4AngcUlnAleU/U4HzijF/z5MM+kTwPm2dwGfBB6jmSTsLmDT1LCapAskLZF0DvCw7VHgG61j\nRJyw9Dgiju1jNB/Ok8Ae4LSyfTNwi6R307yPxmglkmILzbDRhKTDwC3AV1qv7wXupSkr/iDNUBQ0\nw03byzWLk4Bry/abJJ1H08u42/Y+SQeAFcB4GTabpJmu+I3AtZKeoklOV59gO0T8V6rjRkREJxmq\nioiITpI4IiKikySOiIjoJIkjIiI6SeKIiIhOkjgiIqKTJI6IiOjkP2tfRi/Mf+jSAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13da302b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_classes = y_cat_test.values.argmax(axis=1)\n",
    "ax_zillow = sns.violinplot(x=true_classes, y=df_metrics_z['top_vs_mean_low'], palette=\"plasma\")\n",
    "ax_zillow.set_title('Zillow')\n",
    "ax_zillow.set(xlabel='True classes', ylabel='Positive prediction difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1d37ee240>, <matplotlib.text.Text at 0x1d6dfb080>]"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d6def278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_zillow_kde = sns.kdeplot(df_metrics_z['gain_true'], df_metrics_z['top_vs_mean_low'], n_levels=90, cmap=\"Purples_d\")\n",
    "ax_zillow_kde.set_title('Zillow')\n",
    "ax_zillow_kde.set(xlabel='Loss vs Gain', ylabel='Positive prediction difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_features_2 = pd.read_csv('real_business_features_3_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 150)]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAELCAYAAADtIjDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209a4eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_tot = sns.barplot(business_features_2['postal_code'], business_features_2['review_count'])\n",
    "ax_tot.set(ylim=(0, 150))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
